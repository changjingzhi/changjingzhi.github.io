

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="chenli">
  <meta name="keywords" content="">
  
    <meta name="description" content="为什么要系统的学习，因为网络上的博客大多是散装的，不系统，一个名词解释一大堆不同的解释。 人生中充满选择，每次选择就是一次决策，我们正是从一次次决策中，把自己带领到人生的下一段旅程中。在回忆往事时，我们会对生命中某些时刻的决策印象深刻。 什么是强化学习 题目 关于强化学习描述错误的是： C  A. 强化学习的目标是最大化累计奖励。B. 强化学习在某种程度上感知环境的状态。C. 强化学习属于无监督学">
<meta property="og:type" content="article">
<meta property="og:title" content="填坑——强化学习复习">
<meta property="og:url" content="https://chenlidbk.xyz/2024/06/09/tiankeng12-qhxxfx/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="为什么要系统的学习，因为网络上的博客大多是散装的，不系统，一个名词解释一大堆不同的解释。 人生中充满选择，每次选择就是一次决策，我们正是从一次次决策中，把自己带领到人生的下一段旅程中。在回忆往事时，我们会对生命中某些时刻的决策印象深刻。 什么是强化学习 题目 关于强化学习描述错误的是： C  A. 强化学习的目标是最大化累计奖励。B. 强化学习在某种程度上感知环境的状态。C. 强化学习属于无监督学">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://chenlidbk.xyz/pic/tk-qhxxfx.png">
<meta property="article:published_time" content="2024-06-09T09:50:57.000Z">
<meta property="article:modified_time" content="2024-06-09T11:23:05.833Z">
<meta property="article:author" content="chenli">
<meta property="article:tag" content="填坑">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://chenlidbk.xyz/pic/tk-qhxxfx.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>填坑——强化学习复习 - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"chenlidbk.xyz","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  
    <!-- Google tag (gtag.js) -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=", function() {
          window.dataLayer = window.dataLayer || [];
          function gtag() {
            dataLayer.push(arguments);
          }
          gtag('js', new Date());
          gtag('config', '');
        });
      }
    </script>
  

  

  

  

  



  
<meta name="generator" content="Hexo 7.1.1"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>chenli</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="填坑——强化学习复习"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-06-09 17:50" pubdate>
          2024年6月9日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          3.6k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          31 分钟
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">填坑——强化学习复习</h1>
            
            
              <div class="markdown-body">
                
                <p>为什么要系统的学习，因为网络上的博客大多是散装的，不系统，一个名词解释一大堆不同的解释。</p>
<p>人生中充满选择，每次选择就是一次决策，我们正是从一次次决策中，把自己带领到人生的下一段旅程中。在回忆往事时，我们会对生命中某些时刻的决策印象深刻。</p>
<p>什么是强化学习</p>
<h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><ol>
<li>关于强化学习描述错误的是： C</li>
</ol>
<p>A. 强化学习的目标是最大化累计奖励。<br>B. 强化学习在某种程度上感知环境的状态。<br>C. 强化学习属于无监督学习。<br>D. 强化学习通过从交互中学习来实现目标。</p>
<p>强化学习的基本概念：agent：智能体。 enviroment： 环境. goal : 目标.  state： 状态. action： 行动. reward ： 奖励.<br>第一层：  agent：执行动作的主体。 environment：强化学习所处的环境。 goal：强化学习的目标。 强化学习是agent在与环境的互动过程中为了达成一个目标而进行的学习过程。</p>
<p>第二层：  state：当前agent的状态。 action：执行的动作&#x2F;行为。 reward：执行动作得到的实时的奖励。 state和action的循环往复过程构成了强化学习的主体部分。<br>需要注意的是：reward与 goal不是同一个概念，reward是执行某一个动作之后得到的实时的奖励，goal是强化学习最终的目标（一般来说使reward之和最大），但goal决定了reward。</p>
<p>第三层： 也是核心元素，包括两个函数，价值函数（Value function)和策略函数(Policy function）。</p>
<p>价值函数： Value function： 价值函数分为两种，一种是V状态价值函数（state value function),一种是Q状态行动函数（state action value function)。Q值评估的是动作的价值，代表agent做了这个动作之后一直到最终状态奖励总和的期望值；V值评估的是状态的价值，代表agent在这个状态下一直到最终状态的奖励总和的期望。价值越高，表示我从当前状态到最终状态能获得的平均奖励将会越高，因此我选择价值高的动作就可以了。   通常情况下来说，状态价值函数V是针对特定策略定义的，因为计算奖励的期望值取决于选取各个action的概率。状态行动函数V表面上与策略policy没什么关系，他取决于状态转移概率，但在强化学习中状态转移函数一般不变。要注意，Q值和V值之间可以互相转化。</p>
<p>策略函数：  Policy决定了某个state下应该选取哪一个action，也就是说，状态时Policy的输入，action是Policy的输出。策略Policy为每一个动作分配概率，例如：π(s1|a1) &#x3D; 0.3，说明在状态s1下选择动作a1的概率是0.3,而该策略只依赖于当前的状态，不依赖于以前时间的状态，因此整个过程也是一个马尔可夫决策过程。强化学习的核心和训练目标就是要选择一个合适的Policy&#x2F;,使得reward之和最大。</p>
<p><img src="/pic/tk-qhxxfx.png" srcset="/img/loading.gif" lazyload>    </p>
<ol start="2">
<li>在强化学习中，智能体与环境交互产生的数据分布称为什么？ （C）</li>
</ol>
<p>A. 策略函数<br>B. 状态转移<br>C. 占用度量<br>D. 奖励信号</p>
<p>占用度量是强化学习中智能体与环境交互产生的数据分布的术语。<br>强化学习中有一个关于数据分布的概念，叫作占用度量（occupancy measure），归一化的占用度量用于衡量在一个智能体决策与一个动态环境的交互过程中，采样到一个具体的状态动作对（state-action pair）的概率分布。</p>
<p>根据占用度量这一重要的性质，我们可以领悟到强化学习本质的思维方式。</p>
<p>强化学习的策略在训练中会不断更新，其对应的数据分布（即占用度量）也会相应地改变。因此，强化学习的一大难点就在于，智能体看到的数据分布是随着智能体的学习而不断发生改变的。</p>
<p>由于奖励建立在状态动作对之上，一个策略对应的价值其实就是一个占用度量下对应的奖励的期望，因此寻找最优策略对应着寻找最优占用度量。</p>
<p>占用度量有一个很重要的性质：给定两个策略及其与一个动态环境交互得到的两个占用度量，那么当且仅当这两个占用度量相同时，这两个策略相同。也就是说，如果一个智能体的策略有所改变，那么它和环境交互得到的占用度量也会相应改变。<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/660569825">详细解释</a></p>
<ol start="3">
<li>强化学习的目标是什么？ (B)</li>
</ol>
<p>A. 最小化累积奖励<br>B. 最大化累积奖励<br>C. 保持奖励不变<br>D. 随机选择奖励</p>
<p>强化学习的目标是最大化累积奖励，即智能体在多轮交互过程中获得的总奖励的期望值，将goal获取最高的值，而对于单轮的reward可以不一定是最优良的。</p>
<ol start="4">
<li>下列哪项不是强化学习中的智能体关键要素 （A）</li>
</ol>
<p>A. 惩罚<br>B. 奖励<br>C. 感知<br>D. 决策</p>
<p>强化学习中的智能体关键要素包括感知、决策和奖励，不包括惩罚。</p>
<p>感知。智能体在某种程度上感知环境的状态，从而知道自己所处的现状。例如，下围棋的智能体感知当前的棋盘情况；无人车感知周围道路的车辆、行人和红绿灯等情况；机器狗通过摄像头感知面前的图像，通过脚底的力学传感器来感知地面的摩擦功率和倾斜度等情况。</p>
<p>智能体根据当前的状态计算出达到目标需要采取的动作的过程叫作决策。例如，针对当前的棋盘决定下一颗落子的位置；针对当前的路况，无人车计算出方向盘的角度和刹车、油门的力度；针对当前收集到的视觉和力觉信号，机器狗给出4条腿的齿轮的角速度。策略是智能体最终体现出的智能形式，是不同智能体之间的核心区别。</p>
<p>奖励。环境根据状态和智能体采取的动作，产生一个标量信号作为奖励反馈。这个标量信号衡量智能体这一轮动作的好坏。例如，围棋博弈是否胜利；无人车是否安全、平稳且快速地行驶；机器狗是否在前进而没有摔倒。最大化累积奖励期望是智能体提升策略的目标，也是衡量智能体策略好坏的关键指标。</p>
<ol start="5">
<li>以下关于策略的说法哪个是正确的？ （A）</li>
</ol>
<p>A. 以上都是</p>
<p>B. 策略分为确定策略和随机性策略</p>
<p>C. 策略是状态到行为的映射</p>
<p>D. 随机性策略是状态s下产生的行为的概率分布</p>
<ol start="6">
<li>在强化学习中，智能体的策略更新对以下哪些方面有直接影响？ （A，C,E）</li>
</ol>
<p>A. 累积奖励<br>B. 状态转移概率<br>C. 与环境交互产生的数据分布<br>D. 智能体的感知能力<br>E. 占用度量</p>
<p>智能体的策略更新会影响其与环境交互产生的数据分布，占用度量，以及累积奖励。状态转移概率通常由环境本身决定，而智能体的感知能力是由其设计决定的。</p>
<p>为什么不会影响状态转移概率？<br>主要是因为状态转移概率是由环境的动态决定的，而不是由智能体的策略直接决定的。</p>
<p>在马尔可夫决策过程（MDP）中，状态转移概率 ( P(s’|s, a) ) 表示在状态 ( s ) 下采取行动 ( a ) 后转移到状态 ( s’ ) 的概率。这一概率描述了环境在特定状态和行动下的动态行为。</p>
<ol start="7">
<li>下列哪些描述正确地解释了强化学习中的奖励信号？（B、D、E）<br>A. 奖励信号是智能体做出决策时的输入<br>B. 奖励信号是环境根据状态和动作产生的标量信号<br>C. 奖励信号与智能体的累积奖励无关<br>D. 奖励信号是智能体策略优化的目标<br>E. 奖励信号衡量智能体动作的好坏</li>
</ol>
<p>A、奖励reward是一个单一数值，即标量； B、奖励reward是衡量当前动作的好坏的一个标准   C、错。因为智能体做决策的输入是状态state，奖励是环境的输出   D、智能体的策略是获得更大的奖励，所以是它优化的目标   E、。因为累积奖励来自于单个奖励，二者是有强相关的。</p>
<ol start="8">
<li><p>强化学习中，智能体与环境交互涉及哪些关键要素？（A、C、E）<br>A. 奖励<br>B. 惩罚<br>C. 决策<br>D. 动作<br>E. 感知</p>
</li>
<li><p>对于ϵ-greedy策略探索方式，更高的ϵ 优于更低ϵ，更能让算法获得的最终奖励值。 B错<br>A. 对<br>B. 错</p>
</li>
</ol>
<p>ϵ的值只会决定策略的收敛快慢，对于最终的收敛结果并没有一定的强相关联系。</p>
<ol start="10">
<li>在强化学习中，智能体的策略改变会导致其与环境交互产生的数据分布发生改变。A对<br>A. 对<br>B. 错</li>
</ol>
<p>智能体的策略改变会影响其与环境交互的方式，因此产生的数据分布也会发生相应的改变。</p>
<ol start="11">
<li>强化学习中的智能体只需要考虑当前的奖励，而不需要考虑未来的状态变化。 B错<br>A. 对<br>B. 错</li>
</ol>
<p>强化学习中的智能体不仅要考虑当前的奖励，还需要考虑未来的状态变化和累积奖励。、</p>
<ol start="12">
<li>强化学习的数据分布是固定不变的，与智能体的策略无关。 B错<br>A. 对<br>B. 错</li>
</ol>
<p>强化学习中的数据分布是随着智能体策略的不同而变化的，因为智能体的决策会影响其与环境交互产生的数据。</p>
<ol start="13">
<li><p>机器学习可以分为预测型和决策性，有监督学习和无监督学习属于预测型，强化学习属于决策型。 A对<br>A. 对<br>B. 错</p>
</li>
<li><p>基于模型的强化学习和模型无关的强化学习的根本区别在于学习过程中有没有__（环境）__模型。</p>
</li>
</ol>
<p>基于模型的强化学习 (Model-based Reinforcement Learning)</p>
<p><strong>定义：</strong><br>基于模型的强化学习方法利用一个环境的模型来进行学习和决策。这个模型描述了环境的动态，包括状态转移概率和奖励函数。</p>
<p><strong>主要特点：</strong></p>
<ol>
<li><strong>环境模型：</strong> 需要构建或学习一个模型来估计状态转移概率 (P(s’|s, a)) 和奖励函数 (R(s, a))。</li>
<li><strong>规划：</strong> 使用环境模型来模拟和规划未来的决策，通过预测不同动作的结果来选择最优动作。这通常包括算法如动态规划（Dynamic Programming）和蒙特卡罗树搜索（Monte Carlo Tree Search）。</li>
<li><strong>效率：</strong> 可以通过利用模型进行规划和模拟来提高数据效率，减少对实际环境交互的需求。</li>
</ol>
<p><strong>优点：</strong></p>
<ul>
<li>能够通过模拟来减少实际环境中的试验和错误，尤其在实际交互代价高昂或危险的情况下。</li>
<li>更高的数据效率，因为模型能够提供额外的训练数据。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>构建准确的环境模型可能很困难，尤其在复杂或不确定的环境中。</li>
<li>如果模型不准确，可能会导致次优甚至错误的决策。</li>
</ul>
<p>模型无关的强化学习 (Model-free Reinforcement Learning)</p>
<p><strong>定义：</strong><br>模型无关的强化学习方法不使用环境的模型，而是直接从与环境的交互中学习最佳策略。</p>
<p><strong>主要特点：</strong></p>
<ol>
<li><strong>直接学习：</strong> 通过与环境的直接交互，利用奖励信号来学习最优策略或最优值函数。这包括方法如值函数逼近（如Q学习和SARSA）和策略优化（如策略梯度和近端策略优化PPO）。</li>
<li><strong>无模型：</strong> 不需要了解或学习环境的状态转移概率和奖励函数，直接从经验中学习。</li>
</ol>
<p><strong>优点：</strong></p>
<ul>
<li>更加简单，不需要额外的建模步骤。</li>
<li>在高度复杂或不确定的环境中更为实用，因为无需准确建模环境。</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>数据效率较低，需要大量的环境交互来学习有效的策略。</li>
<li>训练过程可能较长，尤其在大型或连续状态空间中。</li>
</ul>
<ol start="15">
<li>在多臂老虎机问题中，ε-贪心算法在每一步选择动作时，以概率__ε___进行探索，以概率___1-ε___进行利用。</li>
</ol>
<p>ε-贪心算法在每一时刻采取动作时，以概率ε随机选择一根拉杆进行探索，以概率1-ε选择以往经验中期望奖励估值最大的那根拉杆进行利用。这种策略平衡了探索新选项与利用已知最佳选项之间的关系。</p>
<ol start="16">
<li>强化学习中的价值（value）是指智能体在与环境交互过程中获得的________的期望。 （整体回报;总体回报;折扣回报）</li>
</ol>
<p>在强化学习中，价值是指智能体在与环境交互过程中每一轮获得的奖励信号累加形成的总回报的期望，有时会对未来回报进行打折，此时整体回报变为折扣回报。</p>
<ol start="17">
<li>ε-贪心算法中，ε值随时间________，以平衡探索与利用。 （衰减;减小;变小）</li>
</ol>
<p>ε-贪心算法中，ε值（探索概率）随时间衰减，以逐渐从探索转向利用。</p>
<ol start="18">
<li>价值函数是用于评估给定策略下_______的好坏。 （状态;state）</li>
</ol>
<p>般不特别说明时，价值函数指V(s)，所以它是评估状态s的好坏的尺度。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E5%A1%AB%E5%9D%91/" class="print-no-link">#填坑</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>填坑——强化学习复习</div>
      <div>https://chenlidbk.xyz/2024/06/09/tiankeng12-qhxxfx/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>chenli</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年6月9日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/06/09/gaodengshuxue6/" title="高等数学 —— 傅里叶变换">
                        <span class="hidden-mobile">高等数学 —— 傅里叶变换</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/changjingzhi/Blog/tree/main" target="_blank" rel="nofollow noopener"><span>联系方式</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
