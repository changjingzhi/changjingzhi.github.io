<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>高等数学 —— 傅里叶变换</title>
    <link href="/2024/06/09/gaodengshuxue6/"/>
    <url>/2024/06/09/gaodengshuxue6/</url>
    
    <content type="html"><![CDATA[<h2 id="傅里叶变换解决的问题"><a href="#傅里叶变换解决的问题" class="headerlink" title="傅里叶变换解决的问题"></a>傅里叶变换解决的问题</h2><h2 id="傅里叶变换"><a href="#傅里叶变换" class="headerlink" title="傅里叶变换"></a>傅里叶变换</h2><ol><li>傅里叶级数： 周期性的函数f(t) 都考研变换维一系列的正（余）弦函数的组合。</li></ol><p>时域 ——傅里叶变换—— 频率，相位，增幅。<br>连续的</p><p><img src="/pic/gdsx-flybh.png"><br>2. 傅里叶变换 （非连续）<br>欧拉公式</p><ol start="3"><li>应用： 声音的处理 ，图像的处理</li></ol><p><img src="/pic/gdsx-flybh2.png"></p>]]></content>
    
    
    
    <tags>
      
      <tag>高等数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>英语-单词7</title>
    <link href="/2024/06/09/English2-7/"/>
    <url>/2024/06/09/English2-7/</url>
    
    <content type="html"><![CDATA[<ol><li></li></ol><ul><li><p>Despite her numerous complaints about the long hours and heavy workload, she stayed late into the evening to finish the project. (Complaint: 抱怨; Evening: 晚上)<br>尽管她对长时间工作和繁重工作量有很多抱怨，但她还是在晚上加班完成了项目。</p></li><li><p>The carpenter spent the entire day carving intricate designs into the piece of wood, transforming it into a work of art. (Wood: 木材)<br>木匠花了一整天时间在这块木材上雕刻复杂的图案，把它变成了一件艺术品。</p></li><li><p>The cozy rug in the living room added a touch of warmth and comfort to the otherwise minimalistic decor. (Rug: 小地毯)<br>客厅里舒适的小地毯为原本极简的装饰增添了一丝温暖和舒适。</p></li><li><p>Her analysis of the data revealed an unexpected bias in the survey results, prompting a revision of the methodology. (Bias: 偏见)<br>她对数据的分析揭示了调查结果中意外的偏见，促使她修订了方法论。</p></li><li><p>The adventurous couple decided to venture into the dense forest, hoping to discover hidden waterfalls and rare wildlife. (Venture: 冒险)<br>这对冒险的情侣决定进入茂密的森林，希望能发现隐藏的瀑布和稀有的野生动物。</p></li><li><p>The dynamic nature of the market requires businesses to continuously adapt and innovate to stay competitive. (Dynamic: 动态的)<br>市场的动态性质要求企业不断适应和创新以保持竞争力。</p></li><li><p>They followed the narrow trail up the mountain, taking in the stunning views and fresh air along the way. (Trail: 小径)<br>他们沿着狭窄的小径上山，沿途欣赏着美丽的风景和新鲜的空气。</p></li><li><p>She wore her hair loose, letting it cascade down her shoulders in soft waves. (Loose: 松散的)<br>她把头发披散开来，让它柔软的波浪状垂在肩上。</p></li><li><p>The storm was so powerful that it completely destroyed the small village, leaving nothing but rubble in its wake. (Destroy: 破坏)<br>风暴威力如此强大，以至于完全摧毁了这个小村庄，只留下瓦砾。</p></li><li><p>In the face of such a massive workload, he found it difficult to cope and often felt overwhelmed. (Cope: 应对)<br>面对如此繁重的工作量，他发现很难应对，经常感到不知所措。</p></li><li><p>Without adequate food and shelter, many of the early settlers perished during the harsh winter. (Perish: 死亡)<br>在没有足够食物和住所的情况下，许多早期定居者在严酷的冬季中死亡。</p></li></ul><ol start="2"><li></li></ol><ul><li><p>He filled the pail with fresh water from the well, ready to carry it back to the house. (Pail: 桶)<br>他用桶从井里打上新鲜的水，准备把它带回家。</p></li><li><p>The parasite slowly weakened its host, draining nutrients and causing illness over time. (Parasite: 寄生虫)<br>寄生虫慢慢地削弱了它的宿主，随着时间的推移吸取营养并导致疾病。</p></li><li><p>The ship’s anchor was dropped into the sea to keep it steady during the storm. (Anchor: 锚)<br>为了在风暴中保持稳定，船的锚被放入海中。</p></li><li><p>The teacher used a visual aid to help divide the class into smaller groups for the project. (Divide: 分开)<br>老师使用视觉辅助工具帮助将班级分成小组进行项目。</p></li><li><p>Her artistic talent was evident in the beautifully painted murals that adorned the walls of the community center. (Artistic: 艺术的)<br>她的艺术才能在社区中心墙壁上装饰的美丽壁画中显而易见。</p></li><li><p>They planned to travel across Europe, visiting historic sites and experiencing diverse cultures. (Travel: 旅行)<br>他们计划旅行穿越欧洲，参观历史遗址并体验多样的文化。</p></li><li><p>As the steward of the estate, he was responsible for managing the property and ensuring everything ran smoothly. (Steward: 管家)<br>作为庄园的管家，他负责管理财产并确保一切顺利进行。</p></li><li><p>The discoveries of the past century have significantly advanced mankind’s understanding of the universe. (Mankind: 人类)<br>过去一个世纪的发现极大地推进了人类对宇宙的理解。</p></li><li><p>The fruit left in the bowl began to rot, emitting an unpleasant odor throughout the kitchen. (Rot: 腐烂)<br>碗里的水果开始腐烂，散发出令人不快的气味。</p></li><li><p>The intricate design of the ancient artifact never failed to impress historians and archaeologists alike. (Impress: 给…留下深刻印象)<br>古代文物的复杂设计从未让历史学家和考古学家失望。</p></li><li><p>The prolonged drought devastated the region, leaving crops withered and water sources depleted. (Drought: 干旱)<br>长期的干旱使该地区遭受重创，作物枯萎，水源枯竭。</p></li><li><p>The city has implemented strict measures to reduce pollution and improve air quality. (Pollution: 污染)<br>这座城市采取了严格措施减少污染和改善空气质量。</p></li><li><p>They chose a bright blue tile to decorate the kitchen backsplash, adding a pop of color to the space. (Tile: 瓷砖)<br>他们选择了亮蓝色的瓷砖来装饰厨房的防溅板，为空间增添了一抹色彩。</p></li><li><p>His niece loved to visit him on weekends, often spending hours playing in his garden. (Niece: 侄女)<br>他的侄女喜欢在周末来看他，经常在他的花园里玩上好几个小时。</p></li></ul><ol start="3"><li></li></ol><ul><li><p>The runners were ready to go as soon as the starting signal was given. (Go: 去)<br>起跑信号一发出，跑步者们就准备出发了。</p></li><li><p>The explorer wore a thick cape to protect himself from the harsh winds of the mountain. (Cape: 披风)<br>探险者穿了一件厚披风来保护自己免受山上强风的侵袭。</p></li><li><p>The application for the scholarship required several essays and letters of recommendation. (Application: 申请)<br>申请奖学金需要提交几篇文章和推荐信。</p></li><li><p>They roasted a turkey for Thanksgiving, filling the house with a delicious aroma. (Turkey: 火鸡)<br>他们为感恩节烤了一只火鸡，整个房子弥漫着美味的香气。</p></li><li><p>She preferred living downtown because of the vibrant nightlife and convenient access to shops. (Downtown: 市中心)<br>她喜欢住在市中心，因为那里夜生活丰富多彩，而且购物便利。</p></li><li><p>He forgot to lock the door, leaving the house vulnerable to intruders. (Lock: 锁)<br>他忘了锁门，使房子容易受到入侵者的侵害。</p></li><li><p>His poor eyesight made it difficult for him to read small print without glasses. (Eyesight: 视力)<br>他的视力很差，不戴眼镜很难阅读小字。</p></li><li><p>The machine’s complicated mechanism required an expert to repair it. (Complicated: 复杂的)<br>这台机器的复杂机制需要专家来修理。</p></li><li><p>The condition of the patient improved significantly after receiving the new treatment. (Condition: 状况)<br>患者在接受新治疗后，病情显著改善。</p></li><li><p>She didn’t possess the necessary qualifications for the job, so she decided to pursue further education. (Possess: 拥有)<br>她没有这个工作的必要资格，所以她决定继续深造。</p></li><li><p>They expect to complete the project by the end of the month, assuming no unexpected delays occur. (Expect: 期望)<br>他们预计在月底前完成这个项目，假设没有发生意外的延误。</p></li><li><p>The baby began to crawl across the floor, exploring the new environment. (Crawl: 爬行)<br>婴儿开始在地板上爬行，探索新的环境。</p></li><li><p>The translation of the ancient text revealed many insights about the culture of that time. (Translation: 翻译)<br>古代文本的翻译揭示了许多关于当时文化的见解。</p></li><li><p>Regular exercise is crucial for maintaining good physical health and preventing diseases. (Physical: 身体的)<br>定期锻炼对保持良好的身体健康和预防疾病至关重要。</p></li></ul><ol start="4"><li></li></ol><ul><li><p>Long-term exposure to harmful chemicals can have detrimental effects on one’s health, leading to chronic diseases and other severe medical conditions. (Exposure: 暴露)<br>长期暴露于有害化学物质中可能对健康造成不利影响，导致慢性疾病和其他严重的医疗状况。</p></li><li><p>The wind howled through the narrow mountain pass, making it difficult for the hikers to maintain their balance. (Wind: 风)<br>狭窄的山口刮过狂风，使徒步旅行者难以保持平衡。</p></li><li><p>He gave the pipe a gentle tap to see if it was clogged with debris, hoping to restore the water flow. (Tap: 轻敲)<br>他轻轻敲了敲管子，看看是否被杂物堵塞，希望能恢复水流。</p></li><li><p>The city council decided to permit the construction of the new park, recognizing its potential benefits for the community. (Permit: 允许)<br>市议会决定允许新公园的建设，认识到它对社区的潜在好处。</p></li><li><p>The night was so black that it was impossible to see anything without a flashlight, enveloping everything in darkness. (Black: 黑色的)<br>夜晚漆黑一片，没有手电筒根本看不见任何东西，黑暗笼罩了一切。</p></li><li><p>The CEO’s decision to dicate the company’s future direction without consulting other executives led to widespread dissatisfaction among the staff. (Dicate: 指挥)<br>CEO在没有咨询其他高管的情况下指挥公司未来的发展方向，导致员工普遍不满。</p></li><li><p>Although he was a dwarf in stature, his achievements in the field of science were colossal and widely respected. (Dwarf: 矮子)<br>尽管他身材矮小，但他在科学领域的成就是巨大的，受到广泛尊敬。</p></li><li><p>The study revealed that certain genetic mutations can increase the risk of developing hereditary diseases, underscoring the importance of genetic screening. (Genetic: 基因的)<br>研究表明，某些基因突变可以增加遗传性疾病的风险，这突显了基因筛查的重要性。</p></li><li><p>She wore a belt around her waist to accentuate her figure, adding a touch of style to her outfit. (Waist: 腰)<br>她在腰间系了一条腰带以突显她的身材，为她的装束增添了一丝风格。</p></li><li><p>Scientists have discovered that the molecule plays a crucial role in cellular processes, influencing how cells grow and divide. (Molecule: 分子)<br>科学家发现，这种分子在细胞过程中起着至关重要的作用，影响细胞的生长和分裂。</p></li><li><p>His selfless actions and unwavering dedication to helping others made him truly worthy of the community’s highest honor. (Worthy: 值得的)<br>他无私的行动和对帮助他人的坚定奉献使他真正值得社区最高的荣誉。</p></li><li><p>The town was known for its friendly atmosphere, where neighbors would often help each other and gather for community events. (Friendly: 友好的)<br>这个小镇以其友好的氛围而闻名，邻居们经常互相帮助并聚集参加社区活动。</p></li><li><p>The board meeting’s agenda was packed with critical topics that required thorough discussion and immediate decisions. (Agenda: 议程)<br>董事会会议的议程上挤满了需要彻底讨论和立即决策的重要议题。</p></li><li><p>The detective’s investigation uncovered the brutal truth behind the crime, revealing a level of cruelty that shocked even the most seasoned officers. (Brutal: 残忍的)<br>侦探的调查揭示了犯罪背后的残酷真相，揭示了一个即使是最有经验的警官也感到震惊的残忍程度。</p></li></ul><ol start="5"><li></li></ol><ul><li><p>The renowned author decided to publish his latest novel independently, believing in the power of self-publishing to reach a wider audience. (Publish: 出版)<br>著名作家决定自主出版他的最新小说，相信自出版能够吸引更广泛的读者群。</p></li><li><p>As a dedicated housewife, she managed the household with remarkable efficiency, ensuring everything was in order. (Housewife: 家庭主妇)<br>作为一个尽职的家庭主妇，她以非凡的效率管理家庭，确保一切井然有序。</p></li><li><p>Many believe that music can touch the soul, offering comfort and inspiration in times of need. (Soul: 灵魂)<br>许多人相信音乐可以触动灵魂，在需要的时候提供安慰和启示。</p></li><li><p>The committee agreed to discuss the proposal in detail, weighing its potential benefits and drawbacks. (Discuss: 讨论)<br>委员会同意详细讨论该提案，权衡其潜在的利弊。</p></li><li><p>Due to unforeseen circumstances, they had to cancel the event at the last minute, disappointing many attendees. (Cancel: 取消)<br>由于不可预见的情况，他们不得不在最后一刻取消活动，这让许多参加者感到失望。</p></li><li><p>The shepherd guided his flock of sheep through the lush pastures, ensuring they were well-fed and safe. (Sheep: 羊)<br>牧羊人带着他的羊群穿过茂盛的牧场，确保它们吃得饱又安全。</p></li><li><p>She pursued a degree in engineering, fascinated by the potential to design and build innovative structures. (Engineering: 工程学)<br>她攻读工程学学位，对设计和建造创新结构的潜力着迷。</p></li><li><p>The incident was unexpected and occurred so suddenly that no one had time to react properly. (Occur: 发生)<br>事件来得如此突然，没人有时间做出正确反应。</p></li><li><p>Efforts to revive the ancient tradition were met with enthusiasm, as the community sought to reconnect with their cultural heritage. (Revive: 复兴)<br>复兴古老传统的努力得到了热情的回应，因为社区希望重新与他们的文化遗产联系起来。</p></li><li><p>He tipped his hat in greeting, a gesture of respect and politeness from a bygone era. (Hat: 帽子)<br>他向人致意时轻轻抬起帽子，这是一种来自过去时代的尊敬和礼貌的姿态。</p></li><li><p>The students were nervous as they prepared to take the final test, knowing it would significantly impact their grades. (Test: 测试)<br>学生们准备参加期末测试时都很紧张，因为他们知道这将极大地影响他们的成绩。</p></li><li><p>The researchers decided to approach the problem from a different angle, hoping to find a more effective solution. (Approach: 方法)<br>研究人员决定从不同的角度解决问题，希望找到更有效的解决方案。</p></li><li><p>The region’s fertile soil made it ideal for agriculture, allowing farmers to grow a variety of crops. (Fertile: 肥沃的)<br>该地区肥沃的土壤非常适合农业，使农民能够种植各种作物。</p></li><li><p>Scientists have successfully created a clone of the endangered animal, aiming to preserve its genetic diversity. (Clone: 克隆)<br>科学家成功地克隆了濒危动物，旨在保护其基因多样性。</p></li><li><p>There was a striking resemblance between the twins, making it difficult for even close friends to tell them apart. (Resemblance: 相似)<br>这对双胞胎有着惊人的相似之处，即使是亲密的朋友也难以将他们区分开来。</p></li></ul><ol start="6"><li></li></ol><ul><li><p>The detective kept a close watch on the suspect until they made a move, ensuring not to lose sight of them. (Watch: 观察)<br>侦探密切关注嫌疑人，直到他们采取行动，确保不失踪。</p></li><li><p>We must wait until the meeting concludes before making any final decisions regarding the project. (Until: 直到)<br>我们必须等到会议结束后才能对项目做出任何最终决定。</p></li><li><p>Many people sympathize with the victims of natural disasters, often donating to aid relief efforts. (Sympathize: 同情)<br>许多人同情自然灾害的受害者，通常会捐款以帮助救援工作。</p></li><li><p>She took a deep breath, inhaling the fresh mountain air, and felt instantly rejuvenated. (Inhale: 吸入)<br>她深深吸了一口新鲜的山间空气，立刻感到焕然一新。</p></li><li><p>Every year, they give generously to various charities, believing in the importance of helping others. (Give: 捐赠)<br>每年，他们都会慷慨地向各种慈善机构捐款，相信帮助他人的重要性。</p></li><li><p>He visited the dental clinic regularly to ensure his teeth and gums remained healthy. (Dental: 牙科的)<br>他定期去牙科诊所，确保牙齿和牙龈保持健康。</p></li><li><p>One of his major shortcomings is his tendency to procrastinate, often delaying important tasks until the last minute. (Shortcoming: 缺点)<br>他的主要缺点之一是拖延，总是把重要任务拖到最后一刻才完成。</p></li><li><p>The new law was passed by congress after much debate, signaling a significant change in national policy. (Congress: 国会)<br>经过激烈辩论后，国会通过了新法律，标志着国家政策的重大变化。</p></li><li><p>The mountain range was a great natural barrier, protecting the valley from harsh weather conditions. (Great: 巨大的)<br>山脉是一个巨大的天然屏障，保护山谷免受恶劣天气的侵袭。</p></li><li><p>The magazine is published on a monthly basis, featuring the latest trends and news in the fashion industry. (Monthly: 每月的)<br>这本杂志每月出版一期，介绍时尚行业的最新趋势和新闻。</p></li><li><p>In the digital age, maintaining one’s online identity securely has become increasingly important. (Identity: 身份)<br>在数字时代，安全地维护个人的在线身份变得越来越重要。</p></li><li><p>They decided to lease the property for a year, with an option to buy at the end of the term. (Lease: 租赁)<br>他们决定租赁这处房产一年，并在租期结束时有购买的选择权。</p></li><li><p>The company launched a big marketing campaign to promote their new product, aiming to reach a wider audience. (Big: 大的)<br>公司发起了一场大型营销活动来推广他们的新产品，旨在吸引更广泛的受众。</p></li></ul><ol start="7"><li></li></ol><ul><li><p>The palace was guarded day and night lest any intruders should attempt to breach its secure walls. (Lest: 以免)<br>宫殿日夜有人守卫，以免任何入侵者试图突破其坚固的墙壁。</p></li><li><p>As they walked through the zoo, they marveled at the variety of animals, each more fascinating than the last. (Zoo: 动物园)<br>当他们穿过动物园时，他们惊叹于各种动物的多样性，每一种都比上一种更令人着迷。</p></li><li><p>She decided to stay in the city for the summer, hoping to find inspiration for her new novel. (Stay: 留下)<br>她决定在夏天留在城市，希望为她的新小说找到灵感。</p></li><li><p>The composer spent hours at the piano, carefully crafting a melody that would evoke a sense of nostalgia. (Compose: 作曲)<br>作曲家在钢琴前花了数小时，小心翼翼地创作出一首能唤起怀旧感的旋律。</p></li><li><p>The use of adjectives in his poetry added a vivid layer of description that brought his imagery to life. (Adjective: 形容词)<br>他诗歌中形容词的使用增添了一层生动的描述，使他的意象栩栩如生。</p></li><li><p>The gentle breeze carried the scent of blooming flowers, creating a serene and calming atmosphere in the garden. (Breeze: 微风)<br>微风轻拂，带来了盛开花朵的芬芳，在花园里营造出宁静而平静的氛围。</p></li><li><p>Due to the limited resources available, the team had to prioritize their tasks to ensure the project’s success. (Limited: 有限的)<br>由于可用资源有限，团队不得不优先处理任务以确保项目的成功。</p></li><li><p>The couple decided to spend their anniversary in a quaint little town, far away from the hustle and bustle of city life. (Couple: 夫妻)<br>这对夫妻决定在一个宁静的小镇度过他们的结婚纪念日，远离城市生活的喧嚣。</p></li><li><p>The scientist gave a fascinating lecture on the properties of silicon, highlighting its importance in modern technology. (Silicon: 硅)<br>科学家做了一场关于硅特性的精彩演讲，强调了它在现代技术中的重要性。</p></li><li><p>The palace, with its grand architecture and opulent decor, was a testament to the kingdom’s rich history. (Palace: 宫殿)<br>这座宫殿以其宏伟的建筑和豪华的装饰，见证了这个王国的丰富历史。</p></li><li><p>The carpenter crafted a beautiful wooden stool, paying close attention to every detail to ensure its durability. (Stool: 凳子)<br>木匠制作了一张漂亮的木凳子，密切关注每一个细节以确保其耐用性。</p></li><li><p>The professor was highly regarded in her field, known for her groundbreaking research and innovative teaching methods. (Highly: 高度)<br>这位教授在她的领域备受尊敬，以其开创性的研究和创新的教学方法而闻名。</p></li></ul><ol start="8"><li></li></ol><ul><li><p>Indeed, the artist’s latest masterpiece was so captivating that it left the entire audience in awe, proving once again his unparalleled talent. (Indeed: 的确)<br>的确，这位艺术家的最新杰作如此吸引人，让整个观众惊叹不已，再次证明了他无与伦比的才华。</p></li><li><p>The company was liable for the damages caused by the faulty product, and they were required to compensate all affected customers. (Liable: 有责任的)<br>公司对有缺陷产品造成的损害负有责任，必须赔偿所有受影响的客户。</p></li><li><p>It took several weeks for the new employee to acquaint himself with the company’s policies and procedures. (Acquaint: 使熟悉)<br>新员工花了几个星期时间熟悉公司的政策和程序。</p></li><li><p>The museum’s collection of porcelain artifacts includes pieces that date back to the Ming Dynasty, showcasing the intricate craftsmanship of that era. (Porcelain: 瓷器)<br>博物馆的瓷器收藏品包括一些明代的作品，展示了那个时代复杂的工艺。</p></li><li><p>When referring to historical events, it is important to consider the context and the perspectives of those who lived through them. (Refer: 提及)<br>在提及历史事件时，重要的是要考虑到当时的背景和经历这些事件的人的观点。</p></li><li><p>The exotic bird was kept in a large cage, allowing it some freedom of movement while still ensuring its safety. (Cage: 笼子)<br>这只异国鸟被关在一个大笼子里，让它在确保安全的同时有一些活动的自由。</p></li><li><p>Her linguistic skills were impressive, as she was fluent in five languages and had a deep understanding of cultural nuances. (Linguistic: 语言的)<br>她的语言技能令人印象深刻，她精通五种语言，并对文化细微差别有深入了解。</p></li><li><p>Despite their best efforts, the team faced defeat in the final match, leaving them with a sense of unfulfilled potential. (Defeat: 失败)<br>尽管他们尽了最大努力，团队在最后一场比赛中遭遇失败，留下了未能发挥潜力的感觉。</p></li><li><p>The local community came together to organize a fundraiser for the new library, demonstrating their strong sense of solidarity and support. (Community: 社区)<br>当地社区联合起来为新图书馆组织了一次筹款活动，展示了他们强烈的团结感和支持。</p></li><li><p>Under the new management, the company saw a significant improvement in both productivity and employee morale. (Under: 在……之下)<br>在新管理层的领导下，公司在生产力和员工士气方面都取得了显著改善。</p></li><li><p>The government decided to amend the existing law to better address the needs of the changing society. (Amend: 修改)<br>政府决定修改现行法律，以更好地满足变化中的社会需求。</p></li><li><p>She gave him a quick wink, signaling that everything was going according to plan. (Wink: 眨眼)<br>她迅速向他眨了一下眼，示意一切都按计划进行。</p></li><li><p>The company’s new strategy was designed to dominate the market, leaving little room for competitors. (Dominate: 主导)<br>公司的新策略旨在主导市场，几乎不给竞争对手留下空间。</p></li></ul><ol start="9"><li></li></ol><ul><li><p>The student’s exceptional performance in all her subjects earned her a full scholarship to the prestigious university. (Exceptional: 卓越的)<br>学生在所有科目中的卓越表现为她赢得了著名大学的全额奖学金。</p></li><li><p>The rich aroma of freshly brewed coffee filled the entire room, making everyone crave a cup. (Rich: 浓郁的)<br>新煮的咖啡浓郁的香气充满了整个房间，让每个人都渴望喝一杯。</p></li><li><p>We congratulate you on your outstanding achievements and wish you continued success in your future endeavors. (Congratulate: 祝贺)<br>我们祝贺你取得的杰出成就，并祝愿你在未来的事业中继续成功。</p></li><li><p>The team spent weeks meticulously developing a plan to launch their new product, ensuring every detail was perfect. (Plan: 计划)<br>团队花了数周时间精心制定推出新产品的计划，确保每一个细节都完美无缺。</p></li><li><p>Her conscientious approach to her work earned her the respect and admiration of her colleagues. (Conscientious: 认真的)<br>她认真工作的态度赢得了同事们的尊重和钦佩。</p></li><li><p>He leaned against the wall, deep in thought, as he considered the implications of the recent changes. (Lean: 倚靠)<br>他倚靠着墙，深思熟虑，思考着最近变化的影响。</p></li><li><p>The surgeon carefully removed the damaged tissue to prevent further infection. (Tissue: 组织)<br>外科医生小心翼翼地移除受损的组织，以防止进一步感染。</p></li><li><p>Chewing gum can help freshen your breath, but it’s important to dispose of it properly. (Gum: 口香糖)<br>咀嚼口香糖可以帮助清新口气，但重要的是要正确处理它。</p></li><li><p>The company offered a five-year warranty as an assurance of the product’s quality and durability. (Assurance: 保证)<br>公司提供了五年保修，作为产品质量和耐用性的保证。</p></li><li><p>With hard work and determination, she was able to attain her dream of becoming a doctor. (Attain: 实现)<br>通过努力和决心，她实现了成为医生的梦想。</p></li><li><p>The speech was filled with genuine sentiment, moving many in the audience to tears. (Sentiment: 情感)<br>演讲充满了真挚的情感，感动了许多观众，使他们流下了眼泪。</p></li><li><p>The new electronic devices on the market are designed to make our lives more convenient and efficient. (Electronic: 电子的)<br>市场上的新电子设备旨在使我们的生活更加便利和高效。</p></li><li><p>The project manager allocated resources and tasks efficiently to ensure the project stayed on schedule. (Allocate: 分配)<br>项目经理高效地分配资源和任务，以确保项目按时完成。</p></li><li><p>The overall performance of the team exceeded expectations, leading to a successful project completion. (Overall: 总体的)<br>团队的总体表现超出预期，项目成功完成。</p></li></ul><ol start="10"><li></li></ol><ul><li><p>The new shopping center will be the focal point of the community, offering a range of services and amenities. (Centre: 中心)<br>新的购物中心将成为社区的中心，提供各种服务和设施。</p></li><li><p>The artist used charcoal to render a detailed portrait of the old man, capturing every wrinkle and expression. (Render: 描绘)<br>艺术家用炭笔描绘了一幅老人的细致肖像，捕捉到了每一个皱纹和表情。</p></li><li><p>The price of oil is currently at a historic low, leading to lower fuel prices for consumers. (Low: 低的)<br>油价目前处于历史低位，导致消费者的燃料价格降低。</p></li><li><p>The rainwater drained away quickly thanks to the newly installed drainage system. (Drain: 排水)<br>新安装的排水系统使雨水迅速排走。</p></li><li><p>The fisherman lived in a small hut by the river, spending his days fishing and enjoying the solitude. (Hut: 小屋)<br>渔夫住在河边的一间小屋里，整天钓鱼，享受着宁静。</p></li><li><p>The young entrepreneur worked hard and smart, eventually becoming a millionaire. (Millionaire: 百万富翁)<br>年轻的企业家努力工作，最终成为了一位百万富翁。</p></li><li><p>After a long day at work, she felt tired and ready to relax at home. (Tired: 疲倦的)<br>工作了一整天后，她感到疲倦，准备在家里放松一下。</p></li><li><p>While some people prefer to work in a team, others thrive when working alone. (While: 而)<br>虽然有些人喜欢团队工作，但也有些人在独自工作时表现更好。</p></li><li><p>The company is currently offloading some of its assets to improve its financial situation. (Off: 卸载)<br>公司目前正在卸载部分资产，以改善其财务状况。</p></li><li><p>The theory of evolution explains how species change over time through natural selection. (Evolution: 进化)<br>进化论解释了物种如何通过自然选择随时间改变。</p></li><li><p>The stationery store sells a variety of paper, pens, and other office supplies. (Stationery: 文具)<br>这家文具店销售各种纸张、钢笔和其他办公用品。</p></li><li><p>He wore a thick vest to keep warm in the cold winter weather. (Vest: 背心)<br>他穿着厚厚的背心在寒冷的冬天保暖。</p></li><li><p>The radio tower was used to transmit signals across long distances. (Transmit: 传输)<br>无线电发射塔被用来在长距离传输信号。</p></li></ul><ol start="11"><li></li></ol><ul><li><p>The room was rectangular in shape, with four walls forming right angles. (Rectangle: 矩形)<br>房间呈矩形，四面墙壁形成直角。</p></li><li><p>The contract included a provision for overtime pay for any hours worked beyond the standard workweek. (Provision: 规定)<br>合同包括加班工资的规定，即超出标准工作周的工时。</p></li><li><p>Please enclose a self-addressed stamped envelope with your application for faster processing. (Enclose: 附上)<br>请附上一个附有您地址的信封，以便更快处理您的申请。</p></li><li><p>The instructions clearly specify the required format for the report. (Specify: 指定)<br>说明书明确指定了报告所需的格式。</p></li><li><p>He used the flu as a pretext to stay home from work, even though he was feeling better. (Pretext: 借口)<br>他借口感冒不舒服而请假在家，即使他已经感觉好多了。</p></li><li><p>The tree was so tall that it could be seen from miles away. (Tall: 高的)<br>这棵树非常高，可以从几英里外看到。</p></li><li><p>She spent the entire day cleaning the house from top to bottom. (Clean: 打扫)<br>她花了一整天的时间从上到下打扫房子。</p></li><li><p>It took several weeks to determine the cause of the mysterious illness. (Determine: 确定)<br>花了几个星期的时间确定了这种神秘疾病的原因。</p></li><li><p>The farmer used a tractor to plow the field in preparation for planting season. (Tractor: 拖拉机)<br>农民用拖拉机犁田，为播种季节做准备。</p></li><li><p>The new business establishment brought much-needed jobs to the local community. (Establishment: 机构)<br>这家新的商业机构为当地社区带来了急需的工作机会。</p></li><li><p>The city council discussed municipal issues such as garbage collection and road maintenance. (Municipal: 市政的)<br>市议会讨论了诸如垃圾收集和道路维护等市政问题。</p></li><li><p>The children played with a ball in the park until it was time to go home. (Ball: 球)<br>孩子们在公园里玩球，直到该回家的时候。</p></li><li><p>Please remember to stamp the envelope before mailing it. (Stamp: 邮票)<br>寄出信封前请记得贴邮票。</p></li><li><p>She was anxious about her upcoming exams, but she studied hard to prepare. (Anxious: 焦虑的)<br>她对即将到来的考试感到焦虑，但她努力学习以备考。</p></li></ul><ol start="12"><li></li></ol><ul><li><p>Despite his mistake, she found it in her heart to forgive him. (Forgive: 原谅)<br>尽管他犯了错误，她还是心存宽恕。</p></li><li><p>The document was subjected to careful scrutiny to ensure its accuracy. (Scrutiny: 仔细检查)<br>对该文件进行了仔细审查，以确保其准确性。</p></li><li><p>After years of hard work, she finally accomplished her goal of becoming a doctor. (Accomplish: 完成)<br>经过多年的努力，她终于实现了成为医生的目标。</p></li><li><p>He was much taller than his classmates, standing out in the crowd. (Much: 很)<br>他比同学们高得多，在人群中显得格外突出。</p></li><li><p>The teacher used a drill to help the students practice their multiplication tables. (Drill: 练习)<br>老师使用了一种训练方法来帮助学生练习乘法口诀。</p></li><li><p>Please direct your attention to the screen for an important announcement. (Direct: 引导)<br>请将注意力集中在屏幕上，等待重要通知。</p></li><li><p>The selection process was entirely random, with no specific criteria for choosing the winner. (Random: 随机的)<br>选择过程完全是随机的，没有选择获胜者的特定标准。</p></li><li><p>The study focused on the physiological effects of stress on the body. (Physiological: 生理的)<br>这项研究关注了压力对身体的生理影响。</p></li><li><p>The legal proceeding lasted for several months before reaching a final verdict. (Proceeding: 过程)<br>法律诉讼持续了几个月才作出最终裁决。</p></li><li><p>The mother had to scold her children for misbehaving in public. (Scold: 责骂)<br>母亲不得不责备孩子们在公共场合表现不好。</p></li><li><p>The solution to the problem was surprisingly simple, once they discovered it. (Simple: 简单的)<br>问题的解决方案出乎意料地简单，一旦他们发现了它。</p></li></ul><ol start="13"><li></li></ol><ul><li><p>Sacrifice is often required to achieve success in life, as one must be willing to give up certain comforts or desires. (Sacrifice: 牺牲)<br>在生活中取得成功通常需要牺牲，因为一个人必须愿意放弃某些舒适或欲望。</p></li><li><p>The location of the new school was chosen for its proximity to residential areas and public transportation. (Location: 位置)<br>新学校的位置之所以被选择，是因为它靠近居民区和公共交通。</p></li><li><p>The surroundings of the park were peaceful and serene, providing a perfect escape from the city’s hustle and bustle. (Surroundings: 环境)<br>公园的周围环境宁静祥和，是逃离城市喧嚣的理想去处。</p></li><li><p>The government’s policy on education aims to improve access to quality education for all children. (Policy: 政策)<br>政府的教育政策旨在提高所有儿童接受优质教育的机会。</p></li><li><p>The dress was made of the finest silk, giving it a luxurious and elegant appearance. (Silk: 丝绸)<br>这件连衣裙是用最好的丝绸制成的，使其看起来奢华而优雅。</p></li><li><p>She felt a sudden impulse to travel to a foreign country and explore new cultures. (Impulse: 冲动)<br>她突然有了一种去外国旅行、探索新文化的冲动。</p></li><li><p>The story of the ancient civilization was passed down from generation to generation through oral tradition. (Story: 故事)<br>古代文明的故事通过口头传统世代相传。</p></li><li><p>The teacher reminded the pupils to study hard and strive for excellence in their academic pursuits. (Pupil: 小学生)<br>老师提醒学生要努力学习，追求学业上的卓越。</p></li><li><p>Anybody can achieve success with hard work and determination, regardless of their background or circumstances. (Anybody: 任何人)<br>任何人只要努力和决心，都可以取得成功，不论他们的背景或环境如何。</p></li><li><p>The scientist is considered foremost in his field, having made groundbreaking discoveries that have changed the course of science. (Foremost: 最重要的)<br>这位科学家在他的领域被认为是最重要的，他做出了开创性的发现，改变了科学的发展方向。</p></li><li><p>Her outlook on life was always positive, even in the face of adversity. (Outlook: 观点)<br>她对生活的看法始终积极，即使面对困境也是如此。</p></li><li><p>The company’s revenue exceeded a billion dollars for the first time in its history, marking a significant milestone. (Billion: 十亿)<br>公司的收入首次超过十亿美元，标志着一个重要的里程碑。</p></li><li><p>It was a pleasant surprise to receive a gift from an unexpected source. (Pleasant: 愉快的)<br>收到意外来源的礼物是一件令人愉快的事情。</p></li><li><p>She helped him pack his belongings as he prepared to move to a new city for a job opportunity. (Pack: 打包)<br>她帮助他整理行李，因为他准备为了一次工作机会搬到一个新的城市。</p></li></ul><ol start="14"><li></li></ol><ul><li><p>She collaborated closely with her colleague on the project, sharing ideas and working towards a common goal. (Colleague: 同事)<br>她与同事在项目中密切合作，分享想法，共同努力实现共同目标。</p></li><li><p>He decided to go for a walk because he needed some fresh air and time to clear his mind. (Because: 因为)<br>他决定出去走走，因为他需要新鲜空气，需要时间来整理思绪。</p></li><li><p>In the past, many people were forced into slavery and had to work under harsh conditions with no freedom. (Slave: 奴隶)<br>在过去，许多人被迫成为奴隶，在恶劣条件下工作，没有自由。</p></li><li><p>The street was lined with tall trees, creating a picturesque avenue for pedestrians to enjoy. (Avenue: 大街)<br>街道两旁都是高大的树木，形成了一条风景如画的大街，供行人欣赏。</p></li><li><p>He felt betrayed by his friend, who had promised to keep his secret but had told others instead. (Betray: 背叛)<br>他感到被朋友背叛了，朋友曾承诺保守他的秘密，但却告诉了其他人。</p></li><li><p>They had to stick to a strict budget to make ends meet and cover their expenses. (Budget: 预算)<br>他们不得不严格控制预算，以维持生计并支付开支。</p></li><li><p>The wolf let out a loud howl, signaling its presence to others in the pack. (Howl: 嚎叫)<br>狼发出了一声响亮的嚎叫，向群体中的其他成员表示自己的存在。</p></li><li><p>The company aims to provide quality services irrespective of the customer’s background or status. (Irrespective: 不考虑)<br>该公司的目标是提供优质的服务，不论客户的背景或地位如何。</p></li><li><p>In the meantime, she continued working on her novel, hoping to finish it by the end of the year. (Meantime: 与此同时)<br>与此同时，她继续着手写她的小说，希望在年底前完成。</p></li><li><p>They ventured into the jungle, eager to explore its mysteries and discover new species of plants and animals. (Jungle: 丛林)<br>他们冒险进入丛林，渴望探索其中的奥秘，发现新的植物和动物物种。</p></li><li><p>The company expects its employees to conform to certain standards of behavior and dress code. (Conform: 遵守)<br>公司期望员工遵守一定的行为准则和着装规范。</p></li><li><p>She decided to start her own business after years of working for others, seeking more independence and control over her career. (Start: 开始)<br>在为他人工作多年后，她决定开始自己的事业，寻求更多的独立性和对自己事业的控制权。</p></li><li><p>The painting was not only visually appealing but also had a deeper aesthetic meaning that resonated with viewers. (Aesthetic: 审美的)<br>这幅画不仅在视觉上吸引人，而且还具有更深层次的审美意义，引起了观众的共鸣。</p></li><li><p>She decided to switch careers and pursue her passion for photography, leaving her stable job behind. (Switch: 转换)<br>她决定转行，追求她对摄影的热情，放弃了她稳定的工作。</p></li></ul><ol start="15"><li></li></ol><ul><li><p>The cow grazed peacefully in the meadow, enjoying the lush grass under the clear blue sky. (Cow: 母牛)<br>母牛在草地上悠闲地吃草，享受着晴朗蓝天下的青草。</p></li><li><p>The county fair was a lively event, with people from all over gathering to enjoy the festivities. (County: 县)<br>县集市是一个热闹的活动，来自各地的人们聚集在一起享受节日。</p></li><li><p>The people of the village were known for their hospitality and welcoming nature towards strangers. (People: 人们)<br>村里的人们以他们对陌生人的好客和热情而闻名。</p></li><li><p>Many scientists are skeptical about the new theory, as it challenges long-held beliefs in the field. (Skeptical: 怀疑的)<br>许多科学家对这个新理论持怀疑态度，因为它挑战了该领域长期以来的信念。</p></li><li><p>The interior of the house was beautifully decorated, with elegant furniture and tasteful artwork. (Interior: 内部)<br>房子的内部装饰精美，配有优雅的家具和雅致的艺术品。</p></li><li><p>The reception for the new ambassador was held in the grand ballroom of the embassy. (Reception: 欢迎会)<br>新大使的欢迎会在大使馆的豪华舞厅举行。</p></li><li><p>She decided to major in biology, as she had always been fascinated by the natural world and its complexities. (Major: 专业)<br>她决定主修生物学，因为她一直被自然界及其复杂性所吸引。</p></li><li><p>The cake was sweet and delicious, with layers of rich chocolate and creamy frosting. (Sweet: 甜的)<br>蛋糕又甜又美味，有着丰富的巧克力层和奶油霜。</p></li><li><p>The medicine had a bitter taste, but she knew it would help her feel better soon. (Bitter: 苦的)<br>药品有一种苦涩的味道，但她知道它会帮助她很快感觉好些。</p></li><li><p>She considered him her closest friend, someone she could always rely on and confide in. (Friend: 朋友)<br>她把他视为自己最亲密的朋友，一个她永远可以依赖和倾诉的人。</p></li><li><p>She couldn’t decide which dress to wear to the party, as they were all so beautiful. (Which: 哪一个)<br>她无法决定穿哪件裙子去参加派对，因为它们都很漂亮。</p></li><li><p>The toxic fumes from the factory were a major concern for the health of the local residents. (Toxic: 有毒的)<br>工厂排放的有毒烟雾是当地居民健康的主要问题。</p></li><li><p>The mutton stew was a hearty meal, perfect for warming up on a cold winter’s day. (Mutton: 羊肉)<br>羊肉炖菜是一顿丰盛的饭菜，适合在寒冷的冬天里暖身。</p></li></ul><ol start="16"><li></li></ol><ul><li><p>The steep cliffs along the coast made for a breathtaking view, especially during sunset. (Steep: 陡峭的)<br>海岸线上陡峭的悬崖景色令人惊叹，尤其是在日落时分。</p></li><li><p>The country was in the midst of a political crisis, with protests and unrest spreading across the nation. (Crisis: 危机)<br>这个国家正处于政治危机之中，抗议活动和动荡正在全国蔓延。</p></li><li><p>The company was able to utilize the latest technology to improve efficiency and productivity. (Utilize: 利用)<br>公司能够利用最新技术提高效率和生产力。</p></li><li><p>She tried to conceal her disappointment with a smile, but her eyes betrayed her true feelings. (Conceal: 隐藏)<br>她试图用微笑掩饰自己的失望，但她的眼神暴露了她真实的感受。</p></li><li><p>The air was hot and humid, making it difficult to breathe. (Humid: 湿的)<br>空气又热又湿，让人难以呼吸。</p></li><li><p>He had a rap for being late, but he always managed to get his work done on time. (Rap: 坏名声)<br>他因经常迟到而声名狼藉，但他总是设法及时完成工作。</p></li><li><p>Their love for each other was evident in the way they looked at each other and the little gestures of affection. (Love: 爱)<br>他们彼此之间的爱情显而易见，体现在他们互相看着对方和亲昵的小动作上。</p></li><li><p>The cellar was cool and damp, the perfect place to store wine and preserves. (Cellar: 地窖)<br>地窖里又凉又湿，是存放葡萄酒和果酱的理想场所。</p></li><li><p>The company was looking to employ new graduates with fresh ideas and a willingness to learn. (Employ: 雇佣)<br>公司正在寻找有新想法和学习意愿的新毕业生。</p></li><li><p>He wrapped the rope around the pole in a tight coil, securing it in place. (Coil: 卷)<br>他把绳子紧紧地缠绕在杆子上，把它固定在那里。</p></li><li><p>The city implemented measures to curb the spread of the virus, including strict lockdowns and travel restrictions. (Curb: 控制)<br>城市采取措施控制病毒的传播，包括严格的封锁和旅行限制。</p></li><li><p>His humorous stories always brought a smile to everyone’s face, even on the gloomiest of days. (Humorous: 幽默的)<br>他幽默的故事总是能让每个人在最阴郁的日子里笑容满面。</p></li></ul><ol start="17"><li></li></ol><ul><li><p>She was on the verge of tears, overwhelmed by the sudden news of her grandmother’s passing. (Verge: 边缘)<br>她快要哭了，突然得知她奶奶去世的消息让她不知所措。</p></li><li><p>We decided to lodge at the mountain cabin for the weekend to escape the city’s hustle and bustle. (Lodge: 寄宿)<br>我们决定周末住在山间小屋里，远离城市的喧嚣。</p></li><li><p>He gave the wheel a hard spin, causing the car to skid and swerve off the road. (Spin: 旋转)<br>他猛地转动方向盘，导致车子打滑并偏离了道路。</p></li><li><p>Aviation has made great strides in safety and efficiency over the past century. (Aviation: 航空)<br>航空在过去一个世纪在安全性和效率方面取得了巨大进步。</p></li><li><p>It took her a while to realise that she had been talking to the wrong person the whole time. (Realise: 意识到)<br>她花了一些时间才意识到她一直在和错误的人说话。</p></li><li><p>They devised a means to improve the efficiency of the production line, resulting in significant cost savings. (Means: 方法)<br>他们想出了一种方法来提高生产线的效率，从而实现了大幅成本节省。</p></li><li><p>The company made several improvements to their product based on customer feedback, resulting in higher satisfaction ratings. (Improvement: 改进)<br>公司根据客户反馈对产品进行了几项改进，导致客户满意度提高。</p></li><li><p>The deadline was nearly upon us, so we had to work extra hours to complete the project on time. (Nearly: 几乎)<br>最后期限已经临近，所以我们不得不加班工作，以便按时完成项目。</p></li><li><p>Further analysis is required to determine the exact cause of the problem. (Further: 进一步)<br>需要进一步分析以确定问题的确切原因。</p></li><li><p>She wore a stylish outfit to the party, which garnered her many compliments. (Outfit: 服装)<br>她穿着一套时尚的服装去参加聚会，赢得了许多赞美。</p></li></ul><ol start="18"><li></li></ol><ul><li><p>The exterior of the building was beautifully decorated with intricate carvings and colorful murals. (Exterior: 外部)<br>建筑物的外部装饰着精美的雕刻和色彩斑斓的壁画。</p></li><li><p>She sat on the porch, enjoying a leisurely sip of her hot tea as she watched the sunset. (Porch: 门廊；Sip: 小口喝)<br>她坐在门廊上，悠闲地小口喝着热茶，看着夕阳。</p></li><li><p>The farmer spread fertilizer over the field to enrich the soil and promote plant growth. (Fertilizer: 肥料)<br>农民在田地上撒肥料，以丰富土壤，促进植物生长。</p></li><li><p>The kids splashed in the pool, laughing and enjoying the cool water on a hot summer day. (Splash: 溅)<br>孩子们在游泳池里嬉戏，笑着享受着炎炎夏日的清凉水。</p></li><li><p>The ratio of students to teachers in the school was 20:1, ensuring that each student received personalized attention. (Ratio: 比率)<br>学校师生比为20:1，确保每个学生都得到个性化关注。</p></li><li><p>She decided to confess her feelings to him, hoping that he felt the same way. (Confess: 坦白)<br>她决定向他坦白自己的感受，希望他也有同样的感觉。</p></li><li><p>The summary of the report provided a concise overview of the key findings and recommendations. (Summary: 摘要)<br>报告的摘要提供了对主要发现和建议的简明概述。</p></li><li><p>The archaeologists discovered a bone fragment that was believed to belong to a prehistoric animal. (Bone: 骨头)<br>考古学家发现了一块骨头碎片，据信是属于一种史前动物的。</p></li><li><p>The arrival of the new year was celebrated with fireworks and festivities across the city. (Arrival: 到来)<br>新年的到来在全城用烟火和庆祝活动来庆祝。</p></li><li><p>May you be blessed with happiness and prosperity in the coming year. (Bless: 祝福)<br>愿您在新的一年里幸福、繁荣。</p></li><li><p>The room was small, but its dimensions were perfect for the cozy atmosphere she wanted to create. (Dimension: 尺寸)<br>房间很小，但尺寸非常适合她想营造的温馨氛围。</p></li><li><p>The doctor wrote a prescription for the patient’s medication, detailing the dosage and frequency. (Prescription: 处方)<br>医生给病人开了一张药方，详细说明了剂量和频率。</p></li><li><p>Hitherto, he had never considered the idea of studying abroad, but now it seemed like an exciting opportunity. (Hitherto: 迄今为止)<br>迄今为止，他从未考虑过出国留学的想法，但现在这似乎是一个令人兴奋的机会。</p></li></ul><ol start="19"><li></li></ol><ul><li><p>The surgeon had to detach the muscle from the bone in order to repair the injury. (Detach: 分离)<br>外科医生不得不将肌肉从骨头上分离，以修复受伤处。</p></li><li><p>If you’re looking for a quiet place to work, you might consider working elsewhere. (Elsewhere: 别处)<br>如果你正在寻找一个安静的工作地方，你可以考虑在别处工作。</p></li><li><p>The painting seemed to evoke a sense of nostalgia in everyone who viewed it. (Evoke: 唤起)<br>这幅画似乎唤起了每个看过它的人心中的怀旧之情。</p></li><li><p>I recommend that you try the new restaurant downtown; the food there is amazing. (Recommend: 推荐)<br>我建议你去市中心试试那家新餐馆；那里的食物非常棒。</p></li><li><p>After deducting all the expenses, the company’s gross profit for the year was quite substantial. (Gross: 总的；Substantial: 可观的)<br>扣除所有费用后，公司今年的总利润相当可观。</p></li><li><p>We need to find a better way to communicate our ideas to the rest of the team. (Communicate: 交流)<br>我们需要找到一个更好的方式来将我们的想法传达给团队的其他成员。</p></li><li><p>The flag was attached to the top of the pole, waving proudly in the wind. (Pole: 杆子)<br>旗帜被系在杆子的顶端，在风中自豪地飘扬着。</p></li><li><p>The weather forecast predicted rain; however, the sun was shining brightly all day. (However: 然而)<br>天气预报预测会下雨；然而，阳光整天都明媚照耀。</p></li><li><p>Despite his anger, he showed great restraint and did not raise his voice. (Restraint: 克制)<br>尽管他很生气，但他表现出极大的克制，没有提高声音。</p></li><li><p>The joint effort of the two teams resulted in a successful project completion. (Joint: 共同的)<br>两个团队的共同努力导致了项目的成功完成。</p></li><li><p>In spring, the trees begin to blossom, filling the air with their sweet fragrance. (Blossom: 开花)<br>春天，树木开始开花，将空气填满了它们甜美的芬芳。</p></li></ul><ol start="20"><li></li></ol><ul><li><p>The light bulb illuminated the room, casting a warm glow over everything. (Bulb: 灯泡)<br>灯泡照亮了房间，使一切都笼罩在温暖的光芒中。</p></li><li><p>The study aimed to investigate the effects of climate change on local wildlife. (Study: 研究)<br>这项研究旨在调查气候变化对当地野生动物的影响。</p></li><li><p>Buying in bulk is often cheaper than buying individual items. (Bulk: 大量)<br>批量购买通常比单独购买要便宜。</p></li><li><p>She subscribed to several fashion magazines to keep up with the latest trends. (Magazine: 杂志)<br>她订阅了几本时尚杂志，以跟上最新的潮流。</p></li><li><p>Solar power is a clean and renewable source of energy. (Power: 能源)<br>太阳能是一种清洁且可再生的能源。</p></li><li><p>We all agreed that the proposal was a good idea. (Agree: 同意)<br>我们都同意这个提议是个好主意。</p></li><li><p>He attended the university’s open day to learn more about their courses. (University: 大学)<br>他参加了大学的开放日，了解更多关于他们的课程的信息。</p></li><li><p>The experimental results confirmed the scientist’s hypothesis. (Experimental: 实验的)<br>实验结果证实了科学家的假设。</p></li><li><p>She was offered a position as a research assistant at the university. (Position: 职位)<br>她被提供了一份大学研究助理的职位。</p></li><li><p>The store sells a wide range of clothes for all ages. (Clothe: 为…穿衣)<br>这家商店销售各个年龄段的广泛服装。</p></li><li><p>The car accelerated to a high speed on the open road. (Speed: 速度)<br>车子在开阔的道路上加速到很快的速度。</p></li><li><p>The folk music festival attracted musicians and fans from all over the country. (Folk: 民间的)<br>民间音乐节吸引了来自全国各地的音乐家和粉丝。</p></li></ul><ol start="21"><li></li></ol><ul><li><p>The new policy aims to diminish the impact of economic disparities on education. (Diminish: 减少)<br>新政策旨在减少经济差距对教育的影响。</p></li><li><p>His wisdom and experience were evident in the way he handled the situation. (Wisdom: 智慧)<br>他处理问题的方式显示出他的智慧和经验。</p></li><li><p>The therapist helped them work on their relationship and improve communication. (Relationship: 关系)<br>治疗师帮助他们改善关系，提高沟通。</p></li><li><p>The scientist discovered a new way to multiply the effectiveness of the medicine. (Multiply: 增加)<br>科学家发现了一种增加药物效果的新方法。</p></li><li><p>The thermometer indicated that the temperature was dropping rapidly. (Thermometer: 温度计)<br>温度计显示温度正在迅速下降。</p></li><li><p>Lavender is often used in perfume for its soothing and calming scent. (Perfume: 香水)<br>薰衣草常被用于香水，因为它具有舒缓和镇定的香气。</p></li><li><p>The concentration of pollutants in the air was higher than normal. (Concentration: 浓度)<br>空气中污染物的浓度高于正常水平。</p></li><li><p>The burglar was caught red-handed as he tried to break into the house. (Burglar: 小偷)<br>小偷在试图闯入房子时被当场抓获。</p></li><li><p>The news of the crime began to agitate the local community. (Agitate: 激动)<br>犯罪消息开始激起当地社区的愤怒。</p></li><li><p>The water cycle is essential for maintaining life on Earth. (Cycle: 循环)<br>水循环对维持地球上的生命至关重要。</p></li><li><p>The violent storm caused extensive damage to homes and infrastructure. (Violent: 暴力的)<br>暴风雨给房屋和基础设施造成了广泛破坏。</p></li></ul><ol start="22"><li></li></ol><ul><li><p>The explorer discovered the ancient ruins of a historic city that had long been extinct. (Historic: 历史性的；Extinct: 灭绝的)<br>探险家发现了一个古老城市的遗迹，这座城市早已灭绝。</p></li><li><p>The king was known for his royal demeanor and the way he carried himself in public. (Royal: 皇家的)<br>国王以其皇家风度和在公众场合的举止而闻名。</p></li><li><p>The company decided to refuse the offer as it did not meet their expectations. (Refuse: 拒绝)<br>公司决定拒绝这个提议，因为它没有达到他们的期望。</p></li><li><p>The comedian’s satire of political figures was both humorous and thought-provoking. (Satire: 讽刺)<br>这位喜剧演员对政治人物的讽刺既幽默又发人深省。</p></li><li><p>The machinery in the factory was old and outdated, causing frequent breakdowns and delays. (Machinery: 机械设备)<br>工厂里的机器设备又旧又过时，导致经常出现故障和延误。</p></li><li><p>The artist was apt at capturing the beauty of nature in his paintings, using vibrant colors and intricate details. (Apt: 天生的)<br>这位艺术家擅长于捕捉自然之美，在他的画作中运用了生动的色彩和复杂的细节。</p></li><li><p>The company’s new advertising campaign was designed to appeal to a wider audience and increase sales. (Supply: 供应)<br>公司的新广告活动旨在吸引更广泛的受众，提高销售额。</p></li><li><p>The inventor worked tirelessly to invent a new type of machinery that would revolutionize the industry. (Invent: 发明)<br>发明家不知疲倦地努力发明一种新型机械，这将彻底改变这个行业。</p></li><li><p>The students were electing a new class president, and each candidate had to present their campaign platform. (Elect: 选举)<br>学生们正在选举新的班级主席，每位候选人都必须提出自己的竞选纲领。</p></li><li><p>The artist’s work was printed in a prestigious art magazine, bringing her widespread recognition and acclaim. (Print: 印刷)<br>这位艺术家的作品被刊登在一本知名艺术杂志上，为她带来了广泛的认可和赞扬。</p></li><li><p>The company was able to supply the demand for its products by increasing production capacity. (Supply: 供应)<br>公司通过增加生产能力，能够满足产品的需求。</p></li><li><p>The negotiation resulted in a bargain for both parties, with each side gaining something of value. (Bargain: 交易)<br>谈判结果对双方都是一笔交易，双方都获得了有价值的东西。</p></li><li><p>The politician’s rise to power was swift, as he was able to seize the opportunity presented by the current political climate. (Seize: 抓住)<br>政治家迅速上台，因为他能够抓住当前政治氛围所提供的机会。</p></li></ul><ol start="23"><li></li></ol><ul><li><p>The snake’s venom is deadly and can kill a person within minutes if not treated promptly. (Deadly: 致命的)<br>这种蛇的毒液是致命的，如果不及时治疗，可以在几分钟内致人死命。</p></li><li><p>The zoo has a new enclosure for the lions, providing them with a larger and more natural habitat. (Enclosure: 围场)<br>动物园为狮子新建了一个围场，为它们提供了更大更自然的栖息地。</p></li><li><p>The judicial system plays a crucial role in ensuring justice and upholding the rule of law in society. (Judicial: 司法的)<br>司法系统在确保公正和维护社会法治中发挥着至关重要的作用。</p></li><li><p>His comment about the project was hasty and ill-considered, leading to misunderstandings among the team members. (Hasty: 草率的)<br>他对项目的评论草率而欠考虑，导致团队成员之间产生了误解。</p></li><li><p>Safety should be our top priority when working in hazardous environments. (Priority: 优先考虑的事项)<br>在危险环境中工作时，安全应该是我们的首要任务。</p></li><li><p>The intensity of the storm surprised everyone, causing widespread damage and power outages. (Intensity: 强度)<br>暴风雨的强度让所有人都感到惊讶，导致了广泛的破坏和停电。</p></li><li><p>The police had a warrant to search the suspect’s house for evidence related to the crime. (Warrant: 授权)<br>警方有搜索令，可以搜查嫌疑人的房屋，寻找与犯罪有关的证据。</p></li><li><p>She loves to cook and often experiments with new recipes to create delicious meals for her family. (Cook: 烹饪)<br>她喜欢烹饪，经常尝试新的食谱，为家人做出美味的餐点。</p></li><li><p>Democracy allows people to have a voice in their government and participate in decision-making processes. (Democracy: 民主)<br>民主让人们在政府中发表自己的意见，并参与决策过程。</p></li><li><p>The earthquake was a stark reminder of the power of nature and the need for preparedness in vulnerable areas. (Remind: 提醒)<br>地震是自然力量的一个鲜明提醒，也提醒我们在易受影响的地区需要做好准备。</p></li></ul><ol start="24"><li></li></ol><ul><li><p>The immigrant struggled to assimilate into the new culture, facing challenges in adapting to the customs and language. (Assimilate: 同化)<br>这位移民在融入新文化方面遇到了困难，面临着适应风俗和语言的挑战。</p></li><li><p>He made a bold decision to start his own business, despite the risks and uncertainties involved. (Bold: 大胆的)<br>尽管涉及风险和不确定性，但他还是做出了创业的大胆决定。</p></li><li><p>The old man had a sharp memory, often recalling events from his childhood with great detail. (Memory: 记忆)<br>这位老人记忆力很好，经常能够详细地回忆起童年的事件。</p></li><li><p>His statement seemed to contradict the evidence presented, leading to doubts about his innocence. (Contradict: 矛盾)<br>他的陈述似乎与提出的证据相矛盾，引发了对他无辜的怀疑。</p></li><li><p>The veteran soldier shared his war stories, recounting his experiences on the battlefield. (Veteran: 老兵)<br>老兵士分享了他的战争故事，回忆起自己在战场上的经历。</p></li><li><p>The angry mob gathered outside the courthouse, demanding justice for the victim. (Mob: 暴民)<br>愤怒的暴民聚集在法院外，要求为受害者伸张正义。</p></li><li><p>The material used in the construction was resistant to heat and corrosion, ensuring the durability of the building. (Resistant: 抵抗的)<br>建筑中使用的材料对热量和腐蚀具有抵抗力，确保了建筑物的耐久性。</p></li><li><p>The company’s new commercial showcased their latest products, highlighting their features and benefits. (Commercial: 商业的)<br>公司的新商业广告展示了他们的最新产品，突出了其特点和优势。</p></li><li><p>They set out to explore the uncharted territories, eager to discover new lands and resources. (Explore: 探索)<br>他们着手探索未知的领土，渴望发现新的土地和资源。</p></li><li><p>The construction of the new highway would displace many families living along the route, leading to protests and complaints. (Displace: 取代)<br>新公路的建设将迫使沿线居住的许多家庭搬迁，引发抗议和投诉。</p></li><li><p>The skilled pilot was able to maneuver the aircraft through turbulent weather conditions, ensuring a safe landing. (Maneuver: 操纵)<br>熟练的飞行员能够操纵飞机穿越动荡的天气条件，确保安全着陆。</p></li><li><p>The crystal clear water of the lake reflected the surrounding mountains, creating a stunningly beautiful scene. (Crystal: 水晶)<br>湖水清澈见底，倒映着周围的山峰，形成了令人惊叹的美景。</p></li></ul><ol start="25"><li></li></ol><ul><li><p>They enjoyed a delicious ham for dinner on Sunday, savoring the main course with hungry appetites. (Sunday: 星期日; Ham: 火腿; Main: 主菜; Hungry: 饥饿的)<br>他们在星期日享用了美味的火腿晚餐，品尝主菜时饥肠辘辘。</p></li><li><p>It is important to assess your preferences before making a decision, considering the different options available. (Assess: 评估; Preference: 偏爱; Different: 不同)<br>在做决定之前评估您的偏好很重要，考虑到现有的不同选择。</p></li><li><p>The scar on his chest was a reminder of the surgery he had undergone, a mark over his heart. (Scar: 疤痕; Heart: 心脏)<br>他胸口上的疤痕是他曾接受过的手术的提醒，是他心脏上的一个印记。</p></li><li><p>The noble knight was known for his bravery and chivalry, a hero in the eyes of the people. (Noble: 高贵的)<br>这位高贵的骑士以其勇敢和骑士精神而闻名，是人们眼中的英雄。</p></li><li><p>The latest bulletin showed that the new restaurant was becoming popular among locals. (Bulletin: 公告; Popular: 受欢迎的)<br>最新的公告显示，这家新餐厅正在成为当地人中受欢迎的地方。</p></li></ul><ol start="26"><li></li></ol><ul><li><p>The company’s new operational strategy proved to be highly effective, leading to increased productivity and profits. (Operational: 运营的)<br>公司的新运营策略被证明非常有效，导致生产力和利润增加。</p></li><li><p>She was not only a successful businesswoman but also a wholesome individual, known for her kindness and generosity. (Wholesome: 健康的)<br>她不仅是一位成功的女商人，还是一位淳朴的人，以她的善良和慷慨而闻名。</p></li><li><p>The artist received a commission to paint a portrait of the mayor for the town hall. (Commission: 委托)<br>艺术家受委托为市政厅画市长的肖像。</p></li><li><p>He was a renowned scholar in the field of physics, known for his groundbreaking research and discoveries. (Scholar: 学者)<br>他是物理学领域著名的学者，以他的开创性研究和发现而闻名。</p></li><li><p>When she heard the news, she was overcome with grief, unable to comprehend the magnitude of her loss. (Grieve: 悲伤)<br>当她听到这个消息时，她被悲伤所淹没，无法理解她所失去的东西的重要性。</p></li><li><p>The bride looked radiant in her wedding gown, her face glowing with happiness and anticipation. (Bride: 新娘)<br>新娘穿着婚纱看起来光彩照人，脸上洋溢着幸福和期待。</p></li><li><p>She admitted her mistake and apologized for any inconvenience she may have caused. (Admit: 承认)<br>她承认了自己的错误，并为可能造成的任何不便道歉。</p></li><li><p>The old man’s hair had turned grey, a testament to the many years he had lived and the experiences he had accumulated. (Grey: 灰色)<br>老人的头发已经变成了灰色，这是他活了许多年和积累了许多经验的证明。</p></li></ul><ol start="27"><li></li></ol><ul><li><p>The invisible hand of the market is a concept in economics that suggests that individuals’ self-interested actions can lead to positive outcomes for society as a whole. (Invisible: 看不见的)<br>市场的看不见的手是经济学中的一个概念，它表明个人的自私行为可以导致整个社会的积极结果。</p></li><li><p>He had to act quickly to save the child from drowning in the pool. (Act: 行动)<br>他必须迅速行动，将孩子从溺水中救出。</p></li><li><p>The musician spent hours trying to tune his guitar to get the perfect sound. (Tune: 调音)<br>音乐家花了几个小时来调整他的吉他，以获得完美的声音。</p></li><li><p>She seldom went out at night, preferring to stay home and read a good book. (Seldom: 很少)<br>她很少在晚上外出，更喜欢呆在家里读一本好书。</p></li><li><p>The equator is an imaginary line that divides the Earth into the Northern Hemisphere and the Southern Hemisphere. (Equator: 赤道)<br>赤道是一条想象中的线，将地球分为北半球和南半球。</p></li><li><p>Despite their differences in beliefs, they respected each other’s views and lived in harmony. (Catholic: 广泛的)<br>尽管他们的信仰不同，但他们尊重彼此的观点，和谐相处。</p></li><li><p>The dome of the cathedral rose high above the city skyline, a symbol of faith and architectural beauty. (Dome: 圆顶)<br>大教堂的圆顶高高耸立在城市天际线之上，象征着信仰和建筑之美。</p></li><li><p>Notwithstanding the challenges they faced, they remained optimistic and determined to succeed. (Notwithstanding: 尽管)<br>尽管他们面临着挑战，但他们仍然乐观并决心成功。</p></li><li><p>The bird began to flap its wings, preparing to take off into the sky. (Flap: 拍打)<br>鸟开始拍打翅膀，准备起飞。</p></li><li><p>She had long, flowing hair that shimmered in the sunlight. (Hair: 头发)<br>她长长的头发在阳光下闪闪发光。</p></li><li><p>He winced in pain as the doctor removed the splinter from his finger. (Hurt: 疼痛)<br>医生从他手指上取出碎片时，他因疼痛而畏缩。</p></li><li><p>The stem of the flower was strong and sturdy, supporting the delicate petals above. (Stem: 茎)<br>花的茎又粗又结实，支撑着上面娇嫩的花瓣。</p></li></ul><ol start="28"><li></li></ol><ul><li><p>She kept the receipt as proof of purchase in case she needed to return the item. (Receipt: 收据)<br>她保存了收据作为购买凭证，以防需要退货。</p></li><li><p>Physics is the study of matter, energy, and the interactions between them. (Physics: 物理学)<br>物理学是研究物质、能量及其之间相互作用的科学。</p></li><li><p>The news of her friend’s illness seemed to depress her, and she struggled to find joy in her daily activities. (Depress: 使沮丧)<br>她朋友生病的消息似乎使她沮丧，她努力在日常活动中找到快乐。</p></li><li><p>The hotel guest complained about the noise coming from the construction site next door. (Guest: 客人)<br>酒店客人抱怨隔壁施工现场传来的噪音。</p></li><li><p>The software is not compatible with older operating systems and may require an upgrade. (Compatible: 兼容的)<br>这款软件与旧操作系统不兼容，可能需要升级。</p></li><li><p>The meat was so tender that it practically melted in your mouth. (Tender: 嫩的)<br>肉是如此嫩，几乎在口中融化。</p></li><li><p>She is a capable leader who can handle challenging situations with ease. (Capable: 有能力的)<br>她是一个有能力的领导者，能够轻松应对具有挑战性的情况。</p></li><li><p>She bit into the juicy pear, savoring its sweet flavor. (Pear: 梨)<br>她咬了一口多汁的梨，享受着它甜美的味道。</p></li><li><p>The ancient pyramid was an architectural marvel, showcasing the ingenuity of its builders. (Pyramid: 金字塔)<br>这座古老的金字塔是一项建筑奇迹，展示了建造者的智慧。</p></li><li><p>Running a marathon is a strenuous activity that requires months of training and preparation. (Strenuous: 费力的)<br>参加马拉松是一项费力的活动，需要数月的训练和准备。</p></li><li><p>Making the decision to move to a new city was a difficult moment for her, but she knew it was the right choice for her career. (Decision: 决定)<br>决定搬到一个新城市对她来说是一个困难的时刻，但她知道这是她事业上的正确选择。</p></li><li><p>The bee’s sting was painful but not serious, and the swelling went down after a few hours. (Sting: 蜇)<br>蜜蜂蜇的疼痛，但不严重，肿胀在几个小时后消退。</p></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>英语</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>计算机网络 —— 总纲</title>
    <link href="/2024/06/08/jsjwl/"/>
    <url>/2024/06/08/jsjwl/</url>
    
    <content type="html"><![CDATA[<p><img src="/pic/jsjwl-jsjwlcc.png" alt="计算机网络划分层次"><br><img src="/pic/jsjwl-jsjwlcc2.png" alt="计算机网络OSI七层协议"><br><img src="/pic/jsjwl-jsjwlcc3.png" alt="计算机网络五层详解"></p><h2 id="1-应用层-application-layer"><a href="#1-应用层-application-layer" class="headerlink" title="(1)应用层(application layer)"></a>(1)应用层(application layer)</h2><p>应用层是体系结构中的最高层。应用层的任务是通过应用进程间的交互来完成特定网络应用。应用层协议定义的是应用进程间通信和交互的规则。这里的进程(process)就是指主机中正在运行的程序。对于不同的网络应用需要有不同的应用层协议。在因特网中的应用层协议很多，如支持万维网应用的HTTP协议，支持电子邮件的SMTP协议，支持文件传送的FTP协议，等等。应用层交互的数据单元称为报文(message)。</p><h2 id="2-运输层-transport-layer"><a href="#2-运输层-transport-layer" class="headerlink" title="(2) 运输层(transport layer)"></a>(2) 运输层(transport layer)</h2><p>运输层的任务就是负责向两个主机中进程之间的通信提供通用的数据传输服务。由于一台主机可同时运行多个进程，因此运输层有复用和分用的功能。复用就是多个应用层进程可同时使用下面运输层的服务，分用与复用相反，是运输层把收到的信息分别交付上面应用层中的相应进程。<br>运输层主要使用以下两种协议：<br>● 传输控制协议TCP (Transmission Control Protocol)——提供面向连接的、可靠的数据传输服务，其数据传输的单位是报文段(segment)。<br>● 用户数据报协议 UDP (User Datagram Protocol)——提供无连接的、尽最大努力(best-effort)的数据传输服务（不保证数据传输的可靠性），其数据传输的单位是用户数据报</p><h2 id="3）网络层-network-layer"><a href="#3）网络层-network-layer" class="headerlink" title="(3）网络层(network layer)"></a>(3）网络层(network layer)</h2><p>网络层负责为分组交换网上的不同主机提供通信服务。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组或包(packet)进行传送。在TCP&#x2F;IP体系中，由于网络层使用IP协议，因此分组也叫作 IP数据报，或简称为数据报(datagram)。本书把“分组”和“数据报”作为同义词使用。网络层的另一个任务就是要选择合适的路由，使源主机运输层所传下来的分组能够通过网络中的路由器找到目的主机。因特网是一个很大的互联网，它由大量的异构(heterogeneous)网络通过路由器(router)相互连接起来。因特网主要的网络层协议是无连接的网际协议IP (Internet Protocol)和许多种路由选择协议，因此因特网的网络层也叫做网际层或IP层。</p><h2 id="4-数据链路层-data-link-layer"><a href="#4-数据链路层-data-link-layer" class="headerlink" title="(4)数据链路层(data link layer)"></a>(4)数据链路层(data link layer)</h2><p>数据链路层常简称为链路层，两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。在两个相邻结点之间传送数据时，数据链路层将网络层交下来的IP数据报组装成帧（framing），在两个相邻结点间的链路上传送帧（frame）。每一帧包括数据和必要的控制信息（如同步信息、地址信息、差错控制等）。</p><h2 id="5-物理层-physical-layer"><a href="#5-物理层-physical-layer" class="headerlink" title="(5)物理层(physical layer)"></a>(5)物理层(physical layer)</h2><p>在物理层上所传数据的单位是比特。发送方发送1（或0）时，接收方应当收到1（或0）而不是0（或1）。因此物理层要考虑用多大的电压代表“1”或“0”，以及接收方如何识别出发送方所发送的比特。物理层还要确定连接电缆的插头应当有多少根引脚以及各条引脚应如何连接。当然，解释比特代表的意思，就不是物理层的任务。传递信息所利用的一些物理媒体，如双绞线、同轴电缆、光缆、无线信道等，并不在物理层协议之内而是在物理层协议的下面。因此也有人把物理媒体当作第0层。</p><p>把数据（即数据单元加上控制信息）通过水平虚线直接传递给对方。这就是所谓的“对等层”(peer layers)之间的通信。我们以前经常提到的各层协议，实际上就是在各个对等层之间传递数据时的各项规定。协议是控制两个对等实体（或多个实体）进行通信的规则的集合。在协议的控制下，两个对等实体间的通信使得本层能够向上一层提供服务。要实现本层协议，还需要使用下面一层所提供的服务。</p><p>● 计算机网络最常用的性能指标是：速率、带宽、吞吐量、时延（发送时延、传播时延、处理时延、排队时延）、时延带宽积、往返时间和信道（或网络）利用率。<br>● 网络协议即协议，是为进行网络中的数据交换而建立的规则。计算机网络的各层及其协议的集合，称为网络的体系结构。<br>● 五层协议的体系结构由应用层、运输层、网络层（或网际层）、数据链路层和物理层组成。运输层最重要的协议是传输控制协议TCP和用户数据报协议UDP，而网络层最重要的协议是网际协议IP。</p>]]></content>
    
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>英语-单词6</title>
    <link href="/2024/06/08/English2-6/"/>
    <url>/2024/06/08/English2-6/</url>
    
    <content type="html"><![CDATA[<ol><li></li></ol><ul><li><p>The census, a comprehensive survey of the population, provides valuable data for government planning. (Census: 人口普查)<br>人口普查是对人口的全面调查，为政府规划提供了宝贵的数据。</p></li><li><p>Children who behave well in school are often rewarded for their good behavior. (Behave: 表现)<br>在学校表现良好的孩子通常会因为他们的良好行为而受到奖励。</p></li><li><p>The cathedral, with its magnificent architecture and intricate details, is a masterpiece of medieval craftsmanship. (Cathedral: 大教堂)<br>这座大教堂以其壮丽的建筑和精美的细节而闻名，是中世纪工艺的杰作。</p></li><li><p>The subject of the meeting was the upcoming changes to company policy. (Subject: 主题)<br>会议的主题是公司政策的即将变更。</p></li><li><p>Leaving food out in the sun can spoil it quickly. (Spoil: 腐败)<br>将食物暴露在阳光下会使其很快变质。</p></li><li><p>The village was without electricity for several days after the storm knocked down power lines. (Electricity: 电力)<br>风暴击倒电线后，村庄在数天内都没有电力。</p></li><li><p>She conducted a thorough investigation to uncover the truth. (Thorough: 彻底的)<br>她进行了彻底的调查，以揭示真相。</p></li><li><p>The payment is due at the end of the month. (Due: 到期)<br>付款应在月底到期。</p></li><li><p>The company decided to sue the contractor for breach of contract. (Sue: 控告)<br>公司决定起诉承包商违约。</p></li><li><p>The police used tear gas to disperse the crowd. (Disperse: 分散)<br>警察使用催泪瓦斯驱散人群。</p></li><li><p>The flight attendant ensured that all passengers were seated and secure before takeoff. (Attendant: 乘务员)<br>飞行员在起飞前确保所有乘客都就座并安全。</p></li><li><p>The party was held on the eve of the new year. (Eve: 前夕)<br>派对是在新年前夕举行的。</p></li><li><p>The boss was pleased with the team’s performance and praised them for their hard work. (Boss: 老板)<br>老板对团队的表现感到满意，并称赞他们的辛勤工作。</p></li><li><p>Is a tomato a fruit or a vegetable? (Tomato: 西红柿)<br>西红柿是水果还是蔬菜？</p></li></ul><ol start="2"><li></li></ol><ul><li><p>The cause of the conflict was rooted in a long history of territorial disputes and cultural differences. (Cause: 原因)<br>冲突的根源在于长期以来的领土争端和文化差异。</p></li><li><p>The constant noise from the construction site began to irritate the residents living nearby. (Irritate: 激怒)<br>建筑工地传来的持续噪音开始激怒附近居民。</p></li><li><p>The annual feast was a lavish affair, with an abundance of food and entertainment for all attendees. (Feast: 盛宴)<br>每年一度的盛宴是一场奢华的盛宴，为所有与会者提供了丰富的食物和娱乐。</p></li><li><p>She blushed and turned her cheek away when he tried to kiss her. (Cheek: 脸颊)<br>当他试图吻她时，她脸红并把脸颊转向一边。</p></li><li><p>The company implemented several security measures to secure the building from potential threats. (Secure: 保护)<br>公司实施了几项安全措施，以保护建筑免受潜在威胁。</p></li><li><p>There was a contradiction between what he said yesterday and what he is saying now. (Contradiction: 矛盾)<br>他昨天说的话和现在说的话之间存在矛盾。</p></li><li><p>The new CEO will be the successor to the current president of the company. (Successor: 继任者)<br>新任CEO将成为公司现任总裁的继任者。</p></li><li><p>The dress was made of a blend of silk and nylon, giving it a smooth and shiny appearance. (Nylon: 尼龙)<br>这件连衣裙是由丝绸和尼龙混合制成的，使其具有光滑而闪亮的外观。</p></li><li><p>The archaeologists uncovered an ancient burial site dating back over a thousand years. (Ancient: 古代的)<br>考古学家们发现了一个有千年历史的古代墓地。</p></li><li><p>The temptation to eat the delicious cake was too strong to resist. (Temptation: 诱惑)<br>吃那个美味蛋糕的诱惑力太强，无法抵挡。</p></li><li><p>The university announced an increase in tuition fees for the upcoming academic year. (Tuition: 学费)<br>大学宣布提高即将到来的学年的学费。</p></li><li><p>She couldn’t bear to face the truth, so she chose to ignore it instead. (Face: 面对)<br>她无法忍受面对事实，所以选择忽视它。</p></li><li><p>After much deliberation, they finally arrived at a solution to the complex problem. (Solution: 解决方案)<br>在经过多次深思熟虑后，他们终于找到了解决这个复杂问题的方案。</p></li><li><p>Many superstitions have been passed down through generations, despite lacking scientific evidence. (Superstition: 迷信)<br>许多迷信虽然缺乏科学依据，但仍然代代相传。</p></li><li><p>The transmission of the virus was traced back to a single source. (Transmission: 传播)<br>病毒的传播被追溯到一个单一的来源。</p></li></ul><ol start="3"><li></li></ol><ul><li><p>The scrap of paper contained a list of names and numbers, but its significance was unclear. (Scrap: 碎片)<br>这张纸片上列有一些名字和数字，但其意义不明。</p></li><li><p>The island is inhabited by a small community of fishermen who rely on the sea for their livelihood. (Inhabit: 居住)<br>这个岛屿上居住着一小群以海为生的渔民社区。</p></li><li><p>The weather forecast predicted that it may rain later in the day. (May: 可能)<br>天气预报预测今天晚些时候可能会下雨。</p></li><li><p>She looked absolutely gorgeous in her wedding dress, stunning everyone in attendance. (Gorgeous: 华丽的)<br>她穿着婚纱看起来绝对华丽，让所有在场的人都感到震惊。</p></li><li><p>The cluster of stars formed a beautiful constellation in the night sky. (Cluster: 群)<br>这群星星在夜空中形成了一个美丽的星座。</p></li><li><p>She sifted the flour before adding it to the mixture to ensure it was free of lumps. (Flour: 面粉)<br>她在将面粉加入混合物之前先过筛，以确保没有结块。</p></li><li><p>The file contained confidential information that was not meant to be shared with anyone outside the company. (File: 文件)<br>这个文件包含了不应该与公司外任何人分享的机密信息。</p></li><li><p>I couldn’t find my keys anywhere; I must have left them at home. (Anywhere: 任何地方)<br>我找不到我的钥匙了，我一定是把它们落在家里了。</p></li><li><p>The community gathered to celebrate the opening of the new park with music, food, and games. (Celebrate: 庆祝)<br>社区聚集在一起，通过音乐、食物和游戏来庆祝新公园的开放。</p></li><li><p>She became a widow after her husband passed away in a tragic accident. (Widow: 寡妇)<br>在丈夫在一次悲剧性事故中去世后，她成了寡妇。</p></li><li><p>The celebrity was surrounded by her entourage as she made her way into the restaurant. (Escort: 护送)<br>这位名人在进入餐厅时被她的随行人员围着。</p></li><li><p>The restaurant offered a series of special dishes for the holiday season. (Series: 系列)<br>这家餐厅为节日期间提供一系列特色菜肴。</p></li><li><p>The protest turned into a riot as tensions escalated between the demonstrators and the police. (Riot: 暴乱)<br>抗议活动由于示威者和警察之间的紧张局势升级而演变成了暴乱。</p></li><li><p>The buffet at the party offered a variety of delicious dishes for guests to enjoy. (Buffet: 自助餐)<br>派对上的自助餐提供了各种美味的菜肴供客人享用。</p></li></ul><ol start="4"><li></li></ol><ul><li><p>The fireman rushed into the burning building to rescue the trapped residents, risking his own life to save others. (Fireman: 消防员)<br>消防员冲进燃烧的建筑物，解救被困的居民，冒着生命危险救人。</p></li><li><p>The sudden drop in temperature caused the water in the pipes to freeze, leading to burst pipes and water damage. (Freeze: 冻结)<br>温度突然下降导致管道中的水结冰，导致管道破裂和水灾。</p></li><li><p>The soldiers surrounded the enemy camp, cutting off all escape routes. (Surround: 包围)<br>士兵们包围了敌营，切断了所有的逃跑路线。</p></li><li><p>The smell of fresh bread permeated the air, enticing customers into the bakery. (Permeate: 弥漫)<br>新鲜面包的香味弥漫在空气中，吸引顾客进入面包店。</p></li><li><p>The bank was robbed by a group of armed criminals who fled the scene with a large sum of money. (Bank: 银行)<br>银行被一群持械罪犯抢劫，他们带着大笔钱财逃离了现场。</p></li><li><p>The Roman Empire was one of the largest empires in history, spanning across three continents. (Empire: 帝国)<br>罗马帝国是历史上最大的帝国之一，横跨三大洲。</p></li><li><p>The wood split with a loud crack as the lumberjack chopped it with his axe. (Split: 劈开)<br>伐木工用斧头砍木头时，木头发出巨大的爆裂声。</p></li><li><p>The candidate was nervous during the job interview, but she answered the questions confidently. (Interview: 面试)<br>求职者在面试时很紧张，但她自信地回答了问题。</p></li><li><p>A flock of birds flew overhead, their wings beating against the sky as they migrated south for the winter. (Flock: 一群)<br>一群鸟在头顶飞过，它们的翅膀拍打着天空，迁徙到南方过冬。</p></li><li><p>The snake sheds its old skin to make way for new, healthier skin to grow. (Skin: 皮肤)<br>蛇蜕皮，让新的、更健康的皮肤生长。</p></li><li><p>The students started a petition to protest against the school’s decision to cancel the annual field trip. (Petition: 请愿)<br>学生们发起请愿，抗议学校取消每年的郊游活动。</p></li><li><p>Despite his disability, he was able to complete the marathon, inspiring others with his determination and perseverance. (Disable: 使残废)<br>尽管他有残疾，但他还是完成了马拉松比赛，用他的决心和毅力激励了其他人。</p></li></ul><ol start="5"><li></li></ol><ul><li><p>The country’s debt had reached an alarming level, prompting calls for austerity measures and economic reforms. (Debt: 债务)<br>该国的债务已经达到了一个危险的水平，促使人们呼吁实施紧缩措施和经济改革。</p></li><li><p>The red traffic light signifies that vehicles must stop, while green signifies they can proceed. (Signify: 表示)<br>红灯表示车辆必须停车，而绿灯表示可以前行。</p></li><li><p>He didn’t have a single penny to his name, having spent all his savings on the unexpected medical bills. (Penny: 便士)<br>他身无分文，把所有的积蓄都花在了意外的医疗费上。</p></li><li><p>Their relationship was built on mutual trust and reciprocal favors, with each one helping the other when needed. (Reciprocal: 互惠的)<br>他们的关系建立在相互信任和互惠的恩惠上，每个人在需要时都会帮助对方。</p></li><li><p>She wore a beautiful silk blouse to the party, accentuating her elegant style and grace. (Blouse: 女式衬衫)<br>她穿着一件漂亮的丝质女式衬衫去参加派对，突显出她优雅的风格和气质。</p></li><li><p>The fellowship of like-minded individuals provided him with a sense of belonging and support during difficult times. (Fellowship: 团体)<br>与志同道合的人们在困难时期给了他一种归属感和支持。</p></li><li><p>The mountain climbers were only equipped with the bare essentials, as they had to travel light to reach the summit. (Bare: 赤裸的)<br>登山者们只装备了基本的必需品，因为他们必须轻装前行才能到达山顶。</p></li><li><p>The old castle was now in ruins, with only remnants of its former grandeur still visible. (Remnant: 残余)<br>这座古老的城堡现在已经成为废墟，只剩下一些曾经辉煌的遗迹仍然可见。</p></li><li><p>He was a master of his craft, known for his exceptional skills and innovative techniques. (Master: 大师)<br>他是他所从事工艺的大师，以其卓越的技能和创新的技术而闻名。</p></li><li><p>Let me introduce you to my colleague, who is a renowned expert in the field of robotics. (Introduce: 介绍)<br>让我介绍一下我的同事，他是机器人领域的知名专家。</p></li><li><p>She decided to change careers and pursue her passion for art, leaving behind her successful but unfulfilling job in finance. (Career: 职业)<br>她决定转行，追求自己对艺术的热爱，离开了自己在金融界成功但不令人满足的工作。</p></li><li><p>The social implications of the new policy were far-reaching, affecting not just individuals but entire communities. (Social: 社会的)<br>新政策的社会影响是深远的，不仅影响个人，还影响整个社区。</p></li><li><p>She caught a cold after getting caught in the rain without an umbrella, leading to a few days of discomfort and illness. (Cold: 感冒)<br>她在没有雨伞的情况下被雨淋了，导致感冒，几天里感到不适和生病。</p></li><li><p>The elementary principles of mathematics form the foundation for more advanced concepts in the subject. (Elementary: 基本的)<br>数学的基本原理构成了这门学科更高级概念的基础。</p></li><li><p>The rape of the land by greedy developers left it barren and devoid of life, a stark reminder of the consequences of unchecked urbanization. (Rape: 掠夺)<br>贪婪的开发商对土地的掠夺使其荒芜，没有生命，这是一个鲜明的提醒，警示着城市化进程</p></li></ul><ol start="6"><li></li></ol><ul><li><p>The deliberate act of sabotage caused a major obstruction in the production line, leading to significant delays. (Deliberate: 故意的)<br>故意的破坏行为在生产线上造成了重大阻碍，导致了重大延误。</p></li><li><p>She raised her eyebrow in suspicion, doubting his explanation for the missing items. (Eyebrow: 眉毛)<br>她怀疑地挑起了眉毛，对他对于失踪物品的解释表示怀疑。</p></li><li><p>The motor of the car suddenly stopped working in the midst of the desert, leaving them stranded. (Motor: 发动机)<br>车子的发动机在沙漠中间突然停止工作，使他们陷入困境。</p></li><li><p>The beautiful sunrise painted the sky with vibrant colors, creating a stunning view. (Beautiful: 美丽的)<br>美丽的日出用生动的色彩描绘了天空，营造出了令人惊叹的景色。</p></li><li><p>He was slotted for the early morning shift, requiring him to wake up at 4 am every day. (Slot: 时间段)<br>他被安排在早班，每天需要在早上4点起床。</p></li><li><p>The zone was restricted to authorized personnel only, with strict security measures in place. (Zone: 区域)<br>这个区域只对授权人员开放，实行严格的安全措施。</p></li><li><p>His actions on Friday raised suspicion among his colleagues, who began to question his motives. (Friday: 星期五)<br>他在星期五的行动引起了同事们的怀疑，他们开始质疑他的动机。</p></li><li><p>The city council voted to restrict parking in the area, citing concerns over traffic congestion. (Restrict: 限制)<br>市议会投票决定限制该地区停车，理由是担心交通拥堵。</p></li><li><p>He found himself in the midst of a heated argument between two colleagues, unsure of how to defuse the situation. (Midst: 中间)<br>他发现自己卷入了两位同事之间的激烈争论中，不知道如何化解这种局面。</p></li><li><p>The obstruction on the road caused a traffic jam, delaying everyone’s morning commute. (Obstruction: 阻碍)<br>道路上的障碍导致交通堵塞，延误了每个人的上班路程。</p></li></ul><ol start="7"><li></li></ol><ul><li><p>The preacher, known for his fervent speeches, continued to preach despite the dwindling crowd. (Preach: 传道)<br>这位以热情洋溢的演讲而闻名的传教士，继续传道，尽管人群越来越少。</p></li><li><p>After much consideration, they decided to consider his proposal for the new project. (Consider: 考虑)<br>经过深思熟虑，他们决定考虑他对于新项目的提议。</p></li><li><p>The old oak tree stood tall and proud, a testament to the passage of time. (Oak: 橡树)<br>古老的橡树高高地矗立着，骄傲地见证着时间的流逝。</p></li><li><p>The radar system detected the incoming missiles, allowing for a timely response. (Radar: 雷达)<br>雷达系统探测到了即将到来的导弹，为及时响应提供了可能。</p></li><li><p>The solid foundation of their relationship helped them withstand many challenges. (Solid: 坚实的)<br>他们关系坚实的基础帮助他们经受了许多挑战。</p></li><li><p>A sudden illness seemed to paralyze him, leaving him bedridden for weeks. (Paralyze: 使瘫痪)<br>一场突如其来的疾病似乎让他瘫痪了，导致他卧床数周。</p></li><li><p>The resolution of the conflict required a compromise from both parties. (Resolution: 解决)<br>解决冲突需要双方做出妥协。</p></li><li><p>They lived in a remote village, far away from the hustle and bustle of the city. (Remote: 偏远的)<br>他们住在一个偏远的村庄，远离城市的喧嚣。</p></li><li><p>The arrow flew through the air, hitting the target with precision. (Arrow: 箭头)<br>箭头穿过空气，精确地击中了目标。</p></li><li><p>His loyalty to the company never wavered, even during tough times. (Loyalty: 忠诚)<br>他对公司的忠诚从未动摇，即使在困难时期也是如此。</p></li><li><p>The e-mail contained important information, so he forwarded it to the relevant department. (E-mail: 电子邮件)<br>电子邮件包含重要信息，因此他将其转发给了相关部门。</p></li><li><p>The holder of the winning ticket could claim their prize at the designated location. (Holder: 持有者)<br>获奖票的持有者可以在指定地点领取奖品。</p></li></ul><ol start="8"><li></li></ol><ul><li><p>The fundamental principles of democracy resemble those of justice and equality. (Fundamental: 基本的)<br>民主的基本原则类似于正义和平等的原则。</p></li><li><p>Without proper training, success in this field is difficult to achieve. (Without: 没有)<br>没有适当的训练，要在这个领域取得成功是很困难的。</p></li><li><p>Entry to the event is restricted to those with a valid ticket. (Entry: 进入)<br>只有持有效票的人才能进入活动现场。</p></li><li><p>The knight wielded his sword with great skill, defeating his opponent in battle. (Sword: 剑)<br>骑士挥舞着他的剑，技艺高超，击败了他的对手。</p></li><li><p>She is wholly dedicated to her work, often working long hours to achieve her goals. (Wholly: 完全地)<br>她完全致力于工作，经常加班工作以实现她的目标。</p></li><li><p>To travel to another country, you may need to apply for a visa. (Visa: 签证)<br>要前往另一个国家，您可能需要申请签证。</p></li><li><p>His birthday falls on the same day as mine, so we often celebrate together. (Birthday: 生日)<br>他的生日和我的生日是同一天，所以我们经常一起庆祝。</p></li><li><p>Marriage is a sacred institution, requiring commitment and dedication from both partners. (Marriage: 婚姻)<br>婚姻是一个神圣的制度，需要双方的承诺和奉献。</p></li><li><p>To excel in any field, one must practice diligently and consistently. (Practice: 练习)<br>要在任何领域取得成功，都必须勤奋和持之以恒地练习。</p></li><li><p>His actual intentions were unclear, leaving us to speculate about his true motives. (Actual: 实际的)<br>他的真实意图不明确，让我们推测他的真实动机。</p></li><li><p>Choosing a vocation that aligns with your interests can lead to a fulfilling career. (Vocation: 职业)<br>选择与自己兴趣相符的职业可以带来一个充实的职业生涯。</p></li></ul><ol start="9"><li></li></ol><ul><li><p>The classical music concert, with its bright and subtle melodies, was a welcome treat for the lord and his tribe. (Classical: 古典的; Bright: 明亮的; Subtle: 微妙的; Welcome: 受欢迎的; Lord: 领主; Tribe: 部落)<br>古典音乐会以其明亮而微妙的旋律，对于领主和他的部落来说是一个受欢迎的享受。</p></li><li><p>The danger of the situation was like a nail on toast, reminding everyone of the fragile nature of their virgin land. (Danger: 危险; Nail: 钉子; Toast: 烤面包; Virgin: 未开垦的; Land: 土地)<br>这种危险的局势就像是一根钉子在烤面包上，提醒着每个人他们未开垦土地的脆弱本质。</p></li><li><p>The beauty of the landscape, with its classical architecture and subtle colors, seemed to welcome and embrace the migrating tribe. (Beauty: 美丽; Landscape: 景观; Architecture: 建筑; Subtle: 微妙的; Migrate: 迁徙)<br>风景的美丽，其古典建筑和微妙的色彩，似乎在欢迎和拥抱着迁徙的部落。</p></li></ul><ol start="10"><li></li></ol><ul><li><p>The captive’s terror was inherent, a vicious cycle fed by the compound effects of his state of capture and the opponent’s relentless shouts of complaint. (Captive: 被囚禁的; Terror: 恐怖; Inherent: 内在的; Vicious: 恶毒的; Compound: 复合的)<br>囚禁者的恐惧是内在的，是囚禁状态和对手无休止的抱怨的复合效应所导致的恶性循环。</p></li><li><p>The federation’s concern was to retrieve the timber from the compound before the opponent could complain and shout about the inherent dangers of such a daring dine in the wild. (Federation: 联邦; Retrieve: 检索; Timber: 木材; Compound: 复合物; Dine: 进餐; Inherent: 内在的)<br>联邦的关注点是在对手抱怨和大声叫嚷有关这样一次大胆野外进餐的内在危险之前，从这个围栏中检索出木材。</p></li><li><p>Concern for the environment has led to stricter regulations on timber harvesting. (Concern: 关注)<br>对环境的关注导致了对木材采伐的更严格监管。</p></li><li><p>The captive audience listened intently as the speaker delivered his address. (Captive: 被俘虏的)<br>被俘虏的观众们专心听着演讲者的讲话。</p></li><li><p>The scientist spent years analyzing the compound to understand its properties. (Analyse: 分析)<br>科学家花了多年时间分析这种化合物，以了解其性质。</p></li><li><p>They shouted in unison, demanding justice for the oppressed. (Shout: 喊叫)<br>他们齐声高喊，要求为受压迫者伸张正义。</p></li><li><p>The state of the economy is often a topic of debate among politicians. (State: 状态)<br>经济状况经常是政治家们争论的话题。</p></li><li><p>She complained bitterly about the poor service at the restaurant. (Complain: 抱怨)<br>她对餐厅的糟糕服务大加抱怨。</p></li><li><p>They decided to dine at a quaint little bistro down the street. (Dine: 用餐)<br>他们决定在街对面一家别致的小餐馆用餐。</p></li><li><p>The concept of freedom is inherent in the ideals of democracy. (Inherent: 内在的)<br>自由的概念是民主理念中固有的。</p></li><li><p>The federation of nations worked together to address global issues. (Federation: 联邦)<br>各国联邦共同努力解决全球性问题。</p></li><li><p>The boxer’s opponent was known for his speed and agility in the ring. (Opponent: 对手)<br>拳击手的对手以在拳击比赛中的速度和敏捷闻名。</p></li><li><p>She managed to retrieve her lost documents from the archives. (Retrieve: 取回)<br>她设法从档案中取回了遗失的文件。</p></li><li><p>The terror of the attack left a lasting impact on the community. (Terror: 恐怖)<br>攻击的恐怖给社区留下了深刻的影响。</p></li><li><p>The dog’s vicious behavior was a result of poor training and socialization. (Vicious: 凶猛的)<br>狗的凶恶行为是训练不当和社交不良的结果。</p></li><li><p>The compound was a complex mixture of chemicals, requiring careful handling. (Compound: 化合物)<br>这种化合物是一种复杂的化学混合物，需要小心处理。</p></li></ul><ol start="11"><li></li></ol><ul><li><p>Emotion can sometimes cloud our judgment, whereas logic allows for clearer thinking. (Emotion: 情感；Whereas: 然而)<br>情感有时会影响我们的判断，而逻辑可以使思维更清晰。</p></li><li><p>I can see the benefit of your proposal, but I’m not sure it’s the best approach. (See: 看到；Benefit: 好处)<br>我能看到你的提议的好处，但我不确定这是否是最好的方法。</p></li><li><p>The loud noises from the construction site undermine the calm atmosphere of the neighborhood. (Undermine: 破坏；Calm: 安静)<br>建筑工地传来的巨大噪音破坏了社区的宁静氛围。</p></li><li><p>She gave a heartfelt speech at her uncle’s funeral, expressing her love and gratitude. (Speech: 演讲；Uncle: 叔叔)<br>她在叔叔的葬礼上发表了一篇发自内心的演讲，表达了她的爱和感激之情。</p></li><li><p>The canvas of the painting showed signs of wear and tear, indicating its age. (Canvas: 画布)<br>画布上显示出磨损的迹象，表明它的年代。</p></li><li><p>The disturbance caused by the hurricane was quite severe, leaving many without homes. (Disturbance: 干扰；Hurricane: 飓风；Quite: 相当)<br>飓风引起的干扰相当严重，导致许多人无家可归。</p></li></ul><ol start="12"><li></li></ol><ul><li><p>The post of chief executive requires a high level of responsibility and leadership. (Post: 职位)<br>首席执行官的职位需要承担高度的责任和领导力。</p></li><li><p>The government provided aid to the victims of the natural disaster. (Aid: 帮助)<br>政府向自然灾害的受害者提供了援助。</p></li><li><p>It has been raining heavily for the past month. (Month: 月份)<br>过去一个月一直在下大雨。</p></li><li><p>The instruction manual provides detailed guidance on how to assemble the furniture. (Instruction: 指导)<br>使用说明书详细介绍了如何组装家具的方法。</p></li><li><p>The intensity of the storm caused widespread damage to the area. (Intense: 强烈的)<br>暴风雨的强度造成了该地区的广泛破坏。</p></li><li><p>She is known for her generous contributions to charitable causes. (Generous: 慷慨的)<br>她以对慈善事业慷慨解囊而闻名。</p></li><li><p>The law prohibits certain types of behavior in public places. (Law: 法律)<br>法律禁止在公共场所进行某些类型的行为。</p></li><li><p>Astronomy is the study of celestial objects and phenomena. (Astronomy: 天文学)<br>天文学是研究天体和现象的科学。</p></li><li><p>We should learn from our mistakes to avoid repeating them in the future. (Learn: 学习)<br>我们应该从错误中吸取教训，避免将来重蹈覆辙。</p></li><li><p>The counter at the entrance was where visitors could obtain information. (Counter: 柜台)<br>入口处的柜台是游客获取信息的地方。</p></li><li><p>The company is conducting an internal investigation into the matter. (Internal: 内部的)<br>公司正在对此事进行内部调查。</p></li><li><p>The act of betraying one’s country is considered treason. (Treason: 叛国罪)<br>背叛自己国家的行为被视为叛国罪。</p></li><li><p>He spoke eloquently, thus convincing the audience of his argument. (Thus: 因此)<br>他雄辩地演讲，从而说服了听众。</p></li></ul><ol start="13"><li></li></ol><ul><li><p>There was a dispute over the ownership of the land between the two neighbors. (Dispute: 争议)<br>两个邻居之间关于土地所有权的争议。</p></li><li><p>She plays the violin beautifully and has won several awards for her performances. (Violin: 小提琴)<br>她演奏小提琴非常优美，曾因表演获得过几项奖项。</p></li><li><p>Playing badminton is a popular leisure activity in many countries. (Badminton: 羽毛球)<br>打羽毛球是许多国家的一种流行休闲活动。</p></li><li><p>The monotonous sound of the dripping water was enough to drive anyone crazy. (Monotonous: 单调的)<br>滴水的单调声音足以让任何人发疯。</p></li><li><p>They went for a walk around the lake to enjoy the peaceful scenery. (Lake: 湖)<br>他们在湖边散步，享受着宁静的风景。</p></li><li><p>The task was so tedious that she struggled to stay focused. (Tedious: 乏味的)<br>这项任务太乏味了，她很难保持专注。</p></li><li><p>The verb “to be” is one of the most commonly used words in the English language. (Verb: 动词)<br>“to be” 动词是英语中最常用的词之一。</p></li><li><p>The artist was working in his studio late into the night. (Studio: 工作室)<br>艺术家深夜在他的工作室里工作。</p></li><li><p>There was a long queue of people waiting to buy tickets for the concert. (Queue: 队列)<br>有一长队人在等待购买音乐会门票。</p></li><li><p>The texture of the fabric was soft and smooth to the touch. (Texture: 质地)<br>这种织物的质地摸起来又软又光滑。</p></li><li><p>She felt a sense of panic when she realized she had lost her phone. (Panic: 恐慌)<br>当她意识到手机丢失时，她感到恐慌。</p></li><li><p>The cloth was made from natural fibers and was very soft. (Cloth: 布料)<br>这块布料是由天然纤维制成的，手感很软。</p></li><li><p>She picked a ripe strawberry from the garden and ate it with delight. (Strawberry: 草莓)<br>她从花园里摘了一个熟透的草莓，高兴地吃了起来。</p></li></ul><ol start="14"><li></li></ol><ul><li><p>She used a spray bottle to water the plants in her garden. (Spray: 喷雾)<br>她用喷雾瓶给花园里的植物浇水。</p></li><li><p>He tried to grasp the concept of quantum physics, but found it difficult to understand. (Grasp: 理解)<br>他试图理解量子物理的概念，但发现很难理解。</p></li><li><p>It’s important to brush your teeth twice a day to maintain good oral hygiene. (Twice: 两次)<br>每天刷牙两次对保持口腔卫生很重要。</p></li><li><p>The consultant provided valuable advice on how to improve the company’s efficiency. (Consultant: 顾问)<br>顾问就如何提高公司效率提供了宝贵的建议。</p></li><li><p>She used bait to attract the fish to her fishing line. (Bait: 鱼饵)<br>她用鱼饵吸引鱼儿上钩。</p></li><li><p>Can you clarify what you meant by that statement? (Clarify: 澄清)<br>你能澄清一下你那个说法的意思吗？</p></li><li><p>She desired nothing more than to travel the world and see new places. (Desire: 渴望)<br>她最渴望的就是环游世界，看看新地方。</p></li><li><p>The concert was a stage for local talent to showcase their skills. (Stage: 舞台)<br>音乐会是本地才艺展示其技能的舞台。</p></li><li><p>He rested his head on the soft pillow and fell asleep. (Pillow: 枕头)<br>他把头靠在柔软的枕头上，睡着了。</p></li><li><p>His contribution to the project was invaluable and greatly appreciated. (Contribution: 贡献)<br>他对这个项目的贡献是无法估量的，受到了极大的赞赏。</p></li><li><p>The truck was loaded with goods for delivery to the warehouse. (Truck: 卡车)<br>卡车上装满了送往仓库的货物。</p></li></ul><ol start="15"><li></li></ol><ul><li><p>The physicist conducted experiments to better understand the nature of the universe. (Physicist: 物理学家)<br>物理学家进行实验，以更好地理解宇宙的本质。</p></li><li><p>The castle stood majestically on top of the hill, overlooking the village below. (Castle: 城堡)<br>城堡雄伟地矗立在山顶上，俯瞰着下面的村庄。</p></li><li><p>She reached out her hand to help him up from the ground. (Reach: 伸出)<br>她伸出手帮助他从地上站起来。</p></li><li><p>The head of the company announced a new policy to increase employee benefits. (Head: 负责人)<br>公司负责人宣布了一项新政策，以增加员工福利。</p></li><li><p>The judge handed down a harsh sentence to the criminal. (Sentence: 判决)<br>法官对罪犯判下了严厉的刑罚。</p></li><li><p>The citizens gathered to vote in the election for their new mayor. (Vote: 投票)<br>市民们聚集在一起投票选举新市长。</p></li><li><p>The mountaineer finally reached the peak of the mountain after days of climbing. (Peak: 山顶)<br>登山者经过几天的攀登终于到达了山顶。</p></li><li><p>The tenant complained to the landlord about the leaky roof in the apartment. (Tenant: 租户)<br>租户向房东抱怨公寓漏水的屋顶。</p></li><li><p>His degenerate behavior shocked his family and friends. (Degenerate: 堕落的)<br>他的堕落行为震惊了他的家人和朋友。</p></li><li><p>She felt proud of her daughter’s accomplishments in school. (Proud: 自豪的)<br>她为女儿在学校取得的成就感到骄傲。</p></li><li><p>The engineer designed a gigantic bridge to span the river. (Gigantic: 巨大的)<br>工程师设计了一座巨大的桥梁跨越河流。</p></li><li><p>She greeted me with a warm smile when I arrived home. (Smile: 微笑)<br>当我到家时，她用热情的微笑向我打招呼。</p></li><li><p>Domestic chores such as cooking and cleaning kept her busy all day. (Domestic: 家庭的)<br>像做饭和打扫卫生这样的家务活让她整天忙碌。</p></li><li><p>She knew how to knit and would often make sweaters for her family. (Knit: 编织)<br>她会织毛衣，经常为家人织毛衣。</p></li></ul><ol start="16"><li></li></ol><ul><li><p>Over time, the company was able to accumulate a vast amount of wealth through its successful business ventures. (Accumulate: 积累)<br>随着时间的推移，该公司通过其成功的商业冒险积累了大量财富。</p></li><li><p>The dress she chose was suitable for the occasion, blending elegance with comfort. (Suitable: 适合的)<br>她选择的连衣裙非常适合这个场合，既优雅又舒适。</p></li><li><p>The team gained momentum as they scored goal after goal, eventually winning the championship. (Momentum: 势头)<br>随着一球接着一球地进球，球队势头越来越猛，最终赢得了冠军。</p></li><li><p>The arch of the bridge was a marvel of engineering, spanning the river with grace and strength. (Arch: 拱形)<br>桥的拱形是工程技术的奇迹，优雅而坚固地横跨了河流。</p></li><li><p>The dish combined sweet and savory flavors, creating a unique and delicious taste. (Combine: 结合)<br>这道菜结合了甜味和咸味，营造出独特而美味的味道。</p></li><li><p>The soldiers dug a trench to protect themselves from enemy fire during the battle. (Trench: 战壕)<br>士兵们在战斗中挖掘了一条战壕，以保护自己免受敌人的火力攻击。</p></li><li><p>The industrial revolution marked the beginning of a new era, bringing significant changes to society. (Era: 时代)<br>工业革命标志着一个新时代的开始，给社会带来了重大变革。</p></li><li><p>His muscular physique was a result of years of training and hard work. (Muscular: 肌肉的)<br>他强健的体魄是多年训练和努力工作的结果。</p></li><li><p>The storm caused extensive damage to the town, leaving many buildings in ruins. (Damage: 损害)<br>暴风雨给小镇造成了大量的损害，许多建筑物都被毁坏了。</p></li><li><p>The invention of the wheel was a milestone in human history, revolutionizing transportation. (Invention: 发明)<br>轮子的发明是人类历史上的一个里程碑，彻底改变了交通运输。</p></li><li><p>The clothing of the period was elaborate and highly decorative, reflecting the opulence of the era. (Clothing: 服装)<br>那个时代的服装精心制作，装饰华丽，反映了时代的奢华。</p></li><li><p>She was nineteen years old when she first traveled abroad, eager to explore new cultures. (Nineteen: 十九)<br>她第一次出国旅行时19岁，渴望探索新的文化。</p></li><li><p>The postage for the package was surprisingly high, considering its small size. (Postage: 邮费)<br>考虑到包裹的小尺寸，邮费竟然很高。</p></li><li><p>The room was empty except for a single chair, placed in the center of the room. (Empty: 空的)<br>房间里除了一把放在房间中央的椅子外，空无一物。</p></li><li><p>The breadth of his knowledge was impressive, spanning a wide range of subjects. (Breadth: 广度)<br>他的知识面广泛，涵盖了多个领域。</p></li></ul><ol start="17"><li></li></ol><ul><li><p>The schedule for the project was carefully planned to ensure that each task was completed on time. (Schedule: 计划)<br>项目的计划安排得很仔细，以确保每个任务都能按时完成。</p></li><li><p>The company decided to release the new product during the holiday season to maximize sales. (Release: 发布)<br>公司决定在假期季推出新产品，以最大化销售。</p></li><li><p>The manager had to dismiss several employees due to budget cuts, which was a difficult decision. (Dismiss: 解雇)<br>由于预算削减，经理不得不解雇几名员工，这是一个艰难的决定。</p></li><li><p>The firefighter used a hose to extinguish the fire, aiming the water at the base of the flames. (Hose: 水龙带)<br>消防员使用水龙带扑灭火灾，将水喷射到火焰的底部。</p></li><li><p>After hours of work, she was finally able to finish the painting, which was a relief. (Finish: 完成)<br>经过几个小时的工作，她终于完成了这幅画，这让人感到宽慰。</p></li><li><p>The criminal was punished with a lash for his crimes, as was the custom in that society. (Lash: 鞭打)<br>罪犯按照当时社会的惯例被鞭打作为惩罚。</p></li><li><p>A heap of books lay on the table, waiting to be sorted and shelved. (Heap: 一堆)<br>一堆书摆在桌子上，等待着整理和上架。</p></li><li><p>The messenger delivered the urgent message to the recipient, ensuring its prompt delivery. (Messenger: 信使)<br>信使将紧急消息送到接收者手中，确保其及时送达。</p></li><li><p>The red wine was a perfect complement to the steak, enhancing its flavor. (Complement: 补充)<br>红酒和牛排搭配得恰到好处，提升了牛排的味道。</p></li><li><p>The artist used a variety of materials to create the sculpture, including wood, metal, and stone. (Material: 材料)<br>艺术家使用了各种材料来创作雕塑，包括木头、金属和石头。</p></li><li><p>She enjoyed a bowl of noodle soup for lunch, savoring the rich flavors. (Noodle: 面条)<br>她午餐时喜欢一碗面条汤，品尝着浓郁的味道。</p></li><li><p>The surfer rode the wave with skill and grace, thrilling the spectators on the shore. (Wave: 浪)<br>冲浪者技艺娴熟地顺着浪花滑行，让岸上的观众兴奋不已。</p></li><li><p>The room needed to be ventilated after painting to remove the strong smell of the paint. (Ventilate: 通风)<br>涂完漆后需要通风房间，以消除油漆的刺鼻气味。</p></li><li><p>The decision to circulate the memo to all employees was made to ensure everyone was informed. (Circulate: 传阅)<br>将备忘录传阅给所有员工的决定是为了确保每个人都得到通知。</p></li></ul><ol start="18"><li></li></ol><ul><li><p>He decided to own his mistakes and take responsibility for the project’s failure. (Own: 拥有)<br>他决定承认自己的错误，并对项目的失败负责。</p></li><li><p>She used a map to navigate through the city and find her way to the museum. (Map: 地图)<br>她使用地图在城市中导航，找到了通往博物馆的路。</p></li><li><p>The catering company provided a delicious meal for the wedding reception. (Cater: 承办酒席)<br>餐饮公司为婚宴提供了美味的餐点。</p></li><li><p>The sudden snowstorm caught everyone by surprise, covering the town in a thick blanket of snow. (Snowstorm: 暴风雪)<br>突然来袭的暴风雪让所有人都措手不及，将整个城镇覆盖在厚厚的雪花中。</p></li><li><p>The scope of the project was much larger than they had anticipated, requiring more resources and time. (Scope: 范围)<br>项目的范围远远超出了他们的预期，需要更多的资源和时间。</p></li><li><p>They set up camp at the base of the mountain, preparing for their ascent the next day. (Camp: 营地)<br>他们在山脚下搭起了帐篷，准备第二天攀登。</p></li><li><p>The new business venture proved to be profitable, bringing in a steady income for the partners. (Profitable: 有利可图)<br>这项新的商业冒险证明是有利可图的，为合伙人带来了稳定的收入。</p></li><li><p>The canyon was so wide that it took them hours to hike from one side to the other. (Wide: 宽阔)<br>峡谷非常宽阔，他们花了几个小时才从一边走到另一边。</p></li><li><p>They stood at the edge of the cliff, marveling at the breathtaking view below. (Cliff: 悬崖)<br>他们站在悬崖边上，惊叹着下方壮丽的景色。</p></li><li><p>The final score of the game was 3-2, with the home team taking the win. (Score: 比分)<br>比赛的最终比分是3比2，主队获胜。</p></li><li><p>She walked down the aisle, her eyes fixed on her soon-to-be husband waiting at the altar. (Aisle: 通道)<br>她走在通道上，眼睛盯着等在祭坛前的未婚夫。</p></li><li><p>There is a possibility of rain tomorrow, so you might want to bring an umbrella just in case. (Possibility: 可能性)<br>明天有可能下雨，所以你可能需要带把伞以防万一。</p></li><li><p>He gave her a signal to start the engine, and she followed his instructions. (Signal: 信号)<br>他给了她一个启动引擎的信号，她按照他的指示行事。</p></li><li><p>The vulnerable population in the area was evacuated to safety before the hurricane hit. (Vulnerable: 脆弱的)<br>在飓风袭击之前，该地区的脆弱人口已被疏散到安全地带。</p></li></ul><ol start="19"><li></li></ol><ul><li><p>The government’s failure to generate sustainable economic growth has led to widespread poverty. (Generate: 产生)<br>政府未能产生可持续的经济增长，导致了普遍的贫困。</p></li><li><p>The existence of life on other planets has long been a subject of scientific inquiry. (Existence: 存在)<br>其他行星上是否存在生命长期以来一直是科学探究的课题。</p></li><li><p>The organization aims to mobilize resources to support communities affected by natural disasters. (Mobilize: 动员)<br>该组织旨在动员资源支持受自然灾害影响的社区。</p></li><li><p>The new regulations pose a challenge to small businesses trying to comply with the law. (Pose: 提出)<br>新规定对试图遵守法律的小型企业构成挑战。</p></li><li><p>She couldn’t help but sob when she heard the tragic news. (Sob: 啜泣)<br>当她听到悲剧性的消息时，她情不自禁地哭泣起来。</p></li><li><p>The recovery of the economy after the recession was slow but steady. (Recovery: 恢复)<br>经济在经历了衰退后的复苏虽然缓慢但稳步。</p></li><li><p>He quickly realized his error and apologized for the confusion it caused. (Error: 错误)<br>他很快意识到自己的错误，并为造成的混乱道歉。</p></li><li><p>The void left by her absence was palpable, as if a part of the room was missing. (Void: 空白)<br>她离开后留下的空白是明显的，就像房间的一部分消失了一样。</p></li><li><p>The housing market has seen a steady increase in prices over the past few years. (Housing: 住房)<br>过去几年来，房屋市场的价格稳步上涨。</p></li><li><p>It is advisable to seek professional advice before making any major financial decisions. (Advisable: 明智的)<br>在做出任何重大财务决策之前最好寻求专业建议。</p></li><li><p>The moss-covered stone walls gave the garden a sense of ancient beauty. (Moss: 苔藓)<br>长满苔藓的石墙给花园增添了古老之美。</p></li><li><p>She used a brush to gently remove the dust from the old painting. (Brush: 刷子)<br>她用刷子轻轻地将古老画作上的灰尘清除干净。</p></li><li><p>His compassion for others was evident in the way he volunteered to help those in need. (Compassion: 同情心)<br>他对他人的同情心表现在他自愿帮助那些需要帮助的人的方式上。</p></li></ul><ol start="21"><li></li></ol><ul><li><p>The pungent smell of garlic filled the kitchen as she prepared dinner. (Garlic: 大蒜)<br>她在准备晚餐时，大蒜的刺鼻气味充满了厨房。</p></li><li><p>Their dwelling was a small, cozy cottage nestled in the countryside. (Dwelling: 住所)<br>他们的住所是一个坐落在乡村的小而舒适的小屋。</p></li><li><p>The treasure was hidden below the old oak tree, buried deep in the ground. (Below: 在…之下)<br>宝藏被藏在老橡树下面，深深地埋在地下。</p></li><li><p>Her narrow escape from the burning building was nothing short of miraculous. (Narrow: 狭窄的)<br>她从燃烧的建筑物中侥幸逃脱，简直是奇迹。</p></li><li><p>The new software update included several practical features to improve user experience. (Practical: 实用的)<br>新的软件更新包括几个实用的功能，以改善用户体验。</p></li><li><p>The cornfield stretched as far as the eye could see, a golden sea of crops. (Corn: 玉米)<br>玉米田一望无际，是一片金黄色的庄稼海洋。</p></li><li><p>She sat down at her desk, ready to tackle the day’s work with determination. (Desk: 书桌)<br>她坐在书桌前，准备下定决心完成当天的工作。</p></li><li><p>The conference room was spacious and well-equipped for their exclusive meeting. (Room: 房间)<br>会议室宽敞，设备齐全，适合他们的独家会议。</p></li><li><p>Despite his friends’ opinions, he decided to oppose the proposed plan. (Oppose: 反对)<br>尽管朋友们的意见，他决定反对提议的计划。</p></li><li><p>The new smartphone features a sophisticated design and advanced technology. (Sophisticated: 复杂的)<br>这款新智能手机具有精致的设计和先进的技术。</p></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>英语</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>英语-单词5</title>
    <link href="/2024/06/07/English2-5/"/>
    <url>/2024/06/07/English2-5/</url>
    
    <content type="html"><![CDATA[<ol><li></li></ol><ul><li><p>The frog, with its vibrant green skin and rhythmic croaking, became the children’s favorite subject of fascination. (Frog: 青蛙)<br>这只青蛙，拥有鲜艳的绿色皮肤和有节奏的呱呱叫声，成了孩子们最喜欢的好奇对象。</p></li><li><p>The menace of the approaching storm was palpable, as dark clouds gathered ominously on the horizon. (Menace: 威胁)<br>迫近风暴的威胁显而易见，乌云在地平线上不祥地聚集。</p></li><li><p>The cat’s tail twitched in anticipation, its eyes locked on the unsuspecting mouse. (Tail: 尾巴)<br>猫的尾巴在期待中抽动，眼睛紧盯着毫无察觉的老鼠。</p></li><li><p>The sheer awe of the magnificent mountain range left the travelers speechless. (Awe: 敬畏)<br>壮丽的山脉让旅行者们目瞪口呆，心生敬畏。</p></li><li><p>The apple, freshly picked from the orchard, was crisp and sweet, a perfect snack for the hike. (Apple: 苹果)<br>这颗新鲜采摘的苹果又脆又甜，是徒步旅行的完美小吃。</p></li><li><p>The government implemented strict measures to safeguard public health during the outbreak. (Safeguard: 保护)<br>政府在疫情爆发期间实施了严格的措施以保护公众健康。</p></li><li><p>He studied hard and, therefore, was able to achieve excellent results in his exams. (Therefore: 因此)<br>他努力学习，因此在考试中取得了优异的成绩。</p></li><li><p>The old steamer, with its billowing smokestacks, chugged steadily down the river. (Steamer: 汽船)<br>旧汽船带着滚滚的烟囱沿着河流稳稳地前行。</p></li><li><p>The engineer adjusted the settings to achieve the optimum performance of the machine. (Optimum: 最佳)<br>工程师调整设置以达到机器的最佳性能。</p></li><li><p>She smiled warmly and acknowledged his kind gesture with a nod. (Acknowledge: 承认)<br>她温暖地微笑，并点头承认了他的好意。</p></li><li><p>The lawyer, known for his sharp wit and relentless determination, won the case against all odds. (Lawyer: 律师)<br>这位律师以其敏锐的智慧和不懈的决心而闻名，在种种不利情况下赢得了案件。</p></li><li><p>The fact that he was late again did not go unnoticed by his boss. (Fact: 事实)<br>他再次迟到的事实没有被他的老板忽视。</p></li><li><p>The fuse of the bomb was ticking, creating a tense atmosphere among the defusal team. (Fuse: 保险丝)<br>炸弹的引线正在滴答作响，在拆弹小组之间制造了紧张的气氛。</p></li><li><p>The sticky note was placed on the fridge as a reminder to buy groceries. (Sticky: 粘的)<br>便签被贴在冰箱上，提醒购买杂货。</p></li></ul><ol start="2"><li></li></ol><ul><li><p>The cube, with its perfectly symmetrical faces and edges, served as a fundamental model in the study of geometry. (Cube: 立方体)<br>立方体以其完全对称的面和边成为几何研究中的基本模型。</p></li><li><p>His sly smile, which hinted at a mischievous plan, made everyone around him feel slightly uneasy. (Sly: 狡猾的)<br>他的狡猾微笑暗示着一个恶作剧的计划，使周围的每个人都有点不安。</p></li><li><p>The temperature fell to minus ten degrees overnight, causing the lake to freeze completely. (Minus: 负的)<br>温度一夜之间降到零下十度，导致湖泊完全结冰。</p></li><li><p>The aerial view of the city, captured from a helicopter, revealed the intricate layout of streets and buildings. (Aerial: 空中的)<br>从直升机拍摄的城市空中景观展现了街道和建筑的复杂布局。</p></li><li><p>The ribbon, a symbol of awareness and support, was worn by everyone at the event to show solidarity. (Ribbon: 丝带)<br>丝带作为意识和支持的象征，在活动中被每个人佩戴以示团结。</p></li><li><p>Each item in the collection was carefully cataloged and displayed in the museum’s main gallery. (Item: 物品)<br>收藏中的每件物品都被仔细编目并展示在博物馆的主画廊中。</p></li><li><p>The side of the mountain was covered in dense forest, making it nearly impossible to climb without proper equipment. (Side: 侧面)<br>山的一侧覆盖着茂密的森林，如果没有适当的装备几乎无法攀登。</p></li><li><p>His hearing was severely impaired after the accident, requiring him to use a hearing aid for the rest of his life. (Impair: 损害)<br>事故后他的听力严重受损，需要终身使用助听器。</p></li><li><p>The statue, crafted from marble, stood in the center of the plaza, attracting tourists from all over the world. (Statue: 雕像)<br>用大理石雕刻的雕像矗立在广场中央，吸引了来自世界各地的游客。</p></li><li><p>The red color of the ribbon denotes bravery and sacrifice, serving as a tribute to those who have served in the military. (Denote: 表示)<br>红色丝带象征着勇气和牺牲，向那些曾在军中服役的人致敬。</p></li><li><p>The quarrel between the two neighbors escalated quickly, drawing the attention of the entire street. (Quarrel: 争吵)<br>两个邻居之间的争吵迅速升级，吸引了整条街的注意。</p></li><li><p>The notable achievements of the scientist were recognized with numerous awards and accolades from prestigious institutions. (Notable: 显著的)<br>科学家的显著成就得到了许多著名机构的奖励和赞誉。</p></li><li><p>The torch, passed from one athlete to another, symbolized the unity and spirit of the international games. (Torch: 火炬)<br>火炬从一个运动员传到另一个运动员手中，象征着国际比赛的团结和精神。</p></li><li><p>Each part of the machine was meticulously assembled, ensuring that the final product would function flawlessly. (Part: 部分)<br>机器的每个部分都经过精心组装，确保最终产品能够完美运行。</p></li></ul><ol start="3"><li></li></ol><ul><li><p>The democratic process, which allows for the peaceful transfer of power, is a cornerstone of modern governance. (Democratic: 民主的)<br>允许权力和平转移的民主进程是现代治理的基石。</p></li><li><p>The gene, responsible for determining hereditary traits, plays a crucial role in the development of an organism. (Gene: 基因)<br>负责决定遗传特征的基因在生物体的发育中起着至关重要的作用。</p></li><li><p>The museum, with its vast collection of artifacts, provides valuable insight into the history and culture of ancient civilizations. (Museum: 博物馆)<br>博物馆以其丰富的文物收藏为人们提供了有关古代文明的宝贵见解。</p></li><li><p>The ocean, covering more than 70% of the Earth’s surface, is home to a diverse array of marine life. (Ocean: 海洋)<br>海洋覆盖了地球表面超过70％的面积，是许多种类海洋生物的家园。</p></li><li><p>The harvest, a result of months of hard work and toil, provides sustenance for the community through the winter months. (Harvest: 收获)<br>收获是数月辛勤劳作的结果，为社区在冬季提供了食物。</p></li><li><p>The spouse, often referred to as a life partner, is someone with whom one shares a deep emotional and intimate bond. (Spouse: 配偶)<br>配偶，通常被称为终身伴侣，是一个人与之分享深厚情感和亲密关系的人。</p></li><li><p>The basketball game, a showcase of skill and athleticism, drew a large crowd of enthusiastic fans. (Basketball: 篮球)<br>篮球比赛展示了技巧和运动能力，吸引了大批热情的球迷。</p></li><li><p>The durable fabric, designed to withstand wear and tear, is ideal for outdoor furniture and upholstery. (Durable: 耐用的)<br>耐用的织物设计用于经受磨损，非常适合户外家具和室内装饰。</p></li><li><p>The greenhouse, with its controlled environment, allows for the year-round cultivation of plants that would not otherwise thrive in the local climate. (Greenhouse: 温室)<br>温室通过其受控环境，使得原本无法在当地气候中茁壮成长的植物全年都可以栽培。</p></li><li><p>The reputation of the company, built over decades of honest and reliable service, is a testament to its commitment to excellence. (Reputation: 声誉)<br>公司数十年来忠实可靠的服务树立了良好的声誉，这证明了其对卓越的承诺。</p></li></ul><ol start="4"><li></li></ol><ul><li><p>Although he had no formal training in the field, his innate talent and dedication allowed him to excel as a garment designer. (Garment: 服装)<br>尽管他没有接受过该领域的正规培训，但他天生的才能和奉献精神使他在服装设计师中脱颖而出。</p></li><li><p>The dispute between the two parties seemed to dissolve as they engaged in constructive dialogue, finding common ground and mutual understanding. (Dissolve: 消除)<br>两党之间的争端似乎在他们进行建设性对话的过程中消解了，他们找到了共同点和相互理解。</p></li><li><p>The invalid, confined to his bed, relied on the kindness of others for his daily care and companionship. (Invalid: 病弱的)<br>这位病弱的人，卧床不起，依赖于他人的关怀和陪伴来度过每一天。</p></li><li><p>The mayor, as the highest-ranking official in the city, presided over the council meeting with authority and impartiality. (Preside: 主持)<br>市长作为城市中最高级别的官员，以权威和公正的态度主持了议会会议。</p></li><li><p>The staircase, with its ornate railings and grand design, served as a focal point of the mansion’s impressive entrance hall. (Staircase: 楼梯)<br>楼梯以其华丽的扶手和宏伟的设计，成为了豪宅引人注目的入口大厅的焦点。</p></li><li><p>The meadow, lush with wildflowers and grasses, was a peaceful retreat for those seeking solace in nature. (Meadow: 草地)<br>这片草地，长满了野花和草草，是那些寻求在大自然中寻找安慰的人们的宁静避所。</p></li><li><p>The custom, passed down through generations, was a symbol of cultural heritage and identity for the community. (Custom: 风俗)<br>这一习俗，代代相传，是社区文化遗产和身份认同的象征。</p></li><li><p>The pain, both physical and emotional, was evident in her eyes, betraying the stoic facade she tried so hard to maintain. (Pain: 疼痛)<br>痛苦，无论是身体上的还是情感上的，都清晰地表现在她的眼中，背叛了她努力维持的坚强外表。</p></li><li><p>The cardinal, with his distinctive red plumage, stood out among the other birds in the forest, a symbol of strength and vitality. (Cardinal: 红衣主教)<br>这只红衣主教，以其独特的红色羽毛，在森林中的其他鸟类中脱颖而出，象征着力量和活力。</p></li><li><p>The freedom, long cherished and hard-won, was a testament to the resilience and determination of the nation’s people. (Freedom: 自由)<br>这种自由，长期珍视并艰难获得，证明了国家人民的韧性和决心。</p></li><li><p>The nickname, affectionately given by her friends, was a reflection of her quirky personality and sense of humor. (Nickname: 绰号)<br>这个绰号，由她的朋友们深情赐予，反映了她古怪的个性和幽默感。</p></li><li><p>The ruin, once a majestic castle, now lay in decay, a haunting reminder of the empire’s former glory. (Ruin: 废墟)<br>这个废墟，曾经是一座雄伟的城堡，现在却已破败不堪，令人不忍卒睹，这是对帝国昔日辉煌的残酷提醒。</p></li><li><p>The sovereign, draped in robes of gold and purple, addressed the crowd with regal authority and grace. (Sovereign: 主权者)<br>这位主权者身披金紫色的长袍，以</p></li></ul><ol start="5"><li></li></ol><ul><li><p>The basement, with its dimly lit corridors and musty smell, was a stark contrast to the bright and airy rooms upstairs. (Basement: 地下室)<br>地下室里昏暗的走廊和发霉的气味与楼上明亮通风的房间形成了鲜明对比。</p></li><li><p>She was nominated for the prestigious award, a recognition of her outstanding contributions to the field. (Nominate: 提名)<br>她被提名为这一备受尊敬的奖项，这是对她在该领域的杰出贡献的认可。</p></li><li><p>The children gathered in the yard to play, their laughter and shouts echoing through the neighborhood. (Play: 玩耍)<br>孩子们聚集在院子里玩耍，他们的笑声和喊声在整个社区回荡。</p></li><li><p>As he walked along the uneven path, he stumbled over a rock and nearly fell. (Stumble: 绊倒)<br>当他沿着不平整的小路走时，他绊倒在一块石头上，险些摔倒。</p></li><li><p>The floor, covered in a thick layer of dust, creaked loudly with every step. (Floor: 地板)<br>地板上积满了厚厚的灰尘，每走一步都会发出刺耳的吱吱声。</p></li><li><p>The process of distilling the essence from the raw material required careful attention to detail. (Distill: 提炼)<br>从原材料中提炼精华的过程需要对细节进行仔细的关注。</p></li><li><p>His words had a powerful sway over the crowd, influencing their thoughts and actions. (Sway: 影响)<br>他的话对人群有着强大的影响力，影响着他们的思想和行动。</p></li><li><p>The company experienced a significant turnover in staff, leading to disruptions in operations. (Turnover: 营业额)<br>公司员工出现了较大的流动性，导致业务出现了中断。</p></li><li><p>After running for several miles without stopping, he finally collapsed, gasping for breath. (Gasp: 喘息)<br>在连续跑了几英里后，他终于倒下了，大口喘着气。</p></li><li><p>It was already eleven o’clock, and the streets were deserted as everyone had retired for the night. (Eleven: 十一)<br>已经是十一点钟了，街上空无一人，因为每个人都已经入睡了。</p></li><li><p>The ancient monument, dating back to the Roman era, stood as a testament to the glory of a bygone dynasty. (Monument: 纪念碑)<br>这座古老的纪念碑可以追溯到罗马时代，它见证了逝去王朝的荣耀。</p></li></ul><ol start="6"><li></li></ol><ul><li><p>The mechanic, with his meticulous attention to detail and expert knowledge, was able to diagnose and fix the complex issue with the engine. (Mechanic: 技工)<br>技工以他对细节的 meticulous 精心注意和专业知识，成功诊断并修复了引擎的复杂问题。</p></li><li><p>The rate at which technology is advancing is astounding, with new innovations and breakthroughs occurring almost daily. (Rate: 率)<br>技术进步的速度令人震惊，新的创新和突破几乎每天都在发生。</p></li><li><p>The autonomy granted to the team allowed them to make decisions independently, leading to a more efficient and effective work process. (Autonomy: 自主权)<br>给予团队的自主权使他们能够独立做出决策，从而实现更加高效和有效的工作流程。</p></li><li><p>The stress of the situation was palpable, with everyone feeling the pressure to perform at their best. (Stress: 压力)<br>情况的压力是明显的，每个人都感到要尽力而为。</p></li><li><p>The briefcase, containing important documents and files, was accidentally left behind in the rush to catch the train. (Briefcase: 公文包)<br>公文包里装着重要文件，因匆忙赶火车而被遗忘。</p></li><li><p>The vivid descriptions in the novel painted a picture of life in the 19th century, capturing the imagination of readers. (Vivid: 生动的)<br>小说中生动的描述描绘了19世纪的生活画面，激发了读者的想象力。</p></li><li><p>The patent for the new invention was granted after years of research and development, securing the inventor’s rights to the technology. (Patent: 专利)<br>经过多年的研究和开发，这项新发明的专利被授予，确保了发明者对该技术的权利。</p></li><li><p>The cable connecting the two devices was damaged, causing a loss of signal and disrupting the communication. (Cable: 电缆)<br>连接两个设备的电缆损坏了，导致信号丢失，影响了通讯。</p></li><li><p>The shilling, once a common unit of currency, is now largely obsolete, replaced by modern decimal-based systems. (Shilling: 先令)<br>先令曾经是一种常见的货币单位，现在已经基本过时，被现代的十进制制度所取代。</p></li><li><p>The gallon of milk purchased at the store was more than enough to last the week, providing plenty of calcium for the family. (Gallon: 加仑)<br>在商店购买的一加仑牛奶足够维持一周，为家人提供了充足的钙。</p></li></ul><ol start="7"><li></li></ol><ul><li><p>His gesture, a subtle movement of his hand, conveyed more than words ever could, expressing his deepest gratitude. (Gesture: 手势)<br>他的手势，一个微妙的手部动作，传达了比语言更多的信息，表达了他最深的感激之情。</p></li><li><p>The grocer, known for his friendly demeanor and quality products, was a beloved figure in the neighborhood. (Grocer: 杂货商)<br>这位杂货商以友好的态度和优质的产品而闻名，是社区中备受爱戴的人物。</p></li><li><p>Her healthy lifestyle, characterized by regular exercise and a balanced diet, contributed to her overall well-being. (Healthy: 健康)<br>她健康的生活方式，以定期锻炼和均衡饮食为特点，有助于她的整体健康。</p></li><li><p>The diameter of the tree, measured at its widest point, was an impressive six feet. (Diameter: 直径)<br>树的直径，在其最宽处测量，达到了令人印象深刻的六英尺。</p></li><li><p>The fountain, a centerpiece of the park, was a popular spot for visitors to relax and enjoy the scenery. (Fountain: 喷泉)<br>这个喷泉，公园的中心景观，是游客放松和欣赏风景的热门地点。</p></li><li><p>Otherwise, the plan was flawless, with every detail meticulously thought out and executed. (Otherwise: 否则)<br>否则，这个计划是完美无缺的，每一个细节都经过了周密的考虑和执行。</p></li><li><p>The occasional sound of a cricket chirping added to the peaceful ambiance of the countryside. (Occasional: 偶尔的)<br>偶尔传来的蟋蟀叫声增添了乡村的宁静氛围。</p></li><li><p>To her surprise, the club, usually reserved for members only, was open to the public for the event. (Surprise: 惊讶)<br>令她惊讶的是，这个俱乐部，通常只对会员开放，这次却向公众开放。</p></li><li><p>His arm, injured in the accident, required immediate medical attention. (Arm: 手臂)<br>他在事故中受伤的手臂需要立即接受医疗救治。</p></li><li><p>The amount of work required to complete the project was more than they had anticipated. (Amount: 数量)<br>完成这个项目所需的工作量超出了他们的预期。</p></li></ul><ol start="8"><li></li></ol><ul><li><p>The inheritance, though substantial, came with a heavy tax burden, prompting him to consider various options for its management. (Inheritance: 遗产)<br>遗产虽然丰厚，但附带了沉重的税收负担，促使他考虑各种管理方式。</p></li><li><p>The reliance on fossil fuels for energy production has led to environmental degradation and calls for a shift towards renewable sources. (Reliance: 依赖)<br>对化石燃料用于能源生产的依赖导致环境恶化，并呼吁转向可再生能源。</p></li><li><p>Despite his qualifications and experience, he felt a sense of inadequacy, unsure yet of his ability to handle the new role. (Yet: 然而)<br>尽管他具备资格和经验，但他对自己是否能够胜任新角色感到不安。</p></li><li><p>The degree of difficulty in the task was far greater than anticipated, requiring a reassessment of the approach and resources needed. (Degree: 程度)<br>任务的难度远远超出了预期，需要重新评估所需的方法和资源。</p></li><li><p>The reading of the will revealed surprising bequests, leaving the beneficiaries in a state of shock and disbelief. (Reading: 阅读)<br>遗嘱的阅读揭示了令人惊讶的遗赠，让受益人感到震惊和不可思议。</p></li><li><p>Learning the alphabet is a fundamental step in a child’s education, laying the groundwork for future language development. (Alphabet: 字母表)<br>学习字母表是孩子教育中的基础步骤，为未来的语言发展奠定基础。</p></li><li><p>The pet, a loyal companion for many years, provided comfort and companionship during difficult times. (Pet: 宠物)<br>这只宠物，多年来忠诚的伴侣，在困难时期提供了安慰和陪伴。</p></li><li><p>The sneak attack caught the enemy by surprise, leading to a swift and decisive victory for the attackers. (Sneak: 偷偷摸摸的)<br>突袭使敌人措手不及，导致攻击者迅速而决定性的胜利。</p></li><li><p>The flash flood, a result of heavy rainfall, caused widespread damage to homes and infrastructure in the area. (Flash: 闪光)<br>突发性洪水是由暴雨引起的，导致该地区的住房和基础设施遭受了广泛的破坏。</p></li><li><p>The bandage, though applied correctly, failed to stop the bleeding, indicating a more serious underlying injury. (Bandage: 绷带)<br>绷带虽然正确使用，但未能止血，表明存在更严重的潜在伤害。</p></li><li><p>The weekday routine of work and school left little time for leisure activities or relaxation during the week. (Weekday: 工作日)<br>工作日的工作和学校日常让人们在一周内很少有时间进行休闲活动或放松。</p></li><li><p>The dry climate of the region made agriculture challenging, requiring innovative irrigation methods to sustain crops. (Dry: 干燥)<br>该地区干燥的气候使农业面临挑战，需要创新的灌溉方法来维持作物生长。</p></li></ul><ol start="9"><li></li></ol><ul><li><p>The amiable demeanor of the host, combined with the exquisite dishes served, created a warm and welcoming atmosphere at the banquet. (Amiable: 和蔼可亲)<br>主人和蔼可亲的态度，加上精美的菜肴，为宴会营造了温馨而欢迎的氛围。</p></li><li><p>As a member of the committee, she was tasked with evaluating the situation and proposing solutions to address the issues at hand. (Member: 成员)<br>作为委员会的一员，她的任务是评估形势，并提出解决当前问题的方案。</p></li><li><p>The situation, though initially challenging, provided an opportunity for growth and development for the team. (Situation: 情况)<br>虽然情况一开始很具有挑战性，但为团队的成长和发展提供了机遇。</p></li><li><p>The hit song, with its catchy melody and meaningful lyrics, quickly rose to the top of the charts. (Hit: 热门歌曲)<br>这首热门歌曲以其动听的旋律和富有意义的歌词迅速登上了排行榜的榜首。</p></li><li><p>The dish, a traditional recipe passed down through generations, was a favorite among the locals. (Dish: 菜肴)<br>这道菜是代代相传的传统食谱，深受当地人喜爱。</p></li><li><p>The fierce competition among the participants pushed everyone to give their best performance. (Fierce: 激烈的)<br>参与者之间的激烈竞争推动着每个人发挥出最佳表现。</p></li><li><p>The import of foreign goods led to a decline in the sales of domestic products. (Import: 进口)<br>外国商品的进口导致了国内产品销售的下降。</p></li><li><p>The clock, a family heirloom, had been passed down for generations and was considered a precious treasure. (Clock: 钟表)<br>这个钟表是家族传世之物，被视为一宝贵的珍宝。</p></li><li><p>She made a passing mention of the issue during the meeting, but it was enough to pique everyone’s interest. (Mention: 提及)<br>她在会议中简单提到了这个问题，但已足以引起所有人的兴趣。</p></li><li><p>The noun, a word used to identify a person, place, or thing, plays a crucial role in sentence structure. (Noun: 名词)<br>名词是用来识别人、地方或事物的词，在句子结构中起着至关重要的作用。</p></li><li><p>The graffiti on the wall was an eyesore, prompting the authorities to take action to erase it. (Wall: 墙壁；Erase: 擦掉)<br>墙上的涂鸦令人讨厌，促使当局采取行动将其擦掉。</p></li><li><p>She decided to enroll in the course to further her education and expand her knowledge in the field. (Enroll: 注册)<br>她决定注册这门课程，以进一步提升自己的教育水平，并扩展在这个领域的知识。</p></li></ul><ol start="10"><li></li></ol><ul><li><p>Despite adverse weather conditions, they managed to complete the project on time and within budget. (Adverse: 不利的)<br>尽管天气条件不利，他们还是设法按时并在预算内完成了项目。</p></li><li><p>His explanation was vague and did not provide a clear understanding of the situation. (Vague: 模糊的)<br>他的解释含糊不清，没有清晰地说明情况。</p></li><li><p>The two companies agreed to cooperate on the development of the new product. (Cooperate: 合作)<br>这两家公司同意在新产品的开发上合作。</p></li><li><p>The lawn, freshly mowed and well-maintained, was a beautiful sight to behold. (Lawn: 草坪)<br>这片新修剪过且被良好维护的草坪，是一道美丽的风景。</p></li><li><p>The flowers emitted a fragrant scent that filled the room. (Fragrant: 芳香的)<br>这些花散发出一种芳香，弥漫在房间里。</p></li><li><p>She had to exert a lot of effort to lift the heavy box. (Exert: 施加)<br>她不得不花费很大力气才能把重箱子抬起来。</p></li><li><p>He’s alive and well, despite the rumors of his demise. (Alive: 活着的)<br>尽管有关他去世的谣言，他仍然活着，并且很好。</p></li><li><p>The brave firefighter rescued the cat from the burning building. (Brave: 勇敢的)<br>勇敢的消防员从着火的建筑物中救出了猫。</p></li><li><p>The super car broke the speed record at the race track. (Super: 超级的)<br>这辆超级跑车在赛车场打破了速度记录。</p></li><li><p>The robot was programmed to perform a variety of tasks autonomously. (Robot: 机器人)<br>这个机器人被编程成可以自主执行各种任务。</p></li><li><p>She could barely hear his whisper over the noise of the crowd. (Whisper: 低语)<br>在人群的喧嚣声中，她几乎听不到他的低语。</p></li><li><p>He put a mark next to the important points in the text for easy reference. (Mark: 标记)<br>他在文本中重要的地方旁边做了标记，方便查阅。</p></li><li><p>She included a comprehensive bibliography at the end of her research paper. (Bibliography: 参考文献)<br>她在研究论文的最后包含了一份详尽的参考文献。</p></li></ul><ol start="11"><li></li></ol><ul><li><p>Caution should be exercised when handling the chemicals, as they can be extremely hazardous if not used properly. (Caution: 小心)<br>在处理化学品时应该小心，如果不正确使用，它们可能会极为危险。</p></li><li><p>The hike up the mountain was challenging but rewarding, offering breathtaking views of the surrounding landscape. (Hike: 徒步旅行)<br>爬山徒步旅行充满挑战，但也很值得，可以欣赏到周围风景的壮丽景色。</p></li><li><p>Dust accumulated on the old furniture, giving it a dull and neglected appearance. (Dust: 灰尘)<br>灰尘在旧家具上积累，使其看起来黯淡而被忽视。</p></li><li><p>The length of the rope was carefully measured to ensure it would reach the ground safely. (Length: 长度)<br>绳子的长度经过精心测量，以确保它能够安全地到达地面。</p></li><li><p>The sportsman trained tirelessly, repeating the same drills and exercises day after day to improve his performance. (Repeatedly: 反复地)<br>运动员孜孜不倦地训练，每天反复进行相同的训练和练习，以提高自己的表现。</p></li><li><p>The cooperative effort of the team resulted in the successful completion of the project ahead of schedule. (Cooperative: 合作的)<br>团队的合作努力导致项目提前成功完成。</p></li><li><p>Capitalism, with its focus on free market principles, has been the dominant economic system in many countries. (Capitalism: 资本主义)<br>资本主义以其对自由市场原则的关注，已成为许多国家主导的经济体系。</p></li><li><p>The expansion of the company into new markets was met with both excitement and trepidation. (Expansion: 扩张)<br>公司进入新市场的扩张既令人兴奋又令人担忧。</p></li></ul><ol start="12"><li></li></ol><ul><li><p>The priest, with his solemn demeanor and comforting words, presided over the funeral service, offering solace to the grieving family. (Priest: 牧师)<br>牧师以庄严的态度和安慰的话语主持了葬礼仪式，给哀伤的家庭带来了安慰。</p></li><li><p>The long and arduous journey through the mountains tested their endurance and resolve, but they pressed on, determined to reach their destination. (Long: 长)<br>穿越山区漫长而艰辛的旅程考验了他们的耐力和决心，但他们坚持不懈，决心要到达目的地。</p></li><li><p>The apparent simplicity of the solution belied the complexity of the problem, requiring a more nuanced approach to be effective. (Apparent: 明显的)<br>解决方案的表面简单性掩盖了问题的复杂性，需要更加细致的方法才能有效。</p></li><li><p>The alternative route, though longer, offered a more scenic drive through the countryside, providing a welcome change of scenery. (Alternative: 另类的)<br>替代路线虽然更长，但途经乡村风景秀丽，提供了一种令人愉悦的景观变化。</p></li><li><p>The shuttle, a marvel of modern engineering, ferried passengers between the airport and the city with remarkable speed and efficiency. (Shuttle: 航天飞机)<br>航天飞机，作为现代工程的奇迹，以非凡的速度和效率在机场和城市之间运送乘客。</p></li><li><p>The singer’s melodious voice filled the concert hall, captivating the audience and leaving them in awe of her talent. (Sing: 唱歌)<br>歌手悦耳的歌声充满了音乐厅，吸引了观众，让他们对她的才华感到敬畏。</p></li><li><p>The skeleton, though missing some bones, provided valuable insights into the anatomy and structure of the ancient creature. (Skeleton: 骨骼)<br>骨架虽然缺少一些骨头，但为古代生物的解剖和结构提供了宝贵的见解。</p></li><li><p>The supersonic aircraft, with its sleek design and powerful engines, broke the sound barrier, marking a new era in aviation. (Supersonic: 超音速的)<br>超音速飞机以其流线型设计和强大的发动机突破了音障，开启了航空业的新时代。</p></li><li><p>The cautious approach to the negotiations, while frustratingly slow, ensured that all parties were heard and their concerns addressed. (Cautious: 谨慎的)<br>谨慎对待谈判虽然进展缓慢，但确保了各方发言并解决了他们的关切。</p></li><li><p>The bureau, with its cluttered desk and stacks of paperwork, was a testament to the busy nature of its occupant’s work. (Bureau: 局)<br>局内乱七八糟的桌子和一堆堆的文件证明了占据者工作繁忙的性质。</p></li><li><p>The decision to embark on the expedition was met with both excitement and trepidation, as the team prepared for the unknown challenges ahead. (Embark: 开始)<br>开始探险的决定既令人兴奋又让人忐忑不安，因为团队正为前方未知的挑战做准备。</p></li><li><p>The system, though efficient, was not without its flaws, as evidenced by the occasional breakdowns and malfunctions. (System: 系统)<br>这个系统虽然效率高，但也不是没有缺陷，偶尔会出现故障和失灵。</p></li><li><p>The lunar landscape, with its barren terrain and desolate beauty, was unlike anything they had ever seen on Earth. (Lunar: 月球的)<br>月球的景观，其贫瘠的地形和荒凉的美丽，与他们在地球上见过</p></li></ul><ol start="13"><li></li></ol><ul><li><p>The student, known for his exceptional academic achievements, was awarded a scholarship to study abroad. (Student: 学生)<br>这位学生因其出色的学业成绩而获得了一笔留学奖学金。</p></li><li><p>The foreigner, despite facing language barriers, was determined to immerse himself in the local culture and learn the native language. (Foreigner: 外国人)<br>这位外国人尽管面临语言障碍，但他决心沉浸在当地文化中，学习本国语言。</p></li><li><p>She washed the dishes with meticulous care, ensuring they were spotless and sparkling. (Wash: 洗)<br>她非常细心地洗碗，确保它们洁净无瑕。</p></li><li><p>In contrast to her outgoing sister, she was shy and reserved, often preferring solitude to social gatherings. (Contrast: 对比)<br>与她外向的姐姐相反，她害羞而内向，通常更喜欢独处而不是社交聚会。</p></li><li><p>The cock crowed loudly, signaling the break of dawn and the start of a new day. (Cock: 公鸡)<br>公鸡啼叫着，宣告了黎明的到来，新的一天开始了。</p></li><li><p>The naked truth was finally revealed, leaving everyone stunned by its harsh reality. (Naked: 裸露的)<br>裸露的真相最终被揭示，让每个人都对其残酷的现实感到震惊。</p></li><li><p>He lit a cigarette and took a long drag, the smoke swirling around him in lazy curls. (Cigarette: 香烟)<br>他点燃了一支香烟，深深地吸了一口，烟雾在他周围慵懒地卷曲着。</p></li><li><p>He used a screwdriver to tighten the loose screw, ensuring the shelf was securely fixed to the wall. (Screw: 螺丝钉)<br>他用螺丝刀拧紧了松动的螺丝，确保架子牢固地固定在墙上。</p></li><li><p>The fresh scent of pine filled the air, a refreshing change from the city’s usual smog. (Fresh: 新鲜的)<br>松树的清新香气弥漫在空气中，与城市常见的雾霾形成了一种清新的对比。</p></li><li><p>At the outset of the project, she had high hopes for its success, but unforeseen challenges soon arose. (Outset: 开始)<br>项目开始时，她对其成功抱有很高的期望，但很快出现了意想不到的挑战。</p></li><li><p>He wanted nothing more than to spend a quiet evening at home, away from the hustle and bustle of the city. (Want: 想要)<br>他最想的就是在家里度过一个安静的夜晚，远离城市的喧嚣。</p></li><li><p>She measured out an ounce of flour for the recipe, ensuring the perfect consistency for the dough. (Ounce: 盎司)<br>她称了一盎司面粉，确保面团的浓度完美。</p></li><li><p>Despite her eccentric behavior, she was completely sane and rational in her decision-making. (Sane: 神志清醒的)<br>尽管她行为古怪，但在做决定时她完全神志清醒和理性。</p></li><li><p>They sat together on the bench, enjoying the warm sunshine and each other’s company. (Bench: 长凳)<br>他们坐在长凳上，享受着温暖的阳光和彼此的陪伴。</p></li><li><p>The park was littered with trash, a stark contrast to its usual pristine condition. (Litter: 杂物)<br>公园里到处是垃圾，与通常的清洁状态形成了鲜明的对比。</p></li><li><p>He was thirteen years old, on the cusp of adolescence, eager to explore the world and all its wonders. (Thirteen: 十三)<br>他十三岁，正值青春期的开始，渴望探索这个世界及其</p></li></ul><ol start="14"><li></li></ol><ul><li><p>The gentle breeze, carrying the scent of blooming flowers, provided a soothing respite from the summer heat. (Gentle: 温和)<br>轻柔的微风带着盛开花朵的香气，为夏日的炎热提供了舒缓的喘息之机。</p></li><li><p>The comparison between the two theories revealed striking similarities and subtle differences that were previously unnoticed. (Comparison: 比较)<br>对这两个理论的比较揭示了惊人的相似之处和之前未曾注意到的细微差别。</p></li><li><p>Her voice, soft yet commanding, resonated through the hall, capturing the attention of everyone present. (Voice: 声音)<br>她的声音，柔和而又有命令力，回荡在大厅里，吸引了在场所有人的注意。</p></li><li><p>Despite thorough searching, the missing documents could not be located, leading to concerns about their possible misplacement. (Missing: 失踪)<br>尽管进行了彻底的搜索，但找不到丢失的文件，引发了对可能被错放的担忧。</p></li><li><p>The sudden blow to the economy sent shockwaves through the nation, prompting urgent measures to stabilize the situation. (Blow: 打击)<br>经济的突然打击在整个国家引起了震动，促使采取紧急措施稳定局势。</p></li><li><p>The messy room, cluttered with books and papers, reflected the chaotic state of the owner’s mind. (Mess: 混乱)<br>整理杂乱的房间里堆满了书籍和文件，反映了主人心境的混乱状态。</p></li><li><p>The region, known for its diverse wildlife and stunning landscapes, attracted tourists from all over the world. (Region: 地区)<br>这个以其丰富多样的野生动植物和令人惊叹的景观而闻名的地区吸引了来自世界各地的游客。</p></li><li><p>Efforts to restore the ancient temple to its former glory were met with numerous challenges, including funding and logistical issues. (Restore: 恢复)<br>恢复古庙昔日荣光的努力面临着诸多挑战，包括资金和后勤问题。</p></li><li><p>With determination and perseverance, he forged forward despite the obstacles, never losing sight of his ultimate goal. (Forward: 向前)<br>他坚定不移、孜孜不倦地向前迈进，尽管遇到了种种障碍，但从未忘记自己的终极目标。</p></li><li><p>The infrared camera detected heat signatures in the dark, revealing hidden objects that were otherwise invisible. (Infrared: 红外线)<br>红外摄像机在黑暗中检测到了热信号，揭示了否则看不见的隐藏物体。</p></li><li><p>The link between the two events was tenuous at best, relying more on speculation than concrete evidence. (Link: 关联)<br>这两个事件之间的联系最多只能说是牵强的，更多地依靠猜测而不是具体证据。</p></li><li><p>The sudden chill in the air made her shiver, a reminder that winter was fast approaching. (Shiver: 发抖)<br>突然的寒意让她打了个冷颤，提醒着冬天即将来临。</p></li><li><p>The thorn on the rose bush pricked her finger, causing a small but painful puncture. (Prick: 刺)<br>玫瑰丛上的刺扎破了她的手指，造成了一个小但疼痛的伤口。</p></li></ul><ol start="15"><li></li></ol><ul><li><p>The headline, bold and eye-catching, dominated the front page of the newspaper, grabbing the attention of passersby. (Headline: 大字标题)<br>大字标题，醒目夺目，主导了报纸的头版，吸引了路人的注意。</p></li><li><p>As a grown-up, he felt a sense of responsibility and duty towards his family, which guided his decisions and actions. (Grown-up: 成年人)<br>作为一个成年人，他对家庭有一种责任和义务感，这指导着他的决定和行动。</p></li><li><p>She would pretend to be interested, but her mind was elsewhere, preoccupied with her own thoughts. (Pretend: 假装)<br>她会假装感兴趣，但她的心思在别处，被自己的想法所困扰。</p></li><li><p>The tank, filled with water, was used to irrigate the fields and provide much-needed hydration for the crops. (Tank: 水箱)<br>这个装满水的水箱被用来灌溉田地，为庄稼提供急需的水分。</p></li><li><p>His wealth, accumulated through years of hard work and wise investments, allowed him to live a life of luxury and comfort. (Wealth: 财富)<br>他通过多年的辛勤工作和明智的投资积累起来的财富，让他过上了奢华舒适的生活。</p></li><li><p>She always tried to do at least one good deed every day, believing that even the smallest act of kindness could make a difference. (Least: 至少)<br>她总是努力每天至少做一件好事，相信即使是最小的善举也能产生影响。</p></li><li><p>The promise of a bonus served as an incentive for the employees to work harder and meet their targets. (Incentive: 激励)<br>奖金的承诺作为一种激励，鼓励员工更加努力地工作，达到他们的目标。</p></li><li><p>The athlete, with his determination and perseverance, overcame numerous challenges to achieve his goal of winning the gold medal. (Athlete: 运动员)<br>运动员凭借他的决心和毅力，克服了许多挑战，实现了赢得金牌的目标。</p></li><li><p>The crowd’s enthusiasm was infectious, spreading like wildfire and igniting a passion in everyone present. (Enthusiasm: 热情)<br>人群的热情是具有感染力的，像野火般蔓延开来，激发了在场每个人的激情。</p></li><li><p>She would instruct her students to pay attention to the smallest details, believing that they could make or break a work of art. (Instruct: 指导)<br>她会指导她的学生注意最细微的细节，认为这些细节可以决定一件艺术品的成败。</p></li><li><p>He added a spoonful of sugar to his tea, stirring it gently until it dissolved completely, adding a hint of sweetness to his morning routine. (Sugar: 糖)<br>他在茶里加了一勺糖，轻轻搅拌直到完全溶解，给他的早晨增添了一丝甜蜜。</p></li><li><p>Given the choice between two options, he chose the one that offered more freedom and flexibility, aligning with his values and goals. (Choice: 选择)<br>在两种选择之间，他选择了那个提供更多自由和灵活性的选项，符合他的价值观和目标。</p></li><li><p>The militant group, known for its radical ideology, was determined to renew its efforts to achieve its extremist goals. (Militant: 激进分子)<br>这个激进组织以其激进的意识形态而闻名，决心重新努力实现其极端主义目标。</p></li><li><p>The crew, consisting of experienced sailors and skilled technicians, worked together seamlessly to ensure the ship’s safe passage. (Crew: 船员)<br>由经验丰富的海员</p></li></ul><ol start="16"><li></li></ol><ul><li><p>The art collection, consisting of priceless masterpieces, was a source of pride and joy for the museum. (Collection: 收藏品)<br>这个艺术收藏品由无价的杰作组成，是博物馆的骄傲和喜悦之源。</p></li><li><p>The family continued to mourn the loss of their loved one, finding solace in each other’s company during this difficult time. (Mourn: 哀悼)<br>家人继续为他们所爱之人的离去而哀悼，在这段困难时期互相陪伴，寻找安慰。</p></li><li><p>The scientist studied the substance under the microscope, analyzing its properties and composition in detail. (Substance: 物质)<br>科学家在显微镜下研究这种物质，详细分析其性质和组成。</p></li><li><p>In case of an immediate threat, the emergency procedures would be activated to ensure the safety of the personnel. (Immediate: 立即的)<br>如果有立即的威胁，将启动紧急程序，确保人员的安全。</p></li><li><p>The laser beam, invisible to the naked eye, was used for precision cutting in delicate surgeries. (Laser: 激光)<br>激光束对肉眼不可见，在精细手术中用于精密切割。</p></li><li><p>In accordance with company policy, the employees were required to complete their shift before leaving the premises. (Accord: 符合)<br>根据公司政策，员工必须在离开工作场所之前完成他们的班次。</p></li><li><p>The river’s current was strong, making it difficult for the swimmers to make progress against it. (Current: 水流)<br>河流的水流很强，使得游泳者难以逆流而上。</p></li><li><p>The patient’s lung capacity was severely compromised, requiring immediate medical attention. (Lung: 肺)<br>患者的肺容量严重受损，需要立即进行医疗处理。</p></li><li><p>The locomotive, fueled by coal, chugged along the tracks, pulling a long line of freight cars behind it. (Locomotive: 火车头)<br>燃煤的火车头沿着轨道呼啸而过，后面拖着一长串货车。</p></li><li><p>The pilot skillfully maneuvered the plane through turbulent weather, ensuring a smooth and safe landing. (Pilot: 飞行员)<br>飞行员熟练地操纵飞机穿越汹涌的天气，确保了一次顺利而安全的着陆。</p></li><li><p>The compartment was small and cramped, barely enough room for the passengers to sit comfortably. (Compartment: 车厢)<br>车厢又小又狭窄，乘客们几乎没有足够的空间坐得舒服。</p></li><li><p>The clown’s antics never failed to amuse the children, bringing smiles and laughter wherever he went. (Amuse: 逗乐)<br>小丑的滑稽动作总是能逗乐孩子们，无论他走到哪里都能带来笑声和欢笑。</p></li><li><p>The sound of the horn, loud and clear, signaled the beginning of the race, much to the excitement of the spectators. (Horn: 喇叭)<br>喇叭声响亮清晰，标志着比赛的开始，令观众们兴奋不已。</p></li></ul><ol start="17"><li></li></ol><ul><li><p>The punishment, though severe, was deemed necessary to maintain order and discipline within the institution. (Punish: 惩罚)<br>惩罚虽然严厉，但被认为是必要的，以维持机构内的秩序和纪律。</p></li><li><p>Her movements on the dance floor were so graceful that she seemed to glide effortlessly across the room. (Graceful: 优雅的)<br>她在舞池里的动作如此优雅，以至于她看起来毫不费力地在房间里滑行。</p></li><li><p>The plan he devised was intricate and detailed, taking into account every possible scenario and outcome. (Devise: 设计)<br>他设计的计划复杂而详细，考虑到了每一种可能的情况和结果。</p></li><li><p>The thorough preparation before the event ensured that everything ran smoothly and without any hitches. (Preparation: 准备)<br>活动前的充分准备确保了一切顺利进行，没有任何问题。</p></li><li><p>In conclusion, the research findings suggest a strong correlation between the two variables. (Conclusion: 结论)<br>总之，研究结果表明这两个变量之间存在着很强的相关性。</p></li><li><p>The order was given to execute the plan immediately, without any further delay. (Execute: 执行)<br>下令立即执行计划，不再拖延。</p></li><li><p>The grass, lush and green, stretched out as far as the eye could see, a testament to the fertile soil. (Grass: 草)<br>草地郁郁葱葱，绿草如茵，一望无际，证明了土地肥沃。</p></li><li><p>He was issued a ticket for parking in a no-parking zone, much to his dismay. (Ticket: 罚单)<br>他因在禁停区停车被开了罚单，让他感到非常沮丧。</p></li><li><p>It is unwise to underestimate her abilities; she is capable of achieving great things if given the chance. (Underestimate: 低估)<br>低估她的能力是不明智的；如果给予机会，她能够取得巨大成就。</p></li><li><p>The day dawned bright and clear, promising a day full of possibilities and adventures. (Day: 天)<br>一天开始变得明亮而清晰，预示着充满可能性和冒险的一天即将到来。</p></li><li><p>The object, a small figurine, was found buried deep within the ancient ruins. (Object: 物体)<br>这个物体，一尊小小的雕像，被发现埋藏在古代遗址深处。</p></li><li><p>Somebody must have forgotten to lock the door, as it was wide open when we arrived. (Somebody: 某人)<br>必定有人忘记锁门了，因为当我们到达时门是敞开的。</p></li><li><p>Despite the misfortune of losing his job, he remained optimistic about finding a new opportunity. (Misfortune: 不幸)<br>尽管失去了工作很不幸，但他对找到新机会保持乐观。</p></li><li><p>It was just a misunderstanding; there’s no need to make such a fuss about it. (Just: 只是)<br>这只是一个误会；没必要为此大惊小怪。</p></li><li><p>The consumption of alcohol is strictly prohibited on these premises. (Alcohol: 酒精)<br>在这些场所严禁饮酒。</p></li></ul><ol start="18"><li></li></ol><ul><li><p>The zip of the jacket, though small, was crucial for keeping out the cold wind. (Zip: 拉链)<br>夹克的拉链虽小，但对防止寒风侵入至关重要。</p></li><li><p>In the virtual world of online gaming, players can interact with each other in ways that mimic real-life social interactions. (Virtual: 虚拟的)<br>在在线游戏的虚拟世界中，玩家可以以模拟现实生活社交互动的方式相互交流。</p></li><li><p>The desert, with its harsh conditions and sparse vegetation, is a challenging environment for any living creature. (Desert: 沙漠)<br>沙漠的恶劣条件和稀疏植被对于任何生物来说都是一个具有挑战性的环境。</p></li><li><p>Regular exercise can help strengthen muscles and improve overall health. (Strengthen: 加强)<br>定期锻炼可以帮助加强肌肉，改善整体健康。</p></li><li><p>Proper maintenance of machinery is essential to ensure its longevity and efficiency. (Maintenance: 维护)<br>对机器的正确维护对于确保其长期使用和高效运转至关重要。</p></li><li><p>The fall from the ladder could easily injure him if he’s not careful. (Injure: 伤害)<br>如果不小心，从梯子上摔下来可能会让他受伤。</p></li><li><p>Life in the bustling city can be quite different from life in a quiet village. (Life: 生活)<br>繁华城市的生活与宁静村庄的生活大不相同。</p></li><li><p>The injury was not only physical but also deeply painful emotionally. (Painful: 痛苦的)<br>这次伤害不仅是身体上的，还在情感上造成了极大的痛苦。</p></li><li><p>In accordance with company policy, all employees must attend the safety training. (Accordance: 依照)<br>根据公司政策，所有员工必须参加安全培训。</p></li><li><p>The host of the party greeted each guest with a warm smile. (Host: 主人)<br>派对的主人用热情的微笑迎接每一位客人。</p></li><li><p>The path toward success is often filled with challenges and obstacles. (Toward: 朝向)<br>成功的道路往往充满了挑战和障碍。</p></li><li><p>The round shape of the table allowed everyone to see and hear each other easily. (Round: 圆形)<br>圆桌的形状使得每个人都可以轻松地看到和听到彼此。</p></li><li><p>The payment for the services rendered was made promptly and without any issues. (Payment: 付款)<br>对所提供服务的支付及时进行，没有任何问题。</p></li></ul><ol start="19"><li></li></ol><ul><li><p>The lapse in judgment led to a series of unfortunate events that could have been avoided with more careful consideration. (Lapse: 失误)<br>判断上的失误导致了一连串不幸事件的发生，如果更加谨慎考虑，本可避免。</p></li><li><p>Tonight, under the starry sky, we shall witness the beauty of nature’s spectacle unfold before our eyes. (Tonight: 今晚)<br>今晚，在繁星点点的天空下，我们将目睹大自然壮丽景观的展现。</p></li><li><p>Suppose we were to take a different approach to the problem, would the outcome be more favorable? (Suppose: 假设)<br>假设我们采取了不同的方法来解决问题，结果会更有利吗？</p></li><li><p>The rural landscape, with its vast fields and quiet villages, offers a peaceful retreat from the hustle and bustle of city life. (Rural: 农村的)<br>农村的景观，有着广阔的田野和宁静的村庄，为人们提供了一个远离城市生活喧嚣的宁静避所。</p></li><li><p>Before making a decision, it is advisable to consult with experts in the field to gather more information. (Consult: 咨询)<br>在做出决定之前，最好与该领域的专家咨询，以收集更多信息。</p></li><li><p>The benign nature of the tumor meant that it was unlikely to cause any harm and could be monitored closely. (Benign: 良性的)<br>良性肿瘤的性质意味着它不太可能造成任何伤害，并且可以进行密切监测。</p></li><li><p>The idea of ​​traveling to exotic locations and experiencing new cultures has always appealed to me. (Idea: 想法)<br>去异国旅行，体验新文化的想法一直吸引着我。</p></li><li><p>His intelligence and quick thinking enabled him to solve the puzzle in record time. (Intelligence: 智力)<br>他的智力和快速思维能力使他在创纪录的时间内解决了这个难题。</p></li><li><p>The chef, with his culinary skills honed over years of practice, created a masterpiece that delighted the senses. (Chef: 厨师)<br>厨师凭借多年的实践经验磨练出的烹饪技巧，创作出一部让人心旷神怡的杰作。</p></li><li><p>The eagle soared high above the mountains, its keen eyes scanning the ground below for any sign of prey. (Eagle: 鹰)<br>鹰高高飞过山巅，其敏锐的眼睛在下方的地面上搜寻着猎物的踪迹。</p></li><li><p>Privacy is a fundamental right that should be respected and protected in all circumstances. (Privacy: 隐私)<br>隐私是一项基本权利，应在所有情况下受到尊重和保护。</p></li><li><p>The cup was filled to the brim with steaming hot tea, ready to be enjoyed on a cold winter’s day. (Brim: 边缘)<br>杯子里装满了滚烫的热茶，准备在寒冷的冬日享用。</p></li><li><p>The book is divided into sections, each focusing on a different aspect of the author’s life. (Section: 部分)<br>这本书分为几个部分，每一部分都专注于作者生活的不同方面。</p></li><li><p>The crime, which shocked the small community, was quickly solved by the diligent police force. (Crime: 犯罪)<br>这起犯罪震惊了小区社区，但很快被勤奋的警方解决了。</p></li><li><p>After months of hard work, he finally decided to take a vacation and recharge his batteries. (Vacation: 假期)<br>经过几个月的辛苦工作，他终于决定休假，充电。</p></li></ul><ol start="20"><li></li></ol><ul><li><p>The discovery of the boson, a fundamental particle in particle physics, revolutionized our understanding of the universe. (Boson: 玻色子)<br>玻色子的发现彻底改变了我们对宇宙的理解。</p></li><li><p>They decided to take the matter into their own hands, believing that they were the only ones who could resolve the issue. (Us: 我们自己)<br>他们决定亲自处理这个问题，认为只有他们自己才能解决这个问题。</p></li><li><p>The radioactive material, if not handled properly, could pose a serious threat to themselves and others. (Themselves: 他们自己)<br>放射性材料如果处理不当，可能对他们自己和其他人构成严重威胁。</p></li><li><p>The bud, a small, undeveloped part of a plant, has the potential to grow into a beautiful flower under the right conditions. (Bud: 芽)<br>芽是植物的一个小而未发育的部分，在适当的条件下有可能长成一朵美丽的花。</p></li><li><p>The dilemma they faced was whether to speak out and risk losing their jobs, or remain silent and betray their principles. (Dilemma: 困境)<br>他们面临的困境是要么说出来冒着失去工作的风险，要么保持沉默背叛自己的原则。</p></li><li><p>The decision was made, and then they proceeded with the plan without hesitation. (Then: 然后)<br>决定已经做出，然后他们毫不犹豫地执行了计划。</p></li><li><p>The elephant’s trunk, a remarkable adaptation, allows it to grasp objects and bring them to its mouth with great precision. (Trunk: 象鼻)<br>大象的鼻子是一个了不起的适应性特征，它可以精确地抓住物体并将其带到嘴里。</p></li><li><p>His clever use of words and persuasive arguments convinced even the most skeptical critics. (Clever: 聪明)<br>他巧妙地运用文字和有说服力的论点甚至说服了最怀疑的批评者。</p></li><li><p>The economic policy resulted in high inflation, causing prices to soar and the economy to stagnate. (Inflation: 通货膨胀)<br>这项经济政策导致了高通货膨胀，导致物价飞涨，经济停滞不前。</p></li><li><p>The opera, a theatrical performance combining music, drama, and spectacle, has been a popular form of entertainment for centuries. (Opera: 歌剧)<br>歌剧是一个结合了音乐、戏剧和视觉效果的戏剧表演，几个世纪以来一直是一种受欢迎的娱乐形式。</p></li><li><p>The chairman, as the leader of the committee, had the final say in all matters related to the organization. (Chairman: 主席)<br>作为委员会的领导者，主席在所有与组织相关的事务中都有最终决定权。</p></li><li><p>She had a particular way of doing things, a unique approach that set her apart from others. (Particular: 特定的)<br>她有一种特定的做事方式，一种与众不同的独特方法，让她脱颖而出。</p></li><li><p>She reached into her purse and pulled out a small, folded piece of paper, handing it to the man with a smile. (Purse: 钱包)<br>她伸手进钱包，拿出一张小巧折叠的纸条，笑着递给那个男人。</p></li><li><p>The plantation, with its rows of neatly arranged crops, stretched as far as the eye could see. (Plantation: 种植园)<br>种植园里整齐排列的庄稼一直延伸到眼睛所能及的地方。</p></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>英语</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>聊天笔记</title>
    <link href="/2024/06/06/yuedubiji2/"/>
    <url>/2024/06/06/yuedubiji2/</url>
    
    <content type="html"><![CDATA[<p>聊天是一门技术，应该怎么聊天是一门必要的学问。在之前的研究和实践中我发现我的认知和思想表现的太浅薄了，表现的不够深入，不够精通。</p><h2 id="我的观点来自于哪里？"><a href="#我的观点来自于哪里？" class="headerlink" title="我的观点来自于哪里？"></a>我的观点来自于哪里？</h2><p>对于这个问题，社会有社会的主流价值观，个人最开始接触世界的渠道各种各样，大部分渠道都是经验，经验只能参考，不能拿来直接使用，否则就犯了经验主义的错误。</p><p>认知体系决定了一个人的行为逻辑，而每个人又都会去做自认为正确的事，也都会反对与自身认知相违背的事。</p><p>要想从根本上改变一个人的想法，就得改变影响这个人的认知体系，但这是一件很困难的事，常常也是一件吃力不讨好的事。最根本的思路是包容一切，学习一切，取长补短。认知水平高的人，都有着终身学习的理念，对未知抱有敬畏，能够接纳不同的观点。</p><p>不同圈子的人，差距是很大的，认知水平、世界观、待人接物的方式。为什么人会被圈子局限、形成认知闭环？因为他跟别的圈子的人交流时，会互相伤害，所以就彼此渐行渐远。强者都会高高在上，不会一直给他好脸色。规矩一定要提前立，让他知道你不好对付。就事论事，分析原因，看到本质，不要妄自菲薄。不要因为别人的否定就自我怀疑，否定你的人，有可能他自己有问题。理解他人就要占到他人的角度去看问题，不能在自己的角度看问题。<br>人最重要的是要找准自己的定位。宝贵的时间和精力，去赚钱、变帅、练肌肉，是更值得的。</p><h2 id="预防pua"><a href="#预防pua" class="headerlink" title="预防pua"></a>预防pua</h2><p>PUA的五大套路</p><p>1、情绪操纵。人是有感情的动物，情绪操纵是PUA的基础。心理学把情绪分为正面情绪和负面情绪，这两种情绪都能够控制别人。</p><p>2、宣传灌输。谎言重复一千遍就是真理。这是一句听起来很没道理的话，真理就是真理、谎言就是谎言，怎么能一样？但很不幸，这就是人性！</p><p>3、公开羞辱。公开羞辱会让人的自信心受挫，尊严受到严重伤害，熬过来的人会被深度控制，熬不过来的人就会走上自杀的道路，以死抗争。</p><p>4、自我贬损。就是通过系统地、重复地施加心理伤害。让你做什么都做不成；干什么都没有效果；想什么都没有结论；达不成任何的目标。</p><p>5、 筛选加<br><a href="https://xinle.gitbook.io/gao-xiao-lv-ba-mei-lai-zi-yi-ge-cheng-xu-yuan-de-ba-mei-xin-de/readme/wo-dui-qing-gan-dao-shi-hang-ye-de-kan-fa"></a></p><h2 id="聊天方法"><a href="#聊天方法" class="headerlink" title="聊天方法"></a>聊天方法</h2><ol><li><p>心态 ，暗示自己是高价值的，并且自己正在不断变成高价值的人。聊天注意平衡感，价值差决定聊天难容。快速筛选，果断换人。想暧昧的得逐步试探，技巧要不断的学习，不要说废话。反向聊天,怎么不找我聊天。多切换话题\多重脉络。</p></li><li><p>聊天技术，指导思想+具体话术。方法匹配条件。筛选，根据具体条件来配合聊天，</p></li><li><p>需求层面，生理需求：脸帅，身材好。情感需求：被爱，被在乎，被理解，共鸣。 物质需求：被供养</p></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>阅读笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线性代数 —— 二次型</title>
    <link href="/2024/06/06/xianxindaishu6/"/>
    <url>/2024/06/06/xianxindaishu6/</url>
    
    <content type="html"><![CDATA[<p>二次型 ，二次型及其矩阵表示，合同变换与合同矩阵，二次型的秩，惯性定理，二次型的标准形和规范形， 用正交变换和配方法化二次型为标准形，二次型及其矩阵的正定性。 </p><table><thead><tr><th align="left"></th></tr></thead><tbody><tr><td align="left"><img src="/pic/xxds-ecx1.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-ecx2.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-ecx3.jpg"></td></tr></tbody></table>]]></content>
    
    
    
    <tags>
      
      <tag>线性代数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线性代数 —— 矩阵的特征值和特征向量</title>
    <link href="/2024/06/06/xianxindaishu5/"/>
    <url>/2024/06/06/xianxindaishu5/</url>
    
    <content type="html"><![CDATA[<p>矩阵的特征值和特征向量， 矩阵的特征值和特征向量的概念、性质， 相似矩阵的概念及性质， 矩阵可相似对角化的充分必要条件及相似对角矩阵， 实对称矩阵的特征值、特征向量及其相似对角矩阵 。</p><table><thead><tr><th align="left"></th></tr></thead><tbody><tr><td align="left"><img src="/pic/xxds-tzz1.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-tzz2.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-tzz3.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-tzz4.jpg"></td></tr></tbody></table>]]></content>
    
    
    
    <tags>
      
      <tag>线性代数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>英语-单词4</title>
    <link href="/2024/06/06/English2-4/"/>
    <url>/2024/06/06/English2-4/</url>
    
    <content type="html"><![CDATA[<ol><li></li></ol><ul><li><p>His oral presentation was both informative and engaging, capturing the attention of everyone in the room. (Oral: 口头的)<br>他的口头报告既信息丰富又引人入胜，吸引了在场所有人的注意。</p></li><li><p>The law obliges citizens to pay taxes in order to fund public services. (Oblige: 迫使)<br>法律迫使公民缴税以资助公共服务。</p></li><li><p>As the children played, they would often spit watermelon seeds across the yard, laughing with joy. (Spit: 吐)<br>孩子们玩耍时，经常会吐西瓜籽到院子里，笑得很开心。</p></li><li><p>She could hardly conceive of a life without music, as it had always been her greatest passion. (Conceive: 想象)<br>她几乎无法想象没有音乐的生活，因为音乐一直是她最大的热情所在。</p></li><li><p>The children’s delight was evident as they unwrapped their gifts on Christmas morning. (Delight: 高兴)<br>孩子们在圣诞早晨拆开礼物时，显而易见地感到高兴。</p></li><li><p>The report began with an outline of the main issues, providing a clear structure for the detailed discussion that followed. (Outline: 概要)<br>报告以主要问题的概要开始，为随后的详细讨论提供了清晰的结构。</p></li><li><p>News of the victory spread quickly through the town, bringing excitement and pride to the community. (Spread: 传播)<br>胜利的消息迅速传遍整个小镇，给社区带来了兴奋和自豪。</p></li><li><p>The park was filled with numerous families enjoying picnics and outdoor games. (Numerous: 众多的)<br>公园里充满了众多家庭，他们享受着野餐和户外游戏。</p></li><li><p>He wrote a will to ensure his assets would be distributed according to his wishes after his death. (Will: 遗嘱)<br>他写了一份遗嘱，以确保他的财产在他去世后按照他的意愿分配。</p></li><li><p>The children were fascinated by the bubbles floating in the air, chasing and popping them with glee. (Bubble: 气泡)<br>孩子们对空中漂浮的气泡感到着迷，欢快地追逐并戳破它们。</p></li><li><p>She valued her independent lifestyle, enjoying the freedom to make her own decisions. (Independent: 独立的)<br>她珍视自己独立的生活方式，享受做出自己决定的自由。</p></li><li><p>The charity organization worked tirelessly to distribute food and clothing to those in need. (Distribute: 分发)<br>慈善组织不懈努力，向有需要的人分发食物和衣物。</p></li></ul><ol start="2"><li></li></ol><ul><li><p>The banquet was a grand celebration. (Banquet: 宴会) 宴会是一场盛大的庆祝活动。</p></li><li><p>As the movie ended, the audience quietly made their exit through the main doors. (Exit: 出口)<br>电影结束后，观众们悄然从主门出口离开。</p></li><li><p>The paper, which discussed groundbreaking scientific research, was published in a prestigious journal. (Paper: 论文)<br>这篇讨论开创性科学研究的论文发表在一份著名的期刊上。</p></li><li><p>The saint, known for his selfless acts and pious life, became a revered figure in the community. (Saint: 圣人)<br>这位以无私行为和虔诚生活而闻名的圣人成为了社区中的一位受人尊敬的人物。</p></li><li><p>The tradition, passed down through centuries, was celebrated with much pomp and ceremony. (Tradition: 传统)<br>这一传统一代代传承下来，以盛大的仪式和庆典来庆祝。</p></li><li><p>The scout, always vigilant and prepared, led the group safely through the dense forest. (Scout: 侦察员)<br>侦察员总是警觉而准备充分，带领小组安全穿越茂密的森林。</p></li><li><p>His discreet handling of the sensitive situation earned him the trust of his colleagues. (Discreet: 谨慎)<br>他对敏感情况的谨慎处理赢得了同事们的信任。</p></li><li><p>The horizontal stripes on the flag symbolized equality and unity among the citizens. (Horizontal: 水平的)<br>旗帜上的水平条纹象征着公民之间的平等与团结。</p></li><li><p>The sad news of his passing left the entire community in a state of mourning. (Sad: 悲伤的)<br>他去世的悲伤消息让整个社区陷入哀悼之中。</p></li><li><p>The spontaneous applause from the audience was a genuine appreciation of the performance. (Spontaneous: 自发的)<br>观众自发的掌声是对演出的真诚赞赏。</p></li><li><p>His influence over the young athletes was profound, shaping their careers and futures. (Influence: 影响)<br>他对年轻运动员的影响是深远的，塑造了他们的职业生涯和未来。</p></li><li><p>The instructions were clear and concise, leaving no room for misunderstanding. (Concise: 简洁)<br>指示明确而简洁，不留任何误解的余地。</p></li><li><p>The corresponding values in the table should be matched accurately for the experiment to succeed. (Corresponding: 对应的)<br>表格中的对应数值应准确匹配，以确保实验成功。</p></li><li><p>The doctor took her time to carefully examine the patient before making a diagnosis. (Examine: 检查)<br>医生花时间仔细检查病人，然后才做出诊断。</p></li><li><p>The greeting card was filled with warm wishes and heartfelt messages. (Greeting: 问候)<br>贺卡里充满了温馨的祝福和真挚的信息。</p></li><li><p>Despite the harsh criticism, she remained confident in her abilities and continued to strive for excellence. (Criticism: 批评)<br>尽管受到严厉的批评，她仍对自己的能力充满信心，并继续追求卓越。</p></li></ul><ol start="3"><li></li></ol><ul><li><p>The drummer’s rhythm was so powerful that it made everyone’s hearts beat in time with the music. (Beat: 跳动)<br>鼓手的节奏如此强劲，大家的心脏都随着音乐的节拍跳动。</p></li><li><p>The factory had to increase its production to meet the monthly quota set by the management. (Quota: 定额)<br>工厂必须增加生产以达到管理层设定的月定额。</p></li><li><p>She decided to close the store early due to the approaching storm. (Close: 关闭)<br>由于风暴即将来临，她决定提前关闭商店。</p></li><li><p>The news of her promotion was enough to excite her entire family, who celebrated with a special dinner. (Excite: 使激动)<br>她升职的消息足以让她的全家感到激动，他们举行了特别的晚宴来庆祝。</p></li><li><p>The young doctor decided to undertake the challenging surgery, despite its risks. (Undertake: 承担)<br>年轻的医生决定承担这次具有挑战性的手术，尽管它存在风险。</p></li><li><p>The announcement through the loudspeaker could be heard clearly throughout the entire campus. (Loudspeaker: 扩音器)<br>通过扩音器的公告在整个校园里都能清晰地听到。</p></li><li><p>Her company was known for its excellent customer service and high-quality products. (Company: 公司)<br>她的公司以其出色的客户服务和高质量的产品而闻名。</p></li><li><p>He is a reliable friend who you can always count on in times of need. (Reliable: 可靠的)<br>他是一个可靠的朋友，在需要的时候你总能依靠他。</p></li><li><p>They invited all their friends and family to a barbecue in their backyard. (Barbecue: 烧烤)<br>他们邀请所有的朋友和家人到他们的后院参加烧烤聚会。</p></li><li><p>She used a clip to keep her hair out of her face while she was working. (Clip: 发夹)<br>她用发夹把头发固定住，以免工作时挡住脸。</p></li><li><p>At the age of eighty, he still enjoyed taking long walks in the park every morning. (Eighty: 八十)<br>在八十岁的时候，他仍然喜欢每天早晨在公园里长时间散步。</p></li><li><p>The sheer number of tasks on her to-do list began to overwhelm her. (Overwhelm: 压倒)<br>她待办事项清单上的任务数量之多开始让她感到不堪重负。</p></li><li><p>He gave a respectful bow to the audience after his performance. (Bow: 鞠躬)<br>表演结束后，他向观众鞠了一躬表示尊敬。</p></li><li><p>The patient had to undergo a transplant operation to replace the failing organ. (Transplant: 移植)<br>病人必须进行移植手术来替换失效的器官。</p></li></ul><ol start="4"><li></li></ol><ul><li><p>They were determined to finish the project on time, despite the many obstacles they faced. (They: 他们)<br>尽管面临许多障碍，他们决心按时完成项目。</p></li><li><p>The artist found her greatest inspiration during her travels around the world. (Inspiration: 灵感)<br>艺术家在环游世界期间找到了最大的灵感。</p></li><li><p>He enjoyed a juicy hamburger at his favorite diner every Friday night. (Hamburger: 汉堡)<br>每个星期五晚上，他都会在最喜欢的餐厅享用一个多汁的汉堡。</p></li><li><p>The professor’s new novel was met with critical acclaim and became a bestseller. (Novel: 小说)<br>这位教授的新小说获得了好评，成为畅销书。</p></li><li><p>She approached her studies with great zeal, always eager to learn more. (Zeal: 热情)<br>她对学习充满热情，总是渴望学到更多。</p></li><li><p>He had to cut the rope to free the trapped animal. (Cut: 切断)<br>他不得不切断绳子以解救被困的动物。</p></li><li><p>After receiving the inquiry, the company promptly provided all the requested information. (Inquiry: 查询)<br>收到查询后，公司迅速提供了所有要求的信息。</p></li><li><p>The instructions were clear and intelligible, making the assembly process straightforward. (Intelligible: 可理解的)<br>说明书清晰易懂，使组装过程变得简单明了。</p></li><li><p>The young athlete’s courage allowed him to defy the odds and win the championship. (Defy: 反抗)<br>年轻运动员的勇气使他能克服困难赢得冠军。</p></li><li><p>She added a slice of cheese to her sandwich for extra flavor. (Cheese: 奶酪)<br>她在三明治里加了一片奶酪来增加风味。</p></li><li><p>He ate the whole pizza by himself, much to everyone’s amazement. (Whole: 整个)<br>他一个人吃掉了整个披萨，令大家惊讶不已。</p></li><li><p>The village was a peaceful place, perfect for a relaxing vacation. (Peaceful: 宁静的)<br>这个村庄是一个宁静的地方，非常适合放松度假。</p></li><li><p>The clergy gathered in the cathedral to discuss important matters concerning the community. (Clergy: 神职人员)<br>神职人员聚集在大教堂里讨论社区的重要事项。</p></li><li><p>The music was so loud that they could hear it from several blocks away. (Loud: 大声的)<br>音乐声很大，隔好几个街区都能听到。</p></li></ul><ol start="5"><li></li></ol><ul><li><p>The usage of complex algorithms in artificial intelligence has revolutionized various industries, from healthcare to finance. (Usage: 使用)<br>在人工智能中使用复杂算法已经彻底改变了从医疗到金融的各个行业。</p></li><li><p>She shared her private thoughts with her closest friend, knowing they would remain confidential. (Private: 私人的)<br>她向最亲密的朋友分享了她的私人想法，知道这些想法会保持机密。</p></li><li><p>Despite being accused of the crime, he remained innocent and maintained his integrity throughout the trial. (Innocent: 无辜的)<br>尽管被指控犯罪，他仍然保持无辜，在整个审判过程中保持了诚信。</p></li><li><p>The cell, with its intricate structure and functions, is the basic unit of life. (Cell: 细胞)<br>细胞，以其复杂的结构和功能，是生命的基本单位。</p></li><li><p>Many modern customs and traditions originate from ancient practices and beliefs. (Originate: 起源)<br>许多现代习俗和传统起源于古老的做法和信仰。</p></li><li><p>The roll of thunder signaled the approaching storm, sending people rushing indoors. (Roll: 轰鸣)<br>雷声滚滚预示着暴风雨的来临，使人们匆忙躲进室内。</p></li><li><p>The red dress she wore to the gala made her stand out in the crowd, capturing everyone’s attention. (Red: 红色的)<br>她在晚会上穿的红色连衣裙使她在人群中脱颖而出，吸引了所有人的注意。</p></li><li><p>As a professional athlete, she trained rigorously every day to maintain her peak performance. (Professional: 专业的)<br>作为一名职业运动员，她每天严格训练以保持最佳状态。</p></li><li><p>Discussions on gender equality have become more prominent in recent years, highlighting the need for social change. (Gender: 性别)<br>近年来，关于性别平等的讨论变得更加突出，强调了社会变革的必要性。</p></li><li><p>He opened his mouth to speak, but the words seemed to stick in his throat, leaving him momentarily speechless. (Mouth: 嘴)<br>他张嘴想说话，但话语似乎卡在喉咙里，让他一时语塞。</p></li><li><p>The feeling of guilt weighed heavily on her, even though she knew she had done nothing wrong. (Guilt: 罪恶感)<br>尽管她知道自己没有做错什么，但罪恶感依然让她心情沉重。</p></li><li><p>The sudden flare of light in the dark alley startled them, making them jump. (Flare: 闪光)<br>黑暗小巷里突然闪起的光让他们大吃一惊，吓了一跳。</p></li><li><p>The company’s profits increased by nearly a quarter compared to the previous year, signaling strong growth. (Quarter: 四分之一)<br>公司的利润比前一年增加了近四分之一，表明增长强劲。</p></li><li><p>She spent her Sunday afternoon doing laundry, folding clothes, and organizing her closet. (Laundry: 洗衣)<br>她在星期天下午洗衣服、折衣服和整理衣柜。</p></li></ul><ol start="6"><li></li></ol><ul><li><p>The show, which had been in the preliminary stages of planning for months, was finally ready for its grand debut. (Show: 演出)<br>经过几个月的初步筹备，这场演出终于准备好了盛大首演。</p></li><li><p>The preliminary results of the experiment were promising, indicating that further research was warranted. (Preliminary: 初步)<br>实验的初步结果令人鼓舞，表明需要进一步研究。</p></li><li><p>The foundation of the ancient structure was found to be remarkably well-preserved, offering new insights into historical construction techniques. (Found: 发现)<br>这座古老建筑的基础被发现保存得相当完好，为历史建筑技术提供了新的见解。</p></li><li><p>His vivid imagination allowed him to create fantastical worlds in his writing, captivating readers with his creativity. (Imagination: 想象力)<br>他丰富的想象力使他在写作中创造出奇幻的世界，凭借其创造力吸引了读者。</p></li><li><p>The ice-cream, melting quickly in the summer heat, provided a momentary but delightful respite from the scorching sun. (Ice-cream: 冰淇淋)<br>冰淇淋在夏日的炎热中迅速融化，为人们在烈日下提供了片刻但愉快的解脱。</p></li><li><p>Despite being illiterate, he possessed a sharp intellect and was able to understand complex concepts through verbal explanation. (Illiterate: 文盲)<br>尽管是文盲，但他头脑聪明，通过口头解释能够理解复杂的概念。</p></li><li><p>A simple gesture of kindness can often suffice to brighten someone’s day, illustrating the power of human connection. (Suffice: 足够)<br>一个简单的善意举动常常足以让某人的一天变得光明，说明了人类联系的力量。</p></li><li><p>His humor, often dry and subtle, was a source of great amusement to his friends and colleagues. (Humor: 幽默)<br>他的幽默，通常干涩而微妙，是他的朋友和同事们的极大乐趣来源。</p></li><li><p>You can choose whatever method works best for you, as long as the end result is achieved. (Whatever: 任何)<br>你可以选择任何对你最有效的方法，只要最终结果实现就行。</p></li><li><p>The fixture, securely installed in the ceiling, provided ample lighting for the entire room. (Fixture: 固定装置)<br>安装在天花板上的固定装置为整个房间提供了充足的照明。</p></li><li><p>She felt incredibly lonely in the big city, despite being surrounded by millions of people. (Lonely: 孤独)<br>尽管身处数百万人之中，她在大城市里依然感到非常孤独。</p></li><li><p>The spark of inspiration came to him suddenly, igniting a creative frenzy that lasted for hours. (Spark: 火花)<br>灵感的火花突然降临，引发了他持续数小时的创作狂潮。</p></li><li><p>The competition was fierce, with each contestant striving to outperform the others and claim the top prize. (Competition: 竞争)<br>竞争非常激烈，每个参赛者都在努力超越他人，争取头奖。</p></li><li><p>The wretched conditions in the refugee camp were a stark reminder of the ongoing humanitarian crisis. (Wretched: 悲惨的)<br>难民营的悲惨状况是当前人道主义危机的一个严酷提醒。</p></li></ul><ol start="7"><li></li></ol><ul><li><p>The verbal agreement between the two parties, though informal, was considered binding by both. (Verbal: 口头的)<br>双方之间的口头协议，尽管不正式，但被双方视为具有约束力。</p></li><li><p>Her curiosity about the world led her to travel extensively, seeking new experiences and knowledge wherever she went. (Curiosity: 好奇心)<br>她对世界的好奇心促使她广泛旅行，随处寻找新的体验和知识。</p></li><li><p>The sight of a flock of geese flying in a perfect V-formation was both mesmerizing and a reminder of nature’s wonders. (Goose: 鹅)<br>看到一群鹅完美的V字形飞行令人着迷，也提醒人们自然的奇观。</p></li><li><p>The message, delivered in a clear and concise manner, conveyed the urgency of the situation effectively. (Message: 信息)<br>这条信息以清晰简洁的方式传达了情况的紧迫性。</p></li><li><p>Despite his extensive experience, he sought advice from his mentor to ensure he was making the right decision. (Advice: 建议)<br>尽管他经验丰富，但他还是向导师寻求建议，以确保自己做出正确的决定。</p></li><li><p>The machine was designed to compress large volumes of data, making storage and transmission more efficient. (Compress: 压缩)<br>这台机器被设计用来压缩大量数据，使存储和传输更加高效。</p></li><li><p>His strong leadership qualities inspired his team to strive for excellence in every project they undertook. (Lead: 领导)<br>他的卓越领导素质激励团队在每个项目中都追求卓越。</p></li><li><p>The gut feeling he had about the deal turned out to be accurate, saving the company from a potential loss. (Gut: 直觉)<br>他对这笔交易的直觉是正确的，挽救了公司免于潜在的损失。</p></li><li><p>The absurd suggestion was met with laughter and quickly dismissed as impractical. (Absurd: 荒谬的)<br>这个荒谬的建议引起了笑声，很快被认为不切实际而被否决。</p></li><li><p>The solution was satisfactory to all parties involved, resolving the conflict amicably. (Satisfactory: 满意的)<br>这个解决方案让所有相关方都满意，和睦地解决了冲突。</p></li><li><p>To the layman, the technical jargon used by the engineers was almost incomprehensible. (Layman: 外行)<br>对外行来说，工程师使用的技术术语几乎是难以理解的。</p></li><li><p>The accident left him crippled, but his determination to overcome his disability was truly inspiring. (Cripple: 使残废)<br>事故使他残废，但他克服残疾的决心真正令人鼓舞。</p></li><li><p>The transport of goods across the country was streamlined by the new logistics system. (Transport: 运输)<br>通过新的物流系统，全国范围内的货物运输更加高效。</p></li></ul><ol start="8"><li></li></ol><ul><li><p>The pace at which technology is advancing is astounding, with new developments and innovations occurring daily. (Pace: 速度)<br>技术发展的速度令人震惊，每天都有新的发展和创新。</p></li><li><p>His knowledge of the subject was extensive, covering a wide range of topics and details. (Extensive: 广泛的)<br>他对这个主题的了解很广泛，涵盖了各种各样的主题和细节。</p></li><li><p>Despite the early hour, the streets were bustling with activity as people began their day. (Early: 早期)<br>尽管时间还很早，但街道上已经熙熙攘攘，人们开始了新的一天。</p></li><li><p>The web of intrigue and deception was so complex that even the most astute investigators were unable to unravel it. (Web: 网络)<br>这个错综复杂的阴谋和欺骗的网络，甚至连最敏锐的调查人员也无法解开。</p></li><li><p>The ray of hope that had sustained them through difficult times finally began to fade. (Ray: 光线)<br>曾经支撑他们度过困难时期的一丝希望最终开始消失。</p></li><li><p>Despite his best efforts, he was unable to sell the idea to his colleagues. (Sell: 出售)<br>尽管他尽了最大的努力，但他无法向同事们推销这个想法。</p></li><li><p>Their booth at the trade show was unlike any other, drawing crowds with its innovative design. (Booth: 亭子)<br>他们在贸易展上的展位与众不同，因其创新设计吸引了众多观众。</p></li><li><p>He was hailed as a hero for his courageous actions during the rescue mission. (Hero: 英雄)<br>他因在营救行动中的勇敢行为而被誉为英雄。</p></li><li><p>The academy provided a rigorous training program for aspiring actors, preparing them for careers in the entertainment industry. (Academy: 学院)<br>这个学院为有抱负的演员提供了严格的培训计划，为他们在娱乐行业的职业生涯做准备。</p></li><li><p>Her style of writing was unique, blending humor and insight in a way that captivated readers. (Style: 风格)<br>她的写作风格独特，以一种融合幽默和洞察力的方式吸引了读者。</p></li><li><p>Despite the challenges they faced, their faithfulness to each other never wavered. (Faithful: 忠诚的)<br>尽管他们面临着挑战，但他们对彼此的忠诚从未动摇。</p></li><li><p>The muddy terrain made the journey difficult, with each step sinking into the dirty ground. (Dirty: 肮脏的)<br>泥泞的地形使旅程变得困难，每一步都陷入肮脏的地面。</p></li><li><p>The technical aspects of the project were complex, requiring specialized knowledge and skills. (Technical: 技术的)<br>项目的技术方面很复杂，需要专业知识和技能。</p></li></ul><ol start="9"><li></li></ol><ul><li><p>The rifle, a long-barreled firearm, is commonly used for hunting and target shooting. (Rifle: 步枪)<br>步枪，一种长枪管的火器，通常用于狩猎和靶射。</p></li><li><p>The principal, the head of the school, was known for his strict but fair leadership style. (Principal: 校长)<br>校长，学校的负责人，以其严格但公平的领导风格而闻名。</p></li><li><p>The clear instructions provided by the teacher helped the students understand the concept easily. (Clear: 清晰)<br>老师提供的清晰指导帮助学生轻松理解了概念。</p></li><li><p>The full moon cast a soft glow over the landscape, creating a serene and magical atmosphere. (Full: 满)<br>满月在风景上投下一抹柔和的光芒，营造出一种宁静而神奇的氛围。</p></li><li><p>The extravagant spending habits of the young man soon led to financial troubles. (Extravagant: 奢侈的)<br>这个年轻人奢侈的消费习惯很快导致了财务问题。</p></li><li><p>The theft of valuable artwork from the museum shocked the community and raised concerns about security. (Theft: 盗窃)<br>博物馆珍贵艺术品的被盗事件震惊了社区，引发了对安全的担忧。</p></li><li><p>Shall we meet at the canteen for lunch? (Canteen: 食堂)<br>我们要不要在食堂见面吃午饭？</p></li><li><p>The council, composed of elected officials, made decisions that affected the entire community. (Council: 理事会)<br>理事会由选举产生的官员组成，他们做出的决定影响着整个社区。</p></li><li><p>The species of birds found in the region are diverse, ranging from small songbirds to large raptors. (Species: 物种)<br>这个地区发现的鸟类物种多样，从小型鸣禽到大型猛禽不等。</p></li><li><p>Her occupation as a teacher allowed her to make a positive impact on the lives of many children. (Occupation: 职业)<br>她作为一名教师的职业使她能够对许多孩子的生活产生积极的影响。</p></li><li><p>The imaginary world created by the author was filled with fantastical creatures and magical landscapes. (Imaginary: 想象的)<br>作者创造的想象世界充满了奇幻生物和神奇的风景。</p></li><li><p>The camera, a device used to capture images, has evolved significantly over the years. (Camera: 相机)<br>相机，用于捕捉图像的设备，经过多年的发展取得了显著进步。</p></li></ul><ol start="10"><li></li></ol><ul><li><p>The installation, a complex process involving multiple steps and specialized equipment, was finally completed after weeks of work. (Installation: 安装)<br>这次安装是一个复杂的过程，涉及多个步骤和专门的设备，在经过数周的工作后终于完成了。</p></li><li><p>The artist carefully carved the intricate design into the wood, creating a masterpiece that would be admired for generations. (Carve: 雕刻)<br>艺术家将复杂的设计精细地雕刻在木头上，创造出一件将被后人赞美的杰作。</p></li><li><p>The slaughter, a brutal and senseless act, shocked the community and led to calls for stricter animal welfare laws. (Slaughter: 屠宰)<br>这场屠宰是一种残忍而毫无意义的行为，震惊了社区，并导致人们呼吁制定更严格的动物福利法律。</p></li><li><p>The young boy, full of curiosity and energy, explored the forest with his friends, eager to discover its secrets. (Youngster: 年轻人)<br>这个年轻男孩充满好奇和活力，和他的朋友一起探索着森林，渴望发现它的秘密。</p></li><li><p>The homeowner was reassured by the contractor’s guarantee that the work would be completed on time and within budget. (Homeowner: 房主)<br>房主得到了承包商的保证，工作将按时完成并在预算内。</p></li><li><p>The teacher assigned a challenging project to her students, hoping to stimulate their creativity and critical thinking skills. (Assign: 分配)<br>老师分配了一个具有挑战性的项目给她的学生，希望能激发他们的创造力和批判性思维能力。</p></li><li><p>The old car was disposed of at the junkyard, its once shiny exterior now rusted and worn. (Dispose: 处置)<br>这辆旧车被送到了废品回收场处置，它曾经闪闪发光的外表现在已经锈迹斑斑、破烂不堪。</p></li><li><p>The villagers hailed the arrival of spring, a time of renewal and growth, with festivities and celebrations. (Hail: 称颂)<br>村民们称颂春天的到来，这是一个更新和成长的时节，他们以庆祝活动和庆祝来庆祝。</p></li><li><p>The painting was an imitation of a famous masterpiece, a tribute to the artist’s skill but lacking in originality. (Imitation: 模仿)<br>这幅画是对一件著名杰作的模仿，是对艺术家技艺的致敬，但缺乏独创性。</p></li><li><p>His increasingly optimistic outlook on life was a result of his positive experiences and supportive relationships. (Increasingly: 越来越)<br>他对生活持越来越乐观的态度是他积极经历和支持性关系的结果。</p></li></ul><ol start="11"><li></li></ol><ul><li><p>The headmaster, a stern but fair leader, was respected by both students and staff for his wisdom and integrity. (Headmaster: 校长)<br>校长是一个严肃但公正的领导者，因其智慧和正直而受到学生和教职员工的尊敬。</p></li><li><p>The poet’s words were like music, flowing effortlessly as he recited his latest work to the captivated audience. (Poem: 诗)<br>诗人的词如音乐般流畅，当他向全神贯注的观众朗诵他最新的作品时，诗句毫不费力地流淌出来。</p></li><li><p>Despite facing many difficulties, she remained determined and focused on achieving her goals. (Difficulty: 困难)<br>尽管面临着许多困难，她仍然坚定不移，专注于实现她的目标。</p></li><li><p>His advice was invaluable, based on years of experience and a deep understanding of the subject. (Invaluable: 无价的)<br>他的建议是无价的，基于多年的经验和对这个问题的深刻理解。</p></li><li><p>The compromise reached between the two parties was fair and satisfactory to both sides. (Compromise: 妥协)<br>双方达成的妥协是公平的，对双方都是令人满意的。</p></li><li><p>The ancient tomb, shrouded in mystery and intrigue, was a subject of fascination for archaeologists and historians. (Tomb: 坟墓)<br>这座古老的坟墓，笼罩在神秘和阴谋之中，是考古学家和历史学家着迷的对象。</p></li><li><p>The company’s headquarters, located in the bustling city center, was a hub of activity and innovation. (Headquarters: 总部)<br>公司的总部位于繁华的市中心，是活动和创新的中心。</p></li><li><p>She had a tendency to overthink things, often imagining problems that didn’t exist. (Tendency: 倾向)<br>她有一种过度思考的倾向，经常想象出并不存在的问题。</p></li><li><p>The artist used vivid colors and bold strokes to illustrate the beauty of the natural world. (Illustrate: 说明)<br>艺术家运用鲜明的色彩和大胆的笔触来描绘自然界的美丽。</p></li><li><p>His radical ideas challenged the status quo and sparked a lively debate among scholars. (Radical: 激进的)<br>他的激进思想挑战了现状，引发了学者们之间的热烈讨论。</p></li><li><p>The painting was hung on the wall, its slender frame barely visible against the dark background. (Slender: 细长的)<br>画挂在墙上，其细长的框架在暗色背景下几乎看不见。</p></li></ul><ol start="12"><li></li></ol><ul><li><p>The boat seemed to float effortlessly on the calm waters, gliding towards the shore. (Float: 漂浮)<br>这艘船似乎毫不费力地漂浮在平静的水面上，向岸边滑去。</p></li><li><p>Painting had always been her favorite hobby, a way to relax and express her creativity. (Hobby: 爱好)<br>绘画一直是她最喜欢的爱好，是一种放松和表达创造力的方式。</p></li><li><p>The inverse relationship between price and demand was a key concept in economics, influencing pricing strategies and market dynamics. (Inverse: 相反)<br>价格与需求之间的相反关系是经济学中的一个关键概念，影响着定价策略和市场动态。</p></li><li><p>The movie reached its climax with a thrilling chase scene, leaving the audience on the edge of their seats. (Climax: 高潮)<br>电影在一场惊险的追逐场景中达到了高潮，让观众坐立不安。</p></li><li><p>The animal kingdom is vast and diverse, with countless species yet to be discovered and studied. (Kingdom: 界)<br>动物王国广阔多样，还有无数物种有待发现和研究。</p></li><li><p>They searched everywhere but could find him nowhere, as if he had vanished into thin air. (Nowhere: 无处)<br>他们到处搜寻，但却找不到他，仿佛他消失得无影无踪。</p></li><li><p>The family enjoyed a leisurely picnic in the park, savoring the delicious food and the beautiful weather. (Picnic: 野餐)<br>家人们在公园里享受着悠闲的野餐时光，品尝着美味的食物和宜人的天气。</p></li><li><p>They decided to gather all the information before making a decision, ensuring they had a clear understanding of the situation. (Gather: 收集)<br>他们决定在做出决定之前收集所有信息，确保他们对情况有清晰的了解。</p></li><li><p>The medicine helped to relieve her pain, allowing her to rest and recover. (Relieve: 缓解)<br>这种药物帮助缓解了她的疼痛，让她得以休息和恢复。</p></li><li><p>Everyone was invited to the party except for him, leaving him feeling excluded and lonely. (Except: 除了)<br>每个人都被邀请参加派对，除了他，让他感到被排除在外和孤单。</p></li><li><p>His contributions to the project were invaluable, helping to ensure its success. (Contribute: 贡献)<br>他对项目的贡献是无价的，有助于确保项目的成功。</p></li><li><p>The chef used fresh raw ingredients to create a delicious meal, emphasizing the importance of quality produce. (Raw: 生的)<br>厨师使用新鲜的生食材制作出美味的一餐，强调了优质食材的重要性。</p></li></ul><ol start="13"><li></li></ol><ul><li><p>The internet has created a vast cyberspace where people from all over the world can connect and share information. (Cyberspace: 虚拟空间)<br>互联网创造了一个广阔的虚拟空间，在这里来自世界各地的人们可以互相连接和分享信息。</p></li><li><p>Their opinions differ on the best way to approach the problem, leading to lively debates and discussions. (Differ: 不同)<br>他们在解决问题的最佳方式上意见不同，导致了生动的辩论和讨论。</p></li><li><p>Before the era of smartphones, people used the telephone to communicate over long distances. (Telephone: 电话)<br>在智能手机时代之前，人们使用电话进行远程通信。</p></li><li><p>The tanker was filled with oil and set sail for its destination, delivering its valuable cargo. (Tanker: 油轮)<br>油轮装满了石油，驶向目的地，运送着宝贵的货物。</p></li><li><p>She showed great talent for music from a young age, and her skills only improved with time and practice. (Talent: 天赋)<br>她从小就表现出对音乐的天赋，随着时间和练习，她的技能只会变得更加出色。</p></li><li><p>During their vacation, they enjoyed various forms of recreation, from hiking to swimming. (Recreation: 娱乐)<br>在假期期间，他们享受了各种形式的娱乐，从徒步到游泳。</p></li><li><p>The country welcomed refugees fleeing from war-torn regions, providing them with shelter and support. (Refugee: 难民)<br>这个国家欢迎逃离战乱地区的难民，为他们提供庇护和支持。</p></li><li><p>Her radiant smile brightened up the room, spreading warmth and positivity to everyone around her. (Radiant: 光芒四射的)<br>她灿烂的微笑照亮了整个房间，给周围的每个人带来了温暖和积极性。</p></li><li><p>People often perceive things differently based on their own experiences and perspectives. (Perceive: 感知)<br>人们往往根据自己的经历和观点对事物有不同的认识。</p></li><li><p>His behavior seemed suspicious, leading many to question his motives and intentions. (Suspicious: 可疑)<br>他的行为看起来很可疑，让许多人质疑他的动机和意图。</p></li><li><p>Sociology is the study of society, including its structure, institutions, and development. (Sociology: 社会学)<br>社会学是研究社会的学科，包括社会结构、制度和发展。</p></li><li><p>After years of service, he decided to resign from his position and pursue other opportunities. (Resign: 辞职)<br>在多年的服务后，他决定辞去职务，追求其他机会。</p></li><li><p>Their farewell was filled with tears and hugs, as they bid each other goodbye and parted ways. (Farewell: 告别)<br>他们的告别充满了眼泪和拥抱，彼此道别，分道扬镳。</p></li><li><p>Her hair had a natural curl to it, giving her a playful and carefree look. (Curl: 卷曲)<br>她的头发有一种天生的卷曲，让她看起来活泼而无忧无虑。</p></li><li><p>His voice echoed through the canyon, creating an eerie but beautiful sound. (Echo: 回声)<br>他的声音在峡谷中回荡，发出一种怪异但美妙的声音。</p></li></ul><ol start="14"><li></li></ol><ul><li><p>His abrupt departure left everyone stunned, as he had not given any indication of his intentions. (Abrupt: 突然的)<br>他突然离开让所有人都感到震惊，因为他没有透露任何他的意图。</p></li><li><p>The soccer match was intense, with both teams giving their all to win the game. (Soccer: 足球)<br>足球比赛非常激烈，两支球队都全力以赴地争取赢得比赛。</p></li><li><p>She felt a sudden swing of emotions, from excitement to fear, as she stood on the edge of the cliff. (Swing: 摇摆)<br>她站在悬崖边上，突然感到一阵情绪的波动，从兴奋到恐惧。</p></li><li><p>From a historical standpoint, this event marks a significant shift in the political landscape of the region. (Standpoint: 观点)<br>从历史的角度来看，这一事件标志着该地区政治格局的重大变化。</p></li><li><p>The parameter for success in this project is not just financial gain but also social impact. (Parameter: 参数)<br>这个项目成功的参数不仅是财务收益，还包括社会影响。</p></li><li><p>She dressed up as a princess for the costume party, complete with a tiara and a flowing gown. (Princess: 公主)<br>她为了化装舞会打扮成了一个公主，戴着皇冠，穿着一袭流苏长裙。</p></li><li><p>He let out a soft moan of pain as the doctor examined his injured leg. (Moan: 呻吟)<br>医生检查他受伤的腿时，他发出了一声轻轻的疼痛呻吟。</p></li><li><p>The conductor of the orchestra led the musicians with great skill and precision. (Conductor: 指挥)<br>乐队的指挥以极高的技巧和精确度带领着音乐家们。</p></li><li><p>A good night’s sleep can boost your mood and energy levels for the next day. (Boost: 提升)<br>一个良好的夜间睡眠可以提升你的心情和第二天的精力水平。</p></li><li><p>His passionate speech ignited a fire in the hearts of the audience, inspiring them to take action. (Ignite: 点燃)<br>他充满激情的演讲点燃了观众内心的火焰，激励他们采取行动。</p></li><li><p>They dwell in a small cottage by the sea, enjoying the peacefulness and beauty of the coastal life. (Dwell: 居住)<br>他们居住在海边的一间小屋里，享受着海岸生活的宁静和美丽。</p></li><li><p>The town square was bustling with activity, as vendors set up their stalls and people gathered for the market. (Square: 广场)<br>城镇广场熙熙攘攘，摊贩们摆起摊位，人们聚集在市场上。</p></li><li><p>The new initiative aims to promote sustainability practices within the community, encouraging residents to reduce waste and conserve resources. (Initiative: 倡议)<br>这项新举措旨在推动社区内的可持续发展实践，鼓励居民减少浪费，节约资源。</p></li><li><p>The fearful expression on her face indicated that she had seen something terrifying. (Fearful: 害怕的)<br>她脸上的恐惧表情表明她看到了什么可怕的事情。</p></li></ul><ol start="15"><li></li></ol><ul><li><p>The topic of the discussion was the impact of climate change on global agriculture. (Topic: 主题)<br>讨论的主题是气候变化对全球农业的影响。</p></li><li><p>The giant statue loomed over the city, its size and presence awe-inspiring. (Giant: 巨大的)<br>巨大的雕像矗立在城市上空，它的大小和存在让人敬畏。</p></li><li><p>The patient was diagnosed with a kidney infection and was prescribed antibiotics. (Kidney: 肾脏)<br>患者被诊断为肾感染，并被开了抗生素。</p></li><li><p>The government announced a new policy that would exempt small businesses from certain taxes. (Exempt: 免除)<br>政府宣布一项新政策，将使小型企业免除某些税收。</p></li><li><p>The reporter interviewed several eyewitnesses to get more information about the accident. (Reporter: 记者)<br>记者采访了几位目击者，以获取更多关于事故的信息。</p></li><li><p>After a long journey, he was glad to return home and be reunited with his family. (Return: 返回)<br>经过漫长的旅程，他很高兴能回家与家人团聚。</p></li><li><p>The old house was rumored to be haunted, with locals claiming to have seen ghosts in the windows. (Ghost: 鬼魂)<br>这座老房子据说闹鬼，当地人声称曾在窗户看到鬼魂。</p></li><li><p>He carefully shaved his beard with a sharp razor, taking care not to cut himself. (Razor: 剃刀)<br>他小心翼翼地用锋利的剃刀刮胡子，小心翼翼地不要割伤自己。</p></li><li><p>The nucleus is the central part of a cell that contains genetic material. (Nucleus: 细胞核)<br>细胞核是细胞的中心部分，包含着遗传物质。</p></li><li><p>The mysterious figure seemed to vanish into thin air, leaving no trace behind. (Vanish: 消失)<br>这个神秘的人物似乎消失得无影无踪，没有留下任何痕迹。</p></li><li><p>The cozy living room was warmed by the crackling fire in the fireplace. (Fireplace: 壁炉)<br>温馨的客厅被壁炉中发出的噼啪声温暖着。</p></li></ul><ol start="16"><li></li></ol><ul><li><p>The explorers ventured deep into the cave, discovering hidden chambers and ancient artifacts. (Cave: 洞穴)<br>探险家们深入洞穴，发现了隐藏的洞室和古代文物。</p></li><li><p>She moved to the countryside to escape the hustle and bustle of the city, seeking a quieter and more peaceful life. (Country: 乡村)<br>她搬到乡村逃离城市的喧嚣，寻求更安静更平静的生活。</p></li><li><p>This year has been full of challenges and changes, but also opportunities for growth and learning. (Year: 年份)<br>今年充满了挑战和变化，但也是成长和学习的机会。</p></li><li><p>Despite his protestations, she could see the truth in his eyes and knew he couldn’t deny it any longer. (Deny: 否认)<br>尽管他强烈抗议，但她能从他的眼神中看出事实真相，知道他再也无法否认。</p></li><li><p>She couldn’t help but giggle at his silly jokes, finding his sense of humor contagious. (Giggle: 咯咯笑)<br>她情不自禁地对他愚蠢的笑话咯咯笑，觉得他的幽默感很有感染力。</p></li><li><p>After much deliberation, they finally resolved their differences and came to a mutual agreement. (Resolve: 解决)<br>在经过多次深思熟虑后，他们终于解决了彼此之间的分歧，达成了共识。</p></li><li><p>They relaxed in the lounge, enjoying the comfortable seating and soothing ambiance. (Lounge: 休息室)<br>他们在休息室里放松，享受着舒适的座椅和宁静的氛围。</p></li><li><p>Walking down the long corridor, she felt a sense of anticipation for what lay ahead. (Corridor: 走廊)<br>走在漫长的走廊上，她对前方的事物充满了期待。</p></li><li><p>It’s important to maintain a healthy lifestyle, including regular exercise and a balanced diet. (Maintain: 保持)<br>保持健康的生活方式很重要，包括定期锻炼和均衡饮食。</p></li><li><p>The party had a casual atmosphere, with people mingling and chatting in a relaxed setting. (Casual: 随意)<br>派对氛围轻松随意，人们在轻松的氛围中交流和聊天。</p></li><li><p>They traveled to the conference via train, enjoying the scenic route and avoiding the traffic. (Via: 经由)<br>他们乘火车前往会议地点，享受着沿途的风景，避开了交通拥堵。</p></li><li><p>The stereo system filled the room with music, creating a lively and vibrant atmosphere. (Stereo: 立体声)<br>立体声音响系统让房间充满了音乐，营造出生动活泼的氛围。</p></li><li><p>They walked through the silent streets, the only sound being the occasional rustle of leaves in the breeze. (Silent: 寂静)<br>他们走在寂静的街道上，唯一的声音是微风中偶尔传来的树叶沙沙声。</p></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>英语</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>渔樵问对</title>
    <link href="/2024/06/05/juzhi7/"/>
    <url>/2024/06/05/juzhi7/</url>
    
    <content type="html"><![CDATA[<p>渔樵问对<br>渔者垂钓于伊水之上。樵者过之，弛担息肩，坐于磐石之上，而问于渔者。</p><p>曰：“鱼可钩取乎？”</p><p>曰：“然。”</p><p>曰：“钩非饵可乎？”</p><p>曰：“否。”</p><p>曰：“非钩也，饵也。鱼利食而见害，人利鱼而蒙利，其利同也，其害异也。敢问何故？”</p><p>渔者曰：“子樵者也，与吾异治，安得侵吾事乎？然亦可以为子试言之。彼之利，犹此之利也；彼之害，亦犹此之害也。子知其小，未知其大。鱼之利食，吾亦利乎食也；鱼之害食，吾亦害乎食也。子知鱼终日得食为利，又安知鱼终日不得食为害？如是，则食之害也重，而钩之害也轻。子知吾终日得鱼为利，又安知吾终日不得鱼不为害也？如是，则吾之害也重，鱼之害也轻。以鱼之一身，当人之食，是鱼之害多矣；以人之一身，当鱼之一食，则人之害亦多矣。又安知钓乎大江大海，则无易地之患焉？鱼利乎水，人利乎陆，水与陆异，其利一也；鱼害乎饵，人害乎财，饵与财异，其害一也。又何必分乎彼此哉！子之言，体也，独不知用尔。”</p><p>樵者又问曰：“鱼可生食乎？”</p><p>曰：“烹之可也。”</p><p>曰：“必吾薪济子之鱼乎？”</p><p>曰：“然。“</p><p>曰：“吾知有用乎子矣。”</p><p>曰：“然则子知子之薪，能济吾之鱼，不知子之薪所以能济吾之鱼也。薪之能济鱼久矣，不待子而后知。苟世未知火之能用薪，则子之薪虽积丘山，独且奈何哉？”</p><p>樵者曰：“愿闻其方。”</p><p>曰：“火生于动，水生于静。动静之相生，水火之相息。水火，用也；草木，体也。用生于利，体生于害。利害见乎情，体用隐乎性。一性一情，圣人能成。子之薪犹吾之鱼，微火则皆为腐臭败坏，而无所用矣，又安能养人七尺之躯哉？”</p><p>樵者曰：“火之功大于薪，固已知之矣。敢问善灼物，何必待薪而后传？”</p><p>曰：“薪，火之体也。火，薪之用也。火无体，待薪然后为体；薪无用，待火然后为用。是故凡有体之物，皆可焚之矣。”</p><p>曰：“水有体乎？”</p><p>曰：“然。”</p><p>曰：“火能焚水乎？“</p><p>曰：“火之性，能迎而不能随，故灭。水之体，能随而不能迎，故热。是故有温泉而无寒火，相息之谓也。”</p><p>曰：“火之道生于用，亦有体乎？”</p><p>曰：“火以用为本，以体为末，故动。水以体为本，以用为末，故静。是火亦有体，水亦有用也。故能相济又能相息，非独水火则然，天下之事皆然，在乎用之何如尔。”</p><p>樵者曰：“用可得闻乎？”</p><p>曰：“可以意得者，物之性也。可以言传者，物之情也。可以象求者，物之形也。可以数取者，物之体也。用也者，妙万物为言者也，可以意得，而不可以言传。”</p><p>曰：“不可以言传，则子恶得而知之乎？”</p><p>曰：“吾所以得而知之者，固不能言传，非独吾不能传之以言，圣人亦不能传之以言也。”</p><p>曰：“圣人既不能传之以言，则六经非言也耶?”</p><p>曰：“时然后言，何言之有？”</p><p>樵者赞曰：“天地之道备于人，万物之道备于身，众妙之道备于神，天下之能事毕矣，又何思何虑！吾而今而后，知事心践形之为大。不及子之门，则几至于殆矣。”</p><p>乃析薪烹鱼而食之，饫而论《易》。</p><p>渔者与樵者游于伊水之上。渔者叹曰：“熙熙乎万物之多，而未始有杂。吾知游乎天地之间，万物皆可以无心而致之矣。非子则孰与归焉？”</p><p>樵者曰：“敢问无心致天地万物之方？”</p><p>渔者曰：“无心者，无意之谓也。无意之意，不我物也。不我物，然后定能物物。”</p><p>曰：“何谓我，何谓物？”</p><p>曰：‘以我徇物，则我亦物也；以物徇我，则物亦我也。我物皆致，意由是明。天地亦万物也，何天地之有焉？万物亦天地也，何万物之有焉？万物亦我也，何万物之有焉？我亦万物也，何我之有焉？何物不我？何我不物？如是则可以宰天地，可以司鬼神，而况于人乎？况于物乎？“</p><p>樵者问渔者曰：“天何依？”</p><p>曰：“依乎地。”</p><p>曰：“地何附？”</p><p>曰：“附乎天。”</p><p>曰：“然则天地何依何附？”</p><p>曰：“自相依附。天依形，地附气。其形也有涯，其气也无涯。有无之相生，形气之相息。终则有始，终始之间，其天地之所存乎？天以用为本，以体为末；地以体为本，以用为末。利用出入之谓神，名体有无之谓圣。唯神与圣，能参乎天地者也。小人则日用而不知，故有害生实丧之患也。夫名也者，实之客也；利也者，害之主也。名生于不足，利丧于有余。害生于有余，实丧于不足。此理之常也。养身者必以利，贪夫则以身殉，故有害生焉。立身必以名，众人则以身殉名，故有实丧焉。窃人之财谓之盗，其始取之也，唯恐其不多也。及其败露也，唯恐其多矣。夫贿之与赃，一物而两名者，利与害故也。窃人之美谓之徼，其始取之也，唯恐其不多也。及其败露，唯恐其多矣。夫誉与毁，一事而两名者，名与实故也。凡言朝者，萃名之地也；市者，聚利之地也。能不以争处乎其间，虽一日九迁，一货十倍，何害生实丧之有耶？是知争也者取利之端也，让也者趋名之本也。利至则害生，名兴则实丧。利至名兴，而无害生实丧之患，唯有德者能之。天依地，地会天，岂相远哉！”</p><p>渔者谓樵者曰：“天下将治，则人必尚行也；天下将乱，则人必尚言也。尚行，则笃实之风行焉；尚言，则诡谲之风行焉。天下将治，则人必尚义也；天下将乱，则人必尚利也。尚义，则谦让之风行焉；尚利，则攘夺之风行焉。三王，尚行者也；五霸，尚言者也。尚行者必入于义也，尚言者必入于利也。义利之相去，一何如是之远耶？是知言之于口，不若行之于身，行之于身，不若尽之于心。言之于口，人得而闻之，行之于身，人得而见之，尽之于心，神得而知之。人之聪明犹不可欺，况神之聪明乎？是知无愧于口，不若无愧于身，无愧于身，不若无愧于心。无口过易，无身过难，无身过易，无心过难。既无心过，何难之有！吁，安得无心过之人，与之语心哉！”</p><p>渔者谓樵者曰：“子知观天地万物之道乎？”</p><p>樵者曰：“未也。愿闻其方。”</p><p>渔者曰：“夫所以谓之观物者，非以目观之也，非观之以目，而观之以心也；非观之以心，而观之以理也。天下之物，莫不有理焉，莫不有性焉，莫不有命焉。所以谓之理者，穷之而后可知也；所以谓之性者，尽之而后可知也；所似谓之命者，至之而后可知也。此三知也，天下之真知也，虽圣人无以过之也。而过之者，非所以谓之圣人也。夫鉴之所以能为明者，谓其能不隐万物之形也。虽然鉴之能不隐万物之形，未若水之能一万物之形也。虽然水之能一万物之形，又未若圣人之能一万物情也。圣人之所以能一万物之情者，谓其圣人之能反观也。所以谓之反观者，不以我观物也。不以我观物者，以物观物之谓也。又安有我于其间哉？是知我亦人也，人亦我也。我与人皆物也。此所以能用天下之目为己之目，其目无所不观矣。用天下之耳为己之耳，其耳无所不听矣。用天下之口为己之口，其口无所不言矣。用天下之心为己之心，其心无所不谋矣。天下之观，其于见也，不亦广乎？天下之听，其于闻也，不亦远乎？天下之言，其于论也，不亦高乎？天下之谋，其于乐也，不亦大乎？夫其见至广，其闻至远，其论至高，其乐至大，能为至广、至远、至高、至大之事，而中无一为焉，岂不谓至神至圣者乎？非唯吾谓之至神至圣者乎，而天下谓之至神至圣者乎。非唯一时之天下渭之至神至圣者乎，而千万世之天下谓之至神圣者乎。过此以往，未之或知也已。”</p><p>樵者问渔者曰：“子以何道而得鱼？”</p><p>曰：“吾以六物具而得鱼。”</p><p>曰：“六物具也，岂由天乎？”</p><p>曰：“具六物而得鱼者，人也。具六物而所以得鱼者，非人也。”</p><p>樵者未达，请问其方。</p><p>渔者曰：“六物者，竿也，纶也，浮也，沉也，钩也，饵也。一不具，则鱼不可得。然而六物具而不得鱼者，非人也。六物具而不得鱼者有焉，未有六物不具而得鱼者也。是知具六物者，人也。得鱼与不得鱼，天也。六物不具而不得鱼者，非天也，人也。”</p><p>樵者曰：“人有祷鬼神而求福者，福可祷而求耶？求之而可得耶？敢问其所以。”</p><p>曰：“语善恶者，人也；福祸者，天也。天道福善而祸淫，鬼神岂能违天乎?自作之咎，固难逃已。天降之灾，禳之奚益？修德积善，君子常分。安有余事于其间哉！”</p><p>樵者曰：“有为善而遇祸，有为恶而获福者，何也？”</p><p>渔者曰：“有幸与不幸也。幸不幸，命也；当不当，份也。一命一份，人其逃乎？”</p><p>曰：“何谓份？何谓命？”</p><p>曰：“小人之遇福，非份也，有命也；当祸，份也，非命也。君子之遇祸，非份也，有命也；当福，份也，非命也。”</p><p>渔者谓樵者曰：“人之所谓亲，莫如父子也；人之所渭疏，莫如路人也。利害在心，则父子过路人远矣。父子之道，天性也。利害犹或夺之，况非天性者乎？夫利害之移人，如是之深也，可不慎乎？路人之相逢则过之，固无相害之心焉，无利害在前故也。有利害在前，则路人与父子，又奚择焉？路人之能相交以义，又何况父子之亲乎？夫义者，让之本也；利者，争之端也。让则有仁，争则有害。仁与害，何相去之远也！尧、舜亦人也。桀、纣亦人也，人与人同而仁与害异尔，仁因义而起，害因利而生。利不以义，则臣弑其君者有焉，子弑其父者有焉。岂若路人之相逢，一目而交袂于中逵者哉！”</p><p>樵者谓渔者曰：“吾尝负薪矣，举百斤而无伤吾之身，加十斤则遂伤吾之身，敢问何故？”</p><p>渔者曰：“樵则吾不知之矣。以吾之事观之，则易地皆然。吾尝钓而得大鱼，与吾交战。欲弃之，则不能舍，欲取之，则未能胜。终日而后获，几有没溺之患矣。非直有身伤之患耶？鱼与薪则异也，其贪而为伤则一也。百斤，力分之内者也，十斤，力分之外者也。力分之外，虽一毫犹且为害，而况十斤乎！吾之贪鱼亦何以异子之贪薪乎！”</p><p>樵者叹曰：“吾而今而后，知量力而动者，智矣哉！”</p><p>樵者谓渔者曰：“子可谓知《易》之道矣。吾也问：《易》有太极，太极何物也？”</p><p>曰：“无为之本也。”</p><p>曰：“太极生两仪，两仪，天地之谓乎？”</p><p>曰：“两仪，天地之祖也，非止为天地而已也。太极分而为二，先得一为一，后得一为二。一二谓两仪。”</p><p>曰：“两仪生四象，四象何物也？”</p><p>曰：“大象谓阴阳刚柔。有阴阳然后可以生天，有刚柔然后可以生地。立功之本，于斯为极。”</p><p>曰：“四象生八卦，八卦何谓也？”</p><p>曰：“谓乾、坤、离、坎、兑、艮、震、巽之谓也。迭相盛衰终始于其间矣。因而重之，则六十四卦由是而生也，而《易》之道始备矣。”</p><p>樵者问渔者曰：“复何以见天地之心乎？”</p><p>曰：“先阳已尽，后阳始生，则天地始生之际。中则当日月始周之际，末则当星辰始终之际。万物死生，寒暑代谢，昼夜变迁，非此无以见之。当天地穷极之所必变，变则通，通则久，故《象》言‘先王以至日闭关，商旅不行，后不省方’，顺天故也。”</p><p>樵者谓渔者曰：“无妄，灾也。敢问何故？”</p><p>曰：“妄则欺他，得之必有祸，斯有妄也，顺天而动，有祸及者，非祸也，灾也。犹农有思丰而不勤稼稿者，其荒也，不亦祸乎？农有勤稼穑而复败诸水旱者，其荒也，不亦灾乎？故《象》言‘先王以茂对时育万物’，贵不妄也。”</p><p>樵者问曰：“姤，何也？”</p><p>曰：“姤，遇也。柔遇刚也，与夬正反。夬始逼壮，姤始遇壮，阴始遇阳，故称姤焉。观其姤，天地之心，亦可见矣。圣人以德化及此，罔有不昌。故《象》言‘施命诰四方’，履霜之慎，其在此也。”</p><p>渔者谓樵者曰：“春为阳始，夏为阳极，秋为阴始，冬为阴极。阳始则温，阳极则热；阴始则凉，阴极则寒。温则生物，热则长物，凉则收物，寒则杀物。皆一气别而为四焉。其生万物也亦然。”</p><p>樵者问渔者曰：“人之所以能灵于万物者，何以知其然耶？”</p><p>渔者对曰：“谓其目能收万物之色，耳能收万物之声，鼻能收万物之气，口能收万物之味。声色气味者，万物之体也。目耳口鼻者，万人之用也。体无定用，惟变是用。用无定体，惟化是体。体用交而人物之道于是乎备矣。然则人亦物也，圣亦人也。有一物之物，有十物之物，有百物之物，有千物之物，有万物之物，有亿物之物，有兆物之物。生一一之物，当兆物之物者，岂非人乎！有一人之人，有十人之人，有百人之人，有千人之人，有万人之人，有亿人之人，有兆人之人。当兆人之人者，岂非圣乎！是知人也者，物之至者也。圣也者，人之至者也。物之至者始得谓之物之物也。人之至者始得谓之人之人也。夫物之物者，至物之谓也。人之人者，至人之谓也。以一至物而当一至人，则非圣人而何？人谓之不圣，则吾不信也。何哉？谓其能以一心观万心，一身观万身，一物观万物，一世观万世者焉。又谓其能以心代天意，口代天言，手代天工，身代天事者焉。又谓其能以上识天时，下尽地理，中尽物情，通照人事者焉。又谓其能以弥纶天地，出入造化，进退今古，表里人物者焉。噫！圣人者，非世世而效圣焉。吾不得而目见之也。虽然吾不得而目见之，察其心，观其迹，探其体，潜其用，虽亿万千年亦可以理知之也。人或告我曰：‘天地之外，别有天地万物，异乎此天地万物。’则吾不得而知之也。非唯吾不得而知之也，圣人亦不得而知之也。凡言知者，谓其心得而知之也。言言者，谓其口得而言之也。既心尚不得而知之，口又恶得而言之乎？以不可得知而知之，是谓妄知也。以不可得言而言之，是谓妄言也。吾又安能从妄人而行妄知妄言者乎！”</p><p>渔者谓樵者曰：“仲尼有言曰：殷因于夏礼，所损益可知也；周因于殷礼，所损益可知也。其或继周者，虽百世可知也。夫如是，则何止于百世而已哉！亿千万世，皆可得而知之也。人皆知仲尼之为仲尼，不知仲尼之所以为仲尼，不欲知仲尼之所以为仲尼则已，如其必欲知仲尼之所以为仲尼，则舍天地将奚之焉？人皆知天地之为天地，不知天地之所以为天地。不欲知天地之所以为天地则已，如其必欲知天地之所以为天地，则舍动静将奚之焉？夫一动一静者，天地至妙者欤？夫一动一静之间者，天地人至妙者欤？是知仲尼之所以能尽三才之道者，谓其行无辙迹也。故有言曰：‘予欲无言’，又曰：‘天何言哉！四时行焉，百物生焉。’其此之谓与？”</p><p>渔者谓樵者曰：“大哉！权之与变乎？非圣人无以尽之。变然后知天地之消长，权然后知天下之轻重。消长，时也；轻重，事也。时有否泰，事有损益。圣人不知随时否泰之道，奚由知变之所为乎？圣人不知随时损益之道，奚由知权之所为乎？运消长者，变也；处轻重者，权也。是知权之与变，圣人之一道耳。”</p><p>樵者问渔者曰：“人谓死而有知，有诸？”</p><p>曰：“有之。”</p><p>曰：“何以知其然？”</p><p>曰：“以人知之。”</p><p>曰：“何者谓之人？”</p><p>曰：“目耳鼻口心胆脾肾之气全，谓之人。心之灵曰神，胆之灵曰魄，脾之灵曰魂，肾之灵曰精。心之神发乎目，则谓之视；肾之精发乎耳，则谓之听；脾之魂发乎鼻，则谓之臭；胆之魄发乎口，则谓之言。八者具备，然后谓之人。夫人也者，天地万物之秀气也。然而亦有不中者，各求其类也。若全得人类，则谓之曰全人之人。夫全类者，天地万物之中气也，谓之曰全德之人也。全德之人者，人之人者也。夫人之人者，仁人之谓也。唯全人，然后能当之。人之生也，谓其气行，人之死也，谓其形返。气行则神魂交，形返则精魄存。神魂行于天，精魄返于地。行于天，则谓之曰阳行；返于地，则谓之曰阴返。阳行则昼见而夜伏者也，阴返则夜见而昼伏者也。是故知日者月之形也，月者日之影也。阳者阴之形也，阴者阳之影也。人者鬼之形也，鬼者人之影也。人谓鬼无形而无知者，吾不信也。”</p><p>樵者问渔者曰：“小人可绝乎？”</p><p>曰： “不可。君子禀阳正气而生，小人禀阴邪气而生。无阴则阳不成，无小人则君子亦不成，唯以盛衰乎其间也。阳六分，则阴四分；阴六分，则阳四分。阳阴相半，则各五分矣。由是知君子小人之时有盛衰也。治世则君子六分。君子六分，则小人四分，小人固不能胜君子矣。乱世则反是，君君，臣臣，父父，子子，兄兄，弟弟，夫夫，妇妇，谓各安其分也。君不君，臣不臣，父不父，子不子，兄不兄，弟不弟，夫不夫，妇不妇，谓各失其分也。此则由世治世乱使之然也。君子常行胜言，小人常言胜行。故世治则笃实之士多，世乱则缘饰之士众。笃实鲜不成事，缘饰鲜不败事。成多国兴，败多国亡。家亦由是而兴亡也。夫兴家与兴国之人，与亡国亡家之人，相去一何远哉！”</p><p>樵者问渔者曰：“人所谓才者，有利焉，有害焉者，何也？”</p><p>渔者曰：“才一也，利害二也。有才之正者，有才之不正者。才之正者，利乎人而及乎身者也；才之不正者，利乎身而害乎人者也。”</p><p>曰：“不正，则安得谓之才？”</p><p>曰：“人所不能而能之，安得不谓之才？圣人所以异乎才之难者，谓其能成天下之事而归之正者寡也。若不能归之以正，才则才矣，难乎语其仁也。譬犹药疗疾也，毒药亦有时而用也，可一而不可再也，疾愈则速已，不已则杀人矣。平药则常日而用之可也，重疾非所以能治也。能驱重疾而无害人之毒者，古今人所谓良药也。《易》曰：‘大君有命，开国承家，小人勿用。’如是，则小人亦有时而用之。时平治定，用之则否。《诗》云：‘它山之石，可以攻玉。’其小人之才乎！”</p><p>樵者谓渔者曰：“国家之兴亡，与夫才之邪正，则固得闻命矣。然则何不择其人而用之？”</p><p>渔者曰：“择臣者，君也；择君者，臣也。贤愚各从其类而为。奈何有尧舜之君，必有尧舜之臣；有桀纣之君，而必有桀纣之臣。尧舜之臣，生乎桀纣之世，桀纣之臣，生于尧舜之世，必非其所用也。虽欲为祸为福，其能行乎？夫上之所好，下必好之。其若影响，岂待驱率而然耶？上好义，则下必好义，而不义者远矣；上好利，下必好利，而不利者远矣。好利者众，则天下日削矣；好义者众，则天下日盛矣。日盛则昌，日削则亡。盛之与削，昌之与亡，岂其远乎？在上之所好耳。夫治世何尝无小人，乱世何尝无君子，不用则善恶何由而行也。”</p><p>樵者曰：“善人常寡，而不善人常众；治世常少，乱世常多，何以知其然耶？”</p><p>曰：“观之于物，何物不然？譬诸五谷，耘之而不苗者有矣。蓬莠不耘而犹生，耘之而求其尽也，亦未如之何矣。由是知君子小人之道，有自来矣。君子见善则喜之，见不善则远之；小人见善则疾之，见不善则喜之。善恶各从其类也。君子见善则就之，见不善则违之；小人见善则违之，见不善则就之。君子见义则迁，见利则止；小人见义则止，见利则迁。迁义则利人，迁利则害人。利人与害人，相去一何远耶？家与国一也，其兴也，君子常多而小人常鲜；其亡也，小人常多而君子常鲜。君子多而去之者，小人也；小人多而去之者，君子也。君子好生，小人好杀。好生则世治，好杀则世乱。君子好义，小人好利。治世则好义，乱世则好利。其理一也。”</p><p>钓者谈已，樵者曰：“吾闻古有伏羲，今日如睹其面焉。”拜而谢之，及旦而去。</p><p>渔者垂钓于伊水之边。有一樵者路过，放下柴担休息，坐在大石头上，问渔者：“能钓到鱼吗？”</p><p>答：“能。”</p><p>问：“鱼钩上不放鱼饵能钓到吗？”</p><p>答：“不能。”</p><p>问：“钓到鱼不是鱼钩而是鱼饵，可见鱼因吃食而受害，人因吃鱼而受利，都是因吃其利一样，而结果不一样。请问这是为什么？”</p><p>渔者说：“你是打柴的，与我工作不一样，又怎么能知道我的事呢？然而我可以给你解释一下。你口中的利就像你看到我钓到了鱼，你口中的害就像你看到鱼丢失了性命。你只知道眼前事件的利害关系，并没有看到影响眼前事件的利害关系是多方面的。鱼的利和我的利是一样的，鱼的害和我的害也是一样的。你只知其一，未知其二。鱼受利于食，我也受利于食，鱼受害于食，我也受害于食。你只知鱼终日有食吃而为利，又怎知鱼若终日无食吃而为害呢？如此，食物的害处太重了，而钓鱼的害处却轻了。你只知我终日钓到鱼而为利，又怎知我若终日钓不到鱼而为害呢？如此，我受到害太重了，而鱼受到的害却轻了。若以鱼为本，人吃了鱼，则鱼受到了伤害；若以人为本，以鱼为食，人无食吃则人受到了伤害。更何况在大江大海里钓鱼，又是多么的危险？鱼生活在水里，人生活在陆地，水与陆地不同，其利益一样。鱼受害于饵，人受害于财，饵与财不同，其害处一样，又何必分彼此呢！你说的，只是事物的本质，而不知事物的变化。”</p><p>樵者又问：“鱼能生吃吗？”</p><p>答：“煮熟之后可以吃。”</p><p>问：“那必然用我的柴煮你的鱼了？”</p><p>答：“当然。”</p><p>问：“那我知道了，我的柴因你的鱼而发生了变化。”</p><p>答：“你知道你的柴能煮我的鱼，可你不知道你的柴为什么能煮我的鱼。用柴煮鱼的方法早就有了，在你之前人们就知道，可世人却不知道柴的作用是火。如果没有火，你的柴就是堆积如山又有何用呢。”</p><p>樵者：“愿意听你说其中的道理。”</p><p>渔者：“火生于动，水生于静。动静相生，水火相息。水火为用，草木为体。用生于利，体生于害。利与害表现在感情上，体与用隐藏于性情中。一明一暗，只有圣人才懂柴与火的道理。就像我的鱼，没有火烧煮直到腐臭烂掉，也不能吃，又怎能养人身体呢？”</p><p>樵者问：“火的功能大于柴，我已经知道了。那为什么易燃物还要柴引燃呢？”</p><p>答：“柴是火的本体，火是柴的作用。火本无体，通过柴燃烧后才有体。柴本无作用，待火烧起后才为有用。因此，凡是有体的物体，都可以燃烧。”</p><p>问：“水有体吗？”</p><p>答：“有。”</p><p>问：“水能燃烧?”</p><p>答：“火的性质，遇水后能与之对立而不能与之相随，所以灭了。水的性质，遇火后能与之相随而不能与之相对立，所以热了。因此有热水而无凉火，是因为水火相息的原因。”</p><p>问：“火的功能来于用，它有体吗？</p><p>答：“火以用为始，以体为终，所以火是动的。水以体为始，以用为终，所以水是静的。因此，火有体，水有用，二者既相济又相息。不止水火，天下的事物都如此，就在于你如何应用。”</p><p>问：“如何应用呢？”</p><p>答：“通过意识得到的，是事物的本性；通过语言传授的，是事物的外在表现；通过眼睛观察的，是事物的形状；；通过数量计算的，是事物的多少。如何应用，阐述万物的奥妙，只可意会，而不能言传。”</p><p>问：“不可以言传，你又如何知道的？”</p><p>答：“我之所以知道，我就不是言传得到的，并非我一人不能言传，圣人也不能用语言来传授。”</p><p>问：“圣人都不能用语言来传授，那六经不是语言传授的？”</p><p>答：“那是后人编的，圣人又说了什么？”</p><p>樵者闻听，赞叹说：“天地的道理具备于人，万物的道理具备于身，变化的道理具备于神，天下的各种道理都具备了，还有什么可思虑的！我从今天开始，才知道事物的变化如此之大，还没有入门，真是白活了。”</p><p>于是，樵者解开柴生火煮鱼。二人吃饱了后而论《易》。</p><p>渔、樵二人游玩于伊水之上。渔者感叹说：“世上万物之多，纷杂繁乱。我知道游戏于天地之间，万物都以无心来了解。并非像你熟悉的那样简单。”</p><p>问：“请问如何以无心来了解万物？”</p><p>答：“无心就是无意，无意就是不把我与物分开，然后物物相通。”</p><p>问：“什么是我？什么是物？”</p><p>答：“以万物为标准，则我也是物。以我为标准，则万物也是我。我与物一样，则道理简单明了。天地也是万物，万物也是天地；我也是万物，万物也是我；我与万物之间可以相互转换。如此可以主宰天地，号令鬼神。更何况于人？何况于物？”</p><p>问：“天依靠什么？”</p><p>答：“天依靠于地。”</p><p>问：“地依赖于什么？”</p><p>答：“地依赖于天。”</p><p>问：“那天地又依附于什么？”</p><p>答：“相互依附。天依靠于地形，地依赖于天气。其地形有边涯，其天气无边际。有与无相生，形与气相息。天与地就存在于终始之间。天以它的作用为主，形体为次；地以它的形体为主，作用为次。作用的表现称作神，形体的有无称作圣。只有神和圣，才能领悟天地的变化。平民百姓天天应用而不明白，所以有灾害产生利益丧失。名誉是次要的，利益才是害人的主体。名誉产生于不知足，利益丧失于有余。危害产生于有余，实际丧失于不知足。这些都是常理。生活于世必须有物质，故贪婪的人时时寻找利益，因此有危害产生。想出人头地必须出名，故世人都争强好胜，因此有东西丧失。窃人财物称之为盗。偷盗之时，唯恐东西偷的少，等到败露后，又恐东西多定罪大。受贿与收贿，都是一种物品，可却是两种名称，是因为利与害的不同。窃人物品时存在侥幸心理，偷时嫌少，逮时嫌多。名誉的兴与毁，虽然是一件事，可却有两种结果，是因为得到或丧失的不同，大机关事业单位，是出名的地方；集贸市场，是聚利的地方，能不以争名夺利的心态居其中，虽然一日官升三级，获利百倍，又怎能伤害得了你呢？因此争名，是夺利的开始。礼让，才是取名的根本。利益到来则危害产生，名扬天下则实物丧失。利益到来又名扬天下，而且无祸害相随，只有重德者才能达到。天依靠于地，地依赖于天，其中的含义多么深远！”</p><p>渔者说：“天下将要治理的时候，人民必然崇尚行动；天下将要叛乱的时候，人民必然崇尚言论。崇尚行动，则诚实之风盛行；崇尚言论，则诡诈之风盛行。天下将要治理的时候，人民必然崇尚仁义；天下将要叛乱的时候，人民必然崇尚利益。崇尚仁义，则谦虚之风盛行；崇尚利益，则争夺之风盛行。三王时代，人民崇尚行动；五霸时代，人民崇尚言论。崇尚行动必注重于仁义，崇尚言论必注重于利益。仁义与利益相比，相差的有多么远？所以言出于口，不如行之于身，行之于身，不如尽之于心。言论出于口，人得以听到；行动在于身体，人得以见到；尽职于心，神得以知道。人的聪明不可以欺骗，更何况神的聪明？因此无愧于口，不如无愧于身，无愧于身，不如无愧于心。无愧于身比无愧于口难；无愧于心比无愧于身难。如果内心都无过错，还有什么灾难！唉！那里找无心过的人，与之交心谈畅！”</p><p>渔者问：“你知道观察天地万物的道理吗？”</p><p>樵者：“不知道。愿听你讲。”</p><p>渔者说：“所谓观物，并非以眼观物；而是以心观物，再进一步说以理观物。天下万物的存在，都有它的道理、本性和命运。所以以理观物，研究以后可以知道；以本性观物，观察以后可以知道；以命观物，推算以后可以知道。此三知，才是天下的真知，就连圣人也无法超过。超出此三知，也就不能称为圣人。鉴别万物而能成为明白的人，是因为能不隐瞒万物的形状；虽然能鉴别而不隐瞒万物的形状，但不如水能化成万物的形状；虽然水能化成万物的形状，又不如圣人能模仿万物的性情。圣人之所以能模仿万物的性情，在于圣人能反观其物。所谓反观其物，就是不以我观物。不以我观物，而是以物观物。既然以物观物，我又怎么会在俩物之间呢？因此我也是人，人也是我，我与人都是物。这样才能用天下人的目为我目，则无所不见；用天下人的耳为我耳，则无所不闻；用天下人的口为我口，则无所不言；用天下人的心为我心，则无所不谋。如此观天下，所见多么广阔！所闻多么深远！所论多么精辟！所谋多么详密！如此所见至广，所闻至远，所论至精，所谋至密，其中无一不明，岂不是至神至圣？并非我一人称为至神至圣，而是天下的人都称之为至神至圣。并非一时天下人称之为至神至圣，几千万年以后天下人仍称之为至神至圣。长此以往，都是如此。”</p><p>樵者问渔者：“你如何钓到鱼？”</p><p>答：“我用六种物具钓到鱼。”</p><p>问：“六物具备，就能钓到鱼吗？”</p><p>答：“六物具备而钓上鱼，是人力所为。六物具备而钓不上鱼，非人力所为。”</p><p>樵者不明白，请问其中的道理。</p><p>渔者说：“六物，鱼杆、鱼线、鱼漂、鱼坠、鱼钩、鱼饵。有一样不具备，则钓不上鱼。然而有六物具备而钓不上鱼的时候，这不是人的原因。有六物具备而钓不上鱼的时候，但没有六物不具备而钓上鱼的时候。因此具备六物，是人力。钓上钓不上鱼，是天意。六物不具备而钓不上鱼，不是天意是人力。”</p><p>樵者问：“有人祈祷鬼神而求福，福可以求到吗？”</p><p>答：“言行善恶，是人的因素；福与祸，是天的结果。天的规律福善祸灾，鬼神岂能违背？自己做的坏事，岂能逃避。上天降下的灾祸，祈祷又有什么用？修德积善，是君子的本分。这样做就不会有灾祸来找！”</p><p>问：“有行善的而遇祸，有行恶的而获福。为什么？”</p><p>答：“这是有幸与不幸之分。幸与不幸，是命。遇与不遇，是分。命与分，人怎么能逃避？”</p><p>问：“什么是分？什么是命？”</p><p>答：“坏人遇福，不是分是命，遇祸是分不是命。好人遇祸，是命不是分，遇福是分不是命。”</p><p>渔者对樵者说：“人与人的亲情，莫过于父子；人与人的疏远莫过于路人，如果利与害在心里，父子之间就会像路人一样远，父子之间的亲情，属于天性，利与害都能夺掉，更何况不是天性的，利与害祸人，如此之深，不能不谨慎！路人相遇一过了之，并无相害之心，是因为没有利与害的关系。若有利与害的关系，路人与路人、父与子之间又如何选择呢？路人若能以义相交，又何况父子之亲呢！所谓义，是谦让之本。而利益是争夺之端。谦让则有仁义，争夺则有危害。仁义与危害相去甚远。尧、舜是人，桀、纣也是人。人与人同，而仁义与危害却不同。仁慈因义气而起，危害因利益而生。利益不会因义气而争夺，否则不会有臣杀君、子杀父之事。路人相逢，也不可能因一眼而情投意合。”</p><p>樵者问渔者：“我经常扛柴，扛一百斤也伤不了我，再加十斤就伤了我，为什么？”</p><p>渔者答：“扛柴我不清楚。以我钓鱼之事论之，其理一样。我经常钓到大鱼，与我较量。欲弃之，不舍得，欲钓取，又不容易。很长时间才能钓上来，有好几次溺水的危险。这不也是伤身的忧患？钓鱼与扛柴虽不一样，但因贪而受伤则无两样。一百斤，力所能及，再加十斤，则在你力所之外。力所之外，加一毫都是有害，何况十斤！我贪鱼，又何异于你贪柴呢？”</p><p>樵者感叹道：“从今以后，我知道做事量力而行才是有智慧的。”</p><p>樵者问：“你是知易理的人。请问易有太极，太极是何物？”</p><p>答：“无为之本。”</p><p>问：“太极生两仪，两仪是天地的称呼吗？”</p><p>答：“两仪，天地之祖，并非单指天地。太极一分为二，先得到的一为一，后得到的一为二，一与二叫做两仪。”</p><p>问：“两仪生四象，四象为何物？”</p><p>答：“四象就是阴阳刚柔。阴阳可以生天，刚柔可以生地。一切事物的根本，于此为极点。”</p><p>问：“四象生八卦。八卦是什么？”</p><p>答：“八卦就是乾、坤、离、坎、兑、艮、震、巽。是事物发展终始、盛衰的表现。两两相重，则六十四卦生出，易学之道就具备了。”</p><p>樵者问渔者：“如何见到天地的本性？”</p><p>答：“先阳耗尽，后阳出生。则天地开始出现，变化到中期日月开始周行，变化到末期星辰显现。万物死生，寒暑代谢，昼夜变迁，事物以此相变。当天地运行到终了必然变化，变则通，通则久。所以《易》中象言‘先王到最后一日闭关，哪儿也不去’，是顺天行所故。”</p><p>问：“无妄（卦名），属于灾，是什么原因？”</p><p>答：“妄是欺骗，得之必有祸，因此称妄。顺天意而行动，有祸秧及也不叫祸而叫灾。就像农民想着丰收而不去护理庄稼，其结果荒芜，不是祸是什么？农民勤劳治理庄稼而遭水涝或干旱，其结果荒芜，不是灾是什么？所以《易》中象言‘先王以诚对万物’，贵于不欺骗。”</p><p>问：“姤（gòu）（卦名），是什么？”</p><p>答：“姤是相遇。以柔遇刚。与夬（guài）卦相反。夬始强壮，姤由弱遇壮，由阴遇阳。故称为姤。观姤，天地的本性由此可见。圣人以德比喻，没有不明白的。所以《易》中象言‘姤施命于天下，就像走在霜雪之上，小心谨慎’，就在于此。”</p><p>渔者接着说：“春天是阳气的开始，夏天是阳气的极限；秋天是阴气的开始，冬天是阴气的极限。阳气开始则天气温暖，阳气极限则天气暑热；阴气开始则天气凉爽，阴气极限则天气寒冷。温暖产生万物，暑热成长万物；凉爽收藏万物，寒冷肃杀万物。皆是一气四种表现。其生万物也如此。”</p><p>樵着问渔者：“人为万物之灵，是如何表现的？”</p><p>渔者回答：“人的目能收万物之色，耳能收万物之声，鼻能收万物之气，口能收万物之味。声色气味，万物之本，目耳鼻口，人人皆用。物体本无作用，通过变化来表现作用；作用也并不是表现在一个物体上，而是不同的物体有不同的作用。由于物体和作用相交，则人和物的变化规律就具备了。然而人也是物，圣人也是人。有一物、百物、千物、万物、亿物、兆物。身为一物，就可以征兆万物，只有人。有一人、百人、千人、万人、亿人、兆人。生为一人，而能征兆他人，只有圣人。因此知道人是物的至尊；圣人是人的至尊。物的至尊为物中之物，人的至尊为人中之人。所以物的至极为至物，人的至极为至人。以一物知万物、以一人知万人，不是圣人是什么？人不是万物之灵，我不信。为什么？因为人能以一心观万心，以一身观万身，以一物观万物，以一世观万世；又能以心代天意，以口代天言，以手代天工，以身代天事；又能上识天时，下晓地理，中尽物情，通照人事；又能弥纶天地，出入造化，进退古今，表里人物。唉！圣人并非世世可见，我虽不能亲眼见到，但我观察其心迹，探访其行踪，研究其作用，虽经亿万年也能以理知道。有人告诉我说，天地之外，还有另外的天地万物，和此天地万物不一样。而我不得而知。并非我不得而知，连圣人也不得而知。凡说知道的，其实内心并不知道。而说出来的，也只是说说而已。既然内心都不明白，嘴又能说出什么？心里不知道而说知道的，叫做妄知。嘴说不清而又要说的，叫做妄言。我又怎么能相信妄人的妄言和妄知呢？”</p><p>渔者对樵者说：“仲尼说的好：‘殷继承于夏礼，所遇的损益便可知道；周继承于殷礼，所遇的损益也可知道。其次继承周礼的，虽经百世也可知道。’如此，何止百世而已！亿千万世，都可以知道。人都知道仲尼叫仲尼，却不知道仲尼为什么叫仲尼。不想知道仲尼为什么叫仲尼则已，若想知道仲尼为什么叫仲尼，则舍弃天地会怎么样？人都知道天地为天地，却不知道天地为什么为天地，不想知道天地为什么为天地则已，若想知道天地为什么为天地，则舍弃动静会怎么样？一动一静，天地至妙，一动一静之间，天地人至妙。因此仲尼之所以能尽三才之道，是因其行没有辙迹。所以有人说：‘仲尼什么也没说。’又说：‘天什么也没说！但四时运行，百物出生。’这些你知道吗？”</p><p>渔者接着说：“大事中：权力与变化谁重要？并非圣人不能讲清楚。变化过后可知天地的消长，掌权之后可知天下的轻重。消长是时间的表现，轻重是事物的表现。时间有亨通与闭塞，事物有损耗与收益。圣人若不知随时间亨通与闭塞之道，又怎知变化之所为呢？圣人若不知随时间损耗与收益之道，又怎知权力之所为呢？运用消长的是变化，处置轻重的是权力。因此权力与变化，是圣人的修行之一。”</p><p>樵者问渔者：“人死后有灵魂存在，有这种事么？”</p><p>答：“有。”</p><p>问：“如何才能知道？”</p><p>答：“以人为知。”</p><p>问：“什么样的叫人？”</p><p>答：“目耳鼻口心胆脾肾之气全的叫人。心之灵称神，胆之灵称魄，脾之灵称魂，肾之灵称精。（中医认为：心之灵称神，肝之灵称魂，脾之灵称意，肺之灵称魄，肾之灵称精。这里有不同的见解，不知原文有误？还是有何深意？——译者注）心之神表现在目，称为视；肾之精表现在耳，称为听；脾之魂表现在鼻，称为臭；胆之魄表现在口，称为言。八者具备，才可称之为人。人，禀天地万物之秀气而生。然而也有缺少某一方面的人，各归其类。如果各方面都齐全的人，则称为全人。全人得万物中的中和之气，则称为全德之人。全德之人，为人中之人。人中之人，则是仁人之称。只有全人，才能得到仁人之称。人之生，在于气行。人之死，则是形体返还。气行则神魂交，形返则精魄存。神魂行于天，精魄返于地。行于天，称之为阳行，返于地，称之为阴返。阳行于白天而夜间潜伏，阴返于夜间而白天潜伏。所以知道太阳是月亮的形状，月亮是太阳的影子，阳者是阴者的形状，阴者是阳者的影子，人是鬼的形状，鬼是人的影子。有人说，鬼无形而不可知，我不相信。”</p><p>樵者问渔者：“小人能灭绝吗？”</p><p>答：“不能。君子禀阳正气而生，小人禀阴邪气而生。无阴则阳不生，无小人则君子不生，只有盛衰的不同。阳六分，则阴四分；阴六分，则阳四分。阴阳各半，则各占五分。由此而知，君子与小人各有盛衰之时。太平盛世时期，君子占六分，小人占四分，小人不能战胜君子。君臣、父子、兄弟、夫妇各安其道。世间纷乱时期正相反。君不君、臣不臣、父不父、子不子、兄不兄、弟不弟、夫不夫、妇不妇则失其道。这是由治世或乱世所造成的。君子常以身作则胜过空话连篇，小人常空话连篇胜过实际行动。所以盛世时期诚实的人多，乱世时期奸诈的人多。诚实容易成事，奸诈容易败事，成事则国兴，败事则国亡。一个家庭也如此。兴家、兴国之人，与亡国、亡家之人，相差的是多么的远！”</p><p>樵者问：“人有才，有的有益，有的有害，为什么？”</p><p>答：“才为一，益与害为二、有才正、才不正之分、才正，益于身而无害，才不正，益于身而害人。”</p><p>问：“才不正，又如何成为才呢？”</p><p>答：“人所不能做的你能做到，能不成为才吗？圣人所以怜惜成才难，是因为能成天下事而又正派的人很少。若不正派，虽然有才，也难称有仁义。比如吃药治病，毒药也有用的时候，可不能一而再再而三的用。病愈则速停，不停则是杀人了。平常药日常皆可用，但遇重病则没有疗效。能驱除重病而又不害人的毒药，古今都称为良药。《易》说：‘开国立家，用君子不用小人。’如此，小人也有有用的时候。安邦治国，则不要用小人。《诗》说：‘它山之石，可以攻玉。’就是借用小人之才。”</p><p>问：“国家兴亡，与人才的正邪，各有其命。哪为什么不择人而用呢？”</p><p>答：“择臣者，是君王的事，择君者，是臣民的事，贤愚各从其类。世上有尧、舜之君，必有尧、舜之臣；有桀、纣之君，必有桀、纣之臣。尧舜之臣，生于桀、纣之世，则不会成为桀纣之臣。生于尧舜之世并非是他的所为，他想要为祸为福，可不是想干就能干的。上边所好的下边必效仿。君王的影响，还用驱赶去执行吗？上好义，则下必好义，而不义的人则远离；上好利，则下必好利，而不好利的人则远离，好利者多，则天下日渐消亡；好义者众，则天下日渐兴旺。日盛则昌，日消则亡。昌盛与消亡，难道不远吗？都是在上好恶影响的。治国安民之时何尝无小人，乱世之际又何尝无君子，没有君子和小人，善恶又如何区分呢？”</p><p>樵者问：“善人常少，不善人常多；盛世时代短，乱世时期长。如何鉴别呢？”</p><p>答：“观察事物。什么事物不能表现出来？比如五谷，耕种之后有长不出来的，而逢野生物不用耕种就能长出来，耕种之后想要全部收获，是不可能的！由此而知君子与小人之道，也是自然而生。君子见善事则欢喜，见不善事则远离；小人见善事则痛苦，见不善事则欢喜。善恶各从其类。君子见善事则去做，见不善事则阻止；小人见善事则阻止，见不善事则去做；君子见义则迁，见利则止；小人见义则止，见利则迁。迁义则益人，迁利则害人；益人与害人，相去有多远？家与国一样兴旺则君子常多，小人常少；消亡则小人常多君子常少。君子多小人躲避，小人多君子躲避。君子好生，小人好杀。好生则治国安民，好杀则祸国殃民。君子好义，小人好利。治国安民则好义，祸国殃民则好利。其道理是一样的。”</p><p>渔者说完，樵者感慨万分：“我听说上古有伏羲，今日好像一睹其面。”对渔者再三拜谢，相别而去。</p>]]></content>
    
    
    
    <tags>
      
      <tag>句子</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>朱子家训</title>
    <link href="/2024/06/05/juzhi6/"/>
    <url>/2024/06/05/juzhi6/</url>
    
    <content type="html"><![CDATA[<p>朱子家训<br>一、整家<br>黎明即起，洒扫庭除，要内外整洁；既昏便息，关锁门户，必亲自检点。一粥一饭，当思来处不易；半丝半缕，恒念物力维艰。宜未雨而绸缪，毋临渴而掘井。自奉必须俭约，宴客切勿留连。器具质而洁，瓦缶胜金玉；饮食约而精，园蔬胜珍馐。勿营华屋，勿谋良田。<br>每天早晨黎明就要起床，洗漱自己，打扫卫生，使自己穿着和屋子内外干净整洁；到了黄昏便要休息并亲自查看一下要关锁的门窗。对于粥饭饮食，应当想着来之不易；对于布履衣衫，我们也要常念着这些物资的产生是很艰难的。以前的衣服新三年，旧三年，缝缝补补又三年。现在也要晓得节省，不是消费刺激生产！凡事先要准备，像没到下雨的时候，要先把房子修补完善，不要临时抱佛脚，不要等到口渴的时候，才来挖井，为时已晚。自己生活上必须节约，聚会在一起吃饭切勿流连忘返。餐具质朴而干净，虽是用泥土做的瓦器，也比金玉制的好；食物简约而精美，虽是园里种的蔬菜，也胜于山珍海味。不要说房子住得怎么样奢华，不要贪图有多好的田园。<br>二、齐家<br>三姑六婆，实淫盗之媒。婢美妾娇，非闺房之福。奴仆勿用俊美，妻妾切忌艳妆。祖宗虽远，祭祀不可不诚。子孙虽愚，经书不可不读。居身务期质朴，教子要有义方。勿贪意外之财，勿饮过量之酒。<br>社会上不正派的女人，都是邪淫和盗窃的媒介，这些人不要来往，是非多。美丽的婢女和娇艳的姬妾，不算是家庭的幸福，正如老话讲“丑妻家中宝”。家僮、奴仆，不可雇用英俊美貌的，妻、妾切不可有艳丽的妆饰。祖宗虽然离我们年代久远了，祭祀却要虔诚；子孙虽然愚笨，五经、四书，却要诵读。自己生活节俭，朴实，不要浮华。以做人的正道来教育子孙，按孩子天生的禀赋、兴趣方向帮助他，但是要有分寸的。现在的家长把自己达不到的目的（升官、发财、功名）加在孩子身上，这是错误的，不懂“义方”。不要贪不属于你的财，不劳而获大多不是好事，不要喝过量的酒。<br>三、为人<br>与肩挑贸易，勿占便宜。见贫苦亲邻，须多温恤。刻薄成家，理无久享。伦常乖舛，立见消亡。兄弟叔侄，须多分润寡。长幼内外，宜法属辞严。听妇言，乖骨肉，岂是丈夫。重资财，薄父母，不成人子。嫁女择佳婿，毋索重聘。娶媳求淑女，毋计厚奁。<br>小贩那买东西，不要贪便宜斤斤计较了，人家没有本事做老板，做小贩就要赚钱。你说他骗我，就算骗，给他骗一下，他要回去养家嘛！看到穷苦的亲戚或邻居，要关心他们，并且要对他们有金钱或其它的援助。对人刻薄而发家的，不可能长久享受迟早会遭报应。行事违背伦常的人，比如对父母不孝顺，很快就垮了。兄弟叔侄之间要互相帮助,富有的要资助贫穷的；治家宜严，无论长幼，都要恪守家规、法纪，这样家庭才更幸福、美满。听信妇人挑拨，而伤了骨肉之情，怎配做一个大丈夫呢？反之女人也一样，勿听信谗言。看重钱财，而薄待父母，不是作人的道理。嫁女儿，要为她选择贤良的夫婿，不要索取贵重的聘礼；娶媳妇，须求贤淑的女子，不要贪图丰厚的嫁妆。<br>四、处世<br>见富贵而生谗容者，最可耻。遇贫穷而作骄态者，贱莫甚。居家戒争讼，讼则终凶。处世戒多言，言多必失。毋恃势力而凌逼孤寡，勿贪口腹而恣杀生禽。乖僻自是，悔误必多。颓惰自甘，家道难成。狎昵恶少，久必受其累。屈志老成，急则可相依。轻听发言，安知非人之谮诉，当忍耐三思。因事相争，安知非我之不是，须平心暗想。<br>看到富贵的人，便做出巴结讨好的样子，是最可耻的，遇着贫穷的人，便作出骄傲的态度看不起人，是鄙夷下贱的。居家和对外，避免争斗诉讼打官司，一旦争斗诉讼，无论胜败，结果都不吉祥。处世不可多说话，言多必失。不可用势力来欺凌压迫孤儿寡妇，不要贪口腹之欲而任意宰杀飞禽走兽、草木虫鱼等动植物，要维护生态平衡。个性太孤僻，自以为是的人，你的后悔和失误一定多；颓废懒惰，沉溺不悟，自甘堕落，是难成家立业的。亲近不良的少年、夜店小混混，日子久了，必然会受牵累；恭敬自谦，虚心地与那些阅历多而品行可靠的人交往，可以学到东西帮助你成长，遇到急难的时候也靠得住。正所谓近朱者赤，近墨者黑。轻信他人说长道短，怎知他不是来挑拨离间？所以要慎思明辨；因事吵架，怎知不是自己太冲动？所以要静下心来反省自己。</p><p>五、修身</p><p>施惠勿念，受恩莫忘。凡事当留余地，得意不宜再往。人有喜庆，不可生妒忌心。人有祸患，不可生喜幸心。善欲人见，不是真善。恶恐人知，便是大恶。见色而起淫心，报在妻女。匿怨而用暗箭，祸延子孙。<br>对人施了恩惠，不要记在心里，受了他人的恩惠，一定要常记在心。常记他人之恩，以感恩之心看待周围的人及所处的环境，则人间即是天堂。以忘恩负义之心看待周围的人事，则人间即是地狱。做人做事要留余地，好事、便宜不要多占，多占会有麻烦的，所谓“知足者富”。他人有了喜庆的事情，不可有妒忌之心；他人有了祸患，不可有幸灾乐祸之心。做了好事，而想他人看见，就不是真正的善人。做了坏事，而怕他人知道，就是真的恶人。看到美貌而起邪心的，果报会应在亲人身上；怀怨在心而暗箭伤人的，将会给自己的子孙留下祸根。<br>六、总结<br>家门和顺，虽饔飧不继，亦有余欢。国课早完，即囊橐无余，自得至乐。读书志在圣贤，为官心存君国。守分安命，顺时听天。为人若此，庶乎近焉。<br>家里和气平安，就算缺衣少食也是快乐的；尽快缴完赋税，即使口袋所剩无余也自得其乐。哈，所以康熙皇帝怎么会不提倡这个格言呢！读书不是为了拿高薪，而是求学问，是以圣贤为榜样和最高目标，并不是求圣贤的名，或者装做道貌岸然的样子；读书不一定做官，万一不幸而出来做官，就要对老百姓负责，对社会国家负责。知道自己的本分，也懂得顺应时势，尽人事听天命。做人做到这样，那就差不多和圣贤做人的道理相合了。</p>]]></content>
    
    
    
    <tags>
      
      <tag>句子</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>英语-单词3</title>
    <link href="/2024/06/05/English2-3/"/>
    <url>/2024/06/05/English2-3/</url>
    
    <content type="html"><![CDATA[<p>1. </p><ul><li><p>He decided to gamble his savings at the casino. (Gamble: 赌博)<br>他决定在赌场赌掉他的积蓄。</p></li><li><p>The witness took an oath to tell the truth in court. (Oath: 誓言)<br>证人在法庭上宣誓说实话。</p></li><li><p>They visited a small town in the countryside. (Town: 小镇)<br>他们参观了乡下的一个小镇。</p></li><li><p>She is the one who solved the puzzle. (One: 一)<br>她是那个解开谜题的人。</p></li><li><p>The odds of winning the lottery are very low. (Odds: 概率)<br>中彩票的几率非常低。</p></li><li><p>We will eat dinner at 7 PM. (Eat: 吃)<br>我们将在晚上七点吃晚餐。</p></li><li><p>The art gallery showcased many beautiful paintings. (Gallery: 画廊)<br>画廊展出了许多美丽的画作。</p></li><li><p>He arrived after the meeting had already started. (After: 之后)<br>他在会议已经开始后才到达。</p></li><li><p>Paris is the capital of France. (Capital: 首都)<br>巴黎是法国的首都。</p></li><li><p>The mechanic used a gauge to measure the tire pressure. (Gauge: 测量仪)<br>机械师使用测量仪测量轮胎压力。</p></li><li><p>They used a paddle to navigate the boat down the river. (Paddle: 桨)<br>他们用桨在河上划船。</p></li><li><p>The ants worked together to build their colony. (Colony: 群体)<br>蚂蚁们一起建立了它们的群体。</p></li><li><p>The telescope can observe cosmic phenomena. (Cosmic: 宇宙的)<br>望远镜可以观察宇宙现象。</p></li></ul><ol start="2"><li></li></ol><ul><li><p>The company’s bureaucracy made it difficult to implement new ideas. (Bureaucracy: 官僚体制)<br>公司的官僚体制使得实施新想法变得困难。</p></li><li><p>He used an old rag to clean the kitchen counter. (Rag: 抹布)<br>他用一块旧抹布清洁厨房台面。</p></li><li><p>She has a vigorous exercise routine that keeps her fit. (Vigorous: 有活力的)<br>她有一套充满活力的锻炼计划来保持健康。</p></li><li><p>The fire alarm went off in the middle of the night. (Alarm: 警报)<br>火警在半夜响起。</p></li><li><p>He was fortunate to have found his lost wallet. (Fortunate: 幸运的)<br>他很幸运找到了丢失的钱包。</p></li><li><p>The teacher has the authority to enforce the rules in the classroom. (Authority: 权威)<br>老师有权在课堂上执行规则。</p></li><li><p>The principal decided to summon the student to discuss his behavior. (Summon: 召唤)<br>校长决定召唤学生讨论他的行为。</p></li><li><p>Please wipe your feet on the mat before entering the house. (Mat: 垫子)<br>进入房子前请在垫子上擦脚。</p></li><li><p>The mechanic used grease to lubricate the machine parts. (Grease: 润滑油)<br>机械师用润滑油润滑机器零件。</p></li><li><p>He hailed a cab to get to the airport. (Cab: 出租车)<br>他叫了一辆出租车去机场。</p></li><li><p>They went bowling with friends on Friday night. (Bowling: 保龄球)<br>他们星期五晚上和朋友去打保龄球。</p></li><li><p>They decided to bury the time capsule in the backyard. (Bury: 埋葬)<br>他们决定把时间胶囊埋在后院。</p></li><li><p>The librarian helped her find the book she was looking for. (Librarian: 图书管理员)<br>图书管理员帮助她找到了她要找的书。</p></li></ul><ol start="3"><li></li></ol><ul><li><p>The tutor helped the student understand the complex math problems. (Tutor: 家教)<br>家教帮助学生理解复杂的数学问题。</p></li><li><p>Please come to the meeting at 3 PM. (Come: 来)<br>请在下午三点来参加会议。</p></li><li><p>She won the championship for three consecutive years. (Consecutive: 连续的)<br>她连续三年赢得了冠军。</p></li><li><p>The fisherman caught a large trout in the river. (Fisherman: 渔夫)<br>渔夫在河里抓到了一条大鳟鱼。</p></li><li><p>He has trust in his team to finish the project on time. (Trust: 信任)<br>他信任他的团队能按时完成项目。</p></li><li><p>Teachers impart knowledge to their students. (Impart: 传授)<br>老师向学生传授知识。</p></li><li><p>Contrary to popular belief, not all spiders are dangerous. (Contrary: 相反的)<br>与普遍看法相反，并非所有蜘蛛都危险。</p></li><li><p>She usually goes for a walk in the evening. (Usually: 通常)<br>她通常在晚上散步。</p></li><li><p>He began to frown when he heard the bad news. (Frown: 皱眉)<br>听到坏消息时，他开始皱眉。</p></li><li><p>The coach’s harsh words discouraged the players. (Discourage: 使沮丧)<br>教练的严厉话语让球员们感到沮丧。</p></li><li><p>His pursuit of knowledge led him to many different countries. (Pursuit: 追求)<br>他对知识的追求带他去了许多不同的国家。</p></li><li><p>The artist was able to depict the landscape beautifully. (Depict: 描绘)<br>艺术家能够美丽地描绘出风景。</p></li><li><p>The ducks were swimming in the pond. (Pond: 池塘)<br>鸭子在池塘里游泳。</p></li><li><p>They set sail for the island early in the morning. (Sail: 航行)<br>他们一大早就扬帆前往岛屿。</p></li></ul><ol start="4"><li></li></ol><ul><li><p>Don’t forget to bring your umbrella; it might rain later. (Forget: 忘记)<br>不要忘记带伞，以防晚些下雨。</p></li><li><p>The detective took a shot in the dark and guessed the culprit. (Shot: 尝试)<br>侦探碰运气猜测了罪犯。</p></li><li><p>The truth will eventually emerge. (Emerge: 浮现)<br>真相终将浮现。</p></li><li><p>She was eager to start her new job. (Eager: 渴望)<br>她渴望开始新工作。</p></li><li><p>There was a sense of sorrow in the air at the funeral. (Sorrow: 悲伤)<br>葬礼上空气中充满了悲伤。</p></li><li><p>Please tag your luggage before boarding the plane. (Tag: 贴标签)<br>请在登机前给行李贴上标签。</p></li><li><p>The company went bankrupt due to poor management. (Bankrupt: 破产)<br>由于管理不善，公司破产了。</p></li><li><p>Please wait in line for your turn. (Line: 排队)<br>请排队等候你的轮次。</p></li><li><p>It was obvious that she was lying. (Obvious: 明显)<br>她说谎是显而易见的。</p></li><li><p>He attended college in the city. (College: 大学)<br>他在城市里上大学。</p></li><li><p>There is no certainty about the outcome of the election. (Certainty: 确定)<br>选举结果没有确定性。</p></li><li><p>Follow me, and I’ll show you the way. (Follow: 跟随)<br>跟着我，我会带你去的。</p></li></ul><ol start="5"><li></li></ol><ul><li><p>His muscles were sore after a long workout. (Sore: 疼痛)<br>经过长时间的锻炼，他的肌肉感到疼痛。</p></li><li><p>Swimming in that river is dangerous due to strong currents. (Dangerous: 危险)<br>在那条河里游泳是很危险的，因为水流湍急。</p></li><li><p>She made a fuss about the smallest things. (Fuss: 大惊小怪)<br>她对最小的事情都大惊小怪。</p></li><li><p>The hunter threw his spear at the charging lion. (Spear: 矛)<br>猎人将矛投向冲过来的狮子。</p></li><li><p>I have a notion that she might be lying. (Notion: 概念)<br>我有一种感觉她可能在撒谎。</p></li><li><p>The company plans to launch a new product next month. (Launch: 推出)<br>公司计划下个月推出一款新产品。</p></li><li><p>The theory represents a new paradigm in physics. (Paradigm: 典范)<br>这个理论代表了物理学中的一个新典范。</p></li><li><p>The proposal was met with mixed reactions. (Proposal: 提案)<br>这个提案引起了不同的反应。</p></li><li><p>The smell of sulfur filled the air near the volcano. (Sulfur: 硫磺)<br>硫磺的气味充满了火山附近的空气。</p></li><li><p>He had to stoop to enter the tiny door. (Stoop: 弯腰)<br>他不得不弯腰才能进入那扇小门。</p></li><li><p>She was accustomed to the noise of the city. (Accustomed: 习惯于)<br>她习惯了城市的噪音。</p></li><li><p>The butterfly fluttered its wings and flew away. (Butterfly: 蝴蝶)<br>蝴蝶扇动着翅膀飞走了。</p></li><li><p>They decided to build a new house on the empty lot. (Build: 建造)<br>他们决定在空地上建一座新房子。</p></li></ul><ol start="6"><li></li></ol><ul><li><p>She wore a beautiful white dress to the party. (White: 白色)<br>她穿了一件漂亮的白色连衣裙去参加派对。</p></li><li><p>The movie was awful; I couldn’t even finish watching it. (Awful: 糟糕的)<br>这部电影太糟糕了，我甚至无法看完。</p></li><li><p>The landlord neglected to repair the leaking roof. (Neglect: 忽视)<br>房东忽视了修理漏水的屋顶。</p></li><li><p>He receives a pension from the government after retiring. (Pension: 养老金)<br>他退休后从政府领取养老金。</p></li><li><p>She bought a new shampoo for her hair. (Shampoo: 洗发水)<br>她为自己的头发买了一种新的洗发水。</p></li><li><p>The company has had successive quarters of growth. (Successive: 连续的)<br>公司连续几个季度都有增长。</p></li><li><p>She drew back the curtain to let in the sunlight. (Curtain: 窗帘)<br>她拉开窗帘让阳光进来。</p></li><li><p>He held out his hand to shake mine. (Hand: 手)<br>他伸出手来和我握手。</p></li><li><p>The company plans to expand its operations next year. (Expand: 扩大)<br>公司计划明年扩大业务。</p></li><li><p>The wind started to scatter the leaves across the yard. (Scatter: 分散)<br>风开始把树叶吹散到院子里。</p></li><li><p>They spent their youth traveling around the world. (Youth: 青春)<br>他们把青春都花在了环游世界上。</p></li><li><p>The program is broadcast on a local channel. (Channel: 频道)<br>这个节目在本地频道播出。</p></li></ul><ol start="7"><li></li></ol><ul><li><p>The team’s efforts will prevail despite the challenges. (Prevail: 盛行，战胜)<br>尽管面临挑战，团队的努力将会取得成功。</p></li><li><p>She decided to treat herself to a nice meal after a long day. (Treat: 对待，宠爱)<br>她决定在漫长的一天结束后好好对待自己，享用一顿美餐。</p></li><li><p>He received a fine for parking in the wrong spot. (Fine: 罚款)<br>他因停车位置不当收到了罚款。</p></li><li><p>Reading books can enrich your mind. (Enrich: 丰富)<br>阅读书籍可以丰富你的思想。</p></li><li><p>She had to drag her suitcase up the stairs. (Drag: 拉，拖)<br>她不得不把行李箱拖上楼梯。</p></li><li><p>He read the passage aloud to the class. (Aloud: 大声地)<br>他把段落大声朗读给班上同学听。</p></li><li><p>Don’t throw that in the bin; it’s not rubbish. (Rubbish: 垃圾)<br>不要把那个扔进垃圾箱，那不是垃圾。</p></li><li><p>In case of an emergency, dial 911. (Emergency: 紧急情况)<br>遇到紧急情况时，请拨打911。</p></li><li><p>The nation celebrated its independence day with great joy. (Nation: 国家)<br>国家以极大的欢乐庆祝独立日。</p></li><li><p>The company became prosperous after implementing new strategies. (Prosperous: 繁荣的)<br>公司在实施新策略后变得繁荣起来。</p></li><li><p>The singer received critical acclaim for her latest album. (Acclaim: 称赞)<br>这位歌手因其最新专辑获得了广泛的好评。</p></li><li><p>He was known for his strong work ethic. (Strong: 强壮的，坚强的)<br>他以工作的强烈职业道德而闻名。</p></li><li><p>She used a comb to untangle her hair. (Comb: 梳子)<br>她用梳子梳理头发。</p></li><li><p>The guideline provides clear instructions for completing the task. (Guideline: 指南)<br>这份指南提供了完成任务的明确说明。</p></li><li><p>Honesty is a value that is highly regarded in this company. (Value: 价值观)<br>诚实是这家公司高度重视的价值观。</p></li><li><p>His ankle began to swell after he twisted it playing soccer. (Swell: 膨胀)<br>在踢足球时扭伤脚踝后，他的脚踝开始肿胀。</p></li><li><p>The company’s profits started to slack during the economic downturn. (Slack: 衰退)<br>公司的利润在经济衰退期间开始下降。</p></li><li><p>They reached a consensus on how to proceed with the project. (Consensus: 共识)<br>他们就如何继续进行项目达成了共识。</p></li><li><p>He was promoted to a higher rank in the military. (Rank: 等级)<br>他在军队中被提升到更高的军阶。</p></li></ul><ol start="8"><li></li></ol><ul><li><p>The meeting will discuss an urgent matter regarding the budget. (Matter: 事情，问题)<br>会议将讨论关于预算的紧急事项。</p></li><li><p>Are you ready to leave? (Ready: 准备好的)<br>你准备好要离开了吗？</p></li><li><p>The painting is a beautiful piece of art. (Art: 艺术)<br>这幅画是一件美丽的艺术品。</p></li><li><p>I would advise you to take a different route. (Advise: 建议)<br>我建议你走另一条路线。</p></li><li><p>She enjoys horse riding in her free time. (Horse: 马)<br>她业余时间喜欢骑马。</p></li><li><p>The earthquake caused the ground to shake. (Shake: 摇动)<br>地震导致地面震动。</p></li><li><p>The doctor examined her breast for any abnormalities. (Breast: 乳房)<br>医生检查了她的乳房是否有异常。</p></li><li><p>He used to be a great singer, but now he rarely sings a song. (Song: 歌曲)<br>他曾经是一个很棒的歌手，但现在很少唱歌了。</p></li><li><p>She tried to convey her feelings through the letter. (Convey: 传达)<br>她试图通过信件表达她的感受。</p></li><li><p>The swan glided gracefully across the lake. (Swan: 天鹅)<br>天鹅优雅地在湖面上滑行。</p></li><li><p>The textbook is up-to-date with the latest research. (Up-to-date: 最新的)<br>这本教科书是根据最新研究编写的。</p></li><li><p>He likes to chew on gum when he’s nervous. (Chew: 咀嚼)<br>他紧张时喜欢嚼口香糖。</p></li></ul><ol start="9"><li></li></ol><ul><li><p>The product had a defect that needed to be fixed. (Defect: 缺陷)<br>该产品存在一个需要修复的缺陷。</p></li><li><p>The constant noise from the construction site was a nuisance. (Nuisance: 讨厌的事物)<br>建筑工地不断的噪音很让人讨厌。</p></li><li><p>After walking in the rain, she needed to soak her clothes. (Soak: 浸泡)<br>在雨中行走后，她需要把衣服浸湿。</p></li><li><p>He decided to quit smoking for his health. (Quit: 放弃)<br>他决定为了健康戒烟。</p></li><li><p>The teacher gave them a prompt to start writing their essays. (Prompt: 提示)<br>老师给了他们一个开始写作的提示。</p></li><li><p>The computer store sells a variety of hardware. (Hardware: 硬件)<br>这家电脑商店出售各种硬件。</p></li><li><p>They made a collective decision to support the new policy. (Collective: 集体的)<br>他们做出了支持新政策的集体决定。</p></li><li><p>He remained mute during the meeting. (Mute: 沉默的)<br>他在会议上保持沉默。</p></li><li><p>She ordered a pint of beer at the bar. (Pint: 品脱)<br>她在酒吧点了一品脱啤酒。</p></li><li><p>They decided to retreat from the battle. (Retreat: 撤退)<br>他们决定从战斗中撤退。</p></li><li><p>The court system strives to deliver justice. (Justice: 正义)<br>法庭系统努力提供正义。</p></li><li><p>His fingers were numb from the cold. (Numb: 麻木的)<br>他的手指因为寒冷而麻木。</p></li><li><p>She stored the cookies in a jar. (Jar: 罐子)<br>她把饼干装在罐子里。</p></li><li><p>The project is almost complete. (Complete: 完成)<br>这个项目几乎完成了。</p></li></ul><ol start="10"><li></li></ol><ul><li><p>The book is hers. (Hers: 她的)<br>这本书是她的。</p></li><li><p>She has a feminine charm. (Feminine: 女性的)<br>她有一种女性的魅力。</p></li><li><p>He is always polite to everyone. (Polite: 有礼貌的)<br>他对每个人都很有礼貌。</p></li><li><p>An auxiliary generator kicked in when the power went out. (Auxiliary: 辅助的)<br>当电力中断时，辅助发电机启动了。</p></li><li><p>She achieved great success in her career. (Success: 成功)<br>她在事业上取得了巨大的成功。</p></li><li><p>He is known for his shrewd business sense. (Shrewd: 精明的)<br>他以精明的商业头脑而闻名。</p></li><li><p>She finished first in the race. (First: 第一)<br>她在比赛中第一个到达终点。</p></li><li><p>The government decided to abolish the outdated law. (Abolish: 废除)<br>政府决定废除过时的法律。</p></li><li><p>The defendant pleaded not guilty at the trial. (Trial: 审判)<br>被告在审判中声称无罪。</p></li><li><p>National pride was evident during the celebration. (National: 国家的)<br>在庆祝活动中，国家自豪感显而易见。</p></li><li><p>She always tries to reason with him calmly. (Reason: 推理)<br>她总是试图以平静的方式和他理性沟通。</p></li><li><p>The new system improved efficiency in the workplace. (Efficiency: 效率)<br>新系统提高了工作效率。</p></li><li><p>The two countries have a long history of hostile relations. (Hostile: 敌对的)<br>这两个国家有着长期的敌对关系。</p></li></ul><ol start="11"><li></li></ol><ul><li><p>The sweater is made of wool. (Wool: 羊毛)<br>这件毛衣是羊毛做的。</p></li><li><p>She’s afraid of spiders. (Afraid: 害怕)<br>她害怕蜘蛛。</p></li><li><p>Some mushrooms are edible, but others are poisonous. (Edible: 可食用的)<br>一些蘑菇是可以吃的，但其他的有毒。</p></li><li><p>It’s important to retain good employees. (Retain: 保留)<br>保留好的员工很重要。</p></li><li><p>The door handle was made of brass. (Brass: 黄铜)<br>门把手是黄铜做的。</p></li><li><p>The bread had started to mould. (Mould: 发霉)<br>面包已经开始发霉了。</p></li><li><p>Do you really think so? (Really: 真的)<br>你真的这么认为吗？</p></li><li><p>There is a strong correlation between smoking and lung cancer. (Correlate: 相关)<br>吸烟和肺癌之间有很强的相关性。</p></li><li><p>The concept of time is different in different cultures. (Concept: 概念)<br>时间的概念在不同文化中是不同的。</p></li><li><p>Fever is a common symptom of flu. (Symptom: 症状)<br>发烧是流感的常见症状。</p></li><li><p>Learning a new language is useful for traveling. (Useful: 有用的)<br>学习一门新语言对旅行很有用。</p></li><li><p>It’s our obligation to help those in need. (Obligation: 义务)<br>帮助那些有需要的人是我们的义务。</p></li><li><p>It’s important to recycle paper and plastic. (Recycle: 回收利用)<br>回收利用纸张和塑料是很重要的。</p></li><li><p>Please disregard my previous email. (Disregard: 忽视)<br>请忽略我的上一封电子邮件。</p></li><li><p>She tightened her grip on the handle. (Grip: 握紧)<br>她抓紧了把手。</p></li></ul><ol start="12"><li></li></ol><ul><li><p>It’s prudent to save some money for unexpected expenses. (Prudent: 谨慎的)<br>为意外开支存些钱是明智的。</p></li><li><p>The radius of the circle is five centimeters. (Radius: 半径)<br>这个圆的半径是五厘米。</p></li><li><p>They shared a kiss before saying goodbye. (Kiss: 吻)<br>他们在告别前亲吻了一下。</p></li><li><p>Please pass me the salt. (Pass: 递给)<br>请把盐递给我。</p></li><li><p>The president proclaimed a national holiday. (Proclaim: 宣布)<br>总统宣布了一个全国假日。</p></li><li><p>They plan to establish a new business next year. (Establish: 建立)<br>他们计划明年建立一家新的企业。</p></li><li><p>She works as a nurse at the local hospital. (Nurse: 护士)<br>她在当地医院做护士。</p></li><li><p>The earthquake had disastrous consequences. (Disastrous: 灾难性的)<br>地震造成了灾难性的后果。</p></li><li><p>They went to hunt deer in the forest. (Hunt: 狩猎)<br>他们去森林里狩猎鹿。</p></li><li><p>Being an adult comes with many responsibilities. (Adult: 成年人)<br>成年人要承担许多责任。</p></li><li><p>The generator provides backup power for the building. (Generator: 发电机)<br>发电机为建筑提供备用电源。</p></li><li><p>She’s on a quest to find the lost city. (Quest: 探索)<br>她正在探寻失落的城市。</p></li><li><p>Come here and sit down. (Here: 这里)<br>过来坐下。</p></li><li><p>Can I use your phone to make a call? (Phone: 电话)<br>我可以用你的电话打个电话吗？</p></li></ul><ol start="13"><li></li></ol><ul><li><p>She loves to spend time working in her garden. (Garden: 花园)<br>她喜欢花时间在自己的花园里干活。</p></li><li><p>The light bulb uses 60 watts of power. (Watt: 瓦特)<br>这个灯泡使用60瓦的功率。</p></li><li><p>Their ideas are similar in many ways. (Similar: 相似的)<br>他们的想法在很多方面是相似的。</p></li><li><p>She is currently working on her thesis for her master’s degree. (Thesis: 论文)<br>她目前正在为她的硕士学位写论文。</p></li><li><p>The children played on the ground. (Ground: 地面)<br>孩子们在地上玩耍。</p></li><li><p>You ought to apologize for what you said. (Ought: 应该)<br>你应该为你说的话道歉。</p></li><li><p>The stars twinkle in the night sky. (Twinkle: 闪烁)<br>星星在夜空中闪烁。</p></li><li><p>The website domain was registered last year. (Domain: 域名)<br>这个网站的域名是去年注册的。</p></li><li><p>The funeral will be held next week. (Funeral: 葬礼)<br>葬礼将于下周举行。</p></li><li><p>They had to call an exterminator to deal with the pest problem. (Pest: 害虫)<br>他们不得不叫了一位灭虫工来解决害虫问题。</p></li><li><p>It’s rude to talk with your mouth full. (Rude: 粗鲁的)<br>嘴里塞满东西还说话是很粗鲁的。</p></li><li><p>He wore a clean shirt to the party. (Shirt: 衬衫)<br>他穿着一件干净的衬衫去参加聚会。</p></li><li><p>Many people believe in God. (God: 上帝)<br>许多人相信上帝。</p></li><li><p>The banquet was a grand celebration. (Banquet: 宴会)<br>宴会是一场盛大的庆祝活动。<br>14 .</p></li><li><p>Despite his youth and inexperience, he was entrusted with the most important task, a decision that proved both prudent and wise in hindsight. (Prudent: 谨慎)<br>尽管他年轻而缺乏经验，但事后证明委以其重任是明智而谨慎的决定。</p></li><li><p>The radius of the circle, which was calculated using a sophisticated mathematical formula, turned out to be larger than initially estimated. (Radius: 半径)<br>这个圆的半径是用复杂的数学公式计算出来的，结果比最初估计的要大。</p></li><li><p>The kiss, a simple gesture of affection, held profound meaning for the couple, symbolizing their deep and enduring love. (Kiss: 吻)<br>这个吻，一个简单的亲昵动作，对这对夫妇来说意义深远，象征着他们深厚而持久的爱情。</p></li><li><p>The pass, a sudden burst of speed and skill, allowed him to evade the defenders and score a spectacular goal. (Pass: 传球)<br>这次传球，突然爆发的速度和技巧，使他得以躲过防守球员，打进了一个壮观的进球。</p></li><li><p>The proclamation, made by the king himself, was met with widespread acclaim and marked a turning point in the nation’s history. (Proclaim: 宣布)<br>国王亲自宣布的声明受到了普遍的赞扬，标志着国家历史的转折点。</p></li><li><p>The establishment of the new policy was a milestone, signifying a shift in the government’s approach to social welfare. (Establishment: 建立)<br>新政策的制定是一个里程碑，标志着政府在社会福利方面的政策取向发生了转变。</p></li><li><p>The nurse, with her gentle demeanor and compassionate care, comforted the patient in his final moments. (Nurse: 护士)<br>护士以温和的态度和富有同情心的照料，安抚了病人在生命最后的时刻。</p></li><li><p>The disastrous consequences of the decision were evident to everyone, leading to widespread criticism of the government’s handling of the situation. (Disastrous: 灾难性的)<br>决定的灾难性后果显而易见，导致人们广泛批评政府对局势的处理方式。</p></li><li><p>The hunt, a tradition passed down through generations, was a test of skill and endurance for the participants. (Hunt: 打猎)<br>这场狩猎，是代代相传的传统，对参与者来说是技术和耐力的考验。</p></li><li><p>The adult, with his worldly experience and maturity, was able to offer valuable insights into the complex issue. (Adult: 成年人)<br>这位成年人，凭借他的世故和成熟，能够为这个复杂的问题提供宝贵的见解。</p></li></ul><ol start="15"><li></li></ol><ul><li><p>The density of the material, measured in grams per cubic centimeter, determines its weight and volume characteristics. (Density: 密度)<br>材料的密度，以克&#x2F;立方厘米为单位，决定了其重量和体积特性。</p></li><li><p>The continuous rain, lasting for days on end, caused widespread flooding and disruption to daily life. (Continuous: 连续的)<br>连续的雨，持续了数天，导致了广泛的洪水和日常生活的中断。</p></li><li><p>The reduction in carbon emissions, achieved through the implementation of stricter environmental regulations, was a major milestone in the fight against climate change. (Reduction: 减少)<br>通过实施更严格的环境法规，减少碳排放是在应对气候变化方面的重要里程碑。</p></li><li><p>Her proficiency in multiple languages, including English, French, and Spanish, made her an ideal candidate for the international project. (Proficiency: 熟练)<br>她在多种语言，包括英语、法语和西班牙语方面的熟练程度，使她成为国际项目的理想人选。</p></li><li><p>The overcoat, made of thick wool, provided warmth and protection from the cold winter weather. (Overcoat: 外套)<br>这件由厚羊毛制成的外套提供了温暖，并保护免受寒冷的冬季天气侵袭。</p></li><li><p>The eagle soared high above the mountains, its wings outstretched, riding the currents of air with effortless grace. (Soar: 翱翔)<br>鹰高高飞过山顶，展翅飞翔，轻盈地乘着气流。</p></li><li><p>The deadline for the project was extended to allow for additional time for research and development. (Extend: 延长)<br>项目的截止日期被延长，以便为研究和开发提供额外的时间。</p></li><li><p>The threshold of pain, different for each individual, determines their ability to tolerate discomfort or injury. (Threshold: 门槛)<br>疼痛的门槛，对于每个人来说都不同，决定了他们对不适或伤害的容忍能力。</p></li><li><p>The doctor used a scanner to obtain a detailed image of the patient’s internal organs. (Scan: 扫描)<br>医生使用扫描仪获得了病人内部器官的详细图像。</p></li><li><p>The visual impact of the painting, with its vibrant colors and bold strokes, was breathtaking. (Visual: 视觉的)<br>这幅画的视觉效果，色彩鲜明，笔触大胆，令人叹为观止。</p></li><li><p>The company reported a profit increase of 10 percent compared to the previous year. (Percent: 百分比)<br>与上一年相比，公司报告利润增长了10%。</p></li><li><p>The quick-thinking driver managed to avert a collision by swerving sharply to the side. (Avert: 避免)<br>这位机智的司机通过急转弯成功避免了一次碰撞。</p></li><li><p>He was happy with the results of the experiment, which confirmed his hypothesis. (Happy: 高兴)<br>他对实验结果感到满意，这证实了他的假设。</p></li><li><p>The gang, known for their criminal activities, was finally apprehended by the authorities. (Gang: 帮派)<br>这个以犯罪活动闻名的团伙最终被当局逮捕。</p></li></ul><ol start="16"><li></li></ol><ul><li><p>The catcher made a spectacular catch, diving to grab the ball just before it hit the ground. (Catch: 抓住)<br>接球员做出了一次壮观的抓球动作，扑向球，就在球触地前抓住了它。</p></li><li><p>The death of the king led to a period of mourning throughout the kingdom. (Death: 死亡)<br>国王的去世导致了整个王国的哀悼。</p></li><li><p>The entire city was engulfed in flames, leaving nothing but destruction in its wake. (Entire: 整个)<br>整个城市被大火吞噬，在它的脚步声中什么都没剩下。</p></li><li><p>The storm clouds loomed ominously on the horizon, signaling an approaching thunderstorm. (Loom: 隐约出现)<br>暴风云密云笼罩在地平线上空，预示着一场雷暴的来临。</p></li><li><p>The sculpture, carved from a single block of marble, depicted a scene from ancient mythology. (Sculpture: 雕塑)<br>这座雕塑是用一块大理石雕刻而成的，描绘了古代神话中的一个场景。</p></li><li><p>She was likewise unimpressed by his excuses, seeing them as mere attempts to evade responsibility. (Likewise: 同样地)<br>她同样对他的借口不以为然，认为这只是逃避责任的企图。</p></li><li><p>The school decided to expel the student for repeatedly breaking the rules. (Expel: 开除)<br>学校决定开除这名学生，因为他反复违反规定。</p></li><li><p>The pirate ship sailed into the harbor under the cover of darkness, ready to plunder and pillage. (Pirate: 海盗)<br>海盗船在黑暗中驶入港口，准备抢劫。</p></li><li><p>The agency was responsible for coordinating relief efforts in the aftermath of the natural disaster. (Agency: 机构)<br>这个机构负责协调自然灾害后的救援工作。</p></li><li><p>He decided to ditch his old car and buy a new one, as the repair costs were becoming too high. (Ditch: 丢弃)<br>他决定放弃旧车，买一辆新车，因为修理费用变得太高了。</p></li><li><p>The elderly man sat on the park bench, feeding breadcrumbs to the pigeons. (Elderly: 老年的)<br>老人坐在公园的长凳上，喂鸽子吃面包屑。</p></li><li><p>The document was marked confidential and was not to be shared with anyone outside the organization. (Confidential: 机密的)<br>这份文件被标记为机密，不得与组织外的任何人分享。</p></li><li><p>The outcome of the experiment was unexpected, leading to new avenues of research. (Outcome: 结果)<br>实验的结果出乎意料，引发了新的研究方向。</p></li><li><p>She went on a strict diet in order to lose weight before her wedding. (Diet: 饮食)<br>她为了在婚礼前减肥而进行了严格的节食。</p></li></ul><ol start="17"><li></li></ol><ul><li><p>She wrapped a colorful scarf around her neck to keep warm in the chilly weather. (Scarf: 围巾)<br>她在脖子上围了一条色彩缤纷的围巾，以抵御寒冷的天气。</p></li><li><p>The label on the package indicated that it was fragile and should be handled with care. (Label: 标签)<br>包装上的标签表明它很容易碎，应该小心处理。</p></li><li><p>Many believe that our destiny is predetermined, while others think we shape our own future. (Destiny: 命运)<br>许多人相信我们的命运是预先确定的，而其他人认为我们塑造自己的未来。</p></li><li><p>She sought counsel from her friends before making a decision about which job offer to accept. (Counsel: 忠告)<br>她在决定接受哪份工作邀约之前征求了朋友的意见。</p></li><li><p>The report distorted the facts, leading to confusion among the readers. (Distort: 扭曲)<br>报告歪曲了事实，导致读者困惑。</p></li><li><p>She had been practicing ballet since she was a child, and it had become a central part of her life. (Ballet: 芭蕾舞)<br>她从小就开始练习芭蕾舞，它已经成为她生活的重要组成部分。</p></li><li><p>He took out a loan to buy a new car, but now he was struggling to make the monthly payments. (Loan: 贷款)<br>他贷款买了一辆新车，但现在他在挣扎着偿还每月的付款。</p></li><li><p>The task seemed overwhelming at first, but with some help, she was able to complete it successfully. (Overwhelming: 压倒性的)<br>这项任务起初似乎很艰巨，但在一些帮助下，她成功地完成了它。</p></li><li><p>Climate change is a global issue that requires cooperation and action from countries around the world. (Global: 全球的)<br>气候变化是一个全球性的问题，需要世界各国的合作和行动。</p></li><li><p>She furrowed her brow in concentration as she tried to solve the difficult puzzle. (Brow: 眉毛)<br>她皱起眉头集中注意力，试图解决这个困难的谜题。</p></li><li><p>The play was well-cast, with each actor perfectly suited to their role. (Cast: 演员阵容)<br>这部剧的演员阵容很好，每个演员都很适合他们的角色。</p></li><li><p>She put the kettle on to boil water for tea, enjoying the sound of it bubbling away. (Kettle: 水壶)<br>她把水壶放上，烧水泡茶，享受着水壶冒泡的声音。</p></li></ul><ol start="18"><li></li></ol><ul><li><p>The company expanded overseas, opening branches in several different countries. (Overseas: 海外)<br>公司扩张到海外，在几个不同的国家开设了分支机构。</p></li><li><p>Many believe that our fate is determined by factors beyond our control. (Fate: 命运)<br>许多人认为我们的命运是由我们无法控制的因素决定的。</p></li><li><p>The new building design was innovative and modern, attracting praise from architects around the world. (Design: 设计)<br>新的建筑设计是创新的和现代的，吸引了全世界的建筑师的赞扬。</p></li><li><p>She received top grades in all her classes, earning her a place on the honor roll. (Grade: 成绩)<br>她在所有课程中都获得了最高的成绩，使她跻身荣誉榜。</p></li><li><p>The artist’s latest work was hailed as a masterpiece, showcasing his talent and creativity. (Masterpiece: 杰作)<br>艺术家的最新作品被誉为杰作，展示了他的才华和创造力。</p></li><li><p>He decided to subscribe to the magazine, as he enjoyed reading the articles and staying informed about current events. (Subscribe: 订阅)<br>他决定订阅这本杂志，因为他喜欢阅读文章并及时了解当前事件。</p></li><li><p>They had to cross the river to reach the other side, but the current was too strong. (Cross: 穿过)<br>他们必须穿过河流才能到达另一边，但是水流太强了。</p></li><li><p>The neighbors gathered to gossip about the new family that had moved in next door. (Gossip: 闲话)<br>邻居们聚在一起闲聊搬进隔壁的新家庭。</p></li><li><p>The soldiers were forced to surrender after running out of ammunition. (Surrender: 投降)<br>士兵们在弹药用尽后被迫投降。</p></li><li><p>Her hands began to quiver with excitement as she realized she was about to witness history in the making. (Quiver: 颤抖)<br>当她意识到自己即将目睹历史的发展时，她的手开始因为兴奋而颤抖。</p></li></ul><ol start="19"><li></li></ol><ul><li><p>The pipes were made of copper, ensuring durability and resistance to corrosion. (Copper: 铜)<br>管道是用铜制成的，确保了耐用性和抗腐蚀性。</p></li><li><p>It’s sensible to bring an umbrella, as the weather forecast predicts rain. (Sensible: 明智的)<br>带伞是明智的，因为天气预报预测会下雨。</p></li><li><p>There was a slight lag in the video feed, causing the audio to be out of sync with the visuals. (Lag: 滞后)<br>视频传输存在轻微的滞后，导致音频与视频不同步。</p></li><li><p>The company implemented new strategies to improve productivity and efficiency. (Productivity: 生产力)<br>公司实施了新的策略来提高生产力和效率。</p></li><li><p>Incidentally, I ran into an old friend at the store yesterday. (Incidentally: 偶然地)<br>偶然地，昨天我在商店里碰到了一个老朋友。</p></li><li><p>He plays baseball every weekend with his friends, enjoying the camaraderie and competition. (Baseball: 棒球)<br>他每个周末都和朋友们打棒球，享受着友谊和竞争。</p></li><li><p>Renewable energy sources like solar and wind power are important resources for a sustainable future. (Resource: 资源)<br>太阳能和风能等可再生能源是可持续未来的重要资源。</p></li><li><p>The humming of the bees could be heard from the garden, a soothing sound on a warm afternoon. (Hum: 嗡嗡声)<br>蜜蜂的嗡嗡声可以从花园里听到，这是一个温暖午后的舒缓声音。</p></li><li><p>She darned the hole in her sock, determined to make it last a little longer. (Sock: 袜子)<br>她把袜子上的洞缝了，决心让它再多穿一段时间。</p></li><li><p>Despite his size, he was surprisingly clumsy, often tripping over his own feet. (Clumsy: 笨拙的)<br>尽管体型庞大，但他出奇地笨拙，经常绊倒自己的脚。</p></li><li><p>She put the letter in an envelope and sealed it before dropping it in the mailbox. (Envelope: 信封)<br>她把信放在信封里，封好后放进邮箱里。</p></li><li><p>The naughty child was always getting into mischief, much to the frustration of his parents. (Naughty: 顽皮的)<br>这个顽皮的孩子总是惹祸，让父母非常沮丧。</p></li></ul><ol start="20"><li></li></ol><ul><li><p>His weak voice could barely be heard over the noise of the crowd. (Weak: 虚弱的)<br>他虚弱的声音在人群的嘈杂声中几乎听不见。</p></li><li><p>The sight of the rotting food filled her with disgust. (Disgust: 厌恶)<br>腐烂食物的景象让她感到厌恶。</p></li><li><p>She put on her jacket and stepped outside into the cold winter air. (Jacket: 夹克)<br>她穿上夹克，走到外面的寒冷冬日空气中。</p></li><li><p>The company submitted a bid for the construction project, hoping to win the contract. (Bid: 投标)<br>公司为建设项目提交了投标，希望赢得合同。</p></li><li><p>The new programme aims to enhance the learning experience for students. (Programme: 节目&#x2F;方案)<br>新的方案旨在提升学生的学习体验。</p></li><li><p>The passenger boarded the train and found a seat by the window. (Passenger: 乘客)<br>乘客上了火车，在窗边找到了一个座位。</p></li><li><p>After a night of drinking, he was finally sober enough to drive home. (Sober: 清醒的)<br>经过一夜的饮酒，他终于清醒到可以开车回家。</p></li><li><p>They planned to visit Paris in July, hoping to enjoy the summer weather. (July: 七月)<br>他们计划在七月份去巴黎，希望享受夏日的天气。</p></li><li><p>The question of who would lead the team was still up for debate. (Who: 谁)<br>谁将领导团队的问题仍然存在争议。</p></li><li><p>She watched the sun arise over the horizon, signaling the start of a new day. (Arise: 升起)<br>她看着太阳从地平线升起，预示着新的一天开始了。</p></li><li><p>They prefer to work during the daytime, when the office is bustling with activity. (Daytime: 白天)<br>他们喜欢在白天工作，办公室里充满了活动。</p></li><li><p>She wore a pink dress to the party, standing out among the crowd in her brightly colored outfit. (Pink: 粉色)<br>她穿了一条粉色的裙子去参加派对，在她鲜艳的服装中脱颖而出。</p></li><li><p>The two sides sat down to negotiate a peace treaty, hoping to end the conflict. (Negotiate: 谈判)<br>双方坐下来谈判一项和平条约，希望结束冲突。</p></li><li><p>The train pulled into the station, and the passengers began to disembark. (Station: 车站)<br>火车驶入车站，乘客开始下车。</p></li><li><p>She took a moment to polish her shoes, wanting to look her best for the job interview. (Polish: 擦亮)<br>她花了一点时间擦亮鞋子，希望在求职面试中表现最好。</p></li><li><p>The staircase spiraled up to the top of the tower, offering a stunning view of the city below. (Spiral: 螺旋)<br>楼梯螺旋式地延伸到塔顶，可以欣赏到下面城市的壮丽景色。</p></li><li><p>He gave a brief summary of the main points of the report, highlighting the key findings. (Brief: 简要的)<br>他简要总结了报告的主要内容，重点介绍了关键发现。</p></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>英语</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>leetcode1</title>
    <link href="/2024/06/05/leetcode1/"/>
    <url>/2024/06/05/leetcode1/</url>
    
    <content type="html"><![CDATA[<p><a href="https://programmercarl.com/%E6%95%B0%E7%BB%84%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80.html"></a></p><p><a href="https://leetcode.cn/studyplan/top-interview-150/"></a></p>]]></content>
    
    
    
    <tags>
      
      <tag>leetcode</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔19-我的文学</title>
    <link href="/2024/06/05/ganwu19/"/>
    <url>/2024/06/05/ganwu19/</url>
    
    <content type="html"><![CDATA[<p>文学不能用看小说的角度来读，而且必须读多次才能理解文字中的内容，虽然做什么都是这样，但是阅读文学作品更是如此。</p><p>我太年轻，以至于看不清自己真正想要什么？</p>]]></content>
    
    
    
    <tags>
      
      <tag>感悟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线性代数 —— 线性方程组</title>
    <link href="/2024/06/04/xianxindaishu4/"/>
    <url>/2024/06/04/xianxindaishu4/</url>
    
    <content type="html"><![CDATA[<p>线性方程组 ，线性方程组的克拉默（Cramer）法则， 齐次线性方程组有非零解的充分必要条件， 非齐次线性方程组有解的充分必要条件， 线性方程组解的性质和解的结构， 齐次线性方程组的基础解系和通解， 非齐次线性方程组的通解 。</p><h2 id="解方程组"><a href="#解方程组" class="headerlink" title="解方程组"></a>解方程组</h2><table><thead><tr><th align="left"></th></tr></thead><tbody><tr><td align="left"><img src="/pic/xxds-fcz1.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-fcz2.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-fcz3.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-fcz4.jpg"></td></tr></tbody></table>]]></content>
    
    
    
    <tags>
      
      <tag>线性代数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线性代数 —— 向量</title>
    <link href="/2024/06/04/xianxindaishu3/"/>
    <url>/2024/06/04/xianxindaishu3/</url>
    
    <content type="html"><![CDATA[<ol start="3"><li>向量 ，向量的概念， 向量的线性组合和线性表示， 向量组的线性相关与线性无关， 向量组的极， 大线性无关组， 等价向量组， 向量组的秩， 向量组的秩与矩阵的秩之间的关系， 向量的内积 ，线性无关向量组的的正交规范化方法 。</li></ol><h2 id="向量的秩，极大无关组"><a href="#向量的秩，极大无关组" class="headerlink" title="向量的秩，极大无关组"></a>向量的秩，极大无关组</h2><p><img src="/pic/xxds-xl1.jpg"></p><h2 id="将向量使用其他向量表示"><a href="#将向量使用其他向量表示" class="headerlink" title="将向量使用其他向量表示"></a>将向量使用其他向量表示</h2><p><img src="/pic/xxds-xl2.jpg"></p><h2 id="线性相关和线性无关"><a href="#线性相关和线性无关" class="headerlink" title="线性相关和线性无关"></a>线性相关和线性无关</h2><p><img src="/pic/xxds-xl3.jpg"></p><h2 id="向量的内积、模，夹角，正交"><a href="#向量的内积、模，夹角，正交" class="headerlink" title="向量的内积、模，夹角，正交"></a>向量的内积、模，夹角，正交</h2><p><img src="/pic/xxds-xl4.jpg"></p><h2 id="向量的正交规范化"><a href="#向量的正交规范化" class="headerlink" title="向量的正交规范化"></a>向量的正交规范化</h2><p><img src="/pic/xxds-xl5.jpg"></p><h2 id="向量空间"><a href="#向量空间" class="headerlink" title="向量空间"></a>向量空间</h2><p><img src="/pic/xxds-xl6.jpg"></p>]]></content>
    
    
    
    <tags>
      
      <tag>线性代数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>填坑 —— 稀奇古怪的链接</title>
    <link href="/2024/06/04/tiankeng11/"/>
    <url>/2024/06/04/tiankeng11/</url>
    
    <content type="html"><![CDATA[<ol><li><p>美团技术团队<a href="https://tech.meituan.com/">链接</a></p></li><li><p>阮一峰的网络日志<a href="https://www.ruanyifeng.com/blog/"></a></p></li><li><p>wed前端导航<a href="https://www.alloyteam.com/nav/"></a></p></li><li><p>小傅哥bugstack虫洞栈<a href="https://bugstack.cn/"></a></p></li><li><p>酷壳-陈皓<a href="https://coolshell.cn/"></a></p></li><li><p>大语言模型<a href="https://github.com/LLMBook-zh/LLMBook-zh.github.io">链接</a></p></li><li><p>github开源项目趋势<a href="https://open.itc.cn/?tab=trends"></a></p></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>填坑</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线性代数 —— 矩阵</title>
    <link href="/2024/06/04/xianxindaishu2/"/>
    <url>/2024/06/04/xianxindaishu2/</url>
    
    <content type="html"><![CDATA[<p>矩阵 ， 矩阵的概念， 矩阵的线性运算， 矩阵的乘法， 方阵的幂， 方阵乘积的行列式， 矩阵的转置，逆矩阵的概念和性质， 矩阵可逆的充分必要条件， 伴随矩阵，矩阵的初等变换，初等矩阵，矩阵的秩，矩阵的等价 分块矩阵及其运算。 </p><h2 id="矩阵-矩阵"><a href="#矩阵-矩阵" class="headerlink" title="矩阵+矩阵"></a>矩阵+矩阵</h2><table><thead><tr><th align="left"></th></tr></thead><tbody><tr><td align="left"><img src="/pic/xxds-jz1.png" alt="矩阵相加"></td></tr><tr><td align="left"><img src="/pic/xxds-jz2.png"></td></tr></tbody></table><h2 id="矩阵乘矩阵（前行乘后列）"><a href="#矩阵乘矩阵（前行乘后列）" class="headerlink" title="矩阵乘矩阵（前行乘后列）"></a>矩阵乘矩阵（前行乘后列）</h2><table><thead><tr><th align="left"></th></tr></thead><tbody><tr><td align="left"><img src="/pic/xxds-jz3.png"></td></tr><tr><td align="left"><img src="/pic/xxds-jz4.jpg"></td></tr></tbody></table><h2 id="矩阵的逆矩阵"><a href="#矩阵的逆矩阵" class="headerlink" title="矩阵的逆矩阵"></a>矩阵的逆矩阵</h2><table><thead><tr><th align="left"></th></tr></thead><tbody><tr><td align="left"><img src="/pic/xxds-jz5.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-jz6.jpg"></td></tr></tbody></table><h2 id="矩阵的行列式"><a href="#矩阵的行列式" class="headerlink" title="矩阵的行列式"></a>矩阵的行列式</h2><p><img src="/pic/xxds-jz7.jpg"></p><h2 id="矩阵的转置"><a href="#矩阵的转置" class="headerlink" title="矩阵的转置"></a>矩阵的转置</h2><p><img src="/pic/xxds-jz8.jpg"></p><h2 id="矩阵的秩"><a href="#矩阵的秩" class="headerlink" title="矩阵的秩"></a>矩阵的秩</h2><p><img src="/pic/xxds-jz9.jpg"></p><h2 id="公式乱炖"><a href="#公式乱炖" class="headerlink" title="公式乱炖"></a>公式乱炖</h2><table><thead><tr><th align="left"></th></tr></thead><tbody><tr><td align="left"><img src="/pic/xxds-jz10.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-jz11.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-jz12.jpg"></td></tr></tbody></table>]]></content>
    
    
    
    <tags>
      
      <tag>线性代数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>How to be a Programmer ——如何做好一名程序员</title>
    <link href="/2024/06/03/yudubiji1/"/>
    <url>/2024/06/03/yudubiji1/</url>
    
    <content type="html"><![CDATA[<ol><li><p>学会如何调试，简而言之就是Debug，真实的含义时通过检查来观察程序的运行，我的调试的方法是print，打印变量，但实际上python提供了调试窗口，只是我懒得使用罢了。调试方法的分类，一种是使用调试工具（IDE中的Debugger），一种是Printlining，对程序做一个临时的修改，比如使用print，一种使用日志。</p></li><li><p>学会如何修改错误，Logging（日志）是一种编写系统的方式，可以产生一系列信息记录，被称为 log。Printlining 只是输出简单的，通常是临时的日志。（怎么生成日志？）性能问题，I&#x2F;O代价，内存管理</p></li><li><p>如何发现信息。你所搜寻的事情的本质决定了你应该如何去寻找它。不要在网上搜索任何带有观点或主观解释的东西：能够抵达真相的概率太低了。如果你需要可能没有人知道的信息，例如，“这个新品牌的软件在海量数据的情况下能工作吗”，你仍然必须在网络和图书馆里搜索。在这些选项都完全竭尽后，你可能需要设计一个实验来搞清楚这个问题。如果你想要做一个只有你自己能做的个人决定，比如你是否应该开始某个事业，尝试把一些对这个想法有益和有害的点列出来。如果这没有什么用，做一些预测。</p></li><li><p>如何睿智的编写文档，人生太短，不能写没人会读的废话，如果你写了废话，没人会去读。文档，就像测试，会花比开发代码多几倍的时间。己所不欲，勿施于人。花时间去确实地思考谁会读你的文档，他们从文档中想要获得的真正的东西是什么，并且你可以如何把这些东西交给他们。如果你这样做，你将会变成一个超过平均水平的文档编写者，和一个好的程序员。最好的程序员们有这样一个普遍的观点：编写具有自我解释功能的代码，仅在你不能通过代码清晰解释其含义的地方，才写注释。有两个好的原因：第一，任何人需要查看代码级别的文档大多数情况下都能够并且更喜欢阅读代码。<br>负责任的程序员也不能让这件事变得更简单些。如何写自解释的代码？那意味着什么？它意味着：</p></li></ol><ul><li>编写知道别人会去阅读的代码(译者注：编写给人看的代码)</li><li>运用黄金法则</li><li>选择直接的解决方案，即使你可以更快地获得另一个解决方案</li><li>牺牲那些可能混淆代码的小的优化</li><li>为读者考虑，把你珍贵的时间花在让她更加容易阅读的事情上,并且</li><li>永远不要使用这样的函数名比如 <code>foo</code>,<code>bar</code>, 或 <code>doIt</code>!</li></ul><ol start="5"><li><p>源代码控制，怎么使用源代码控制？</p></li><li><p>如何成长，承担超过你的权力的责任。扮演你想要扮演的角色。如果你想成为团队的领导，去激励与团结。如果你想成为一个经理，担起规划的责任。计划学习新技能的方式，包括琐碎的技术类型，比如学习一个新的软件系统，和困难的社交类型，像漂亮的写作，把它们集成到你的工作中。为了提升到某个位置，找到那个位置期望做的事情，然后去做。树的种子包含了成长的思想，但不完全实现成长体的形式与力量。胚胎会成长。它会变大。它看起来更像成长体，并越来越有用。最终它孕育果实。最后，它死亡并且它的躯体喂养了其他的有机体。</p></li><li><p>如何和非工程师交谈，非工程师聪明，但在创造技术类的东西不像我们那样踏实。我们制造东西。他们销售，处理，统计，管理，但他们在制造上不是专家。非工程师可以理解技术的东西，但他们不会做那件甚至对我们来讲都很困难的事情 - 技术评审。</p></li><li><p>如何保持活力，如果当程序员被要求做一些既不美丽，也没有用，也不漂亮的事情，他们会斗志低落。虽然可以通过做丑陋的，愚蠢的，无聊的东西赚很多的钱，但最后，乐趣才会为公司赚最多的钱。进步，进步，进步</p></li><li><p>如何学习新技能，人类通过做来学。读书和上课是有用的。但你对一个从不写程序的程序员会有任何敬意吗？学习任何技能，你应该把自己放在一个可以练习技能的宽容的位置。学习一个新的编程语言时，在你必须做一个大工程前，试着用它做一个小的工程。学习管理软件项目时，先试着管理一个小的工程。不要忘记程序员最重要的技能不是技术。让你的团队成员有一个机会去玩，锻炼勇气，诚实，以及交流。</p></li><li><p>经常表扬，但不要浪费。尤其是表扬那些反对你且确实值得表扬的人。公开表扬，私下批评</p></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>阅读笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>收集的句子</title>
    <link href="/2024/06/03/juzhi5/"/>
    <url>/2024/06/03/juzhi5/</url>
    
    <content type="html"><![CDATA[<p>1、在这个浮躁的时代，只有自律的人，才能够脱颖而出，成就大事。 </p><p>2、遍地哀鸿满城血，无非一念救苍生。 </p><p>3、礼貌的本质是什么呢？是体谅、照顾他人的情绪。</p><p>4、他们可以挡住天上的太阳，但他们无法挡住民主的光芒。</p><p>5、道德是用来律己的，不是用来责人的；道德是用来躬行实践的，不是在嘴头空喊的。 </p><p>6、“我辜鸿铭生在南洋，学在西洋，娶在东洋，仕在北洋，但是我，是一个堂堂正正的中国人！” </p><p>7、“革命者光明磊落，视死如归，只有站着死，决不下跪。”为有牺牲多壮志，敢叫日月换新天。肉体已逝，脊梁仍在。</p><p>8、自信可以，但是不能盲目自信。 </p><p>9、何为自觉？自觉就是改进国家精神，自强不息地创立一个新国家。我们不能因为这个国家不可爱了，就不爱国了，更不能因为我们没有享受到这个国家的爱，就去厌恶甚至抛弃这个国家。 </p><p>10、阳春白雪、下里巴人、鱼龙混杂、包罗万象，机遇与风险并存。 </p><p>13、一个中国人西化成一个洋人的时候，恰恰会引起他们的蔑视。只有让他们看到，我们中国人，有着与众不同的文明与精神，他们才会在心里对我们有真正的尊重。 </p><p>14、我觉得人不能为了自己而活着，你到长辛店去看看，那些破败不堪的工棚；你去津浦线去看看，那些饿殍千里的难民；你再去前门大街去看看，那些沿街乞讨的乞丐；我们难道不该为他们干点什么吗？你难道要求我们像你一样光鲜亮丽地活着吗？</p><p>15、因为我爱这个国家，这个国家不仅是我的，更是你们的。我要为这个国家去做点什么！ </p><p>16、比知识更重要的，是人的思想、立场和职业操守。 </p><p>17、什么监狱什么死，都不能屈服了你。因为你拥护真理，所以真理拥护你。 </p><p>18、我们中国人，思想、性格，有很多的弱点。但是，在我们中国人身上，有其他任何民族都没有的、难以言喻的东西，那就是温良。温良，不是温顺，更不是懦弱，温良是一种力量，是一种同情和人类智慧的力量。 </p><p>19、敢于努力救国之青年，筋骨强，方能气力雄，才能把外国人叫我们东亚病夫的帽子彻底踩在脚下！ </p><p>20、宽容和厚道是我们读书人从小的习养，但是宽容和厚道，它不是没有限度的呀！ </p><p>21、我们自己的国家，我们自己不爱，谁爱？ </p><p>22、任何人都不能去阻挡历史前进的车轮，你非要挡呢，结果只有一个，什么呢？被碾着腿嘛!</p><p>23.人生就像玩游戏，游戏初期一定要多投资自己的天赋而不是装备。比如角色的血量、蓝条、敏捷属性和力量属性。后期再想办法搞装备，前后顺序不要搞错。自己的个人能力就是角色自带的属性，而外界的钱、运势、关系，就是后天的装备。</p><p>24.你不理财，财不理你。年纪轻轻就要建立一个良好的理财观点。</p><p>25.物欲能让人开心，可带来的快乐是极其短暂的。精简生活不是一种口号，而是繁华看尽后的质朴回归。你一生的终极修炼是自己，而不是外物，有趣的灵魂比美丽的外表更迷人。</p><p>26.在你身上找自信或藐视你的人不要做朋友或是恋人。</p><p>27.永远保持20%的神秘感。毫无保留的男人和女人都像是过期的电影。</p><p>28.对方说了分手之后，即便心理再有不甘也不要挽回。不然爱情太卑微了。</p><p>29.女性的魅力在于独立，当一个女人能够不依靠与不依赖男性时，才是最美的。进退有度，才能立于不败之地。</p><p>30.感情是自愿的事情，不要标榜自我牺牲。对方根本看不到。愿意付出就付出，不愿意就是不愿意。不要为了让对方有负罪感，强迫自己做一些事情。</p><p>31.两个人一定要共同进步，当差距太大时，是时候该考虑放弃了</p><p>32.经营人脉不如经营自己，人脉的本质是交换。</p><p>33.阅读是一个积少成多的事情，通过大量的阅读你会发现自己的视野、格局都在慢慢扩大。</p><p>34.不要因为没有朋友，而降低朋友的标准。别太在意别人的看法，你内心中的自责情绪很可能只是自怜。脸皮一定要厚一点，胆子大一点。也别委屈自己去迁就别人，都是第一次做人，凭什么你要一退再退。</p><p>35.职场中，要求涨薪不如要求涨权限。</p><p>36.一定要管住自己的嘴，不要留下任何把柄。</p><p>37.选择比努力重要。但“选择”本身就是一种需要大量练习、大量努力来磨练的技能。</p><p>38.人类的大部分痛苦，都是虚幻的。自己身体的疼痛是真实的，亲人、朋友逝去的痛苦是真实的。其他的痛苦，都是与自身价值观的冲撞中形成的。</p><p>39.生活其实是一种运营，事业、友谊、家庭、需要我们不断的调整运营力度，已达到最微妙的平衡。人生没有平衡是没有幸福感的。</p><p>40.叫醒你的不应该是梦想，而是昨晚早睡。</p><p>41.绝对不要从集体中寻找安全感。当你与他人都在做相同的事时，你会感到安全感。因为你觉得，虽然可能我无法超过大家，但至少，我不会掉队。别人谈恋爱，我们也谈。别人通宵打4年游戏我们也打。所谓天才，绝不是一帮人扎堆做同样的事。而是脱离集体归属感，专心做自己的事。</p>]]></content>
    
    
    
    <tags>
      
      <tag>句子</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>作文 + 阅读 —— 2022年6月大学英语六级考试真题 （第一套）</title>
    <link href="/2024/05/30/English4-1/"/>
    <url>/2024/05/30/English4-1/</url>
    
    <content type="html"><![CDATA[<h2 id="作文"><a href="#作文" class="headerlink" title="作文"></a>作文</h2><p>作文： Nowadays more and more people choose to live an environmentally friendly lifestyle<br>分析： 环保，lifestyle（生活方式）</p><ol><li><p>Nowadays more and more people choose to live an environmentally friendly lifestyle.（话题句）<br>如今，越来越多的人选择过环保的生活方式。</p></li><li><p>According to a recent survey conducted by CCTV, a high proportion of 59.4 percent of people started to pay more attention to environmental protection. （话题阐述）<br>中央电视台最近进行的一项调查显示，59.4%的人开始更加重视环境保护。</p></li></ol><p>中间</p><ol start="3"><li><p>There may be a combination of factors which can explain this considerable progress. （过渡句）<br>可能有多种因素可以解释这一重大进展。</p></li><li><p>A large-scale education campaign was launched to inform the public that many people especially those in poverty-stricken areas are still suffering from starvation or resource exhaustion.<br>开展了大规模的教育活动，告知公众许多人，特别是贫困地区的人民仍在遭受饥饿或资源枯竭的痛苦。</p></li><li><p>As a result, more civilians realized the seriousness of the situation and thus wanted to do something by leading an environmental-friendly lifestyle.<br>结果，更多的平民意识到了情况的严重性，因此想通过过环保的生活方式来做点什么。</p></li><li><p>The wide popularity of new energy vehicles is an example.<br>新能源汽车的广泛普及就是一个例子。</p></li></ol><p>7.By shifting from traditional automobiles to more environmental-friendly ones, individuals reduced the exhaust emission which is detrimental to the environment.<br>通过从传统汽车转向更环保的汽车，个人减少了对环境有害的废气排放。</p><p>中间结尾句的过程要注意一下，根本不会写。 绿水青山，就是金山银山。 Lucid waters and lush mountain are invaluable assets. </p><p>结尾</p><ol start="8"><li>In brief, taking into account all of these factors,（总结） we may reach the conclusion that environmental protection is everybody’s duty and thanks to the combined efforts of all people, we can surely have a greener future.（建议，展望）<br>简而言之，考虑到所有这些因素，我们可以得出结论，环境保护是每个人的责任，并且由于所有人的共同努力，我们一定可以拥有更绿色的未来。</li></ol><h2 id="阅读"><a href="#阅读" class="headerlink" title="阅读"></a>阅读</h2><p>阅读技巧： 定位法，画线。<br>第一篇</p><p>Selective colleges and universities in the U.S. are under fire for being too elite and too expensive, and for not training graduates for the world of work. Such charges ignore the fact that these institutions continue to prepare students for success in their work, for thoughtful engagement in civic life, for lifelong learning, and for understanding the world and those with whom they live.<br>美国的精选高校和大学因过于精英化、过于昂贵以及未能为毕业生进入职场做好准备而受到批评。这些指责忽视了一个事实，即这些机构继续为学生在工作中的成功、在公民生活中的深思熟虑参与、终身学习以及理解世界和与他们共存的人们做好准备。</p><p>46.What fact does the author emphasize concerning selective colleges and universities?（B）</p><p>A)  They have been ignoring the training of graduates for the world of work.   </p><p>B)  They have been doing well in ensuring their students a successful future.   </p><p>C)  They have been constantly attacked for being too elite and too expensive.   </p><p>D)  They have been actively engaged in civic life beyond the school campus.</p><p>A) 他们一直忽视了对毕业生进行职场培训。</p><p>B) 他们在确保学生拥有成功的未来方面做得很好。</p><p>C) 他们因为过于精英化和过于昂贵而不断受到攻击。</p><p>D) 他们一直积极参与校园之外的公民生活。</p><p>These colleges and universities must be doing something right. Applications are at record highs, and their financial aid programs make them more accessible than ever. This model of education has long played a central role in creating opportunity, driving economic growth, and spurring innovation.<br>这些学院和大学一定是做对了什么。申请人数创历史新高，他们的助学金项目使这些学校比以往任何时候都更易于接近。这种教育模式长期以来在创造机会、推动经济增长和激发创新方面发挥了核心作用。</p><p>47.What does the author say in arguing for the model of education in the U.S.?（A）</p><p>A)  It has contributed substantially to the nation’s overall development. </p><p>  B)  It has succeeded in maintaining sustainable financial aid programs.  </p><p>  C)  It has given priority to innovative programs for graduate studies.   </p><p>  D)  It has played a central role in attracting international applicants.</p><p>作者在为美国的教育模式辩护时说了什么？</p><p>A) 它对国家整体发展做出了巨大贡献。</p><p>B) 它成功地维持了可持续的经济援助项目。</p><p>C) 它优先考虑了研究生项目的创新计划。</p><p>D) 它在吸引国际申请者方面发挥了核心作用。</p><p>Yet, there is growing skepticism about the value of this model. The recent tax reform bill is a wake-up call that our strongest colleges and universities are under assault by some in government. The initial proposals would have made education unaffordable for many by taxing tuition waivers for graduate students and ending deductions for student loan interest. Thankfully, these provisions were ultimately stripped from the bill, but lawmakers let stand a new tax on the investment income of some colleges and universities.<br>然而，越来越多的人对这种模式的价值表示怀疑。最近的税收改革法案是一个警钟，表明我们最强大的高校和大学正受到某些政府人员的攻击。最初的提案将通过对研究生的学费减免征税和取消学生贷款利息扣除，使得教育对许多人来说变得不可负担。幸运的是，这些条款最终被从法案中删除，但立法者仍保留了对某些高校和大学投资收入的新税收。</p><p>What do we learn about the initial proposals concerning the recent tax reform bill?（D）</p><p>A)  They would have stripped many students of life’s chances. </p><p>B)  They would have deducted graduate student loan interest. </p><p>C)  They would have added to many students’financial burden. </p><p>D)  They would have increased the number of tuition waivers.</p><p>我们从最近的税改法案初始提案中了解到什么？</p><p>A) 它们本可能剥夺许多学生的生活机会。</p><p>B) 它们本可能扣除研究生贷款利息。</p><p>C) 它们本可能增加许多学生的经济负担。</p><p>D) 它们本可能增加学费减免的数量。</p><p>While these attacks are motivated by misguided ideas, we need to do a better job of explaining why these claims are false and why what we do is valuable. We cannot take for granted that any of this is obvious.<br>尽管这些攻击是出于误导的想法，我们需要更好地解释为什么这些指控是错误的以及我们所做的事情为什么有价值。我们不能理所当然地认为这一切是显而易见的。</p><p>It is often said that elite colleges and universities do not train students, particularly those who study the liberal arts, for the workforce. But this can be refuted by scholarly research. The data are clear: a liberal arts education is great career preparation, both for excellent lifetime earnings and for satisfaction with the work. This education develops the skills of critical thinking, rigorous analysis of data and facts, communication with the written and spoken word, understanding of cultural differences and issues, and the ability to keep learning. In fact, liberal arts graduates do extremely well in every imaginable field.<br>人们常说精英高校和大学不会培训学生，尤其是那些学习文科的学生，不为劳动力市场做准备。但这可以通过学术研究来反驳。数据显示：文科教育是很好的职业准备，无论是终身收入还是对工作的满意度都很高。这种教育培养了批判性思维、对数据和事实的严格分析、书面和口头交流、对文化差异和问题的理解以及持续学习的能力。事实上，文科毕业生在每一个可以想象的领域都表现极为出色</p><p>49.What do the data show about elite colleges and universities? （D）</p><p>A)  Their graduates lack the rigor required for doing statistical analysis.</p><p>B)  Their students prove to be inadequately prepared for their future careers.   </p><p>C)  Their focus on research is conducive to developing students’ critical thinking.   </p><p>D)  Their liberal arts education enables graduates to excel in whatever field they are in.</p><p>数据显示关于精英学院和大学的什么？</p><p>A) 他们的毕业生缺乏进行统计分析所需的严谨性。</p><p>B) 他们的学生证明对未来职业准备不足。</p><p>C) 他们对研究的关注有助于培养学生的批判性思维。</p><p>D) 他们的文科教育使毕业生在任何领域都能表现出色。</p><p>Access to an education at selective colleges and universities is now more available than ever to low-and middle-income families. We have built endowments from donations by alumni (校友)and parents who understand and appreciate our mission to provide access and opportunity, and a significant portion of the returns from these endowments is used to fund financial aid.<br>如今，低收入和中等收入家庭的学生比以往任何时候都更容易获得精选高校和大学的教育。我们通过校友和家长的捐赠建立了捐赠基金，这些人理解并欣赏我们的使命，即提供机会和机会，这些捐赠基金的一大部分回报被用于资助助学金。</p><p>Ironically, the new tax on endowments drains financial aid funds from the very schools most able to offer opportunity to those who have earned a spot but cannot otherwise afford this education. Beyond the virtue of access to those who have earned a place at these schools, the diversity of economic backgrounds enhances the education and experience of all of our students.<br>具有讽刺意味的是，新的捐赠基金税削减了最有能力为那些获得一席之地但无法负担教育费用的人提供机会的学校的助学金资金。除了为那些在这些学校中获得一席之地的人提供的机会的美德外，经济背景的多样性还增强了我们所有学生的教育和经验。</p><p>50.What is an advantage of providing financial aid for students? （B）</p><p>A)  Every student can choose the institution they wish to attend.   </p><p>B)  All students can benefit from a diversified student population.   </p><p>C)  All students will be able to earn a place on university campus.   </p><p>D)  Less privileged students will be more competitive at elite schools.</p><p>提供学生资助的优势是什么？</p><p>A) 每个学生都可以选择他们希望就读的机构。</p><p>B) 所有学生都可以从多样化的学生群体中受益。</p><p>C) 所有学生将有机会获得大学校园的位置。</p><p>D) 较为贫困的学生在精英学校将更具竞争力。</p><p>第二篇</p><p>When a group of Australians was asked why they believed climate change was not happening, about 36% said it was “common sense”, according to a report published last year by the Commonwealth Scientific and Industrial Research Organization. This was the most popular reason for their opinion, with only 11% saying their belief that climate change was not happening was based on scientific research.<br>当一组澳大利亚人被问及为什么他们认为气候变化没有发生时，约有36%的人表示这是“常识”，根据澳大利亚联邦科学与工业研究组织去年发布的一份报告。这是他们观点的最普遍原因，只有11%的人表示他们认为气候变化没有发生是基于科学研究。</p><ol start="51"><li>What does the author intend to show by citing the findings from the report published（A）</li></ol><p>A)  People seldom appeal to rationality in their thinking.   </p><p>B)  It is often the case that truth lies in the hands of a few.   </p><p>C)  Common sense and science are the two sides of a coin.   </p><p>D)  Few people know if climate change is really happening.</p><p>作者引用这份报告的调查结果的目的是：</p><p>A) 表明人们在思考时很少诉诸于理性。</p><p>B) 常常情况下，真理掌握在少数人手中。</p><p>C) 表明常识和科学是同一个硬币的两面。</p><p>D) 很少有人知道气候变化是否真的正在发生。</p><p>But what do we mean by an appeal to common sense? Presumably it’s an appeal to rationality of some sort that forms the basis of more complex reasoning. The appeal to common sense, however, is usually nothing more than an appeal to thinking that just feels right, but what feels right to one person may not feel right to another. Whether it feels right is usually a reflection of the world view and ideologies we have internalised, and that frames how we interact with new ideas. When new ideas are in accord with what we already believe, they are more readily accepted. When they are not, they, and the arguments that lead to them, are more readily rejected.<br>但是，我们所说的“常识”是什么意思呢？可以推测，这是一种基于某种形式的理性的呼吁，构成更复杂推理的基础。然而，对常识的呼吁通常只是对感觉正确的思维的呼吁，但一个人感觉正确的事情可能并不适合另一个人。它是否感觉正确通常是我们内化的世界观和意识形态的反映，它们构成了我们与新观念互动的框架。当新观念与我们已经相信的东西一致时，它们更容易被接受。当它们不一致时，它们以及导致它们的论点更容易被拒绝。</p><p>52.What is the appeal to common sense according to the author? （D）</p><p>A)  It is the basis for the internalisation of individuals’ideologies.   </p><p>B)  It is a series of conceptions formulated from complex reasoning.   </p><p>C)  It is collective wisdom that helps people interact with new ideas.   </p><p>D)  It is something subjective based on what one perceives to be right.</p><ol start="52"><li>根据作者的说法，常识的吸引力是什么？</li></ol><p>A) 它是个人意识形态内化的基础。 </p><p>B) 它是从复杂推理中制定的一系列概念。 </p><p>C) 它是帮助人们与新观念互动的集体智慧。 </p><p>D) 它是基于个人认为正确的主观感觉。</p><p>We often mistake this automatic compatibility testing of new ideas with existing beliefs as an application of common sense, but, in reality, it is more about judging than thinking. As Nobelist Daniel Kahneman notes in Thinking, Fast and Slow, when we arrive at conclusions in this way, the outcomes also feel true, regardless of whether they are. We are not psychologically well equipped to judge our own thinking.<br>我们经常将对新观念与现有信念的自动兼容性测试误认为是对常识的应用，但实际上，这更多是关于判断而不是思考。正如诺贝尔奖得主丹尼尔·卡尼曼在《思考，快与慢》中所指出的那样，当我们以这种方式得出结论时，结果也会感觉正确，无论它们是否正确。我们在心理上没有能力判断自己的思维。</p><ol start="53"><li>What does Daniel Kahneman think is the problem of testing new ideas with existing beliefs?（A）</li></ol><p>A)  It may lead to incorrect judgment.   </p><p>B)  It makes no use of common sense.   </p><p>C)  It fails to correct mistakes through serious reasoning.   </p><p>D)  It can produce psychologically unacceptable outcomes.</p><ol start="53"><li>丹尼尔·卡尼曼认为用现有信念来测试新观念的问题是什么？</li></ol><p>A) 这可能导致错误的判断。</p><p>B) 这没有利用常识。</p><p>C) 它无法通过严肃的推理来纠正错误。</p><p>D) 这可能产生在心理上无法接受的结果。</p><p>We are also highly susceptible to a range of cognitive biases such as giving preference to the first things that come to mind when making decisions or giving weight to evidence.<br>我们也极易受到一系列认知偏见的影响，比如在做决定或给证据权重时更倾向于首先想到的事情。</p><p>One way we can check our internal biases and inconsistencies is through the social verification of knowledge, in which we test our ideas in a rigorous and systematic way to see if they make sense not just to us, but to other people. The outstanding example of this socially shared cognition is science.<br>我们可以通过知识的社会验证来检验我们内在的偏见和不一致性，即通过以严谨和系统的方式测试我们的想法，看看它们不仅对我们自己而且对其他人是否有意义。这种社会共享认知的杰出例子就是科学。</p><p>54.What can we do to be less susceptible to cognitive biases?（C）</p><p>A)  Give equal weight to evidence of both sides in a conflict.   </p><p>B)  Provide convincing examples in developing an argument.   </p><p>C)  Establish socially shared cognition via scientific methods.  </p><p>D)  Avoid inconsistencies when addressing controversial issues.</p><ol start="54"><li>我们可以做些什么来减少认知偏见的影响？</li></ol><p>A) 在冲突中给予双方证据同等的重视。</p><p>B) 在论证过程中提供令人信服的例子。</p><p>C) 通过科学方法建立社会共享的认知。</p><p>D) 在处理有争议的问题时避免不一致性。</p><p>That does not mean that individuals are not capable of excellent thinking, nor does it mean no individual is rational. But the extent to which individuals can do this on their own is a function of how well integrated they are with communities of systematic inquiry in the first place. You can’t learn to think well by yourself.<br>这并不意味着个体无法进行出色的思考，也不意味着没有个体是理性的。但个体能够独立进行这种思考的程度取决于他们与系统性探究社群的整合程度。你无法靠自己学会思考。</p><p>In matters of science at least, those who value their common sense over methodological, collaborative investigation imagine themselves to be more free in their thinking, unbound by involvement with the group, but in reality they are tightly bound by their capabilities and perspectives. We are smarter together than we are individually, and perhaps that’s just common sense.<br>至少在科学问题上，那些看重自己的常识而不是方法论、合作性调查的人，认为自己在思考上更自由，没有被群体牵制，但实际上他们受到了能力和观点的严格限制。我们一起比单独更聪明，或许这就是常识。</p><p>55.What message does the author try to convey at the end of the passage?（D）</p><p>A)  Multiple perspectives stimulate people’s interest in exploring the unknown.   </p><p>B)  Individuals can enhance their overall capabilities by interacting with others.   </p><p>C)  Individuals should think freely to break from the restrictions of common sense.   </p><p>D)  Collaborative efforts can overcome individuals limitations in scientific inquiry.</p><ol start="55"><li>作者在文章结尾试图传达什么信息？</li></ol><p>A) 多角度激发人们探索未知的兴趣。</p><p>B) 个人可以通过与他人互动提升整体能力。</p><p>C) 个人应自由思考以突破常识的限制。</p><p>D) 合作努力可以克服个人在科学探究中的局限。</p><h2 id="2022年12月大学英语六级考试真题（第二套）"><a href="#2022年12月大学英语六级考试真题（第二套）" class="headerlink" title="2022年12月大学英语六级考试真题（第二套）"></a>2022年12月大学英语六级考试真题（第二套）</h2><p>第一篇</p><p> Some people in the US have asserted that forgiving student loan debt is one way to stimulate the economy and give assistance to those in need. One government proposition is to eliminate $ 10,000 of debt for ‘economically distressed’ students. Some in US Congress have gone so far as to suggest forgiving up to $50,000 in debt per student borrower, but does forgiving student debt necessarily correlate to helping the economically disadvantaged?</p><p>一些美国人声称，宽恕学生贷款是刺激经济、帮助有需要的人的一种方式。政府的一个提议是为“经济困难”的学生减免10000美元的债务。一些美国国会议员甚至建议为每位学生借款人宽恕高达50000美元的债务，但宽恕学生债务是否必然意味着帮助经济弱势群体呢？</p><p>46.Why do some people advocate forgiving student loan debt? （B）</p><p>A)  They assert it will narrow the gap between the wealthy and the poor.   </p><p>B)  They believe it will benefit both the economy and the underprivileged.   </p><p>C)  They claim it will eliminate economic distress among college students.   </p><p>D)  They think the cost of education is the responsibility of the government.</p><p>为什么有些人主张宽恕学生贷款？</p><p>A) 他们断言这将缩小富人和穷人之间的差距。</p><p>B) 他们认为这将有利于经济和贫困人口。</p><p>C) 他们声称这将消除大学生中的经济困扰。</p><p>D) 他们认为教育费用是政府的责任。</p><p> The answer is no. This policy is just giving money away to universities and the most affluent students in attendance. Federal Reserve data reveals that the highest-income 40 percent of households owe approximately 60 percent of outstanding student debt, while the lowest 40 percent owe just under 20 percent. This could be due to a combination of factors：students from high-income households are more likely to go to expensive colleges, less likely to receive financial aid, and more likely to have high incomes post-graduation. Plus, the majority of student debt is held by graduate degree earners, who earn approximately 25 percent more than their undergraduate counterparts. Clearly, giving free reign to banks to forgive student debt is a step in the wrong direction.  </p><p> 这项政策实际上只是在向大学和出席的最富裕的学生散发钱财。美联储的数据显示，收入最高的40％家庭拥有约60％的未偿还学生贷款，而最低的40％仅拥有略低于20％。这可能是由于多种因素的结合：来自高收入家庭的学生更有可能上昂贵的大学，更不太可能获得助学金，并且更有可能在毕业后有高收入。此外，大多数学生贷款由获得研究生学位的人持有，他们的收入约比本科同行高25％。显然，给予银行自由原谅学生债务是朝着错误的方向迈出的一步。</p><p> 47.What do we learn from the Federal Reserve data? （B）</p><p> A)  Approximately 60% of student debt remains unpaid.   </p><p> B)  Cancelling student debt benefits wealthy families most.  </p><p> C)  Forgiving student debt provides little benefit to universities.   </p><p> D)   Low-income families owe the biggest amount of student debt.</p><p>从美联储的数据中我们学到了什么？</p><p>A) 学生债务约有60％仍未偿还。</p><p>B) 取消学生债务最有利于富裕家庭。</p><p>C) 原谅学生债务对大学的好处很少。</p><p>D) 低收入家庭欠款最多。</p><p> Other proposals for broader, long-term student loan plans have some fundamental problems. One idea is to cancel student debt only for undergraduate degrees and for students making less than $ 125,000.            </p><p> This attempts to address the fact that Congress’ previously mentioned student loan forgiveness plan largely helps out the wealthy, but is an adverse incentive for universities to keep raising tuition and for students to choose to major in low-earning degree programs. Colleges have no reason to make their programs more affordable if they believe students will just take out more debt. And, students will feel more comfortable making the irresponsible decision to go tens of thousands of dollars in debt to major in impractical or idealistic subjects if they know their loans will be forgiven.</p><p> 对于更广泛、长期的学生贷款计划，还有一些根本性问题。一个想法是只为本科学位和收入低于125,000美元的学生取消学生债务。</p><p> 这试图解决国会先前提到的学生贷款宽免计划主要帮助富人的事实，但对大学来说是一个逆向激励，他们会继续提高学费，而学生则会选择主修收入较低的学位课程。如果他们相信学生只会贷款更多，大学就没有理由让他们的项目变得更加负担得起。而且，如果学生知道他们的贷款会被宽免，他们会更容易地做出不负责任的决定，欠下数以万计的债务主修不切实际或理想主义的科目。</p><p> 48.What does the author say students are likely to do if they know they needn’t repay their loans? 选（A） 错选（D）<br> A)  They will choose to study subjects without considering their job prospects.   </p><p> B)  They will be free to pursue their goals without being burdened financially.   </p><p> C)  They will over-borrow and live beyond their means.   </p><p> D)  They will be able to enroll in expensive universities.</p><ol start="48"><li>如果学生知道他们不需要偿还贷款，作者说他们可能会做什么？</li></ol><p> A) 他们将选择学习科目，而不考虑就业前景。</p><p> B) 他们将能够在不受财务负担的情况下追求自己的目标。</p><p> C) 他们会过度借贷，生活超出自己的能力范围。</p><p> D) 他们将能够在昂贵的大学就读。</p><p>第48题   正确答案：A    您的答案：D</p><p>【定位】由题干中的if they know和 needn’t repay their loans定位到第四段最后一句。</p><p>【精析】推理判断题。定位句指出 ，如果学生们知道自己的贷款会被免除，那么他们更容易做出不负责任的决定，主修不切实际或理想主义的科目，而不惜签下数万美元的债务。由此可知，作者认为学生提前知道学费债务免除的后果，主要是导致他们选择的专业不实际。再结合该段首句中所说的，学生因此会选择主修低收入学位课程，概括而言，如果学生知道债务可以免除,那么他们就会不太考虑就业后的收入前景，主修不切实际的课程，故A）为答案。</p><p>【避错】B）项具有干扰性，但原文所说的“做出不负责任的决定”，学习“不切实际或理想主义的科目”明显是负面含义,不可等同于自由追求目标，故排除;原文说学生可能会不惜欠下数万债务，但并未说这样做是否会导致其生活入不敷出，C）项为过度推断,故排除;D）项所述内容在相关部分并未提及，故排除。</p><p>  This is especially concerning given the pandemic (大流行病)has rendered a college education practically worthless. Students are paying tens of thousands of dollars per year to live at home and be lectured on the Internet. Do we really want to tell colleges that they can get away with providing below average service for an outrageous cost?<br>这一点尤为令人担忧，因为大流行病使得大学教育几乎毫无价值。学生每年花费数万美元在家上网课。我们真的想告诉大学，他们可以用极高的费用提供低于平均水平的服务吗？</p><p>49.What does the author imply about colleges offering online education? （C） 错选（A）</p><p> A)  They cannot get away with the serious consequences.   </p><p> B)  They have suffered greatly from the current pandemic.   </p><p> C)  The tuition they charge is not justified by the quality of their service.   </p><p> D)  The tuition they charge has surged outrageously during the pandemic.</p><p>作者对提供在线教育的大学暗示了什么？</p><p>A) 他们无法摆脱严重后果。</p><p>B) 他们在当前大流行中遭受了巨大损失。</p><p>C) 他们收取的学费与其服务质量不成比例。</p><p>D) 他们在大流行期间收取的学费激增。</p><p>第49题   正确答案：C    您的答案：A</p><p>【定位】由题干中的 online education定位到第五段第二句。</p><p>【精析】推理判断题。定位句提到，大流行病期间，学生们每年支付数万美元却只是待在家里，接受网上授课。在随后一句，作者批评这些大学收取高昂的费用而只提供低于平均水平的服务，可知其学费与服务质量不相匹配，故 答 案 为C)。</p><p>【避错】A）表述含糊不清，文中并未提到在线教育会对大学产生什么后果，故排除;根据定位段可知，提供在线教育的大学并未降低学费，可知B）所说的遭受巨大损失并无依据; 作者只提到提供在线教育的大学收取高昂的学费，但没有说它们是否提高了学费，故排除D）。</p><p>  In the case of any of these student debt plans, working-class Americans who chose not to or could not afford to go to college will be subsidizing the education of the professional class. Plumbers and retail workers will be paying for the degrees of doctors and lawyers.           </p><p>  The US government’s effort to help those in debt is commendable but is this really the solution that will help the poor financially recover?</p><p>在任何这些学生债务计划的情况下，选择不上大学或无法负担上大学费用的工薪阶层美国人将为专业阶层的教育提供补贴。 水管工和零售工人将为医生和律师的学位买单。</p><p>美国政府帮助负债者的努力值得赞赏，但这真的是有助于贫困人口经济复苏的解决方案吗？</p><p>50.What will happen if any of the proposed student debt plans is implemented? （C） 错选（B）</p><p> A)  Plumbers and retail workers will have a chance of becoming professionals.   </p><p> B)  Working-class students will have increasing access to subsidized education.  </p><p> C)  Blue-collar workers will have to bear the cost of educating would-be high-eamers.   </p><p> D)  A growing number of students will be able to earn degrees in medicine and law.</p><p>如果实施了任何提出的学生债务计划，会发生什么？</p><p>A) 水管工和零售工人将有机会成为专业人士。</p><p>B) 工薪阶层学生将逐渐获得更多受资助的教育机会。</p><p>C) 蓝领工人将不得不承担培养未来高收入者的成本。</p><p>D) 越来越多的学生将能够获得医学和法律学位。</p><p>第50题   正确答案：C    您的答案：B</p><p>【定位】由题干中的 student debt plans 和implemented定位到倒数第二段。</p><p>【精析】事实细节题。定位段首句指出，无论施行何种学生债务计划，都是让美国工薪阶层资助专业阶层的教育，随后采用举例的方式,说管道工和零售工人将为医生和律师的学位支付学费，也就是蓝领阶层将为高收入的专业人士承担教育费用 ，故答案为C)。</p><p>【避错】选项 A )和 B)均混淆了原句概念，定位段的意思是管道工和零售工人为他人的教育买单，工薪阶层资助专业人士的教育，而不是自己受教育成为专业人士或获得更多资助，故均排除; D)项偏离了定位段主题,该段主要探讨的是免除学生债务是否公平，是否不利于工人阶层，并未涉及获得学位的学生是否会增多的问题，故排除。y</p>]]></content>
    
    
    
    <tags>
      
      <tag>英语</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>英语-单词2</title>
    <link href="/2024/05/28/English2-2/"/>
    <url>/2024/05/28/English2-2/</url>
    
    <content type="html"><![CDATA[<p>2024&#x2F;4&#x2F;20</p><p>The infant smiled for the first time. (Infant: 婴儿)<br>婴儿第一次微笑了。</p><p>We need to evaluate the results of the experiment. (Evaluate: 评估)<br>我们需要评估实验的结果。</p><p>The teacher used examples to reinforce the students’ understanding. (Reinforce: 强化)<br>老师用例子来强化学生的理解。</p><p>The archaeologist discovered a well-preserved skull. (Skull: 颅骨)<br>考古学家发现了一个保存完好的颅骨。</p><p>He sat on the wooden chair by the window. (Chair: 椅子)<br>他坐在窗边的木椅上。</p><p>Her intuition told her something was wrong. (Intuition: 直觉)<br>她的直觉告诉她有些不对劲。</p><p>She made a beautiful quilt for the bed. (Quilt: 被子)<br>她做了一床漂亮的被子。</p><p>The internet has transformed the way we communicate. (Internet: 互联网)<br>互联网改变了我们的交流方式。</p><p>He wore a dark cloak to blend in with the night. (Cloak: 斗篷)<br>他穿了一件黑色的斗篷，以融入夜色。</p><p>She explained the addition problem to the students. (Addition: 加法)<br>她向学生们解释了加法问题。</p><p>The teacher used an analogy to explain the concept. (Analogy: 类比)<br>老师用类比来解释这个概念。</p><p>They believed that their loved ones were in heaven. (Heaven: 天堂)<br>他们相信他们的亲人正在天堂。</p><p>They went to the temple to worship. (Worship: 崇拜)<br>他们去寺庙做礼拜。<br>13.</p><ul><li><p>She used a filter to make the photo look more artistic. (Filter: 滤镜)<br>她使用滤镜使照片看起来更有艺术感。</p></li><li><p>The company has offices worldwide. (Worldwide: 全球范围内的)<br>这家公司在全球范围内都有办公室。</p></li><li><p>The book includes an illustration of the concept. (Illustration: 插图)<br>这本书包含了对这个概念的插图。</p></li><li><p>The movie portrays a reality that many people face. (Reality: 现实)<br>电影描绘了许多人面临的现实。</p></li><li><p>She has a cheerful disposition. (Disposition: 性情)<br>她性情开朗。</p></li><li><p>The door swung on its hinge. (Hinge: 铰链)<br>门在它的铰链上摇摆。</p></li><li><p>Smoking is forbidden in this area. (Forbid: 禁止)<br>在这个区域禁止吸烟。</p></li><li><p>The dove is a symbol of peace. (Dove: 鸽子)<br>鸽子是和平的象征。</p></li><li><p>He is good at arithmetic. (Arithmetic: 算术)<br>他擅长算术。</p></li><li><p>They celebrated Christmas with a big feast. (Christmas: 圣诞节)<br>他们用盛大的宴会庆祝圣诞节。</p></li><li><p>She had never seen such a beautiful sunset. (Never: 从未)<br>她从未见过如此美丽的日落。</p></li><li><p>Let’s work together to solve this problem. (Together: 一起)<br>让我们一起解决这个问题。</p></li><li><p>Their salaries are comparable to those of other professionals. (Comparable: 可比较的)<br>他们的薪水与其他专业人员相当。</p></li><li><p>She wore a veil over her face. (Veil: 面纱)<br>她脸上戴着面纱。</p></li><li><p>The bird’s wing was covered in feathers. (Feather: 羽毛)<br>鸟的翅膀上覆盖着羽毛。</p></li></ul><ol start="14"><li></li></ol><ul><li><p>The business trip incurred（v： 招致；遭受） a lot of expense. (Expense: 费用)<br>这次商务旅行产生了很多费用。</p></li><li><p>Good communication is key to a successful marital relationship. (Marital: 婚姻的)<br>良好的沟通是成功婚姻关系的关键。</p></li><li><p>The correct posture is important for good health. (Posture: 姿势)<br>正确的姿势对健康很重要。</p></li><li><p>She is a typical teenager, always on her phone. (Teenager: 青少年)<br>她是一个典型的青少年，总是玩手机。</p></li><li><p>The project received substantial funding. (Substantial: 大量的)<br>这个项目获得了大量的资金支持。</p></li><li><p>The workers threatened to strike if their demands were not met. (Strike: 罢工)<br>工人们威胁说如果他们的要求得不到满足就会罢工。</p></li><li><p>We could hear the sound of the waterfall in the distance. (Waterfall: 瀑布)<br>我们能听到远处瀑布的声音。</p></li><li><p>She enlarged the photo to see the details better. (Enlarge: 放大)<br>她把照片放大以便更好地看到细节。</p></li><li><p>The company faces competitive challenges in the market. (Competitive: 竞争的)<br>公司在市场上面临激烈的竞争挑战。</p></li><li><p>It is probable that they will arrive late. (Probable: 可能的)<br>他们可能会迟到。</p></li><li><p>Why did you do that? (Why: 为什么)<br>你为什么那样做？</p></li><li><p>There is a small gap between the two buildings. (Gap: 间隙)<br>两栋建筑物之间有一个小缝隙。</p></li><li><p>The majesty of the mountains took our breath away. (Majesty: 威严)<br>山的威严让我们惊叹不已。</p></li><li><p>It is an honor to meet you. (Honor: 荣幸)<br>很荣幸见到您。</p></li></ul><ol start="15"><li></li></ol><ul><li><p>The lecture was so dull that I struggled to stay awake. (Dull: 乏味的)<br>这个讲座太无聊了，我几乎睡着了。</p></li><li><p>It is important to protect your skin from the sun. (Protect: 保护)<br>保护皮肤不受阳光伤害很重要。</p></li><li><p>Can you help me carry these boxes? (Help: 帮助)<br>你能帮我搬这些箱子吗？</p></li><li><p>He felt dumb after giving the wrong answer. (Dumb: 愚蠢的)<br>在回答错了问题后，他觉得很愚蠢。</p></li><li><p>The pond was a perfect oval shape. (Oval: 椭圆形的)<br>池塘是一个完美的椭圆形。</p></li><li><p>She gave him a stern look. (Look: 看)<br>她严厉地看了他一眼。</p></li><li><p>Her remark made everyone laugh. (Remark: 评论)<br>她的评论让大家都笑了。</p></li><li><p>The investigation revealed new evidence. (Reveal: 揭露)<br>调查揭示了新的证据。</p></li><li><p>He broke a rib in the accident. (Rib: 肋骨)<br>他在事故中折断了一根肋骨。</p></li><li><p>They offered a discount for buying in bulk. (Discount: 折扣)<br>他们为批量购买提供折扣。</p></li><li><p>Many people see religion as a path to salvation. (Salvation: 拯救)<br>许多人把宗教视为拯救之路。</p></li><li><p>The sky was cloudy, so we didn’t see the stars. (Cloudy: 多云的)<br>天空多云，所以我们看不到星星。</p></li><li><p>We gathered to commemorate the anniversary of his death. (Commemorate: 纪念)<br>我们聚集在一起纪念他去世的周年纪念日。</p></li><li><p>A mouse scurried across the floor. (Mouse: 老鼠)<br>一只老鼠在地板上蹑手蹑脚地跑过。</p></li><li><p>She sat by the window to contemplate the meaning of life. (Contemplate: 沉思)<br>她坐在窗边思考生命的意义。</p></li></ul><ol start="16"><li></li></ol><ul><li><p>The painting was sold at an auction for a high price. (Auction: 拍卖)<br>这幅画在拍卖会上以高价卖出。</p></li><li><p>Don’t speculate about things you don’t know for sure. (Speculate: 推测)<br>不要对你不确定的事情进行推测。</p></li><li><p>She was confident that she would pass the exam. (Confident: 自信的)<br>她确信自己会通过考试。</p></li><li><p>I suspect that he is not telling the truth. (Suspect: 怀疑)<br>我怀疑他没有说实话。</p></li><li><p>His sarcastic remarks offended many people. (Sarcastic: 讽刺的)<br>他讽刺的话冒犯了许多人。</p></li><li><p>He expressed his gratitude for their help. (Gratitude: 感激)<br>他对他们的帮助表示感激。</p></li><li><p>The university was endowed with a large sum of money. (Endow: 捐赠)<br>大学受到了一大笔钱的捐赠。</p></li><li><p>She wore beautiful jewelry to the party. (Jewelry: 珠宝)<br>她戴着漂亮的珠宝去参加派对。</p></li><li><p>She kept a diary to record her thoughts and experiences. (Diary: 日记)<br>她写日记记录她的想法和经历。</p></li><li><p>The counselor tried to console her after the loss. (Console: 安慰)<br>她失去后，辅导员试图安慰她。</p></li><li><p>The alien creature was unlike anything they had ever seen. (Alien: 外星的)<br>这个外星生物与他们以往所见的任何东西都不同。</p></li><li><p>His argument was based on sound logic. (Logic: 逻辑)<br>他的论点建立在严谨的逻辑基础上。</p></li><li><p>The government provides welfare for the needy. (Welfare: 福利)<br>政府为有需要的人提供福利。</p></li><li><p>The rebellion was quickly suppressed by the authorities. (Rebellion: 叛乱)<br>叛乱很快被当局镇压。</p></li><li><p>He was stabbed in the chest during the fight. (Stab: 刺)<br>他在战斗中被刺中胸部。</p></li></ul><ol start="17"><li></li></ol><ul><li><p>The representative of the company will be attending the meeting. (Representative: 代表)<br>公司的代表将出席会议。</p></li><li><p>It’s important to seek assistance when you need it. (Assistance: 帮助)<br>在需要时寻求帮助是很重要的。</p></li><li><p>Be careful not to slip on the wet floor. (Slide: 滑动)<br>小心不要在湿滑的地板上滑倒。</p></li><li><p>The king died without leaving a clear succession plan. (Succession: 继承)<br>国王去世时没有留下明确的继承计划。</p></li><li><p>She used a trick to solve the puzzle quickly. (Trick: 诡计)<br>她用诡计快速解决了这个谜题。</p></li><li><p>She was in distress after losing her job. (Distress: 苦恼)<br>失去工作后，她感到非常苦恼。</p></li><li><p>He had to concede defeat after realizing he was wrong. (Concede: 承认)<br>在意识到自己错误后，他不得不承认失败。</p></li><li><p>The poll showed that most people supported the new policy. (Poll: 民意调查)<br>民意调查显示大多数人支持新政策。</p></li><li><p>He will report to the manager about the progress of the project. (Report: 报告)<br>他将向经理汇报项目的进展情况。</p></li><li><p>They climbed to the top of the hill to enjoy the view. (Hill: 小山)<br>他们爬上山顶欣赏风景。</p></li><li><p>They went for a walk at night. (Night: 夜晚)<br>他们在夜晚出去散步。</p></li></ul><ol start="18"><li></li></ol><ul><li><p>They have an intimate relationship. (Intimate: 亲密的)<br>他们之间有着亲密的关系。</p></li><li><p>The word “derive” is derived from Latin. (Derive: 派生)<br>“Derive”一词源自拉丁语。</p></li><li><p>Let’s talk about your plans for the weekend. (Talk: 谈话)<br>让我们谈谈你周末的计划。</p></li><li><p>He is fifteen years old. (Fifteen: 十五)<br>他十五岁。</p></li><li><p>They live in the southern part of the city. (Southern: 南方的)<br>他们住在城市的南部。</p></li><li><p>The typhoon caused widespread damage. (Typhoon: 台风)<br>台风造成了广泛的破坏。</p></li><li><p>They took the ferry to the island. (Ferry: 渡船)<br>他们乘坐渡船去了岛上。</p></li><li><p>The weather is nice today. (Weather: 天气)<br>今天天气很好。</p></li><li><p>Being a good listener is important in communication. (Being: 存在)<br>在交流中，做一个好的倾听者很重要。</p></li><li><p>The document needs to be certified by a professional. (Certify: 证明)<br>这份文件需要由专业人士证明。</p></li><li><p>His actions embody the spirit of the organization. (Embody: 体现)<br>他的行动体现了组织的精神。</p></li><li><p>She has a fever and needs to rest. (Fever: 发烧)<br>她发烧了，需要休息。</p></li><li><p>They decided to roast marshmallows over the campfire. (Roast: 烤)<br>他们决定在篝火上烤棉花糖。</p></li><li><p>They will initiate the project next week. (Initiate: 开始)<br>他们将在下周启动这个项目。</p></li></ul><ol start="19"><li></li></ol><ul><li><p>The team showed great spirit in the final match. (Spirit: 精神)<br>球队在最后一场比赛中表现出色的精神。</p></li><li><p>They plan to reclaim the land and turn it into a park. (Reclaim: 取回)<br>他们计划收回这片土地，并将其建成公园。</p></li><li><p>She is a very thoughtful person, always considering others’ feelings. (Thoughtful: 深思熟虑的)<br>她是一个非常体贴周到的人，总是考虑别人的感受。</p></li><li><p>The advent of the internet has changed the way we communicate. (Advent: 出现)<br>互联网的出现改变了我们的交流方式。</p></li><li><p>The book was lying open upon the table. (Upon: 在…之上)<br>书摊放在桌子上。</p></li><li><p>The bedrooms are upstairs. (Upstairs: 楼上)<br>卧室在楼上。</p></li><li><p>The dress was covered in glitter. (Glitter: 闪光)<br>这件连衣裙上撒满了闪粉。</p></li><li><p>She put on her boots and went outside. (Boot: 靴子)<br>她穿上靴子走出去了。</p></li><li><p>He turned the knob and opened the door. (Knob: 旋钮)<br>他转动旋钮打开了门。</p></li><li><p>The spacecraft launched successfully into orbit. (Spacecraft: 宇宙飞船)<br>宇宙飞船成功进入轨道。</p></li><li><p>The new policy will take effect next month. (Effect: 生效)<br>新政策将于下个月生效。</p></li><li><p>The city was under siege for several weeks. (Siege: 围困)<br>这座城市被围困了几个星期。</p></li><li><p>The puzzle was challenging, but he managed to solve it. (Puzzle: 智力游戏)<br>这个智力游戏很有挑战性，但他设法解决了。</p></li></ul><ol start="20"><li></li></ol><ul><li><p>The poison was hidden in a small vial. (Poison: 毒药)<br>毒药被隐藏在一个小瓶子里。</p></li><li><p>The water from the holy well is believed to have healing properties. (Holy: 圣洁的)<br>圣井的水被认为具有治疗功效。</p></li><li><p>The museum has a fascinating history. (History: 历史)<br>博物馆有着迷人的历史。</p></li><li><p>The mural is made up of many small mosaic tiles. (Mosaic: 马赛克)<br>壁画由许多小马赛克瓷砖组成。</p></li><li><p>The group decided to boycott the company’s products. (Boycott: 联合抵制)<br>团体决定联合抵制该公司的产品。</p></li><li><p>Among the guests, there were several important politicians. (Among: 在…之中)<br>在客人中间，有几位重要的政治家。</p></li><li><p>What do you mean by that? (Mean: 意味着)<br>你这话是什么意思？</p></li><li><p>His smile seemed to imply that he knew something. (Imply: 暗示)<br>他的微笑似乎在暗示他知道一些事情。</p></li><li><p>The scientist examined the specimen under the microscope. (Microscope: 显微镜)<br>科学家用显微镜检查了标本。</p></li><li><p>There was a wide selection of books at the bookstore. (Selection: 选择)<br>书店里有各种各样的书籍供选择。</p></li><li><p>They sat around the table discussing the project. (Table: 桌子)<br>他们围着桌子讨论项目。</p></li><li><p>The hen laid three eggs this morning. (Hen: 母鸡)<br>今天早上母鸡下了三个蛋。</p></li><li><p>The area is designated as a nature reserve. (Designate: 指定)<br>这个地区被指定为自然保护区。</p></li></ul><ol start="21"><li></li></ol><ul><li><p>She was very sympathetic when I told her about my problem. (Sympathetic: 富有同情心的)<br>当我向她诉说我的问题时，她非常富有同情心。</p></li><li><p>The play received rave reviews for its outstanding performance. (Performance: 表现)<br>这部剧因其出色的表现而收到了热烈的好评。</p></li><li><p>He has a bright prospect in the company. (Prospect: 前景)<br>他在公司有一个光明的前景。</p></li><li><p>He has a rather backward way of thinking. (Backward: 落后的)<br>他的思维方式相当落后。</p></li><li><p>He is a fellow of the Royal Society. (Fellow: 同事；会员)<br>他是皇家学会的一员。</p></li><li><p>The company offers a bonus to its employees at the end of the year. (Bonus: 奖金)<br>公司在年底向员工发放奖金。</p></li><li><p>The orientation program helps new employees get familiar with the company. (Orientation: 方向；定向)<br>新员工定向培训计划帮助他们熟悉公司。</p></li><li><p>The numerical value of pi is approximately 3.14159. (Numerical: 数值的)<br>圆周率π的数值约为3.14159。</p></li><li><p>It’s odd that she hasn’t called yet. (Odd: 奇怪的)<br>她还没有打电话是很奇怪的事情。</p></li><li><p>The school has a large gymnasium for sports activities. (Gymnasium: 体育馆)<br>学校有一个大型的体育馆供体育活动使用。</p></li><li><p>The store sells a wide range of merchandise. (Merchandise: 商品)<br>这家商店出售各种各样的商品。</p></li><li><p>They have a swimming pool in their backyard. (Pool: 游泳池)<br>他们的后院有一个游泳池。</p></li><li><p>He let out a groan of pain when he stubbed his toe. (Groan: 呻吟)<br>当他脚趾碰到东西时，他发出了一声痛苦的呻吟。<br>22</p></li><li><p>She always feels happy whenever she visits her grandparents. (Whenever: 无论何时)<br>她每次去她的祖父母家都感到非常开心。</p></li><li><p>He closed the shutter to keep the sunlight out. (Shutter: 百叶窗)<br>他关闭百叶窗挡住阳光。</p></li><li><p>There was tension in the air as they waited for the results. (Tension: 紧张)<br>当他们等待结果时，空气中弥漫着紧张气氛。</p></li><li><p>He is a true gentleman, always polite and respectful. (Gentleman: 绅士)<br>他是一个真正的绅士，总是彬彬有礼。</p></li><li><p>They are twins, but they look very different from each other. (Twin: 双胞胎)<br>他们是双胞胎，但他们看起来非常不同。</p></li><li><p>The constant noise was a torment to her ears. (Torment: 折磨)<br>持续的噪音让她的耳朵受到折磨。</p></li><li><p>They came up with a scheme to increase sales. (Scheme: 计划)<br>他们想出了一个增加销售的计划。</p></li><li><p>It is important to educate children about the environment. (Educate: 教育)<br>教育孩子们了解环境是很重要的。</p></li><li><p>The city has a mild climate, with warm summers and mild winters. (Climate: 气候)<br>这座城市气候温和，夏季温暖，冬季温和。</p></li><li><p>His observation skills are excellent; he notices things that others miss. (Observation: 观察)<br>他的观察力很出色，他能注意到其他人忽略的事物。</p></li><li><p>The new shopping mall is huge, with over 200 stores. (Huge: 巨大的)<br>这个新的购物中心非常大，有200多家商店。</p></li><li><p>She likes to trim the bushes in her garden to keep them neat. (Trim:修剪)<br>她喜欢修剪花园里的灌木，保持整洁。</p></li><li><p>He has a talent for playing musical instruments. (Musical: 音乐的)<br>他有演奏乐器的才华。</p></li></ul><ol start="23"><li></li></ol><ul><li><p>We decided to stay overnight at the hotel to avoid driving home late. (Overnight: 过夜)<br>我们决定在酒店过夜，以避免太晚驾车回家。</p></li><li><p>The bird spread its wings and flew into the sky. (Fly: 飞)<br>鸟展开翅膀飞向天空。</p></li><li><p>She is always so nice to everyone she meets. (Nice: 友好的)<br>她总是对她遇到的每个人都很友好。</p></li><li><p>The businessman tried to bribe the official to get the contract. (Bribe: 贿赂)<br>这名商人试图贿赂官员以获取合同。</p></li><li><p>The scientist conducted empirical research to test her hypothesis. (Empirical: 经验主义的)<br>科学家进行了经验主义研究来验证她的假设。</p></li><li><p>The soldiers fought to liberate their country from oppression. (Liberate: 解放)<br>士兵们为解放国家免受压迫而战斗。</p></li><li><p>The wedding ceremony was beautiful and heartfelt. (Wedding: 婚礼)<br>婚礼仪式既美丽又充满了感情。</p></li><li><p>I got bitten by a mosquito while camping in the woods. (Mosquito: 蚊子)<br>我在森林露营时被蚊子叮了。</p></li><li><p>The sudden thunder scared the children. (Thunder: 雷声)<br>突然的雷声吓到了孩子们。</p></li><li><p>He has to work overtime to finish the project on time. (Work: 工作)<br>他不得不加班工作，以便按时完成项目。</p></li><li><p>An atom is the smallest unit of a chemical element. (Atom: 原子)<br>原子是化学元素的最小单位。</p></li><li><p>She received a text message from her friend inviting her to dinner. (Text: 短信)<br>她收到了朋友发来的短信邀请她吃饭。</p></li><li><p>He has a negative attitude towards change. (Negative: 消极的)<br>他对变化持消极态度。</p></li><li><p>The book is written in a narrative style, telling the story from the protagonist’s point of view. (Narrative: 叙述)<br>这本书以叙述方式写成，从主人公的角度讲述故事。</p></li></ul><ol start="24"><li></li></ol><ul><li><p>The prince lived in a luxurious suite in the palace. (Prince: 王子; Suite: 套房)<br>王子住在宫殿里豪华的套房里。</p></li><li><p>The heat in the desert was unbearable. (Heat: 热)<br>沙漠中的热浪令人无法忍受。</p></li><li><p>She showed great strength in overcoming her fears. (Strength: 力量)<br>她在克服恐惧时表现出了巨大的力量。</p></li><li><p>Certain chemicals can inhibit the growth of bacteria. (Inhibit: 抑制)<br>某些化学物质可以抑制细菌的生长。</p></li><li><p>He deserved a slap for his rude behavior. (Slap: 拍击)<br>他因为粗鲁的行为应该受到一记耳光。</p></li><li><p>Don’t worry about the trifle, it’s not important. (Trifle: 琐事)<br>不要担心那点小事，那不重要。</p></li><li><p>She is allergic to peanuts. (Peanut: 花生)<br>她对花生过敏。</p></li><li><p>He takes great pride in his work. (Pride: 自豪)<br>他对自己的工作感到非常自豪。</p></li><li><p>The road was covered in sticky tar. (Tar: 沥青)<br>道路上覆盖着黏黏的沥青。</p></li><li><p>His character was known for its honesty and integrity. (Character: 人品)<br>他的品格以诚实和正直而著称。</p></li><li><p>The horror movie was so scary that it made me scream. (Scare: 吓唬)<br>那部恐怖电影太可怕了，把我吓得尖叫起来。</p></li><li><p>The farmer’s hard work yielded a bountiful harvest. (Yield: 产出)<br>农民的辛勤工作带来了丰收。</p></li></ul><ol start="25"><li></li></ol><ul><li><p>She had to count to twelve before she could find her wristwatch. (Twelve: 十二)<br>她必须数到十二才能找到她的手表。</p></li><li><p>The laughter of children is like music to the ears. (Laugh: 笑)<br>孩子们的笑声就像音乐一样动听。</p></li><li><p>Drawing is a great way to express your creativity. (Drawing: 画)<br>画画是表达创造力的好方法。</p></li><li><p>The sound of the waves was so soothing. (Sound: 声音)<br>海浪的声音是如此舒缓。</p></li><li><p>The magnetic field was too weak to attract the metal. (Magnetic: 磁性)<br>磁场太弱，无法吸引金属。</p></li><li><p>Convenience is a key factor in modern living. (Convenience: 便利)<br>便利是现代生活的关键因素。</p></li><li><p>His speech was articulate and well-received by the audience. (Articulate: 表达清晰的)<br>他的演讲表达清晰，受到了观众的好评。</p></li><li><p>The adventure novel was full of excitement and intrigue. (Adventure: 冒险)<br>冒险小说充满了刺激和神秘。</p></li><li><p>The intricate design of the jewelry was truly remarkable. (Intricate: 复杂精细的)<br>珠宝的精致设计真是令人赞叹。</p></li><li><p>The rigorous training regimen prepared him well for the competition. (Rigorous: 严格的)<br>严格的训练计划为他很好地准备了比赛。</p></li><li><p>The oppressor sought to oppress the people and take away their freedom. (Oppress: 压迫)<br>压迫者试图压迫人民，剥夺他们的自由。</p></li><li><p>Hay is used as feed for livestock. (Hay: 干草)<br>干草被用作牲畜的饲料。</p></li><li><p>She had a headache from studying too much. (Headache: 头痛)<br>她因为学习过多而头痛。</p></li><li><p>The creation of the universe is a topic of great debate among scientists. (Create: 创造)<br>宇宙的创造是科学家们争论的焦点。</p></li><li><p>The associate professor was well-respected in his field. (Associate: 联合的)<br>副教授在他的领域内受到很高的尊重。</p></li></ul><ol start="26"><li></li></ol><ul><li><p>The confusion in the room was palpable as nobody knew what to do next. (Confusion: 混乱)<br>房间里的混乱是明显的，因为没有人知道接下来该怎么做。</p></li><li><p>The driver of the bus was experienced and knew the route well. (Driver: 司机)<br>公共汽车司机经验丰富，对路线很熟悉。</p></li><li><p>The roundabout was decorated with flowers and looked beautiful. (Roundabout: 环岛)<br>环岛被鲜花装饰着，看起来很漂亮。</p></li><li><p>There was an array of options to choose from at the buffet. (Array: 一系列)<br>自助餐厅有各种各样的选择。</p></li><li><p>She decided to seek advice from a professional before making a decision. (Seek: 寻找)<br>她决定在做出决定之前向专业人士寻求建议。</p></li><li><p>The grain in the wood was beautifully highlighted by the polish. (Grain: 纹理)<br>木头上的纹理被打磨后显得格外美丽。</p></li><li><p>It took him a while to locate the book he was looking for in the library. (Locate: 定位)<br>他花了一段时间在图书馆里找到他要找的书。</p></li><li><p>He signed the deed to officially transfer ownership of the house. (Deed: 证书)<br>他签署了这份证书，正式将房子的所有权转让给他。</p></li><li><p>The latent talent of the young artist was finally discovered. (Latent: 潜在的)<br>这位年轻艺术家潜在的才华终于被发现了。</p></li><li><p>She decided to send a letter to express her gratitude. (Send: 发送)<br>她决定写封信表达感谢之情。</p></li><li><p>The restaurant served delicious oriental cuisine. (Oriental: 东方的)<br>这家餐厅供应美味的东方美食。</p><p>2024&#x2F;4&#x2F;27</p></li></ul><p>1. </p><ul><li><p>I need to buy some groceries on the way home. (Buy: 购买)<br>我需要在回家的路上买些杂货。</p></li><li><p>The snow started to melt as the sun came out. (Melt: 融化)<br>太阳出来时，雪开始融化。</p></li><li><p>He had to plead with his boss for a day off. (Plead: 恳求)<br>他不得不恳求老板放一天假。</p></li><li><p>Don’t forget to list all the ingredients you need before going shopping. (List: 列出)<br>不要忘记在购物前列出所有你需要的食材。</p></li><li><p>She is deaf in one ear and wears a hearing aid. (Deaf: 聋的)<br>她一只耳朵是聋的，戴着助听器。</p></li><li><p>The characters in the story interact in interesting ways. (Interact: 互动)<br>故事中的人物以有趣的方式互动。</p></li><li><p>The rules are very rigid and must be followed strictly. (Rigid: 严格的)<br>规则非常严格，必须严格遵守。</p></li><li><p>The country is undergoing a process of modernization. (Modernization: 现代化)<br>这个国家正在进行现代化进程。</p></li><li><p>This is the final warning before action is taken. (Final: 最后的)<br>这是采取行动之前的最后警告。</p></li><li><p>The metric system is used in most countries around the world. (Metric: 公制的)<br>大多数国家都使用公制系统。</p></li><li><p>She tried to resist the temptation to eat another piece of cake. (Resist: 抵抗)<br>她努力抵制吃另一块蛋糕的诱惑。</p></li><li><p>His hypocrisy was revealed when his actions contradicted his words. (Hypocrisy: 虚伪)<br>当他的行动与言辞相矛盾时，他的虚伪就暴露出来了。</p></li><li><p>The government decided to impose strict regulations to control pollution. (Impose: 强加)<br>政府决定实施严格的法规来控制污染。</p></li><li><p>He likes to poke fun at his friends in a friendly way. (Poke: 戳)<br>他喜欢以友好的方式取笑他的朋友们。</p></li></ul><ol start="2"><li></li></ol><ul><li><p>She likes to pedal her bike around the park on weekends. (Pedal: 踩踏)<br>她喜欢在周末骑自行车绕着公园骑行。</p></li><li><p>He keeps his tools in the closet in the garage. (Closet: 壁橱)<br>他把工具放在车库里的壁橱里。</p></li><li><p>This book belongs to my friend, not me. (Belong: 属于)<br>这本书属于我的朋友，不是我。</p></li><li><p>The origin of this tradition can be traced back to ancient times. (Origin: 起源)<br>这一传统的起源可以追溯到古代。</p></li><li><p>One characteristic of cats is their independence. (Characteristic: 特征)<br>猫的一个特点是它们的独立性。</p></li><li><p>A breakdown in communication led to misunderstandings between the two parties. (Breakdown: 故障)<br>沟通中断导致了双方之间的误解。</p></li><li><p>Finally, after hours of hard work, they completed the project. (Finally: 最终)<br>经过几个小时的努力工作，他们终于完成了项目。</p></li><li><p>The store sells a variety of goods, from clothing to electronics. (Goods: 商品)<br>这家商店销售各种商品，从服装到电子产品。</p></li><li><p>They plan to go on a road trip for a fortnight during the summer vacation. (Fortnight: 两周)<br>他们计划在暑假期间进行为期两周的公路旅行。</p></li><li><p>His reckless behavior often gets him into trouble. (Reckless: 鲁莽的)<br>他的鲁莽行为经常让他惹上麻烦。</p></li><li><p>His new car is much better than his old one. (His: 他的)<br>他的新车比他的旧车好多了。</p></li><li><p>The movie tells the story of an ordinary man who becomes a hero. (Ordinary: 普通的)<br>这部电影讲述了一个普通人成为英雄的故事。</p></li><li><p>The team finished at the top of the league this season. (League: 联赛)<br>这个赛季，这个队获得了联赛冠军。</p></li><li><p>You can choose whichever book you like from the shelf. (Whichever: 无论哪个)<br>你可以从书架上选择任何一本你喜欢的书。</p></li><li><p>The surgeon successfully performed the delicate operation. (Surgeon: 外科医生)<br>外科医生成功地进行了这个精细的手术。</p></li></ul><ol start="3"><li></li></ol><ul><li><p>She likes to eat peas with her dinner. (Pea: 豌豆)<br>她喜欢在晚餐时吃豌豆。</p></li><li><p>Children are often dependent on their parents for support. (Dependent: 依赖的)<br>孩子们经常依赖父母的支持。</p></li><li><p>Please put the milk back in the fridge after you pour a glass. (Fridge: 冰箱)<br>请在倒一杯牛奶后把牛奶放回冰箱。</p></li><li><p>He is fourteen years old and in the eighth grade. (Fourteen: 十四)<br>他今年十四岁，读八年级。</p></li><li><p>This course is a module of the larger program. (Module: 模块)<br>这门课程是更大课程的一部分。</p></li><li><p>She is currently an undergraduate student at the university. (Undergraduate: 本科生)<br>她目前是大学本科生。</p></li><li><p>There are innumerable stars in the night sky. (Innumerable: 无数的)<br>夜空中有无数颗星星。</p></li><li><p>The toilet is located at the end of the hallway. (Toilet: 厕所)<br>厕所位于走廊的尽头。</p></li><li><p>Please appoint a time for our meeting tomorrow. (Appoint: 指定)<br>请指定我们明天的会议时间。</p></li><li><p>The projector is used to display images on the screen. (Projector: 投影仪)<br>投影仪用于在屏幕上显示图像。</p></li><li><p>He bumped his elbow against the door and it hurt. (Elbow: 肘部)<br>他的肘部撞到门上，很疼。</p></li><li><p>They adhere to the orthodox teachings of their religion. (Orthodox: 正统的)<br>他们遵循他们宗教的正统教义。</p></li><li><p>The teacher paid special attention to the student’s progress. (Attention: 注意)<br>老师特别关注学生的进步。</p></li><li><p>She left for home, for she was tired. (For: 因为)<br>她回家了，因为她累了。</p></li></ul><ol start="4"><li></li></ol><ul><li><p>The news outlet was found to fabricate stories to attract more viewers. (Fabricate: 制造，捏造)<br>这家新闻机构被发现捏造新闻以吸引更多观众。</p></li><li><p>Please cover the pot while the soup is simmering. (Cover: 覆盖)<br>煮汤时请盖上锅盖。</p></li><li><p>The lion is often referred to as the king of the jungle. (Lion: 狮子)<br>狮子常被称为丛林之王。</p></li><li><p>The hotel is adjacent to the train station, making it very convenient for travelers. (Adjacent: 邻近的)<br>酒店毗邻火车站，对旅行者非常方便。</p></li><li><p>The castle has stood for centuries, a testament to its enduring architecture. (Century: 世纪)<br>这座城堡已经立了几个世纪，证明了它持久的建筑。</p></li><li><p>Someone left their umbrella behind in the restaurant. (Someone: 某人)<br>有人把伞忘在了餐厅里。</p></li><li><p>The kettle began to emit steam as the water inside heated up. (Steam: 蒸汽)<br>水壶开始冒出蒸汽，因为里面的水在加热。</p></li><li><p>The embassy provides assistance to citizens traveling or living abroad. (Embassy: 大使馆)<br>大使馆为出国旅行或居住的公民提供协助。</p></li><li><p>The bed was hard and uncomfortable to sleep on. (Hard: 硬的)<br>床很硬，睡起来很不舒服。</p></li><li><p>The punishment was harsh and not proportional to the offense. (Harsh: 严厉的)<br>惩罚很严厉，不符合犯罪行为的严重程度。</p></li><li><p>The software engineer wrote a new code to improve the performance of the application. (Code: 代码)<br>软件工程师编写了新代码来提高应用程序的性能。</p></li><li><p>She keeps a journal to record her thoughts and experiences. (Journal: 日记)<br>她写日记记录她的想法和经历。</p></li><li><p>By the time they arrived, the party was already over. (By: 到…的时候)<br>他们到达的时候，派对已经结束了。</p></li></ul><ol start="5"><li></li></ol><ul><li><p>She found a delicious recipe for chocolate cake online. (Recipe: 食谱)<br>她在网上找到了一个美味的巧克力蛋糕食谱。</p></li><li><p>His role in the company is to oversee the marketing department. (Role: 角色)<br>他在公司的角色是监督市场部门。</p></li><li><p>Please discard any food that has passed its expiration date. (Discard: 丢弃)<br>请丢弃任何过期的食物。</p></li><li><p>She had to confront her fears in order to overcome them. (Confront: 面对)<br>她不得不面对自己的恐惧才能克服它们。</p></li><li><p>The cop arrested the thief and took him to the police station. (Cop: 警察)<br>警察逮捕了小偷并把他带到了警察局。</p></li><li><p>They spent the weekend at a cottage by the coast. (Coast: 海岸)<br>他们周末在海岸边的一间小屋度过。</p></li><li><p>The field was covered with wildflowers in the spring. (Field: 田野)<br>春天，田野上长满了野花。</p></li><li><p>She reads the newspaper every morning to stay informed. (Newspaper: 报纸)<br>她每天早上看报纸保持消息灵通。</p></li><li><p>The factory produces over 1,000 cars a day. (Factory: 工厂)<br>这家工厂每天生产超过1,000辆汽车。</p></li><li><p>She likes to shop at local markets for fresh produce. (Shop: 购物)<br>她喜欢在当地市场购买新鲜食材。</p></li><li><p>He’s been single for a while and isn’t looking for a relationship right now. (Single: 单身的)<br>他单身已有一段时间，现在并不寻求恋爱关系。</p></li><li><p>The valley was surrounded by mountains, creating a picturesque scene. (Valley: 山谷)<br>山谷被山包围，形成了一幅美丽的景色。</p></li><li><p>Her attitude towards the project was very positive. (Attitude: 态度)<br>她对这个项目的态度非常积极。</p></li><li><p>The company has over 500 employees working in various departments. (Employee: 员工)<br>公司有500多名员工在各个部门工作。</p></li></ul><ol start="6"><li></li></ol><ul><li><p>The apartment building has several storeys, each with its own entrance. (Storey: 楼层)<br>公寓大楼有几层楼，每层都有自己的入口。</p></li><li><p>The installation of the new software should only take a few minutes. (Installation: 安装)<br>新软件的安装只需要几分钟。</p></li><li><p>She made a purchase of new clothes for the upcoming season. (Purchase: 购买)<br>她购买了新的衣服，准备迎接即将到来的季节。</p></li><li><p>The fire left nothing but ash where the house once stood. (Ash: 灰烬)<br>火灾只留下了房子曾经所在的地方的灰烬。</p></li><li><p>Following the correct procedure is crucial for safety. (Procedure: 程序)<br>遵循正确的程序对安全至关重要。</p></li><li><p>They conducted a survey to gather opinions from the community. (Survey: 调查)<br>他们进行了一项调查，收集社区的意见。</p></li><li><p>The basin in the bathroom was filled with water. (Basin: 盆地)<br>浴室的盆地里装满了水。</p></li><li><p>He played the drum in the school band. (Drum: 鼓)<br>他在学校乐队里打鼓。</p></li><li><p>She drove a pickup truck to transport the furniture. (Pickup: 皮卡车)<br>她开着一辆皮卡车运送家具。</p></li><li><p>That guy over there is my neighbor. (Guy: 人)<br>那边的那个人是我的邻居。</p></li><li><p>It’s common for people to feel nervous before a big presentation. (Common: 普遍的)<br>在做重要演讲前感到紧张是很普遍的。</p></li><li><p>The history of ancient civilizations never fails to fascinate me. (Fascinate: 迷住)<br>古代文明的历史总是让我着迷。</p></li><li><p>After a long day, she felt too lazy to cook dinner. (Lazy: 懒惰的)<br>经过漫长的一天，她感到太懒了，不想做晚饭。</p></li><li><p>Both options have their advantages and disadvantages. (Both: 两者都)<br>两种选择都有各自的优缺点。</p></li></ul><ol start="7"><li></li></ol><ul><li><p>He dedicated his lifetime to the study of marine biology. (Lifetime: 一生)<br>他把一生都献给了海洋生物学的研究。</p></li><li><p>The initial plan was to launch the project in September. (Initial: 最初的)<br>最初的计划是在九月份启动这个项目。</p></li><li><p>Metal can corrode if exposed to certain chemicals. (Corrode: 腐蚀)<br>金属如果暴露在某些化学物质中会腐蚀。</p></li><li><p>The estimated cost is approximate and may vary. (Approximate: 大约的)<br>估计的成本是大约的，可能会有所变化。</p></li><li><p>The project was awarded based on merit rather than seniority. (Merit: 优点)<br>这个项目是基于功绩而不是资历授予的。</p></li><li><p>He exchanged his dollars for euros at the bank. (Dollar: 美元)<br>他在银行把美元换成了欧元。</p></li><li><p>The flowers in the garden were a beautiful shade of violet. (Violet: 紫罗兰色)<br>花园里的花朵是美丽的紫罗兰色。</p></li><li><p>The lorry delivered the goods to the warehouse. (Lorry: 卡车)<br>卡车把货物送到了仓库。</p></li><li><p>The track around the park is used for jogging and cycling. (Track: 轨道)<br>公园周围的跑道用于慢跑和骑车。</p></li><li><p>The assault on the castle was part of a larger military campaign. (Assault: 攻击)<br>对城堡的攻击是一场更大的军事行动的一部分。</p></li><li><p>The recipe’s simplicity makes it easy to follow. (Simplicity: 简单)<br>这个食谱的简单性使得它易于跟随。</p></li><li><p>The product comes with a money-back guarantee. (Guarantee: 保证)<br>该产品附带退款保证。</p></li><li><p>The invention of the internet was revolutionary in terms of communication. (Revolutionary: 革命性的)<br>互联网的发明在通讯方面是革命性的。</p></li></ul><ol start="8"><li></li></ol><ul><li><p>She felt ashamed of her actions and apologized to everyone. (Ashamed: 羞愧的)<br>她为自己的行为感到羞愧，并向所有人道歉。</p></li><li><p>The fire department quickly extinguished the fire. (Fire: 火)<br>消防部门迅速扑灭了火灾。</p></li><li><p>The tiger prowled through the jungle, searching for prey. (Tiger: 老虎)<br>老虎在丛林中游荡，寻找猎物。</p></li><li><p>Adolescents often experience a range of emotions as they grow up. (Adolescent: 青少年)<br>青少年在成长过程中常常经历各种情绪。</p></li><li><p>The goal of education is to civilize society and promote progress. (Civilize: 文明)<br>教育的目标是使社会文明化并促进进步。</p></li><li><p>The scandal rocked the political world and led to several resignations. (Scandal: 丑闻)<br>这场丑闻震动了政治界，导致了几位官员辞职。</p></li><li><p>He added some spices to the dish to give it more relish. (Relish: 享受)<br>他在菜里加了一些香料，使其更加美味。</p></li><li><p>After a long day of work, he finally had a chance to rest. (Rest: 休息)<br>经过一天的辛苦工作，他终于有机会休息了。</p></li><li><p>The safe in the bank contained valuable documents and money. (Safe: 保险柜)<br>银行的保险柜里装有贵重文件和钱。</p></li><li><p>The chemical turned into vapour when heated. (Vapour: 蒸气)<br>这种化学物质在加热时变成了蒸气。</p></li><li><p>She was hailed as a heroine for her bravery during the rescue mission. (Heroine: 女英雄)<br>她因在救援任务中的勇敢表现而被称为女英雄。</p></li><li><p>The excitement of the carnival could be felt throughout the town. (Excitement: 兴奋)<br>庆祝活动的兴奋感在整个城镇中都能感觉到。</p></li><li><p>The store sells items in bulk to save money. (Bulk: 大量)<br>该商店以大宗销售商品以节省成本。</p></li></ul><ol start="9"><li></li></ol><ul><li><p>The ancient Greeks believed that the gods could divine the future. (Divine: 神圣的)<br>古希腊人相信神灵可以预测未来。</p></li><li><p>She is pursuing her academic studies at the university. (Academic: 学术的)<br>她正在大学攻读学术研究。</p></li><li><p>The depth of the ocean is unfathomable to most people. (Depth: 深度)<br>海洋的深度对大多数人来说是无法想象的。</p></li><li><p>They decided to renovate the old house rather than tear it down. (Renovate: 翻新)<br>他们决定翻新这座老房子，而不是拆掉它。</p></li><li><p>The ball bounced off the wall and landed on the floor. (Bounce: 弹跳)<br>球从墙上弹起，落在地板上。</p></li><li><p>She tried her best to complete the project on time. (Try: 尝试)<br>她尽力按时完成项目。</p></li><li><p>She looked elegant in her evening gown. (Elegant: 优雅的)<br>她穿着晚礼服看起来很优雅。</p></li><li><p>The market is abound with fresh fruits and vegetables. (Abound: 大量存在)<br>市场上充斥着新鲜水果和蔬菜。</p></li><li><p>He did his utmost to help his friend in need. (Utmost: 极度的)<br>他尽了最大的努力帮助他需要帮助的朋友。</p></li><li><p>The necklace was adorned with a single pearl in the center. (Pearl: 珍珠)<br>项链中央点缀着一颗珍珠。</p></li><li><p>Socialism advocates for collective ownership and control of the means of production. (Socialism: 社会主义)<br>社会主义主张生产资料的集体所有制和控制。</p></li><li><p>The children watched in awe as the balloon floated into the sky. (Balloon: 气球)<br>孩子们惊叹地看着气球飘向天空。</p></li></ul><ol start="10"><li></li></ol><ul><li><p>She packed her stuff and left the house. (Stuff: 东西)<br>她收拾好东西离开了房子。</p></li><li><p>The teacher gave a dictation exercise to the students. (Dictation: 听写)<br>老师让学生听写练习。</p></li><li><p>The truck was carrying a heavy freight of goods. (Freight: 货物)<br>卡车载着一大堆货物。</p></li><li><p>The architect presented a model of the new building. (Model: 模型)<br>建筑师展示了新建筑的模型。</p></li><li><p>They sat in a circle and discussed the plan. (Circle: 圈子)<br>他们围成一圈讨论计划。</p></li><li><p>I have a lot of work to do today. (Have: 有)<br>我今天有很多工作要做。</p></li><li><p>The food was so spicy that it made him choke. (Choke: 呛)<br>食物太辣了，让他呛了一下。</p></li><li><p>The company holds a yearly conference for its employees. (Yearly: 每年一次)<br>公司每年为员工举办一次年会。</p></li><li><p>Please omit the unnecessary details from your report. (Omit: 省略)<br>请从你的报告中省略掉不必要的细节。</p></li><li><p>Can you confirm your reservation for tomorrow’s flight? (Confirm: 确认)<br>你能确认明天航班的预订吗？</p></li><li><p>The shirt is made of 100% cotton. (Cotton: 棉花)<br>这件衬衫是100%棉的。</p></li><li><p>The company’s slogan is “Quality and Innovation.” (Slogan: 口号)<br>公司的口号是“质量和创新”。</p></li><li><p>The sudden noise startled the sleeping cat. (Sudden: 突然的)<br>突然的噪音吓醒了正在睡觉的猫。</p></li></ul><ol start="11"><li></li></ol><ul><li><p>Children often receive a weekly allowance from their parents. (Allowance: 零用钱)<br>孩子们经常从父母那里拿到每周的零用钱。</p></li><li><p>The committee will approve the budget for the new project. (Approve: 批准)<br>委员会将批准新项目的预算。</p></li><li><p>She used a recorder to capture the sounds of birds in the forest. (Recorder: 录音机)<br>她用录音机录下了森林中鸟儿的声音。</p></li><li><p>Please peel the skin off the potatoes before cooking them. (Peel: 剥皮)<br>请在烹饪前把土豆的皮剥掉。</p></li><li><p>He decided to ask his boss for a raise. (Ask: 请求)<br>他决定向老板要求加薪。</p></li><li><p>Despite the rain, they continued with their outdoor picnic. (Despite: 尽管)<br>尽管下雨，他们仍然继续进行户外野餐。</p></li><li><p>The company has set a minimum requirement for job applicants. (Minimum: 最低的)<br>公司为求职者设定了最低要求。</p></li><li><p>Somehow, he managed to finish the project on time. (Somehow: 不知怎么地)<br>不知怎么地，他设法按时完成了项目。</p></li><li><p>She has an appointment with the dentist tomorrow. (Dentist: 牙医)<br>她明天有一个牙医的约会。</p></li><li><p>The library has a vast collection of literature from around the world. (Literature: 文学作品)<br>图书馆收藏着来自世界各地的大量文学作品。</p></li><li><p>The twins are so alike that even their parents sometimes mix them up. (Alike: 相似)<br>双胞胎长得如此相似，以至于连他们的父母有时都会把他们搞混。</p></li><li><p>It’s important to wear a helmet when riding a bike. (Helmet: 头盔)<br>骑自行车时戴头盔很重要。</p></li><li><p>It’s difficult to quantify the impact of climate change. (Quantify: 量化)<br>很难量化气候变化的影响。</p></li><li><p>The possibilities of the universe seem infinite. (Infinite: 无限的)<br>宇宙的可能性似乎是无限的。</p></li></ul><ol start="12"><li></li></ol><ul><li><p>He packed his belongings into a box and moved to a new city. (Box: 箱子)<br>他把自己的物品装进箱子里，搬到了一个新城市。</p></li><li><p>The company’s mass production of goods led to lower prices. (Mass: 大量的)<br>公司大量生产商品导致价格下降。</p></li><li><p>He found a wallet filled with money on the street and returned it to its owner. (Money: 钱)<br>他在街上找到了一个装满钱的钱包，并将其归还给了失主。</p></li><li><p>As she walked down the street, she passed a group of passer-by. (Passer-by: 路人)<br>当她走在街上时，她经过了一群路人。</p></li><li><p>The political rally attracted thousands of people. (Rally: 集会)<br>政治集会吸引了成千上万的人。</p></li><li><p>The mountain top was covered in snow. (Top: 顶部)<br>山顶覆盖着雪。</p></li><li><p>The company has seen steady growth over the past few years. (Growth: 增长)<br>公司在过去几年里稳步增长。</p></li><li><p>The hostages were finally released after negotiations. (Hostage: 人质)<br>经过谈判，人质们终于被释放了。</p></li><li><p>She studied psychiatry in college and became a psychiatrist. (Psychiatry: 精神病学)<br>她在大学里学习了精神病学，成为了一名精神科医生。</p></li><li><p>He picked up a pencil and started sketching the landscape. (Pencil: 铅笔)<br>他拿起一支铅笔，开始勾画风景。</p></li><li><p>The deadline for the project is definite and cannot be extended. (Definite: 明确的)<br>项目的截止日期是明确的，不能延长。</p></li><li><p>She decided to inquire about the job opening at the company. (Inquire: 询问)<br>她决定询问一下公司的职位空缺情况。</p></li><li><p>The miner descended into the shaft to start his shift. (Shaft: 井筒)<br>矿工下到井筒里开始他的工作。</p></li><li><p>The company announced a layoff of 100 employees due to financial difficulties. (Layoff: 裁员)<br>公司由于财务困难宣布裁员100人。</p></li></ul><ol start="13"><li></li></ol><ul><li><p>She placed a bouquet of flowers in a vase on the table. (Vase: 花瓶)<br>她把一束花放在桌子上的花瓶里。</p></li><li><p>He managed to contrive a plan to escape from the prison. (Contrive: 设法做到)<br>他设法制定了一个逃离监狱的计划。</p></li><li><p>The nursery is full of children playing and laughing. (Nursery: 托儿所)<br>托儿所里挤满了玩耍和笑声的孩子们。</p></li><li><p>The landscape was plain and uninteresting. (Plain: 平原)<br>这片土地是平坦而乏味的。</p></li><li><p>They decided to adopt a child from a local orphanage. (Adopt: 领养)<br>他们决定从当地的孤儿院领养一个孩子。</p></li><li><p>The milk had gone nasty and sour. (Nasty: 讨厌的)<br>牛奶变质了，变得又讨厌又酸。</p></li><li><p>Let’s meet on Tuesday to discuss the project. (Tuesday: 星期二)<br>我们星期二见面讨论项目。</p></li><li><p>She stood at the rear of the line, waiting patiently. (Rear: 后面)<br>她站在队伍的后面，耐心等待。</p></li><li><p>The dish had a unique flavor that was both sweet and spicy. (Flavor: 味道)<br>这道菜有一种独特的味道，既甜又辣。</p></li><li><p>The perpetual noise from the construction site was tiresome. (Perpetual: 永久的；Tiresome: 令人厌烦的)<br>来自建筑工地的持续噪音令人厌烦。</p></li><li><p>He suffered a serious injury in the accident. (Injury: 受伤)<br>他在事故中受了重伤。</p></li><li><p>The hotel is situated near the beach, offering stunning views. (Situated: 位于)<br>酒店位于海滩附近，景色优美。</p></li><li><p>They walked through the gate and into the garden. (Gate: 大门)<br>他们走过大门进入花园。</p></li></ul><ol start="14"><li></li></ol><ul><li><p>The artist’s work attracted a wealthy patron who supported his career. (Patron: 赞助人)<br>艺术家的作品吸引了一位富有的赞助人，支持他的职业生涯。</p></li><li><p>The politician’s ideology was based on equality and social justice. (Ideology: 意识形态)<br>政治家的意识形态基于平等和社会正义。</p></li><li><p>They kept in touch through regular correspondence. (Correspondence: 通信)<br>他们通过定期通信保持联系。</p></li><li><p>She used a ribbon to wrap the gift. (Wrap: 包装)<br>她用丝带包装礼物。</p></li><li><p>The waiter placed the cup and saucer on the table. (Saucer: 茶托)<br>侍者把杯子和茶托放在桌子上。</p></li><li><p>She finished the race in second place. (Second: 第二)<br>她以第二名完成比赛。</p></li><li><p>They picked mushrooms in the forest. (Mushroom: 蘑菇)<br>他们在森林里采摘蘑菇。</p></li><li><p>The ruler is divided into inches. (Inch: 英寸)<br>这把尺子刻有英寸。</p></li><li><p>The meeting will be held over lunch. (Over: 在…期间)<br>会议将在午餐期间举行。</p></li><li><p>Her handwriting was neat and legible. (Handwriting: 字迹)<br>她的字迹整齐清晰。</p></li><li><p>The company’s guiding principle is customer satisfaction. (Principle: 原则)<br>公司的指导原则是顾客满意。</p></li><li><p>He couldn’t tolerate the noise any longer and left the room. (Tolerate: 忍受)<br>他再也无法忍受这噪音，于是离开了房间。</p></li><li><p>It’s a paradox that some of the poorest countries have the richest resources. (Paradox: 悖论)<br>一些最贫穷的国家拥有最丰富的资源，这是一个悖论。</p></li><li><p>The bull charged at the matador. (Bull: 公牛)<br>公牛向斗牛士冲过去。</p></li><li><p>She had a guilty conscience about what she had done. (Conscience: 良心)<br>她对自己所做的事感到愧疚。</p></li><li><p>The orderly arrangement of books on the shelf made it easy to find what she was looking for. (Orderly: 有序的)<br>书架上书籍的整齐排列使得她很容易找到她要找的东西。</p></li></ul><ol start="15"><li></li></ol><ul><li><p>Is anyone here? (Anyone: 任何人)<br>这里有人吗？</p></li><li><p>She gave a little hop of excitement. (Hop: 跳)<br>她兴奋地跳了一下。</p></li><li><p>The rider pulled on the reins to slow the horse. (Rein: 缰绳)<br>骑手拉缰绳减慢了马的速度。</p></li><li><p>The finding of the research supported their hypothesis. (Finding: 发现)<br>研究的发现支持了他们的假设。</p></li><li><p>We have class from nine to ten. (Period: 时段)<br>我们从九点到十点有课。</p></li><li><p>This method is more effective than the previous one. (Comparative: 比较的)<br>这种方法比之前的更有效。</p></li><li><p>The kitten had soft fur. (Soft: 柔软的)<br>小猫的毛发很柔软。</p></li><li><p>It’s likely that it will rain tomorrow. (Likely: 可能)<br>明天可能会下雨。</p></li><li><p>Don’t be silly, it’s just a harmless prank. (Silly: 愚蠢的)<br>别傻了，这只是一个无害的恶作剧。</p></li><li><p>Nine is the number after eight. (Nine: 九)<br>九是八之后的数字。</p></li><li><p>He is presumably on his way home now. (Presumably: 大概)<br>他大概现在正在回家的路上。</p></li><li><p>I got this book from my friend. (From: 从…来)<br>我是从朋友那里得到这本书的。</p></li><li><p>She wrote the answer on the blackboard. (Blackboard: 黑板)<br>她把答案写在黑板上。</p></li></ul><ol start="16"><li></li></ol><ul><li><p>The doctor found a tumour during the examination. (Tumour: 肿瘤)<br>医生在检查中发现了一个肿瘤。</p></li><li><p>I need to refresh my memory on that topic. (Refresh: 刷新)<br>我需要刷新一下我对那个话题的记忆。</p></li><li><p>His story seems dubious to me. (Dubious: 可疑的)<br>他的故事对我来说似乎有些可疑。</p></li><li><p>I left my keys in the locker at the gym. (Locker: 储物柜)<br>我把钥匙留在了健身房的储物柜里。</p></li><li><p>He used a cleaver to chop the vegetables. (Chop: 砍)<br>他用菜刀切菜。</p></li><li><p>Let us pray for those in need. (Pray: 祈祷)<br>让我们为有需要的人祈祷。</p></li><li><p>“Damn!” he muttered under his breath. (Damn: 该死)<br>“该死！”他低声咒骂道。</p></li><li><p>She’s a bit shy around strangers. (Shy: 害羞的)<br>她在陌生人面前有点害羞。</p></li><li><p>The building cast a shadow over the park. (Shadow: 阴影)<br>建筑物在公园上投下了阴影。</p></li><li><p>The TV had static on the screen. (Static: 静态)<br>电视屏幕上出现了静态。</p></li><li><p>The ceremony will commence at noon. (Commence: 开始)<br>典礼将在中午开始。</p></li><li><p>The glass was transparent, allowing us to see through it. (Transparent: 透明的)<br>玻璃是透明的，我们可以透过它看到外面。</p></li><li><p>He was known as a poet of great talent. (Poet: 诗人)<br>他被誉为才华横溢的诗人。</p></li><li><p>The heading of the article caught my attention. (Heading: 标题)<br>文章的标题引起了我的注意。</p></li></ul><ol start="17"><li></li></ol><ul><li><p>The curtains are used to separate the living room from the dining area. (Separate: 分开)<br>窗帘被用来将客厅和餐厅分开。</p></li><li><p>The two cars collided at the intersection. (Collide: 碰撞)<br>两辆车在十字路口发生了碰撞。</p></li><li><p>The box was too heavy for her to lift. (Heavy: 重的)<br>这个箱子对她来说太重了，搬不动。</p></li><li><p>The occurrence of earthquakes in this region is rare. (Occurrence: 发生)<br>这个地区地震的发生是罕见的。</p></li><li><p>Please shut the door behind you. (Shut: 关闭)<br>请在你身后关上门。</p></li><li><p>They decided to settle their differences peacefully. (Settle: 解决)<br>他们决定和平解决彼此之间的分歧。</p></li><li><p>The cat licked its paw. (Its: 它的)<br>猫舔了舔它的爪子。</p></li><li><p>Her advice was very helpful to me. (Helpful: 有帮助的)<br>她的建议对我很有帮助。</p></li><li><p>She’s very fond of music. (Fond: 喜爱)<br>她非常喜爱音乐。</p></li><li><p>The children jumped for joy when they heard the news. (Joy: 欢乐)<br>孩子们听到这个消息后欢天喜地地跳了起来。</p></li><li><p>I adore the way you’ve decorated the room. (Adore: 非常喜欢)<br>我非常喜欢你装饰房间的方式。</p></li><li><p>The stream flows gently through the valley. (Stream: 小溪)<br>小溪轻轻地流过山谷。</p></li><li><p>She’s busy with housework today. (Housework: 家务活)<br>她今天很忙于做家务。</p></li><li><p>The arrow pointed upward. (Upward: 向上)<br>箭头指向上方。</p></li></ul><ol start="18"><li></li></ol><ul><li><p>Einstein was a genius in the field of physics. (Genius: 天才)<br>爱因斯坦是物理学领域的天才。</p></li><li><p>Wipe the table clean with a damp cloth. (Wipe: 擦)<br>用湿布把桌子擦干净。</p></li><li><p>The magician’s performance entertained the audience. (Entertain: 娱乐)<br>魔术师的表演让观众很开心。</p></li><li><p>There is a grocery store nearby. (Nearby: 附近)<br>附近有一家杂货店。</p></li><li><p>The music stimulated memories of her childhood. (Stimulate: 刺激)<br>音乐唤起了她童年的记忆。</p></li><li><p>She felt faint after standing in the sun for too long. (Faint: 晕倒)<br>她在阳光下站了太久后感到晕眩。</p></li><li><p>The ship will dock at the port tomorrow morning. (Dock: 靠岸)<br>船明天早上将靠岸。</p></li><li><p>The government’s goal is to unify the country. (Unify: 统一)<br>政府的目标是统一国家。</p></li><li><p>The pilot had to eject from the plane before it crashed. (Eject: 弹射)<br>飞行员不得不在飞机坠毁前弹射出来。</p></li><li><p>She’s so vain, always checking herself in the mirror. (Vain: 虚荣的)<br>她非常爱虚荣，总是在镜子前检查自己。</p></li><li><p>The room was filled with daylight. (Daylight: 日光)<br>房间里充满了日光。</p></li><li><p>Can you spell your name for me? (Spell: 拼写)<br>你能给我拼写你的名字吗？</p></li><li><p>She is a strong advocate for human rights. (Advocate: 拥护者)<br>她是人权的坚定拥护者。</p></li><li><p>The new system is much more efficient than the old one. (Efficient: 高效的)<br>新系统比旧系统效率高得多。</p></li></ul><ol start="19"><li></li></ol><ul><li><p>The biologist examined the specimen under the microscope. (Specimen: 标本)<br>生物学家在显微镜下检查标本。</p></li><li><p>The circus came to town and set up its tents in the park. (Circus: 马戏团)<br>马戏团来到镇上，在公园里搭起了帐篷。</p></li><li><p>She paid the next installment on her car loan. (Installment: 分期付款)<br>她支付了汽车贷款的下一期分期付款。</p></li><li><p>The digital clock is a modern analogue of the traditional clock. (Analogue: 类似物)<br>数字时钟是传统时钟的现代类似物。</p></li><li><p>Good communication is integral to a successful team. (Integral: 不可或缺的)<br>良好的沟通对于一个成功的团队至关重要。</p></li><li><p>He looked at her with scorn, unable to hide his contempt. (Scorn: 轻蔑)<br>他轻蔑地看着她，无法掩饰他的鄙视。</p></li><li><p>The analytic approach to problem-solving involves breaking down the problem into smaller parts. (Analytic: 分析的)<br>分析性解决问题的方法涉及将问题分解为较小的部分。</p></li><li><p>He gave the coin a toss and it landed on heads. (Toss: 抛)<br>他把硬币抛起来，硬币落在了正面。</p></li><li><p>The waves were so high, they were topped with foam. (Foam: 泡沫)<br>浪花如此之高，上面都覆盖着泡沫。</p></li><li><p>The sky turned pink with the dawn of a new day. (Dawn: 黎明)<br>天空在新的一天的黎明变成了粉红色。</p></li><li><p>She had a bruise on her arm from where she bumped into the table. (Bruise: 擦伤)<br>她的手臂上有一个淤青，是撞到桌子上造成的。</p></li><li><p>The loud noise outside disrupted our conversation. (Disrupt: 打扰)<br>外面的巨大噪音打断了我们的谈话。</p></li><li><p>I couldn’t help but overhear their conversation on the bus. (Overhear: 无意中听到)<br>我不由自主地在公共汽车上听到了他们的谈话。</p></li><li><p>The hostess greeted us warmly at the restaurant. (Hostess: 女主人)<br>女主人在餐厅热情地接待了我们。</p></li></ul><ol start="20"><li></li></ol><ul><li><p>The office building is equipped with air-conditioning to keep the temperature comfortable. (Air-conditioning: 空调)<br>办公楼配备了空调，以保持舒适的温度。</p></li><li><p>She refuted the accusations against her with strong evidence. (Refute: 反驳)<br>她用强有力的证据驳斥了对她的指控。</p></li><li><p>The documentary provided a detailed look into the life of the famous artist. (Documentary: 纪录片)<br>这部纪录片详细展示了这位著名艺术家的生活。</p></li><li><p>The level of pollution in the city has reached alarming levels. (Level: 水平)<br>城市的污染水平已经达到了令人担忧的水平。</p></li><li><p>The old house had a robust structure that stood strong against the storm. (Robust: 强壮的)<br>这座老房子有坚固的结构，能够抵御风暴。</p></li><li><p>The operation was successful, and the patient is recovering well. (Operation: 手术)<br>手术很成功，病人恢复良好。</p></li><li><p>He was beloved by all who knew him for his kindness and generosity. (Beloved: 被爱戴的)<br>他因其善良和慷慨而被所有认识他的人所爱戴。</p></li><li><p>The mystery novel’s plot was full of intrigue and suspense. (Intrigue: 阴谋)<br>这本悬疑小说的情节充满了阴谋和悬念。</p></li><li><p>It’s important not to generalize based on just a few examples. (Generalize: 归纳)<br>不应该只根据少数几个例子就做出概括。</p></li><li><p>After a day at the beach, she had a nice tan. (Tan: 晒黑)<br>在海滩度过一天后，她晒得很黑。</p></li><li><p>The government’s denial of the allegations only fueled more speculation. (Denial: 否认)<br>政府对指控的否认只会引发更多的猜测。</p></li></ul><ol start="21"><li></li></ol><ul><li><p>The tree provided shade from the hot sun. (Shade: 遮蔽处)<br>这棵树提供了遮蔽，挡住了炎热的阳光。</p></li><li><p>Please place your order at the counter. (Order: 订单)<br>请在柜台下单。</p></li><li><p>Conservation of natural resources is important for future generations. (Conservation: 保护)<br>自然资源的保护对于子孙后代至关重要。</p></li><li><p>The mechanic worked to repair the car’s engine. (Repair: 修理)<br>技工努力修理汽车的发动机。</p></li><li><p>The math problem was too complex for me to solve. (Complex: 复杂的)<br>这个数学问题对我来说太复杂了，无法解决。</p></li><li><p>The reservoir supplies water to the surrounding areas. (Reservoir: 水库)<br>水库为周围地区供水。</p></li><li><p>After a long day of work, she felt a deep fatigue. (Fatigue: 疲劳)<br>一天的工作后，她感到非常疲劳。</p></li><li><p>He struggled to lift his heavy luggage. (Luggage: 行李)<br>他费力地提起沉重的行李。</p></li><li><p>The nurse found a vein to insert the IV needle. (Vein: 静脉)<br>护士找到了一个静脉来插入静脉输液针。</p></li><li><p>A Swiss Army knife is handy for many situations. (Handy: 方便的)<br>瑞士军刀在许多情况下都很方便。</p></li><li><p>They went to the theater to watch a play. (Theater: 剧院)<br>他们去剧院看戏。</p></li><li><p>Workers are busy at the construction site. (Construct: 建造)<br>工人们在建筑工地忙碌着。</p></li><li><p>She holds conservative views on social issues. (Conservative: 保守的)<br>她在社会问题上持保守观点。</p></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>英语</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>阅读-2022年12月大学英语六级考试真题（第一套）</title>
    <link href="/2024/05/22/English5/"/>
    <url>/2024/05/22/English5/</url>
    
    <content type="html"><![CDATA[<h2 id="单词选填"><a href="#单词选填" class="headerlink" title="单词选填"></a>单词选填</h2><p>During the summer, when I was a visiting poet at a residency out of state, an angry, confused woman wandered into my class and said：”I have three guns and I want to use them.” We all （froze (害怕)） . It wasn’t clear if she had the guns, but we each know that, when we teach in America, we are already in danger.            I was dizzy with fear. The woman, who later turned out to be a schizophrenic (精神分裂症患者) without  to her medications, was, by some force, wrestled out and  away, then put in a hospital for observation, in a step that was actually safer for everyone than any one of us pressing charges. My class went on；we talked about poems. But despite the fact that the rest of our days on campus passed , I was rattled. I couldn’t shake the sense that in this country we always live at  risk.            A few months later, crisis  again. While my husband was locking his bike to drop off our 3-year-old daughter for her preschool-aged day camp, a different woman approached. Swiftly and for no  reason, she bent down, picked up our daughter, and began to carry her down the street. It was so fast and confusing that my daughter  cried. My husband, in a burst of speed, chased the woman and reclaimed our daughter. The woman, clearly confused, retreated into the public library. A  of homeless people who generally know the other homeless in the area said they did not recognize the woman. The woman was so clearly unwell that when she was taken into custody she was incoherent. Heartbreakingly, she called our daughter by the name of someone else’s child. Each part of the episode was haunting as it was terrifying（可怕的） .<br>在那个夏天，当我在外州一个驻留项目中担任客座诗人时，一位愤怒、困惑的女人闯进了我的课堂，说：“我有三把枪，我想用它们。”我们都冻住了（害怕）。不清楚她是否真的有枪，但我们每个人都知道，在美国教学，我们已经处于危险之中。</p><p>I was dizzy with fear. The woman, who later turned out to be a schizophrenic (精神分裂症患者) without (access 机会)  to her medications, was, by some force, wrestled out and （beescorted 被护送） away, then put in a hospital for observation, in a step that was actually safer for everyone than any one of us pressing charges. My class went on；we talked about poems. But despite the fact that the rest of our days on campus passed （peacefully 平静地） , I was rattled. I couldn’t shake the sense that in this country we always live at （incredible ）  risk.<br>我被吓得头晕目眩。后来发现，这个女人是一名没有获得药物（机会）的精神分裂症患者（精神分裂症患者），在某种力量的作用下，她被摔倒并护送（被护送）离开，然后被送往医院观察，这比我们任何人提出指控都更安全。我的课继续进行；我们谈论诗歌。尽管我们在校园里的日子平静地（平静地）度过了，但我仍然感到不安。我无法摆脱这种感觉：在这个国家，我们总是生活在极大的风险中。</p><p>A few months later, crisis （struck 侵袭）  again. While my husband was locking his bike to drop off our 3-year-old daughter for her preschool-aged day camp, a different woman approached. Swiftly and for no （apparent 明确的） reason, she bent down, picked up our daughter, and began to carry her down the street. It was so fast and confusing that my daughter （barely 几乎没有） cried. My husband, in a burst of speed, chased the woman and reclaimed our daughter. The woman, clearly confused, retreated into the public library. A （network 关系网）  of homeless people who generally know the other homeless in the area said they did not recognize the woman. The woman was so clearly unwell that when she was taken into custody she was incoherent. Heartbreakingly, she called our daughter by the name of someone else’s child. Each part of the episode was haunting as it was .<br>几个月后，危机再次侵袭（侵袭）。当我丈夫锁好自行车，准备送我们三岁的女儿去她的学龄前日营时，另一名女子走近了。她迅速且毫无明显（明确的）理由地弯下腰，抱起我们的女儿，开始沿街走去。事情发生得太快太混乱，以至于我女儿几乎没有（几乎没有）哭。我丈夫以飞快的速度追上了那名女子，并夺回了我们的女儿。那名女子显然很困惑，退回了公共图书馆。通常认识其他无家可归者的一群无家可归者说他们不认识那名女子。那名女子明显不健康，被拘留时语无伦次。令人心碎的是，她称呼我们的女儿为另一个孩子的名字。整个事件的每一部分都既令人难以忘怀又令人恐惧（可怕的）</p><h2 id="选段落"><a href="#选段落" class="headerlink" title="选段落"></a>选段落</h2><p>A) Michael Wardian pushed forward into the penetrating arctic (北极的)wind, fighting the urge to speed up. Too much effort and he’d begin to sweat, which, he was told, would only increase the risk of hypothermia (体温过低).<br>A) 迈克尔·沃迪安冒着刺骨的北极寒风向前推进，努力抑制加速的冲动。过多的运动会让他开始出汗，而他被告知这只会增加体温过低的风险。<br>Over-exertion in extreme cold can lower one’s body temperature to a dangerous point.<br>在极冷的环境中过度运动会使人的体温降至危险水平。</p><p>B) At the 2014 North Pole Marathon, the temperature dipped to minus-22 degrees F, with a wind chill that made it feel even colder. Along the route, armed guards wandered the large sheets of floating ice to minimize the risk of polar bear attacks.<br>B) 在2014年的北极马拉松比赛中，气温降到了零下22华氏度，风寒效应使得体感温度更低。沿途，武装警卫在大片漂浮的冰上巡逻，以减少北极熊袭击的风险。</p><p>C) “I like to do stuff that scares me,“ Wardian said. With ice frozen to his beard, Wardian crossed the finish line that April afternoon in a winning time of 4 hours 7 minutes and 40 seconds, almost two hours slower than his personal best over 26.2 miles. The race for Wardian, however, was less about the result than overcoming his aversion to the cold.<br>C) “我喜欢做让我害怕的事情，”沃迪恩（Michael Wardian）说。那年四月的下午，沃迪恩胡子上结满冰，他以4小时7分钟40秒的成绩冲过终点，比他在26.2英里上的个人最佳成绩慢了近两小时。然而，对于沃迪恩来说，这次比赛的意义在于克服对寒冷的恐惧，而不是结果。<br>For Wardian, the marathon in the Arctic was more about how to triumph over the extreme cold.<br>对于 Wardian 来说，北极马拉松更多的是关于如何战胜极寒。</p><p>D) In a few days, Wardian will once again compete in an unfamiliar territory and below-freezing temperatures. He will line up Monday in Antarctica (南极) for the first leg of the World Marathon Challenge—joining 32 other adventure seekers on an unusual journey where participants travel through different time zones and climates to run seven marathons on seven continents in seven days.<br>D) 几天后，沃迪恩将再次在陌生的地方和零度以下的气温中比赛。他将在周一的南极洲（南极）站在世界马拉松挑战赛的起跑线上，与其他32位冒险者一起踏上这段不寻常的旅程，参与者将穿越不同的时区和气候，在七天内跑完七大洲的七个马拉松。<br>Wardian hopes his participation in the seven-day marathon series will contribute to a worthy cause.<br>Wardian 将与三十多名其他跑者一起参加为期一周的马拉松系列赛。</p><p>E) An elite ultra-runner, Wardian has his sights on breaking the event’s record average marathon time of 3：32：25 set last January by U. S. Marine Corps captain Daniel Cartica. Wardian, a 42-year-old Arlington resident, is a record-breaking racer, known in the ultra-running community for seeking tough courses and setting world records. Last year, he ran 1,254.65 miles in 47 races. The World Marathon Challenge, like most of Wardian’s running goals, will be about pushing his limits. “I love diverse and unique challenges,” he said. “I’m definitely interested in seeing what I can handle and what my body can accept. That drives me.”<br>E) 作为一名精英超马选手，沃迪恩的目标是打破去年1月由美国海军陆战队上尉丹尼尔·卡蒂卡（Daniel Cartica）创下的平均马拉松时间3小时32分25秒的纪录。42岁的沃迪恩是阿灵顿居民，是一名破纪录的赛车手，以追求艰难的赛道和创造世界纪录而闻名于超马社区。去年，他在47场比赛中跑了1254.65英里。世界马拉松挑战赛，和沃迪恩的大多数跑步目标一样，是关于挑战自己的极限。“我喜欢多样而独特的挑战，”他说。“我绝对对看看我能承受什么，我的身体能接受什么感兴趣。这激励着我。”<br>Wardian regards the various extraordinary challenges as a test of his physical endurance.  （E）<br>Wardian 将各种非凡的挑战视为对他身体耐力的考验。</p><p>F) Something about the way Richard Donovan carried himself appealed to Wardian. Perhaps it was the sense of adventure Donovan displayed when they first met at the 2010 50K Championships in Galway, Ireland, where Donovan was the race director. The two hit it off, and soon Wardian was participating in Donovan’s events. It was at the North Pole Marathon, a race that Donovan organizes, that Wardian first heard about the Irishman’s plan for the World Marathon Challenge—a challenge that Donovan himself completed in 2009 and 2012. “I knew that many people had a goal of running seven marathons on seven continents during any time period,“ Donovan, 50, said. “I felt the natural extension to this idea would be to try to achieve it within a seven-day period.”<br>F) 理查德·多诺万（Richard Donovan）的某种气质吸引了沃迪恩。也许是多诺万在2010年爱尔兰戈尔韦50公里锦标赛上展示的冒险精神吸引了他，当时多诺万是赛事的导演。两人一拍即合，不久之后，沃迪恩便开始参加多诺万的赛事。沃迪恩第一次听说爱尔兰人的世界马拉松挑战赛计划是在北极马拉松上，那是多诺万组织的比赛。“我知道很多人有在任何时间段内完成七大洲七个马拉松的目标，”50岁的多诺万说。“我觉得这个想法的自然延伸是尝试在七天内完成它。”<br>Wardian was very much impressed by a race director’s sense of adventure.<br>Wardian 对一位比赛总监的冒险精神印象深刻。</p><p>G) Wardian started saving for the trip in 2014, connecting with sponsors and getting approval from his wife, Jennifer, before committing. Registration for the event costs 36,000 euros, which covers international charter flights to each of the seven marathon locations：Union Glacier (Antarctica), Punta Arenas, Chile (South America), Miami (North America), Madrid (Europe), Marrakesh, Morocco (Africa), Dubai (Asia) and Sydney (Australia). The challenge is a test of both physical strength and mental fitness. Sleeping on a crammed plane, adjusting to different time zones and finding food to eat (Wardian is a vegetarian) would make it an exhausting trip over a month, let alone a week. “The key to a race like this is getting comfortable being uncomfortable,” said Becca Pizzi, last year’s women’s champion. “The highs of the race are incredibly high, and the lows incredibly low.”<br>G) 沃迪恩从2014年开始为这次旅行储蓄，与赞助商联系，并在得到妻子詹妮弗（Jennifer）的批准后才承诺报名。参加这项活动的注册费为36000欧元，这包括到七个马拉松地点的国际包机：南极洲的联合冰川（Union Glacier）、智利的蓬塔阿雷纳斯（Punta Arenas，南美洲）、迈阿密（北美洲）、马德里（欧洲）、摩洛哥的马拉喀什（非洲）、迪拜（亚洲）和悉尼（澳大利亚）。这项挑战是对体力和心理素质的双重考验。睡在拥挤的飞机上，适应不同的时区，并找到食物（沃迪恩是素食主义者），这些在一个月内已经够累人的了，更别说在一周内完成了。“这种比赛的关键是让自己在不舒适中找到舒适，”去年的女子冠军贝卡·皮齐（Becca Pizzi）说。“比赛的高潮极其高，低谷极其低。”<br>To participate in the seven-day marathon series, Wardian had to raise a lot of money and have his wife’s support.<br>为了参加七天马拉松系列赛，Wardian 不仅需要筹集大量资金，还需要得到妻子的支持。</p><p>H) Since turning it into an organized event in 2015, Donovan has attracted a variety of runners. This year’s challenge will feature a far more elite field, which includes Ryan Hall, America’s fastest marathon runner. Despite his proven track record, Hall said he has no time goals and that he still suffers from the same fatigue issues that forced him to leave the professional ranks in 2015. Hall plans to run with his friend, Pastor Matthew Barnett of The Dream Center in Los Angeles—one of the six American men who will be competing. “I don’t expect to run a step with Mike, but I will be excited to see how he does,“ said the 34-year-old Hall, who began weight-lifting after retiring. “If I finish within an hour of him in each marathon, I’d be surprised.”<br>H) 自2015年将其变成一个有组织的活动以来，多诺万吸引了各种各样的跑步者。今年的挑战将包括更为精英的选手，其中包括美国最快的马拉松选手瑞恩·霍尔（Ryan Hall）。尽管有着出色的成绩记录，霍尔表示他没有时间目标，并且他仍然受到2015年离开职业圈的疲劳问题的困扰。霍尔计划与他的朋友，洛杉矶梦想中心的牧师马修·巴尼特（Matthew Barnett）一起跑步，这是六位美国男性参赛者之一。“我不指望和迈克一起跑步，但我会很高兴看到他表现如何，”34岁的霍尔说，他在退役后开始举重训练。“如果我在每个马拉松中能在他身后一个小时内完赛，我会感到惊讶。”<br>One top American marathoner quit his running career because of his physical condition.<br>一位顶尖的美国马拉松选手因身体状况退出了他的跑步生涯。</p><p>I) Instead, 43-year-old Petr Vabrousek, an elite Czech Ironman champion, is expected to be Wardian’s closest challenger. To others on the trip, simply finishing will be its own reward. Sinead Kane of Ireland is aiming to become the first blind person to complete the challenge. And Beth Ann Telford, a 47-year-old federal government worker from Fairfax and the only American female in this year’s mix, is using the event as a platform to raise money for cancer research. It’s a cause with a personal connection to Telford, who was diagnosed with brain cancer in 2004. “Doing something like this is definitely the hardest challenge that I’ve ever done except for the chemotherapy and brain surgery,” she said. “It’s going to raise awareness… I just wanted to do something that is epic and this certainly is right up there.” Wardian, too, hopes his involvement will give him a platform to promote a cause. He recently became an ambassador for the United Nations Women’s HeForShe initiative to fight inequalities faced by women and girls worldwide.<br>I) 相反，43岁的捷克精英铁人三项冠军佩特·瓦布鲁塞克（Petr Vabrousek）预计将是沃迪恩最接近的挑战者。对于旅行中的其他人来说，完成比赛本身就是一种回报。爱尔兰的希妮德·凯恩（Sinead Kane）计划成为第一个完成挑战的盲人。而47岁的贝丝·安·特尔福德（Beth Ann Telford），是来自费尔法克斯的联邦政府工作人员，今年唯一的美国女性参赛者，正在利用这项活动作为平台为癌症研究筹集资金。这对特尔福德来说是一个与自己息息相关的原因，她在2004年被诊断出患有脑癌。“除了化疗和脑部手术，这绝对是我做过的最艰难的挑战，”她说。“这将提高人们的意识……我只想做一些史诗般的事情，而这确实符合我的期望。”沃迪恩也希望通过参与比赛，能够为自己支持的事业提供平台。他最近成为联合国妇女署“他为她”倡议的代言人，以打击全球女性和女孩面临的不平等现象。<br>Wardian hopes his participation in the seven-day marathon series will contribute to a worthy cause.<br>Wardian 希望他参与七天马拉松系列赛能够为有价值的事业做出贡献。<br>To many of the week-long marathon participants, completing the race will be a success in itself.<br>对于许多参加为期一周马拉松的选手来说，完成比赛本身就是一种成功。</p><p>J) On a chilly December afternoon, Wardian wove through Washington’s crowded sidewalks on the way home from his full-time job as an international ship broker. His elastic, 6-foot frame bounced gently and efficiently off the ground with each step of the hilly six-mile trip back to Arlington. This is a daily routine during the week for Wardian, who started racing professionally in 2003 and runs seven days a week, often multiple times a day. When he travels, he prefers to explore new places on his feet.<br>J) 在一个寒冷的十二月下午，沃迪恩在从他的全职国际船舶经纪人工作回家的路上穿过华盛顿拥挤的人行道。他那富有弹性的6英尺身躯每一步都轻盈而高效地从地面弹起，踏上回阿灵顿的6英里陡坡。这是沃迪恩在工作日的日常习惯，他在2003年开始职业比赛，每周跑七天，经常一天跑几次。当他旅行时，他喜欢用双脚探索新地方。</p><p>K) But in some ways, Wardian still has trouble thinking of himself as a runner. For the majority of his childhood, Wardian devoted his energy to becoming a Division I lacrosse (长曲棍球) player—a dream he realized when he was recruited to play at Michigan State University. “Once he decides to do something, he just works at it until he does it,“ Michaefs younger sister, Mariele, said. “Once he decides to do it, it’s usually something that’s going to happen. He’s always been like that. He’s a very motivated individual.”<br>K) 但在某些方面，沃迪恩仍然难以将自己视为跑步者。在大部分童年时期，沃迪恩将精力投入到成为一名一级长曲棍球（长曲棍球）选手的目标上——这是他在被密歇根州立大学招募后实现的梦想。“一旦他决定做某事，他就会努力直到实现它，”沃迪恩的妹妹玛里埃尔（Mariele）说。“一旦他决定了，这件事通常会发生。他一直是这样的人。他是一个非常有动力的人。”<br>Once Wardian sets his mind on something, he is determined to make it happen.<br>一旦 Wardian 决定做某事，他就会下定决心去实现它。</p><p>L) It was only a year or so ago that Wardian realized that he had been a runner longer than a lacrosse player. It was not until he ran in the 2004 U. S. Olympic Marathon Trials—the first of three for Wardian—that he felt that he was a legitimate runner. Now more than 10 years and numerous ultramarathon national titles and world records later, he embraces that identity. Wardian wants to see how far his legs can take him, one epic challenge at a time. “I want to always keep doing things that are exciting, adventurous, different and most importantly, probably things I’m not the best at,“ Wardian said, “because if you’re not seeking things out that are challenging and difficult for you, then you’re not growing… So I hope maybe people see what I do, and say, ‘Okay, I want to do something different or try something new… I’m going to do something that scares me.’ That’s what I’m hoping people will take from it.”<br>L) 大约一年前，沃迪恩才意识到自己已经比打长曲棍球的时间更长了跑步。他直到参加了2004年美国奥运马拉松选拔赛——这是沃迪恩三次参赛中的第一次——才觉得自己是真正的跑步者。现在，十多年和无数的超马国家冠军和世界纪录之后，他开始接受这个身份。沃迪恩想看看他的双腿能带他走多远，一次史诗般的挑战接着一次。“我想一直做一些令人兴奋、冒险、不同的事情，最重要的可能是那些我并不擅长的事情，”沃迪恩说，“因为如果你不去寻找那些对你有挑战性和困难的事情，那么你就不会成长……所以我希望人们看到我做的事情，然后说，‘好吧，我想做一些不同的事情或尝试一些新的东西……我要做一些让我害怕的事情。’这就是我希望人们从中获得的。”</p><h2 id="短文阅读"><a href="#短文阅读" class="headerlink" title="短文阅读"></a>短文阅读</h2><p>Many people associate their self-worth with their work. The more successful their career, the better they feel about themselves. Work-related self-esteem is therefore a worthy ideal to pursue with vigor, right? Well, not always. According to recent research, in which psychologists interviewed 370 full-time workers over a period of three weeks, the reality is a little more complicated. And it involves negative as well as positive consequences.<br>许多人将自我价值与他们的工作联系在一起。事业越成功，他们对自己的感觉就越好。因此，与工作相关的自尊心是一个值得积极追求的理想，对吧？实际上，并不总是如此。根据最近的研究，心理学家在三周内采访了370名全职工作者，发现现实情况要复杂得多，涉及到负面和正面的影响。</p><p>It’s natural to be drawn towards pleasure and to step away from pain. In the workplace, if that pleasure comes from a triumph which swells our self-respect, people will try to repeat the accomplishment. But repeating that accomplishment is often not realistic, which can lead to severe negative emotional consequences when it doesn’t reoccur. This form of motivation is widely regarded as a negative type of motivation. It can hinder other more positive motivation types, such as completing a task purely because it’s fulfilling or enjoyable.<br>人们自然会被愉悦吸引并远离痛苦。在工作场所，如果这种愉悦来自于成功带来的自尊心膨胀，人们会试图重复这一成就。但重复这一成就通常是不现实的，这会在未能再次取得成功时导致严重的负面情绪后果。这种形式的动机被广泛认为是一种消极的动机。它可能会妨碍其他更积极的动机类型，例如仅仅因为完成任务是有成就感或令人愉快而去完成它。</p><p>What consumes the employee instead is a pressing need to feel mighty and sure of themselves. They then take on only tasks and objectives which serve that ego-driven need. As a result, to avoid feelings of shame and worthlessness associated with failure, they extend themselves to such a degree that there’s a subsequent adverse effect on their well-being. This internal pressure to succeed at all costs demands a lot of effort. It depletes their energy, culminating in disproportionate levels of damaging sentiment.<br>员工反而会被一种强烈的需要感所驱使，渴望感到强大和自信。然后，他们只承担那些能够满足这种自我驱动需求的任务和目标。因此，为了避免与失败相关的羞耻和无价值感，他们会将自己推到极限，以至于对他们的健康产生负面影响。这种为了成功而付出一切代价的内部压力需要大量的努力。它消耗了他们的能量，导致不成比例的负面情绪。</p><p>Those negative emotions mount into heightened anxiety, impacting their ability to make the most of their personal life. Their desire to avoid feeling inferior ends up making them feel inferior when it comes to their diminished capacity for friendship and leisure. They end up dissatisfied both at work and outside of it.<br>这些负面情绪积累成高度的焦虑，影响他们充分利用个人生活的能力。他们避免感到低人一等的愿望最终使他们在友谊和休闲方面的能力减弱时感到低人一等。他们最终在工作和生活中都感到不满意。</p><p>But thankfully, for those people compelled almost entirely by this specific form of motivation, the news isn’t all bad, or bad at all. The study also discovered several positive outcomes that can actually outweigh the harmful ones. Though these types of employees are motivated by the desire to avoid negative consequences, they are also motivated by the excitement of pursuing emotional rewards. This excitement makes pursuing goals enjoyable and stimulates pleasure and pride that would result from success. An effcet of the positive motivation is that it neutralizes the existence of negative motivation.<br>但值得庆幸的是，对于那些几乎完全由这种特定形式的动机驱动的人来说，情况并不全是坏消息，甚至并非完全糟糕。研究还发现了一些实际上可以超过有害影响的积极结果。虽然这些类型的员工受到避免负面后果的动机驱动，但他们也受到追求情感回报的兴奋感的激励。这种兴奋使追求目标变得愉快，并激发成功带来的愉悦和自豪感。积极动机的一个效果是中和了消极动机的存在。</p><p>Sure, it affects people’s personal lives to what could be deemed an unhealthy extent, because leisure activities are often seen as a part of life that must be sacrificed to manage work and family demands. However, the way people feel about their work has less to do with whether they’re motivated by the preservation of self-esteem but more with the fact that they’re simply motivated. <br>当然，这会对人们的个人生活产生被认为不健康的影响，因为休闲活动通常被视为必须为了管理工作和家庭需求而牺牲的生活部分。然而，人们对工作的感觉与他们是否被保护自尊心的动机驱动关系不大，更多的是因为他们被简单地激励了。</p><h2 id="短文阅读二"><a href="#短文阅读二" class="headerlink" title="短文阅读二"></a>短文阅读二</h2><p>Degradation of the world’s natural resources by humans is rapidly outpacing the planet’s ability to absorb the damage, a recent UN environmental study has found. The study concludes that without radical action the level of prosperity that millions of people in the developed world count on will be impossible to maintain or extend to poorer countries.          <br>最近一项联合国环境研究发现，人类对世界自然资源的破坏迅速超过了地球吸收这些损害的能力。该研究得出结论称，如果不采取激进的行动，发达国家数以百万计的人们所依赖的繁荣水平将无法维持或延伸到较贫穷的国家。</p><p>Water scarcity is the curse of some of the poorest regions on Earth, leaving developing countries increasingly unable to feed themselves, and causing hardship for millions of people. There appears little prospect of this desperate situation being remedied without radical action being taken. Water resources are under increasing threat from population growth, climate change, rapid urbanization, rising levels of consumption, and the degradation of lands that previously provided a natural replenishment (补 充 )of water resources.          <br>水资源短缺是地球上一些最贫困地区的诅咒，导致发展中国家日益无法养活自己，使数百万人陷入困境。在不采取激进行动的情况下，似乎很难解决这种绝望的局面。水资源正受到人口增长、气候变化、快速城市化、消费水平上升以及之前提供水资源自然补充的土地退化等因素日益威胁。</p><p>The rate of damage to the natural environment was found to increase globally, despite concerted efforts to persuade governments to take measures to improve the condition. “If current trends continue, and the world fails to improve patterns of production and consumption, then the state of the world’s environment will continue to decline,”warned UN executive director Achim Steiner.          <br>尽管劝说各国政府采取措施改善环境状况的努力在全球范围内增加，但自然环境受到破坏的速度仍在加快。联合国执行主任阿希姆·施泰纳警告称：“如果当前趋势继续下去，世界未能改善生产和消费模式，那么世界环境的状况将继续恶化。”</p><p>He said the tools for improving the environment for millions of people existed in developed countries, but were in danger of not being used.          <br>他表示，改善环境的工具在发达国家已存在，但存在未被使用的危险。</p><p>The study found that basic measures to tackle some of the key causes of environmental damage were still not being taken. These included measures to reduce air pollution, to control the damage to marine eco-systems, which can have a huge effect on fish stocks on which hundreds of millions of people depend；and to curb the degradation of land where modern agricultural methods were pursued without regard to thelonger-term consequences.          <br>该研究发现，仍未采取一些基本措施来解决一些环境破坏的关键原因。这些措施包括减少空气污染、控制对海洋生态系统的破坏，这对数亿人口依赖的鱼类资源产生巨大影响；以及遏制对土地的破坏，在这些地方，现代农业方法的推行忽视了长期后果。</p><p>Despite the recent global agreement on cutting greenhouse gas emissions, global carbon output continues to rise. This will put a long-term strain on the ability of developing economics to feed their own people. Climate change is aggravated by the emissions of greenhouse gases from chemical and natural fertilisers used in agriculture which increased by more than a quarter between 2000 and 2010. Other problem areas identified in the report included glaciers, which provide vital water resources for millions of people, but which are shrinking as the climate warms.          <br>尽管最近全球达成了减少温室气体排放的协议，但全球碳排放量仍在上升。这将长期对发展中国家养活自己的能力造成压力。气候变化受到农业化学和天然肥料排放的温室气体的影响，在2000年至2010年间增加了超过四分之一。报告中还指出的其他问题领域包括冰川，这些冰川为数百万人提供了重要的水资源，但随着气候变暖而萎缩。</p><p>In rich countries, these problems have built up over decades and centuries while economic growth was pursued at the expense of the environment. Subsequent efforts to remedy the environment have met with partial success. But in developing countries, the path of future development has more potential to change, which has encouraged international institutions to devise more sustainable growth pathways that are supposed both to alleviate poverty and preserve the environment.<br>在富裕国家，这些问题是在数十年甚至几个世纪的时间里积累起来的，而在追求经济增长的过程中环境受到了损害。后来的环境补救措施取得了部分成功。但在发展中国家，未来发展的道路更有可能发生变化，这促使国际机构制定更加可持续的增长路径，既可以减轻贫困，又可以保护环境。</p>]]></content>
    
    
    
    <tags>
      
      <tag>英语</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔18</title>
    <link href="/2024/05/22/ganwu18/"/>
    <url>/2024/05/22/ganwu18/</url>
    
    <content type="html"><![CDATA[<h2 id="需求为王，能力为主"><a href="#需求为王，能力为主" class="headerlink" title="需求为王，能力为主"></a>需求为王，能力为主</h2><p>需求是重要的，时刻明白自己的需求是重要的，而其他的东西是在明白需求之后才慢慢建立的。作为一名终生学习者，没有必要为自己的标签所限制。比如我的专业是人工智能，我就只需要做人工智能的事情吗？不是这样的，这样反而将自己限制住了，明白自己的需求，自己需要解决什么，自己想要实现一个什么东西。而其他的都是能力上的差距了，而能力是可以锻炼的，无非是多花点时间和心力而已。<br>从顶层设计，慢慢探索实现自己的想法的过程中需要解决的问题，而后慢慢探索。</p><p>不断的扩大自己的舒适圈，学习区和恐慌区。在舒适圈内行动，在舒适圈外学习。</p><p>作为一个创客，自己需要有能力去实现自己想做的。</p><h2 id="控制情绪，不要影响他人"><a href="#控制情绪，不要影响他人" class="headerlink" title="控制情绪，不要影响他人"></a>控制情绪，不要影响他人</h2><p>我是社交恐惧症患者吗？<br>我有这种现象，碰见一个熟人迎面走来，不知该怎么打招呼，觉得挺尴尬的。<br>打招呼尴尬，包含了这几种思考方式：一种是自卑，因此总想迎合别人，把什么问题都拦在自己身上，认为尴尬是自己的问题；第二，认为要跟人搞好关系，一定要在每次见面中都留下好印象，一次没搞好就可能变为“敌人”；第三种，想让每个人都喜欢自己，对自己人际关系的要求无比苛刻；第四种，心虚、害羞；等等。</p><p>端正态度：<br>所以，你发现没有，尴尬只是因为你自己想太多、怕失败、怕得罪人，你小时候不这么干的时候不是也过得好好的嘛？到底你是碰到多少小人、官僚主义者，让自己变得这么势利？是有多垃圾要靠着讨好这个讨好那个才活得下去？请记住：自卑心理能把一个人变成垃圾。</p><p>不同情境、对象，怎么办?工作场所中，领导可以加一个称呼，比如“X总好”，目视微笑点头一套过即可；平级以下的一般打招呼、不卑不亢、不鄙视不敌视。一般领导、长辈级的都是加一个称呼即可，加不加“好”都行，有称呼已经有区别了。一般情况下都没有辈分级别之分，基本“目视、微笑、点头”即可。如果是很好的朋友，那就随便聊；如果是“熟人”却不是“好朋友”类别的，那就随缘，你想说就说，不想说就不说，别强迫自己非要跟别人多好，而若是对方是健谈的，你又没话说，那你可以听听，表达礼貌，无需硬聊，如果有事走开就告知一声，别强迫自己。如果发现对方或是一群人在一起，而没有看见自己的情况，做法是，如果遇见了，可以试着打招呼，如果没有看见，也不要有压力，你没有义务去“认出”每个经过的人，冲上去硬打招呼也可能会打扰人家，自己也显得傻乎乎。不管情况怎么样，都只要做好基本就够了，端正好心态、不卑不亢，自然你就不会尴尬了。</p><p>常见的打招呼方式。当然，打招呼的方式不是只有这么死板的一种，视情况而定。比如年轻人之间说一句“嗨”、“嘿”，顽皮的朋友可能还会突然大声喊你或者拍你肩膀，吓你一跳，这些方式可以帮助不熟的人之间找到聊天的话题，变得更熟悉，等等。如果你没有什么想法，做好基本的就够了，更多的方法需要你在日常生活中发挥聪明才智，慢慢发现。</p><p>自信为王。不就惧怕失败，就事论事，承认自己的不足，有自己的主见，不否认别人，包容别人。工作是因为热爱，恋爱是因为喜欢。</p><p>斯金纳的鸽子,很多人认为，只要在学习的过程中承受痛苦，人就能取得进步，然而,这根本就是彻头彻尾的迷信，这是在痛苦和进步之间强行建立的因果关系,其实这种因果根本不存在。”Focus专注、Feedback反馈、以及Fix it修正,只要有大量科学的训练，就能够诞生高手，各行各业都是如此<br><img src="/pic/ganwu19-1.jpg"></p><h2 id="价值关系"><a href="#价值关系" class="headerlink" title="价值关系"></a>价值关系</h2><p>这个世界不只有功利的人际关系，也有非功利的人际关系。<br>人不是物品，并不是凡事都唯价值论。人和人之间，还有自己作为人的属性，有情，有义，有柔软的内心。这个世界不只有功利的人际关系，也有非功利的人际关系。，90%的人都是闷骚的，都不会主动联系的，等着别人联系自己，这就是为什么他们是普通人。一群闷骚的人在一起，永远都不会产生什么化学反应。真正会处人际关系的人，都会主动联系，这些人只占到10%，但他们是人际关系的成功者。没有谁是天生的吸引者，所有的人际关系，都是靠自己主动破冰。我知道了永远不要等着别人主动来联系我，应该主动联系。</p><h2 id="正反馈，而不是负反馈"><a href="#正反馈，而不是负反馈" class="headerlink" title="正反馈，而不是负反馈"></a>正反馈，而不是负反馈</h2><p>学习重要的是正向的反馈，包括生活也是。在学习过程中，一点点的进步，把进步当作正向的反馈，而不是说我只进步了这样一点点，将反馈变成负反馈。在自己的思想中，就要将一些东西看为正反馈。</p><h2 id="我的构成"><a href="#我的构成" class="headerlink" title="我的构成"></a>我的构成</h2><p>理性，感性，兽性。本能脑，情绪脑，智慧脑。这些都是我，包容，改变，进步，突破。</p><h2 id="精确性"><a href="#精确性" class="headerlink" title="精确性"></a>精确性</h2><p>任务：任务的精确性估计是一个必然需要锻炼的能力，一开始是没有的，慢慢在做的过程中来把握的。一件事情需要不断细化，但不能太过于细化了</p><h2 id="手机控制我？？？"><a href="#手机控制我？？？" class="headerlink" title="手机控制我？？？"></a>手机控制我？？？</h2><p>手机是工具，人怎么能被工具所控制，是自己被工具控制还是自己被其他人所裹挟？</p><p>技术只是一种工具，一种方法，实现我的想法的一种技术，而不能让这个来不断裹挟着自己，控制着自己。</p><h2 id="运动"><a href="#运动" class="headerlink" title="运动"></a>运动</h2><p>持续不断的久坐，需要坚持不懈的锻炼来与之抗衡。</p><h2 id="增强意识"><a href="#增强意识" class="headerlink" title="增强意识"></a>增强意识</h2><p>相比较于“难于上青天”的阶级跃迁，“增强自我意志”显然是一个更好的解决问题方式。去增加个人的体验。</p>]]></content>
    
    
    
    <tags>
      
      <tag>感悟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深度学习环境配置-pytroch</title>
    <link href="/2024/05/20/deeplearnbook0/"/>
    <url>/2024/05/20/deeplearnbook0/</url>
    
    <content type="html"><![CDATA[<h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><p>查看显卡能支持最高的CUDA版本：<code>nvidia-smi</code><br>查看安装的CUDA <code>nvcc -V</code></p><ol><li>安装NVIDIA驱动,<a href="https://www.nvidia.cn/content/DriverDownloads/confirmation.php?url=/Windows/552.44/552.44-desktop-win10-win11-64bit-international-dch-whql.exe&lang=cn&type=GeForce">3080</a></li><li>安装CUDA Toolkit <a href="https://developer.nvidia.com/cuda-toolkit-archive"></a></li></ol><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">absl</span>-py==<span class="hljs-number">2</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">addict</span>==<span class="hljs-number">2</span>.<span class="hljs-number">4</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">asttokens</span>==<span class="hljs-number">2</span>.<span class="hljs-number">4</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">backcall</span>==<span class="hljs-number">0</span>.<span class="hljs-number">2</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">cachetools</span>==<span class="hljs-number">5</span>.<span class="hljs-number">3</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">certifi</span>==<span class="hljs-number">2023</span>.<span class="hljs-number">7</span>.<span class="hljs-number">22</span><br><span class="hljs-attribute">chardet</span>==<span class="hljs-number">5</span>.<span class="hljs-number">2</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">charset</span>-normalizer==<span class="hljs-number">3</span>.<span class="hljs-number">3</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">click</span>==<span class="hljs-number">8</span>.<span class="hljs-number">1</span>.<span class="hljs-number">7</span><br><span class="hljs-attribute">colorama</span>==<span class="hljs-number">0</span>.<span class="hljs-number">4</span>.<span class="hljs-number">6</span><br><span class="hljs-attribute">comm</span>==<span class="hljs-number">0</span>.<span class="hljs-number">2</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">contourpy</span>==<span class="hljs-number">1</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">cycler</span>==<span class="hljs-number">0</span>.<span class="hljs-number">12</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">debugpy</span>==<span class="hljs-number">1</span>.<span class="hljs-number">8</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">decorator</span>==<span class="hljs-number">5</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">defusedxml</span>==<span class="hljs-number">0</span>.<span class="hljs-number">7</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">executing</span>==<span class="hljs-number">2</span>.<span class="hljs-number">0</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">filelock</span>==<span class="hljs-number">3</span>.<span class="hljs-number">13</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">fonttools</span>==<span class="hljs-number">4</span>.<span class="hljs-number">45</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">fsspec</span>==<span class="hljs-number">2023</span>.<span class="hljs-number">10</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">google</span>-auth==<span class="hljs-number">2</span>.<span class="hljs-number">23</span>.<span class="hljs-number">4</span><br><span class="hljs-attribute">google</span>-auth-oauthlib==<span class="hljs-number">1</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">graphviz</span>==<span class="hljs-number">0</span>.<span class="hljs-number">20</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">grpcio</span>==<span class="hljs-number">1</span>.<span class="hljs-number">59</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">huggingface</span>-hub==<span class="hljs-number">0</span>.<span class="hljs-number">19</span>.<span class="hljs-number">4</span><br><span class="hljs-attribute">idna</span>==<span class="hljs-number">3</span>.<span class="hljs-number">4</span><br><span class="hljs-attribute">imageio</span>==<span class="hljs-number">2</span>.<span class="hljs-number">33</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">importlib</span>-metadata==<span class="hljs-number">6</span>.<span class="hljs-number">8</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">importlib</span>-resources==<span class="hljs-number">6</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">ipykernel</span>==<span class="hljs-number">6</span>.<span class="hljs-number">26</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">ipython</span>==<span class="hljs-number">8</span>.<span class="hljs-number">12</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">jedi</span>==<span class="hljs-number">0</span>.<span class="hljs-number">19</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">Jinja2</span>==<span class="hljs-number">3</span>.<span class="hljs-number">1</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">joblib</span>==<span class="hljs-number">1</span>.<span class="hljs-number">3</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">jupyter_client</span>==<span class="hljs-number">8</span>.<span class="hljs-number">6</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">jupyter_core</span>==<span class="hljs-number">5</span>.<span class="hljs-number">5</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">kiwisolver</span>==<span class="hljs-number">1</span>.<span class="hljs-number">4</span>.<span class="hljs-number">5</span><br><span class="hljs-attribute">lazy_loader</span>==<span class="hljs-number">0</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">lxml</span>==<span class="hljs-number">4</span>.<span class="hljs-number">9</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">Markdown</span>==<span class="hljs-number">3</span>.<span class="hljs-number">5</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">MarkupSafe</span>==<span class="hljs-number">2</span>.<span class="hljs-number">1</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">matplotlib</span>==<span class="hljs-number">3</span>.<span class="hljs-number">7</span>.<span class="hljs-number">4</span><br><span class="hljs-attribute">matplotlib</span>-inline==<span class="hljs-number">0</span>.<span class="hljs-number">1</span>.<span class="hljs-number">6</span><br><span class="hljs-attribute">mne</span>==<span class="hljs-number">1</span>.<span class="hljs-number">6</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">nest</span>-asyncio==<span class="hljs-number">1</span>.<span class="hljs-number">5</span>.<span class="hljs-number">8</span><br><span class="hljs-attribute">netron</span>==<span class="hljs-number">7</span>.<span class="hljs-number">2</span>.<span class="hljs-number">9</span><br><span class="hljs-attribute">networkx</span>==<span class="hljs-number">3</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">nltk</span>==<span class="hljs-number">3</span>.<span class="hljs-number">8</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">numpy</span>==<span class="hljs-number">1</span>.<span class="hljs-number">24</span>.<span class="hljs-number">4</span><br><span class="hljs-attribute">oauthlib</span>==<span class="hljs-number">3</span>.<span class="hljs-number">2</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">opencv</span>-python==<span class="hljs-number">4.2.0.32</span><br><span class="hljs-attribute">packaging</span>==<span class="hljs-number">23</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">pandas</span>==<span class="hljs-number">2</span>.<span class="hljs-number">0</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">parso</span>==<span class="hljs-number">0</span>.<span class="hljs-number">8</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">pickleshare</span>==<span class="hljs-number">0</span>.<span class="hljs-number">7</span>.<span class="hljs-number">5</span><br><span class="hljs-attribute">Pillow</span>==<span class="hljs-number">10</span>.<span class="hljs-number">1</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">platformdirs</span>==<span class="hljs-number">4</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">pooch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">8</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">prompt</span>-toolkit==<span class="hljs-number">3</span>.<span class="hljs-number">0</span>.<span class="hljs-number">41</span><br><span class="hljs-attribute">protobuf</span>==<span class="hljs-number">4</span>.<span class="hljs-number">25</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">psutil</span>==<span class="hljs-number">5</span>.<span class="hljs-number">9</span>.<span class="hljs-number">6</span><br><span class="hljs-attribute">pure</span>-eval==<span class="hljs-number">0</span>.<span class="hljs-number">2</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">pyasn1</span>==<span class="hljs-number">0</span>.<span class="hljs-number">5</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">pyasn1</span>-modules==<span class="hljs-number">0</span>.<span class="hljs-number">3</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">pycocotools</span>==<span class="hljs-number">2</span>.<span class="hljs-number">0</span>.<span class="hljs-number">7</span><br><span class="hljs-attribute">pyemd</span>==<span class="hljs-number">1</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">pygame</span>==<span class="hljs-number">2</span>.<span class="hljs-number">5</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">Pygments</span>==<span class="hljs-number">2</span>.<span class="hljs-number">16</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">pyparsing</span>==<span class="hljs-number">3</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">python</span>-dateutil==<span class="hljs-number">2</span>.<span class="hljs-number">8</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">pytz</span>==<span class="hljs-number">2024</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">PyWavelets</span>==<span class="hljs-number">1</span>.<span class="hljs-number">4</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">pywin32</span>==<span class="hljs-number">306</span><br><span class="hljs-attribute">PyYAML</span>==<span class="hljs-number">6</span>.<span class="hljs-number">0</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">pyzmq</span>==<span class="hljs-number">25</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">regex</span>==<span class="hljs-number">2023</span>.<span class="hljs-number">10</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">requests</span>==<span class="hljs-number">2</span>.<span class="hljs-number">31</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">requests</span>-oauthlib==<span class="hljs-number">1</span>.<span class="hljs-number">3</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">rsa</span>==<span class="hljs-number">4</span>.<span class="hljs-number">9</span><br><span class="hljs-attribute">safetensors</span>==<span class="hljs-number">0</span>.<span class="hljs-number">4</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">scikit</span>-image==<span class="hljs-number">0</span>.<span class="hljs-number">21</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">scikit</span>-learn==<span class="hljs-number">1</span>.<span class="hljs-number">3</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">scipy</span>==<span class="hljs-number">1</span>.<span class="hljs-number">10</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">seaborn</span>==<span class="hljs-number">0</span>.<span class="hljs-number">13</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">six</span>==<span class="hljs-number">1</span>.<span class="hljs-number">16</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">stack</span>-data==<span class="hljs-number">0</span>.<span class="hljs-number">6</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">summary</span>==<span class="hljs-number">0</span>.<span class="hljs-number">2</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">tensorboard</span>==<span class="hljs-number">2</span>.<span class="hljs-number">14</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">tensorboard</span>-data-server==<span class="hljs-number">0</span>.<span class="hljs-number">7</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">thop</span>==<span class="hljs-number">0</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span>.post2209072238<br><span class="hljs-attribute">threadpoolctl</span>==<span class="hljs-number">3</span>.<span class="hljs-number">2</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">tifffile</span>==<span class="hljs-number">2023</span>.<span class="hljs-number">7</span>.<span class="hljs-number">10</span><br><span class="hljs-attribute">timm</span>==<span class="hljs-number">0</span>.<span class="hljs-number">6</span>.<span class="hljs-number">13</span><br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">12</span>.<span class="hljs-number">1</span>+cu116<br><span class="hljs-attribute">torch</span>-tb-profiler==<span class="hljs-number">0</span>.<span class="hljs-number">4</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">torchaudio</span>==<span class="hljs-number">0</span>.<span class="hljs-number">12</span>.<span class="hljs-number">1</span>+cu116<br><span class="hljs-attribute">torchsummary</span>==<span class="hljs-number">1</span>.<span class="hljs-number">5</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">torchvision</span>==<span class="hljs-number">0</span>.<span class="hljs-number">13</span>.<span class="hljs-number">1</span>+cu116<br><span class="hljs-attribute">torchviz</span>==<span class="hljs-number">0</span>.<span class="hljs-number">0</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">tornado</span>==<span class="hljs-number">6</span>.<span class="hljs-number">3</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">tqdm</span>==<span class="hljs-number">4</span>.<span class="hljs-number">66</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">traitlets</span>==<span class="hljs-number">5</span>.<span class="hljs-number">13</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">typing_extensions</span>==<span class="hljs-number">4</span>.<span class="hljs-number">8</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">tzdata</span>==<span class="hljs-number">2024</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">urllib3</span>==<span class="hljs-number">2</span>.<span class="hljs-number">1</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">wcwidth</span>==<span class="hljs-number">0</span>.<span class="hljs-number">2</span>.<span class="hljs-number">10</span><br><span class="hljs-attribute">Werkzeug</span>==<span class="hljs-number">3</span>.<span class="hljs-number">0</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">zipp</span>==<span class="hljs-number">3</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span><br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>听力-2022年12月大学英语六级考试真题</title>
    <link href="/2024/05/20/English4-0/"/>
    <url>/2024/05/20/English4-0/</url>
    
    <content type="html"><![CDATA[<p><a href="https://www.bilibili.com/video/BV1b44y1G7Xc/?spm_id_from=333.999.0.0&vd_source=9814cf6702c46a0b906cb31de22baa58">2022六级听力-做题方法合集</a></p><p>听前： 预测 读音 意思</p><ol><li>长对话。</li><li>篇章</li><li>讲座</li></ol><p>思路：</p><h1 id="2022年12月大学英语六级考试真题（第一套）"><a href="#2022年12月大学英语六级考试真题（第一套）" class="headerlink" title="2022年12月大学英语六级考试真题（第一套）"></a>2022年12月大学英语六级考试真题（第一套）</h1><h2 id="第一段听力"><a href="#第一段听力" class="headerlink" title="第一段听力"></a>第一段听力</h2><p>1-4题： 对话<br>M: How’s your dissertation going? Fm proofreading my first draft and will submit it to my professor tomorrow.<br>M：你的论文写得怎么样了？我在校对我的初稿，明天就会提交给我的教授。</p><p>W: Oh, (1) I haven’t even started writing mine yet, so I’m really worried about finishing by the end of next semester.<br>W：哦，我还没开始写呢，所以我很担心能否在下学期结束前完成。</p><p>M: You mean you haven’t even begun yours yet? The final draft is due in five months.<br>M：你是说你还没开始写？最终稿在五个月后就要交了。</p><p>W: Of course Fve started it, but I can’t get to the writing yet as I haven’t found enough resources to use, so I’m still researching the topic.<br>W：当然开始了，但还没能动笔，因为还没找到足够的资料，所以还在研究主题。</p><p>M: Maybe the problem is the way you’re doing your research. (2) I started by talking to my professor about where to look for information. And based on that, I found books in the library and a lot of reputable journal articles on the Internet.<br>M：也许问题出在你做研究的方法上。我一开始就和教授讨论了该去哪里找信息。然后根据这些信息，我在图书馆找到了书籍，并在网上找到了很多可信的期刊文章。</p><p>W: I’ve tried all that, but don’t have enough to write the dissertation as my department’s minimum length is 70 pages. I think the problem is that my topic isn’t viable. (3) And honestly, my professor did warn me at the beginning that I might not be able to find enough material. But I was so interested in the topic that I didn’t let his advice to turn me.<br>W：我试过这些，但还是不够写论文，因为我们系的最低篇幅要求是70页。我觉得问题在于我的主题不太可行。而且，说实话，我的教授一开始就警告我，可能找不到足够的资料。但我对这个主题太感兴趣了，没有听从他的建议。</p><p>M: Well, I suggest you find a new topic. After all, our professors are here to guide us, so it’s best to listen to them.<br>M：我建议你换个主题。毕竟，教授在这里是为了指导我们，所以最好听从他们的建议。</p><p>W: In retrospect, I wish I had listened to him, but I didn’t. And now I don’t want to give up my topic as I’ve already invested so much time and energy.<br>W：回想起来，我希望当时听了他的建议，但我没有。现在我不想放弃这个主题，因为我已经投入了太多的时间和精力。</p><p>M: If you’re committed to your current topic, maybe you could make some adjustments rather than abandon it completely. What is your topic?<br>M：如果你坚持现有的主题，也许可以做一些调整，而不是完全放弃。你的主题是什么？</p><p>W: It’s “Depictions of Femininity and Folklore from the South of the Country”.<br>W：是“南部地区民俗中的女性形象描绘”。</p><p>M: That’s pretty narrow. You could find more material if you made the topic broader, maybe by including other kinds of depictions.<br>M：这个主题确实很狭窄。如果把主题扩展一点，比如包括其他类型的描绘，可能会找到更多的资料。</p><p>W: (4) Broadening the topic is a great idea. I’ll start by including folklore from other regions of the country.<br>W：扩展主题是个好主意。我会先从包括其他地区的民俗开始。</p><h2 id="听力第二段"><a href="#听力第二段" class="headerlink" title="听力第二段"></a>听力第二段</h2><p>5-8题：对话<br>W: Today, on Book Talk, we are lucky enough to host John Robbins and discuss his new book, Why Americans Are Fat and How We Can Lose Weight. (5-1) John isn’t just a respected writer；he’s also one of the rare celebrity authors writing about science today.<br>W：今天在《书籍访谈》节目中，我们很荣幸邀请到约翰·罗宾斯来讨论他的新书《为什么美国人肥胖以及我们如何减肥》。约翰不仅是一位受人尊敬的作家，他也是当今为数不多的撰写科学类作品的名人作者之一。</p><p>M: Thanks for having me, Rebecca, but I’m hardly a celebrity.<br>M：谢谢你的邀请，丽贝卡，但我可不算是名人。</p><p>W: That’s very modest of you to say, (5-2) considering that your four books have sold a total of seven million copies worldwide, and they’ve been translated into 12 different languages. What makes people so fascinated with your work?<br>W：你这么说真是太谦虚了，考虑到你的四本书在全球总共卖出了七百万册，并且被翻译成了12种不同的语言。是什么让人们对你的作品如此着迷？</p><p>M: (6) Well, people read my books because more than 60% of Americans are overweight or obese. And other countries are facing similar problems. Basically, we all want to know how to fix things.<br>M：嗯，人们读我的书是因为超过60%的美国人超重或肥胖。而其他国家也面临类似的问题。基本上，我们都想知道如何解决这些问题。</p><p>W: We certainly do. I’ve read your new book and it’s fabulous, especially when it comes to the way you make difficult science easy for laymen to understand. That’s no small achievement.<br>W：我们确实如此。我读了你的新书，真是太棒了，尤其是你让普通人能够理解复杂的科学。这可不是件容易的事。</p><p>M: I’m glad to hear you find my work accessible, because I was worried when I wrote it that discussing the science might make the book more suited for a specialist audience. (7) My last book was written primarily for the medical community. But this time, I want to help ordinary people take control of their weight.<br>M：很高兴听到你觉得我的作品通俗易懂，因为我写这本书时担心讨论科学内容会让它更适合专业观众。我上一本书主要是为医学界写的。但这次，我希望能帮助普通人控制他们的体重。</p><p>W: And how do you suggest they do that? Can you give us the basics of your advice for people who want to lose weight?<br>W：那你建议他们怎么做呢？你能给我们讲讲你的减肥建议的基本要点吗？</p><p>M: Briefly, (8) I argue that every person needs to sn sid er their metabolism and eat what suits their body’s needs. I don’t advocate one single diet. Some people should eat more carbohydrates than others. And different people need different amounts of protein and fat.<br>M：简单来说，我认为每个人都需要考虑他们的新陈代谢，并吃适合他们身体需求的食物。我不提倡单一的饮食。有些人应该比其他人吃更多的碳水化合物。而不同的人需要不同量的蛋白质和脂肪。</p><p>W: But you do have some recommendations for everyone, including eating ten servings of vegetables and three of fruit a day. We’ll talk about those recommendations next, but now we need to take a short break for a message from our sponsor.<br>W：但是你确实有一些对所有人的建议，包括每天吃十份蔬菜和三份水果。我们接下来会讨论这些建议，但现在我们需要休息一下，听一段赞助商的信息。</p><h2 id="听力第三段"><a href="#听力第三段" class="headerlink" title="听力第三段"></a>听力第三段</h2><p>9-11:短文</p><p>Stress is often depicted as negative, but research shows that moderate amounts of it can be beneficial for your brain and your body.<br>压力通常被认为是负面的，但研究表明，适量的压力对你的大脑和身体是有益的。</p><p>First, the benefits for the brain. Studies have shown that short periods of stress can actually bolster cognitive functioning. (9) Researchers discovered that placing rats in a stressful situation for just a few hours doubled the growth of new brain cells. The rats also did better on a memory test later on. Scientists think the same thing happens in humans. But how does stress improve memory? It’s simple. When your brain cells multiply, your memory can improve. Viewed from a biological perspective, this makes sense, (10) because animals that are better at remembering dangerous situations can avoid them in the future. If an animal encounters a predator and escapes, for example, it’s important to remember where and when that encounter happened. Experts assert that the same principle applies to humans.<br>首先是对大脑的好处。研究表明，短时间的压力实际上可以增强认知功能。研究人员发现，让老鼠在一个有压力的环境中呆上几个小时，新的脑细胞的生长量会翻倍。这些老鼠在后来的记忆测试中表现得更好。科学家们认为同样的事情也会发生在人类身上。但是压力是如何改善记忆的呢？这很简单。当你的脑细胞增多时，你的记忆力就能得到提升。从生物学的角度来看，这是有道理的，因为能更好记住危险情况的动物可以在未来避免这些情况。例如，如果一只动物遇到捕食者并成功逃脱，那么记住那次遭遇的时间和地点就非常重要。专家们断言，同样的原理也适用于人类。</p><p>Now, let’s turn to how stress benefits the body. This may come as a surprise to laymen. But experts say that stress can keep you from getting sick. (11) Scientists concede that chronic stress can make you more prone to illness. But research shows that short periods of stress can actually provide some protection against getting sick, because it increases your immune functioning. One study shows that rats that experienced brief stress had a surge of immune cell response, which makes the immune system better prepared to fight illness. For humans, there’s even evidence that experiencing stress before getting vaccinated could help make vaccines more effective.<br>现在，让我们看看压力是如何对身体有益的。这可能会让普通人感到惊讶。但专家们表示，压力可以防止你生病。科学家们承认，长期的压力会使你更容易生病。但研究表明，短时间的压力实际上可以提供一些防病的保护，因为它可以增强你的免疫功能。一项研究显示，经历短暂压力的老鼠，其免疫细胞反应会激增，使免疫系统更好地准备好对抗疾病。对于人类来说，还有证据表明，在接种疫苗前经历压力可以帮助提高疫苗的有效性。</p><h2 id="听力第四段"><a href="#听力第四段" class="headerlink" title="听力第四段"></a>听力第四段</h2><p>12-15：短文<br>For many managers and people who work in leadership positions, dealing with emails is a dilemma. It’s likely the unpredictable, uncontrollable and ongoing nature of day-to-day email in terms of volume, importance and urgency contributes to their levels of anxiety and to diminished leadership skills. That’s because it’s not unusual for many leaders to prioritize email management over people management. An obsession with managing their inbox prevents them from dealing with their employees.</p><p>对于许多管理者和领导岗位上的人来说，处理电子邮件是一种困境。日常电子邮件在数量、重要性和紧迫性方面的不可预测性、不可控性和持续性可能导致他们的焦虑水平上升，并削弱他们的领导技能。这是因为许多领导者往往优先处理电子邮件，而不是管理人员。他们对管理收件箱的痴迷阻碍了他们与员工的互动。</p><p>(13) As a result, they ignore the issues that might only be mild problems at first, until unfortunately, they inevitably transform into a major problem or crisis by virtue of neglect. (14) As leaders, they are expected to motivate and inspire their team in pursuit of longer term strategic goals and also, less ambitiously but more practically, to monitor their daily output, to set clear expectations, and to give regular feedback. When presented with a choice between the appeal of their inbox and other more important activities, many sacrifice the latter. Daily email demands have a negative impact on their goal progress. This is because leaders must divert resources from other tasks to check, filter and respond to emails.</p><p>因此，他们忽视了最初可能只是轻微问题的事项，直到这些问题因为被忽视而不可避免地演变成重大问题或危机。作为领导者，他们被期望能够激励和激发团队，以追求长期的战略目标，同时也需要实际地监控团队的日常工作，设定明确的期望，并给予定期的反馈。然而，在面对收件箱的吸引力和其他更重要的活动时，许多人选择牺牲后者。日常的电子邮件需求对他们的目标进展产生了负面影响。这是因为领导者必须将资源从其他任务上转移出来，以检查、过滤和回复电子邮件。</p><p>(15) The solution is cultivating self-control which is like a muscle- - it can be strengthened or improved over time through exercise. Some suggestions include making space in your diary for the only periods during which you’ll be checking emails, setting a timer for yourself so you don’t become distracted by your inbox for too long, turning off email alerts so you’re not interrupted by them.</p><p>解决方案是培养自我控制力，这就像一块肌肉——通过锻炼可以得到加强或改善。一些建议包括在日程表中留出专门检查电子邮件的时间段，为自己设定一个计时器，以免因处理收件箱而分散注意力太久，关闭电子邮件提醒，以免被其打断。</p><p>听力看都看不懂，更别说听懂了。（2024&#x2F;6&#x2F;3）</p><h2 id="听力第五段"><a href="#听力第五段" class="headerlink" title="听力第五段"></a>听力第五段</h2><p>16-18</p><p>Appear to be submissive, humble, grateful and undemanding; show great pleasure when a doctor comes into your room, even if the visit is brief and useless. Don’t challenge anyone with authority unless you are famous or very rich.</p><p>显得顺从、谦卑、感激且不过分要求；即使医生的拜访短暂而无用，也要表现出极大的喜悦。当医生进入你的房间时，不要挑战任何权威，除非你非常有名或非常富有。</p><p>Those are a few strategies for dealing with today’s American medical establishment. (16)What patients want is to be treated with respect and consideration. But in my experience, too few hospitals and doctors are ready to do that. In his book, A Whole New Life, novelist Reynolds Price recalls that his doctors chose a crowded hallway as the place to tell him he might have a tumor on his spinal cord. It did not occur to the two physicians that a hallway was not the most appropriate place for that particular piece of news.</p><p>这些是应对当今美国医疗体制的一些策略。患者希望得到尊重和体贴的对待。但在我的经验中，很少有医院和医生准备这样做。在他的书《全新生活》中，小说家雷诺兹·普莱斯回忆起，他的医生选择在一个拥挤的走廊里告诉他，他的脊髓上可能有肿瘤。这两位医生没有想到，走廊不是传达这一消息的最合适地点。</p><p>My surgeon, who is in his mid-thirties, looks tired. He has been overwhelmed with patients who have fallen on the winter ice. He is a witty man, but sometimes his wit is unwelcome.</p><p>我的外科医生大约三十多岁，看起来很疲惫。他被在冬天冰面上摔倒的患者压得喘不过气来。他是个机智的人，但有时他的机智并不受欢迎。</p><p>“The health insurance company Blue Cross wants me to put you out in the snow tomorrow afternoon,n he tells me after I have been in the hospital for more than a week. I’m terrified because I have no idea where to go. I cannot walk or even lift my leg a few inches. The hospital social worker strikes me as an idiot. But my complaints about her only annoy my surgeon. “I have to work with these people,” he tells my friend, Dr. Karen Brudlney, when she mercifully intervenes on my behalf and arranges for me to be transferred to another hospital.</p><p>“健康保险公司Blue Cross希望我明天下午把你赶出去，”在我住院超过一周后，他这样告诉我。我感到害怕，因为我不知道该去哪里。我不能走路，甚至不能抬起几英寸的腿。医院的社会工作者让我觉得她是个白痴。但我对她的抱怨只会惹恼我的外科医生。当我的朋友Karen Brudney医生仁慈地为我说情并安排我转到另一家医院时，他告诉她：“我不得不与这些人一起工作。”</p><p>“If you say one negative thing, they get defensive,”she tells me later. “They have this kind of institutional loyalty. (17)Always bring an advocate, that is, any other person with you to the hospital, and write down every single question and the answer, the name of every doctor and nurse. When people know you have their names, they behave better. And,” Brudney adds, “if you, as a patient, suggest that you might like to control even part of the situation or be consulted or informed, then you are considered difficult. (18)They want you to be totally passive, The entire health care system, particularly hospitals and nursing homes, exists for reasons that have nothing to do with taking care of patients. Patients are incidental.”</p><p>“如果你说一句负面的话，他们会变得很防御，”她后来告诉我。“他们有这种机构忠诚感。永远带一个支持者，也就是任何其他人，和你一起去医院，记录下每一个问题和答案，每一个医生和护士的名字。当人们知道你有他们的名字时，他们会表现得更好。而且，”Brudney补充说，“如果你作为患者建议你可能希望控制甚至部分情况，或者被咨询或告知，那么你会被认为很难缠。他们希望你完全被动，整个医疗系统，特别是医院和疗养院的存在，原因与照顾病人无关。病人只是附带的。”</p><h2 id="听力第六段"><a href="#听力第六段" class="headerlink" title="听力第六段"></a>听力第六段</h2><p>19-21</p><p>There are probably teams you’re worked with but you never want to work with again. But there must have also been other teams that you would prize reuniting with professionally. In other words, your team had vitality. (19)Vitality comes about when the ties people form with their fellow team members are such that they stay connected even after the team breaks up.</p><p>你可能有一些团队合作的经历，不希望再次合作，但也一定有一些团队，你会珍视与之再次合作的机会。换句话说，你的团队充满活力。团队活力的产生在于成员之间建立的联系，即使团队解散后，这些联系依然保持。</p><p>What characteristics of a team make its members more likely to stay in contact despite no longer working together? This question has been answered recently in a study published in a business journal.</p><p>什么样的团队特征使成员在不再一起工作后仍然保持联系？这个问题在最近发表在商业期刊的一项研究中得到了回答。</p><p>One of the two key factors the research team discovered is sameness. Specifically, sharing the same gender or ethnic origin. (20)The more members of a team share similar demographics, the more inclined they will be to remain associates long after the team has served its purpose. After ties are established, similarity strengthens them. As a result, they regard these individuals with greater trust and mutual understanding, which motivates them to seek further opportunities for collaboration. In effect, people tend to create stronger and longer-lasting connections with similar others, Someone who looks and sounds different from us may have the resources we need to be more successful. Yet, we find then to be significantly less credible simply because they are different. If you are a fierce advocate of workplace diversity, youll no doubt be horrified by such a revelation.</p><p>研究团队发现的两个关键因素之一是相似性。具体来说，是指成员在性别或种族上的相似性。团队成员共享相似的人口统计特征时，他们更倾向于在团队任务完成后继续保持联系。相似性在关系建立后进一步加强这些关系。结果是，成员之间会有更大的信任和相互理解，推动他们寻找进一步合作的机会。人们往往与相似的人建立更强、更持久的联系。尽管与我们看起来和听起来不同的人可能拥有我们成功所需的资源，但我们仅仅因为他们的不同而觉得他们不可信。如果你是职场多样性的强烈倡导者，那么这样的发现无疑会令你震惊。</p><p>The second factor identified by the researchers is the quality of the relationships among the team members. The more they trust one another, share the same goals and depend on each other for the achievement of those goals, the stronger their chances of maintaining their connections, despite no longer working as one team. Teams with quality relationships have a shared belief that ifs safe to take risks with each ether, and their members are obliged to share the workload and help out.</p><p>研究人员发现的第二个因素是团队成员之间关系的质量。成员之间的信任、共同的目标以及彼此依赖实现这些目标的程度越高，即使不再作为一个团队工作，他们保持联系的可能性也越大。高质量关系的团队成员相信彼此之间冒险是安全的，并且有义务分担工作量和帮助他人。</p><p>From personal experience, I can see both the truth and the inconsistency of such studies. The truth is some of my closest friendships were formed as a result of having worked together on teams, and I actively seek opportunities to work with them again. (21)The inconsistency, though, is that Pve never worked for a team more successful and cohesive than the one of which I am a member right now. And yet, the four of us have very little in common and are completely different demographically. So I am unlikely to question the value of a diverse workforce.</p><p>从个人经验来看，我能看到这些研究的真相和不一致性。真相是，我一些最亲密的友谊是通过团队合作形成的，我也积极寻找再次与他们合作的机会。然而，不一致的是，我从未在一个比我现在的团队更成功和凝聚力更强的团队中工作过。尽管我们四个人几乎没有共同点，且在人口统计上完全不同。因此，我不可能质疑多样化团队的价值。</p><h2 id="听力第七段"><a href="#听力第七段" class="headerlink" title="听力第七段"></a>听力第七段</h2><p>22-25</p><p>An American researcher who studied 600 millionaires found how rich you can get comes down to six wealth factors. She found that six behaviors are related to net worth potential, regardless of age or income. These were thriftiness, confidence, responsibility, planning, focus and social indifference.</p><p>一位研究了600名百万富翁的美国研究人员发现，财富的积累可以归结为六个关键因素。她发现，无论年龄或收入如何，有六种行为与净资产潜力相关：节俭、自信、责任感、计划、专注和社会冷漠。</p><p>Being thrifty comes as no great surprise. Spending above your means, spending instead of saving for retirement, spending in anticipation of becoming wealthy, makes you a slave to the paycheck. (22)”Even with an astronomical level of income,” she wrote, “to properly build wealth, experts recommend saving 20% of your income and living off the remaining 80%.”</p><p>节俭是一个显而易见的因素。超出自己经济能力的消费、用消费代替储蓄退休金、期待未来变富而花钱，这些行为都会让你成为薪水的奴隶。她写道：“即使收入水平极高，为了正确积累财富，专家建议储蓄收入的20%，并用剩下的80%生活。”</p><p>Having confidence is another key characteristic, as it helps people to be thrifty. (23)It takes confidence to live within your means. It also takes confidence to invest properly. Instead of making investing decisions with your emotions, financial planners advise that you should leave your investments alone and focus on a long term investment plan. But people can’t invest or manage their own money without accepting responsibility for the outcomes. Many millionaires take on personal responsibility, and most also happen to be self-made, meaning they didn’t acquire their wealth through luck. (24)Millionaires don’t count on anyone else to make them rich, and they dorft blame anyone else if they fall short. They focus on things they can control and align their daily habits to the goals they have set for themselves. They tend to be goal-oriented and hard workers, which enables them to plan financially and focus on seeing those plans through. 92% of the milionaires surveyed developed a longtenn plan for their money and 97% almost always achieved the goals they set for themselves.</p><p>自信是另一个关键特征，因为它有助于人们保持节俭。生活在自己经济能力范围内需要自信，正确投资也需要自信。财务规划师建议，不要用情绪来做投资决策，而是要坚持长期的投资计划。但是，人们不能在没有承担结果责任的情况下投资或管理自己的钱。许多百万富翁承担个人责任，而且大多数是自力更生，这意味着他们的财富不是靠运气获得的。百万富翁不依赖其他人使他们变富，如果未能达到目标，他们也不责怪别人。他们专注于自己能控制的事情，并将日常习惯与自己设定的目标对齐。他们通常是目标导向和勤奋的，这使他们能够制定财务计划并专注于实现这些计划。调查的百万富翁中，92%制定了长期的财务计划，97%几乎总是实现了自己设定的目标。</p><p>And it is these behaviors that make it easy for them to be socially indifferent. They resist lifestyle creep, the tendency to spend more whenever one earns more. (25)Essentially, they don’t yield to pressure to buy the latest thing or to keep up with others or what they have acquired. Instead of being focused on what might make them happy today, they’re focused on their long-term wealth-building plan.</p><p>这些行为使他们能够轻松地在社会上保持冷漠。他们抵制生活方式攀升的趋势，即收入增加时花费更多。他们不会屈服于购买最新产品或与他人攀比的压力，而是专注于他们的长期财富积累计划。</p><h1 id="2022年12月大学英语六级考试真题（第二套）"><a href="#2022年12月大学英语六级考试真题（第二套）" class="headerlink" title="2022年12月大学英语六级考试真题（第二套）"></a>2022年12月大学英语六级考试真题（第二套）</h1>]]></content>
    
    
    
    <tags>
      
      <tag>英语</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>英语-听力(2023年英语6级听力原文及翻译)</title>
    <link href="/2024/05/19/English3/"/>
    <url>/2024/05/19/English3/</url>
    
    <content type="html"><![CDATA[<p><a href="https://cet.itongzhuo.com/fourSix/exam/jumpFourSixExam.do?meType=11">在线练习网站</a></p><h2 id="第一段听力"><a href="#第一段听力" class="headerlink" title="第一段听力"></a>第一段听力</h2><p>对话：1-4题</p><p>M:Thanks for inviting me out tonight. I’ve been wantic. to try this place for weeks. I usually pass it on my way home from work but never seem to have time to stop.<br>男：今晚邀请我出去真是太感谢了。我几个星期前就想来这个地方尝试一下了。我通常下班回家的路上经过这里，但似乎从来没时间停下来。</p><p>W: I’ve been dying to come here as well. I was worried that the menu might not be accommodating.But one of my close friends ate here last week. She’s a vegetarian. She told me that there were a lot of options for her,and they offered alternative dishes.<br>女：我也一直想来这里。我担心菜单可能不太适合我，但我的一个好朋友上周在这里吃过。她是素食主义者。她告诉我这里有很多适合她的选择，而且他们还提供了替代菜肴。</p><p>M: But you’re not vegetarian, are you?W:Well,not entirely.I don’t eat meat at all,But I don’t have a problem eating fish,seafood,or eggs.<br>男：但你不是素食主义者，对吧？</p><p>M isnt that very dificult? imagine giving up a premiumjuicy steak or bacon cheeseburgers. </p><p>W:I wouldn’t know.My parents followed the same diet. Even when I was younger. We never had meat during meals. And I never really had a craving to try it.I bet it would be hard though.Giving up something you’re accustomed to eacogitied cutting back on coffee in the morning and it was awful.Come to think of it.It was probably even worse for my colleagues that had to deal with me at morning meetings.<br>女：嗯，不完全是。我完全不吃肉，但我吃鱼、海鲜或者蛋没问题。我想象不出要放弃一个优质多汁的牛排或培根芝士汉堡有多困难。我不知道。我的父母也是这样饮食的。即使在我年轻的时候，我们吃饭时也从未吃过肉。我从未真正渴望尝试过。我打赌这应该很难。放弃你习惯的东西，比如减少早上的咖啡摄入量，那是很糟糕的。回想起来，对于那些不得不忍受我在早晨会议上的同事们来说，可能更糟糕。</p><p>M: That’s even harder to imago.out without coffee.So you say your parents also bought a partially vegetarian diet. Why did they decide to do that?<br>男：没有咖啡确实很难想象。所以你说你的父母也是部分素食主义者。他们为什么决定这样做呢？</p><p>W: That’s an interesting question. I never thought to ask them though. My best guess is for health reasons. They’re not terribly active or knowledgeable about animal preservation efforts,but they’re serious about their health.Both are in their 70s now eat organic as often as posibte and take part in regular physical exer sep betther of them has any healtn probtems, and they hardly ever get sick.<br>女：这是个有趣的问题。我从未想过问他们。我最好的猜测是出于健康原因。他们对动物保护工作并不是很积极或了解，但他们对健康非常认真。他们现在都七十多岁了，尽可能经常食用有机食品并参加定期的体育锻炼。他们俩都没有健康问题，几乎从不生病。</p><p>M: In that case, I might give it a try someday.<br>男：那我也许会有一天试试看。</p><p>W: Now back to the menu. What are you going to have?<br>女：现在回到菜单上。你打算吃什么？</p><h2 id="第二段听力"><a href="#第二段听力" class="headerlink" title="第二段听力"></a>第二段听力</h2><p>对话：5-8题<br>W: How did your annual performance evaluation meeting with your manager go? Did you get much in the way of praise?<br>女：你和经理的年度绩效评估会谈进行得怎么样？他有没有对你表示赞扬？</p><p>M: Next to zero.When we came to the part about discussing my areas for growth,he bluntly told me that thad an attitude problem(Question 5).But he woutdn’t’really expand on that description.He said it’s the little things I do and say(Question.5).<br>男：几乎没有。当我们讨论我需要改进的方面时，他直言告诉我说我有态度问题。但他没有详细解释。他说是我做和说的一些小事情。</p><p>W:Did you ask him for a specific example?<br>女：你有没有问他要一个具体的例子？</p><p>M: I did ask him a few more questions to try to narrow it down. He said my constant questioning of him and his decisions was the most obvious example he could give.Then our conversation was swiftly brought to a close.<br>男：我确实问了他几个问题，试图缩小范围。他说我经常质疑他和他的决定是最明显的例子。然后我们的对话很快就结束了。</p><p>W:I had a similar experience once,my manager told me I was too honest. In most cases, I thought my honesty was helpful, as did my colleagues, but my manager thought otherwise. Some managers really adopt manipulative language to disguise the unreasonable choices they have made,They don’t use the rational power of arguments to resolve issues of conflict or complaints about unfairness(Question 6).<br>女：我曾经有过类似的经历，我的经理告诉我我太诚实了。在大多数情况下，我认为我的诚实是有帮助的，我的同事也是这么认为的，但我的经理却持相反意见。有些经理确实采用操纵性语言来掩饰他们所做的不合理选择，他们不使用理性的论证力量来解决冲突或投诉不公平的问题。</p><p>M:Right.Some employ their persuasive l and influential communication style to win workplace arguments by compelling people to perform the intended action.<br>男：是的。有些人利用自己有说服力和影响力的沟通方式来赢得工作场所的争论，迫使人们执行既定的行动。</p><p>W:Exactly.Too honest,isn’t that a good thing?I thought that’s surely something we should have covered earlier in the section discussing strengths and talents. But now, honesty was deemed to be more of a sin than a virtue,since it made people feel uncomfortable(Question 7)or at least it made the most powerful folks feel uncomfortable.<br>女：确实。太诚实了，这不是一件好事吗？我原以为这是我们在讨论优点和才能的部分应该提前讨论的内容。但现在，诚实被认为更像是一种罪过而不是美德，因为它让人感到不舒服，或者至少让最有权势的人感到不舒服。</p><p>M:lndeed,rhetoric is viewed by many philpsophers a’the method through which the powerful accumulate more power. By virtue of having the loudest voice,they’re able to command greater attention and to further assert their dominance. Even when what they’re saying doesn’t really mak much sense.<br>男：的确，许多哲学家将修辞视为强大积累更多权力的方法。凭借声音最响亮，他们能够获得更多关注并进一步巩固他们的统治地位。即使他们说的话并没有太多意义。</p><p>W: And retaining their power and orestige is their priority(Question 8)<br>女：保持他们的权力和威望是他们的首要任务。</p><p>M: It’s what makes the most sense to a lot of them Question<br>男：这对许多人来说是最合理的选择。</p><h2 id="第三段听力"><a href="#第三段听力" class="headerlink" title="第三段听力"></a>第三段听力</h2><p>短文：9-11</p><p>Athletes are seen as heroes (9) because they can do things that most of us can’t do. They can hit fast balls coming at them at nearly 100 miles an hour, and leap and hang in the air, seemingly defying gravity. They get paid millions of dollars for their efforts, and their names and faces appear on everything from running shoes to advertising boards. Athletes who are champions also show qualities such as perseverance, dedication, and the ability to keep their cool under pressure. Many show those same qualities off the playing field,too. Stories about superstar athletes teach us about working hard and believing in ourselves and in being passionate about what we do.<br>运动员被视为英雄，因为他们能够做大多数人无法做到的事情。他们能击中时速接近100英里的快速球，并且在空中腾跃，似乎违背了重力。他们因努力而获得数百万美元的报酬，他们的名字和面孔出现在从跑鞋到广告牌的各种物品上。成为冠军的运动员还表现出坚持不懈、奉献精神以及在压力下保持冷静的能力。许多人在场外也展现出这些品质。关于超级运动员的故事教会我们努力工作、相信自己并热爱我们所做的事情。</p><p>Although it’s usually bad behavior that gets an athlete a spot on the 6 o’clock news,(10)many high -profile players work hard to be positive role models to children They raise money for charities and act as mentor,talling to student groups and volunteering their time to programs that help children keep off drugs and stay in school. Still, even the greatest champions have flaws. Just because an athlete has the perfect golf swing doesn’t mean he is the perfect parent,jfriend,or spokesperson.They also make mistakes.(11)Separating an athlete’s professional and personal lives can be tough.When a sports star gets in trouble with the law or does something wrong in their private life, fans are often left disappointed. Before he died,baseball star,Mickey Mantle,who was plagued with alcohol problems,told young ball players and the fans who admired him “To play like me; don’t be like me”.<br>虽然通常是不良行为让运动员登上晚间新闻，但许多知名球员努力成为孩子们的正面榜样。他们为慈善机构筹集资金，作为导师与学生团体交流，并志愿参加帮助孩子远离毒品和继续上学的项目。然而，即使是最伟大的冠军也有缺陷。仅仅因为一名运动员有完美的高尔夫挥杆动作，并不意味着他是完美的父母、朋友或代言人。他们也会犯错。将运动员的职业生活和个人生活分开可能很难。当一名体育明星陷入法律纠纷或在私生活中做错事时，粉丝们常常感到失望。棒球明星米奇·曼托在去世前曾饱受酒精问题困扰，他对年轻的棒球选手和崇拜他的粉丝说：“要像我一样打球，但不要像我一样生活。”</p><h2 id="第四段听力"><a href="#第四段听力" class="headerlink" title="第四段听力"></a>第四段听力</h2><p>短文：12-15<br>Q12.We don’t need to tell you that weddings can get expensive.Even with the most meticulous budgeting, a few unexpected costs are bound to occur.While most brides tend to:ascept this as fact, one Canadian woman who is only known as Susan, attempted to avoid all wedding costs. She did this by asking her friends and family to pay up to attend her wedding.It went about as well as you’d expect.<br>我们无需告诉你，婚礼可能会变得很昂贵。即使进行了最细致的预算，也可能会发生一些意外费用。虽然大多数新娘倾向于接受这一事实，但一位只被称为苏珊的加拿大女士试图避免所有婚礼费用。她这样做是通过要求她的朋友和家人支付参加她婚礼的费用。结果可想而知。</p><p>Susan is causing quite the debate online after posting a bizarre Facebook complaint about her now canceled wedding. Yes, the couple called off the wedding just days before their wedding vows,Q13.since the guest refused to-pay the $1500 attendance fee,the $60000dream wedding was put on permanent hold. In her long explanation filled with cursing and swearing,the bride accused her friends and family of ruining her marriage and her life. She stated thatjeach guest would only need to pay S1500, while she sacrificed everything for the day. Q14. Her maid of honour told her to stick to the budget as she was asking too much from her guest,but Susan ignored her.Not surprisingly, only 8 people responded positively to the wedding invitations and money requests.<br>苏珊在发布了一条关于她现在已经取消的婚礼的奇怪Facebook投诉后，在网上引起了很大争议。是的，这对夫妇在举行婚礼誓言的几天前取消了婚礼，因为客人拒绝支付1500美元的参加费用，这场价值60000美元的梦幻婚礼被永久搁置了。在她充满诅咒和咒骂的长篇解释中，新娘指责她的朋友和家人毁了她的婚姻和她的生活。她说每位客人只需要支付1500美元，而她为这一天牺牲了一切。她的伴娘告诉她要坚持预算，因为她向客人要求的太多了，但苏珊没有听从她的建议。不足为奇的是，只有8个人对婚礼邀请和资金要求做出了积极回应。</p><p>Realizing they would not be able:te afford their dream wedding,Susan’s future husband suggested getting married in Las Vegas:Q15,jThe bride quickly shut down the idea,saying she did not want a wedding of gambling and heavy drinking. It seems her dream wedding has now become a nightmare.<br>意识到他们无法承担自己的梦想婚礼，苏珊的未来丈夫建议在拉斯维加斯结婚。新娘迅速拒绝了这个想法，称她不想要一个以赌博和酗酒为主题的婚礼。看来她的梦幻婚礼现在变成了一场噩梦。</p><h2 id="第5段听力"><a href="#第5段听力" class="headerlink" title="第5段听力"></a>第5段听力</h2><p>演讲： 16-18<br>It has long been scientifically established that weather changes can affect people’s moods. Q16 Now a new study has provided evidence that temperature can influence people’s personalities. This study of over 1.6 million people revealed that 22-degrees Celsius is the perfect air temperature to live in. A city with an average annual temperature closer to 22 tends to have a population who are more agreeable,conscientious,emotionatlyistable,and outgoing. It is the least taxing temperature for the body to regulate its own temperature. The study was observational and didn’t show cause and effect,Q17 but the scientists behind it theorized that better weather leads people to leave their home more often. This in turn leads to more social interaction,which encourages them to develop a friendlier and socially more acceptable personality.<br>新的研究已经长期确立了天气变化会影响人们的情绪。现在一项新研究提供了证据表明温度可以影响人们的个性。这项对160多万人进行的研究发现，22摄氏度是理想的生活气温。一个年平均气温接近22摄氏度的城市往往有更多性格友善、有责任心、情绪稳定和外向的人口。这是身体调节自身体温最不费力的温度。这项研究是观察性的，没有显示因果关系，但背后的科学家们推测，更好的天气会促使人们更频繁地离开家。这反过来会导致更多的社交互动，鼓励他们发展出更友好和社交上更可接受的个性。更温暖的气候也会让人们总体感觉更积极。他们往往更为友善和有责任心。这些发现可能有助于解释为什么寒冷和温暖的国家往往会产生具有不同个性的人。</p><p>Warmer climates also make people feel more positive in general. They tend to be more agreeable and conscientious. The findings might help explain why colder and warmer countries tend to produce people with different personalities. Roughbspeaking, about 40% of a person’s personality is determined bletheir genes, the other 60% by their environment. It was already well-known that personality traits vary across geographic regions. Scientists also knew that these geographic personality traits are associated with a broad range of consequential outcomes. These outcomes include economic activity,for”example entrepreneurial startup rates, and also crime rates, health behaviors, and health outcomes.<br>大致而言，一个人大约40%的个性是由他们的基因决定的，另外60%是由他们的环境决定的。已经众所周知，个性特征在地理区域之间有所不同。科学家们也知道，这些地理上的个性特征与一系列重要的结果相关。这些结果包括经济活动，例如创业创业率，以及犯罪率，健康行为和健康结果。并且已经确定，个性特征在不同国家之间是不同的。</p><p>And it is well established that personality traits differ between countriesThe research team speculated the two might be linked. To test this, they gave online personality tests to 5587 Chinese students and 1.66 million Americans. They then compared the results with the average annual temperature where they grew up. The tests measured personality along 5 well-studied characteristics. The 5 were agreeability, conscientiousness, emotional stability, outgoingness, and openness to new experiences. In both groups, the researchers found the closer a town’s average-annual temperature was to 22 degrees, the more its population exhibited those personality characteristics. However, the findings were much stronger for the Chinese group than the Americans studied,Q18which suggests that though temperature plays a role,it does not play a dominant role. The effects are fairly weak. It’s unlikely to lead to many arguments over the temperature setting of the office air conditioner.<br>研究团队推测这两者可能有关联。为了测试这一点，他们给5587名中国学生和160多万名美国人进行了在线个性测试。然后，他们将结果与他们成长的地方的年平均气温进行了比较。这些测试测量了个性的5个经过深入研究的特征。这5个特征是宜人性、责任心、情绪稳定性、外向性和对新经验的开放性。在两组人中，研究人员发现一个城镇的年平均气温越接近22摄氏度，其人口就越表现出这些个性特征。然而，对于中国人群来说，这一发现要比研究的美国人群更为明显，这表明尽管温度起一定作用，但并不起主导作用。效果相当弱。这不太可能会导致人们就办公室空调的温度设置发生许多争论。</p><h2 id="第六段听力"><a href="#第六段听力" class="headerlink" title="第六段听力"></a>第六段听力</h2><p>演讲： 19-21</p><p>Today we’re talking abooly Loneliness and social isolation are growing public health concerns for people of all ages in the United States, from adolescence to the elderly.Public health experts are worried because loneliness seems to be on the rise. And studies have long found correlations between loneliness and an assortment of medical conditions that threaten health and longevity.<br>孤独和社交孤立正成为美国各个年龄段人群的日益严重的公共健康问题，从青少年到老年人。公共卫生专家感到担忧，因为孤独现象似乎在加剧。长期以来，研究已经发现孤独与一系列威胁健康和寿命的医疗条件之间存在相关性。孤独问题可能甚至比我们想象的更为严重。</p><p>The problem of loneliness maybe even greater than we thought.A new national poll found that about a third of older Americans are to nely; and almost as many seniors feet isolated. This is a serious problem, as research shows that chronic lone particula That’s because it can impair olders adults’ memory and damage their physical and mental health. Chronic loneliness even impacts the life expectancy of seniors,inciosingitheir risk of early mortality.(Question 19)<br>一项新的全国民意调查发现，大约三分之一的美国老年人感到孤独，几乎有同样多的老年人感到孤立。这是一个严重的问题，因为研究显示，慢性孤独可能会损害老年人的记忆力，损害他们的身体和心理健康。慢性孤独甚至会影响老年人的预期寿命，增加他们早逝的风险。</p><p>Let’s take a closer look at that poll now. More than a third of seniors in the poll said they felt lonely at least some of the time,and 27% said they somet exor often felt isolated. This reflects how much time the sehiors spent with others.Almost 30% said they socialized with friends, family, or neighbors once a week or less. Women were more likely than men to report loneliness. But there is good news.It looks like loneliness can be reversed.(Question 20) But researchers are still trying to determine the best way to do so.Why is that? Resolving the problem of loneliness among seniors often isn’t as simple as getting them together with others or moving them in with their children. In fact, the poll found that seniors who lived with their children were more likely to report feeling lonely than those who didn’t. This may be because loneliness refers to the discrepancy between aw ual and desired relationships. So it’s possible that someone who lives alone doesn’t meet that definition, while someone in a house full of busy people does. How can we solve the problem? Well, the researchers assert that it’s important to address each person’s underlying cause of loneliness,(Question 21)whether it’s the death of a spouse, mediral problems, or social exptations that haven’t been fulfilled. It’s noteworthy that there is one general recommendation. While finding solutions for loneliness is highly personal, research suggests the best interventions are those that involve meaningful social contact at least once a week.(Question 21)Depending on the person, that could mean volunteering, ein old friend, or something else.<br>让我们现在更仔细地看看这项调查。调查中超过三分之一的老年人表示他们至少有时感到孤独，27%的人表示他们有时或经常感到孤立。这反映了老年人与他人相处的时间。几乎30%的人表示他们每周与朋友、家人或邻居社交一次或更少。女性比男性更有可能报告孤独感。但也有好消息，看起来孤独是可以逆转的。但研究人员仍在努力确定最佳解决方法。为什么呢？解决老年人孤独问题通常并不像让他们与他人在一起或搬到子女家中那样简单。事实上，调查发现与子女同住的老年人比没有与子女同住的老年人更有可能报告感到孤独。这可能是因为孤独是指实际关系与期望关系之间的差距。因此，一个独居的人可能不符合这一定义，而一个住满繁忙人群的房子的人可能符合。我们如何解决这个问题呢？研究人员强调，重要的是要解决每个人孤独的根本原因，无论是配偶去世、医疗问题还是未实现的社交期望。值得注意的是，有一个普遍的建议。虽然找到孤独问题的解决方案是非常个人化的，但研究表明，最好的干预措施是每周至少进行一次有意义的社交接触。根据个人的情况，这可能意味着做志愿工作，见老朋友，或其他事情。</p><h2 id="第七段听力"><a href="#第七段听力" class="headerlink" title="第七段听力"></a>第七段听力</h2><p>演讲：22-25</p><p>Hello, I am co-founder of the popular female travel community, We Are Trawnl:Girls. We collect and publish stories from women traveling all over the world.We promote comeh’s blogs. We host meetings and events and are getting ready to launch our Travel with Us trips in Bali, Japan and Malawi,<br>您好，我是女性旅行社区“We Are Travel Girls”的联合创始人。我们收集并发布来自世界各地旅行的女性的故事。我们推广女性的博客。我们举办会议和活动，并准备在巴厘岛、日本和马拉维推出我们的“与我们一起旅行”之旅。</p><p>Before I started We Are Travel Girls. I had a successful 10-year career in finance in Jondon where I advised private clients on their investments. Having always had a huge love for travel, I finally took the leap and left finance to pursue my drearc fjstarting a travel company. For as long as I can remember, I wanted to be a travel writer. Before blogs existed, and everything we read was online, I would go to travel writing seminars by writers who were published in travel magarinesel was desperate to write for one of those magazines but didn’t know how to break into-that industry.After university, I ended up working in finance, but always had a desire to travel and write about it.<br>在我开始We Are Travel Girls之前，我在伦敦有着成功的10年金融职业生涯，在那里我为私人客户提供投资建议。我一直热爱旅行，最终我决定离开金融业，追求我的梦想，开办一家旅行公司。我记得很久以前我就想成为一名旅行作家。在博客存在之前，我们阅读的一切都在网上，我曾经参加过旅行写作研讨会，听那些在旅行杂志上发表作品的作家讲课。我曾经非常渴望为那些杂志之一写作，但不知道如何打入这个行业。大学毕业后，我最终进入金融业工作，但一直渴望旅行并写下旅行见闻。</p><p>In 2015, I was looking at ways to leave finance, and my b Vanessa,who grew up on a’ranch on the central coast of California, suggested starting a blog. But when we started creating it,we realized that was the same thing every girl was doing. So we turned our attention to creating a community among these women. This led us to start We Are Travel Girls, which has now grown into a community of over 200,000 followers.<br>2015年，我在寻找离开金融业的方法时，我的朋友Vanessa建议我开始写博客。但当我们开始创建博客时，我们意识到每个女孩都在做同样的事情。因此，我们将注意力转向在这些女性之间创建一个社区。这促使我们创建了We Are Travel Girls，现在已经发展成为拥有超过20万名关注者的社区。</p><p>To anyone thinking about becoming a travel writer, I would suggest they first try and look for a unique way to enter the industry. There are a lot of travel writers now and it can be hard to stand out from the crowd, which is really why we started We Are Travel Girls. Be prepared to work hard if you want to turn it into a full-time business. Q25 And try not to rush to selling advertising spaces before you have created a dedicated audience. The size of your audience doesn’t necessarily need to be huge, but you want them to be engaged. If you post too many promotions early on, you will turn many people off.<br>对于任何想成为旅行作家的人，我建议他们首先尝试寻找进入该行业的独特方式。现在有很多旅行作家，要脱颖而出可能很困难，这也是我们创办We Are Travel Girls的初衷。如果您想把它变成全职业务，就要做好充分准备。并且在您拥有忠实读者之前，不要急于销售广告空间。您的受众规模不一定需要很大，但您希望他们参与进来。如果您在早期发布过多的推广信息，将会失去很多人的兴趣。</p>]]></content>
    
    
    
    <tags>
      
      <tag>英语</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>高等数学 —— 常微分方程</title>
    <link href="/2024/05/18/gaodengshuxue5/"/>
    <url>/2024/05/18/gaodengshuxue5/</url>
    
    <content type="html"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/19759362">傅里叶方程</a></p><p>常微分方程。<br>常微分方程的基本概念，变量可分离的微分方程，齐次微分方程，一阶线性微分方程 ，可降阶的高阶微分方程，线性微分方程解的性质及解的结构定理，二阶常系数齐次线性微分方程， 高于二阶的某些常系数齐次线性微分方程，简单的二阶常系数非齐次线性微分方程 ，微分方程的简单应用 </p><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><table><thead><tr><th align="left"></th></tr></thead><tbody><tr><td align="left"><img src="/pic/gdsx-hbs_73.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_74.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_75.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_76.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_77.png"></td></tr></tbody></table>]]></content>
    
    
    
    <tags>
      
      <tag>高等数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>填坑——强化学习——使用智能体来预测股票</title>
    <link href="/2024/05/17/tiankeng10/"/>
    <url>/2024/05/17/tiankeng10/</url>
    
    <content type="html"><![CDATA[<h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p><a href="https://gym-trading-env.readthedocs.io/en/latest/">Gym Trading Env</a>Gym Trading Env is a Gymnasium environment for simulating stocks and training Reinforcement Learning (RL) trading agents. It was designed to be fast and customizable for easy RL trading algorithms implementation.<br><a href="https://github.com/wangshub/RL-Stock">如何用深度强化学习自动炒股</a><br><a href="https://github.com/Jack-Cherish/quantitative?tab=readme-ov-file">量化交易</a><br><a href="https://github.com/waditu/czsc">czsc</a></p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>获取股票数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">import</span> baostock <span class="hljs-keyword">as</span> bs<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> os<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">mkdir</span>(<span class="hljs-params">directory</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(directory):<br>        os.makedirs(directory)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Downloader</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 output_dir,</span><br><span class="hljs-params">                 date_start=<span class="hljs-string">&#x27;1990-01-01&#x27;</span>,</span><br><span class="hljs-params">                 date_end=<span class="hljs-string">&#x27;2024-03-16&#x27;</span></span>):<br>        self._bs = bs<br>        bs.login()<br>        self.date_start = date_start<br>        <span class="hljs-comment"># self.date_end = datetime.datetime.now().strftime(&quot;%Y-%m-%d&quot;)</span><br>        self.date_end = date_end<br>        self.output_dir = output_dir<br>        self.fields = <span class="hljs-string">&quot;date,open,high,low,close,amount,volume&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">exit</span>(<span class="hljs-params">self</span>):<br>        bs.logout()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_codes_by_date</span>(<span class="hljs-params">self, date</span>):<br>        <span class="hljs-built_in">print</span>(date)<br>        stock_rs = bs.query_all_stock(date)<br>        stock_df = stock_rs.get_data()<br>        <span class="hljs-built_in">print</span>(stock_df)<br>        <span class="hljs-keyword">return</span> stock_df<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>(<span class="hljs-params">self</span>):<br>        stock_df = self.get_codes_by_date(self.date_end)<br>        <span class="hljs-keyword">for</span> index, row <span class="hljs-keyword">in</span> stock_df.iterrows():<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;processing <span class="hljs-subst">&#123;row[<span class="hljs-string">&quot;code&quot;</span>]&#125;</span> <span class="hljs-subst">&#123;row[<span class="hljs-string">&quot;code_name&quot;</span>]&#125;</span>&#x27;</span>)<br>            df_code = bs.query_history_k_data_plus(row[<span class="hljs-string">&quot;code&quot;</span>], self.fields,<br>                                               start_date=self.date_start,<br>                                               end_date=self.date_end).get_data()<br>        <span class="hljs-comment"># 替换文件名中的*字符为_</span><br>            code_name = row[<span class="hljs-string">&quot;code_name&quot;</span>].replace(<span class="hljs-string">&#x27;*&#x27;</span>, <span class="hljs-string">&#x27;_&#x27;</span>)<br>            df_code.to_csv(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;self.output_dir&#125;</span>/<span class="hljs-subst">&#123;row[<span class="hljs-string">&quot;code&quot;</span>]&#125;</span>.<span class="hljs-subst">&#123;code_name&#125;</span>.csv&#x27;</span>, index=<span class="hljs-literal">False</span>)<br>        self.exit()<br><br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-comment"># 获取全部股票的日K线数据</span><br>    mkdir(<span class="hljs-string">&#x27;./data/train&#x27;</span>)<br>    downloader = Downloader(<span class="hljs-string">&#x27;./data/train&#x27;</span>, date_start=<span class="hljs-string">&#x27;2000-01-01&#x27;</span>, date_end=<span class="hljs-string">&#x27;2024-2-29&#x27;</span>)<br>    downloader.run()<br><br>    mkdir(<span class="hljs-string">&#x27;./data/test&#x27;</span>)<br>    downloader = Downloader(<span class="hljs-string">&#x27;./data/test&#x27;</span>, date_start=<span class="hljs-string">&#x27;2024-3-1&#x27;</span>, date_end=<span class="hljs-string">&#x27;2024-3-15&#x27;</span>)<br>    downloader.run()<br><br></code></pre></td></tr></table></figure><p><a href="http://baostock.com/baostock/index.php/Python_API%E6%96%87%E6%A1%A3">Baostack的API文档</a></p><h2 id="选股器"><a href="#选股器" class="headerlink" title="选股器"></a>选股器</h2><p>思路，股票是波动的，但是波动是现象，可能今天是下跌，但是明天就上升了。</p><p>根据什么指标来构建筛选股票？，评价指标是什么?</p><h3 id="聚宽平台"><a href="#聚宽平台" class="headerlink" title="聚宽平台"></a>聚宽平台</h3><p><a href="https://www.joinquant.com/help/api/help#name:aboutData">聚宽数据</a><br><a href="">新手指引</a><a href="https://www.joinquant.com/view/community/detail/7e4989804f4d3cd12532cafefeea1bcb">https://www.joinquant.com/view/community/detail/7e4989804f4d3cd12532cafefeea1bcb</a><br>关于聚宽数据<br>股票数据：我们拥有所有A股上市公司2005年以来的股票行情数据、财务数据、上市公司基本信息、融资融券信息等。为了避免幸存者偏差，我们包括了已经退市的股票数据。其中volume（成交量）字段单位是股。<br>商品期货：我们支持从2005年以来上海国际能源交易中心、上期所、郑商所、大商所的行情数据，并包含历史产品的数据。<br>基金数据：我们目前提供了600多种在交易所上市的基金的行情、净值等数据，包含ETF、LOF、分级A&#x2F;B基金以及货币基金的完整的行情、净值数据等，请点击基金数据查看。<br>金融期货数据：我们提供中金所推出的所有金融期货产品的行情数据，并包含历史产品的数据。<br>股票指数：我们支持近600种指数数据，包括指数的行情数据以及成分股数据。为了避免未来函数，我们支持获取历史任意时刻的指数成分股信息，具体见get_index_stocks。<br>行业板块：我们支持按行业、按板块选股，具体见get_industry_stocks<br>概念板块：我们支持按概念板块选股，具体见get_concept_stocks<br>宏观数据：我们提供全方位的宏观数据，为投资者决策提供有力数据支持。</p><h3 id="本地化数据JQData"><a href="#本地化数据JQData" class="headerlink" title="本地化数据JQData"></a>本地化数据JQData</h3><p><a href="https://www.joinquant.com/help/api/help#JQData:JQData">JQData</a><br>QData由聚宽团队专门维护清洗，为金融机构、学术团体和量化研究者们提供的本地量化金融数据服务。 数据产品不仅对外服务，同时服务于聚宽所有业务线，历经平台40万用户、基金百亿资产、每年万亿交易额的考验。本着推动量化行业快速发展的良好愿景，JQData现已开放注册。</p><p>安装本地数据JQData<code>pip install jqdatasdk</code></p><h3 id="代码解析工程"><a href="#代码解析工程" class="headerlink" title="代码解析工程"></a>代码解析工程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">优化说明:</span><br><span class="hljs-string">    1.使用修正标准分</span><br><span class="hljs-string">        rsrs_score的算法有：</span><br><span class="hljs-string">            仅斜率slope，效果一般；</span><br><span class="hljs-string">            仅标准分zscore，效果不错；</span><br><span class="hljs-string">            修正标准分 = zscore * r2，效果最佳;</span><br><span class="hljs-string">            右偏标准分 = 修正标准分 * slope，效果不错。</span><br><span class="hljs-string">    2.将原策略的每次持有两只etf改成只买最优的一个，收益显著提高</span><br><span class="hljs-string">    3.将每周调仓换成每日调仓，收益显著提高</span><br><span class="hljs-string">    4.因为交易etf，所以手续费设为万分之三，印花税设为零，未设置滑点</span><br><span class="hljs-string">    5.修改股票池中候选etf，删除银行，红利等收益较弱品种，增加纳指etf以增加不同国家市场间轮动的可能性</span><br><span class="hljs-string">    6.根据研报，默认参数介已设定为最优</span><br><span class="hljs-string">    7.加入防未来函数</span><br><span class="hljs-string">    8.增加择时与选股模块的打印日志，方便观察每笔操作依据</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment">#导入函数库</span><br><span class="hljs-keyword">from</span> jqdata <span class="hljs-keyword">import</span> *<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment">#初始化函数 </span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">initialize</span>(<span class="hljs-params">context</span>):<br>    <span class="hljs-comment"># 设定沪深300作为基准</span><br>    set_benchmark(<span class="hljs-string">&#x27;000300.XSHG&#x27;</span>)<br>    <span class="hljs-comment"># 用真实价格交易</span><br>    set_option(<span class="hljs-string">&#x27;use_real_price&#x27;</span>, <span class="hljs-literal">True</span>)<br>    <span class="hljs-comment"># 打开防未来函数</span><br>    set_option(<span class="hljs-string">&quot;avoid_future_data&quot;</span>, <span class="hljs-literal">True</span>)<br>    <span class="hljs-comment"># 将滑点设置为0</span><br>    set_slippage(FixedSlippage(<span class="hljs-number">0.001</span>))<br>    <span class="hljs-comment"># 设置交易成本万分之三</span><br>    set_order_cost(OrderCost(open_tax=<span class="hljs-number">0</span>, close_tax=<span class="hljs-number">0</span>, open_commission=<span class="hljs-number">0.0003</span>, close_commission=<span class="hljs-number">0.0003</span>, close_today_commission=<span class="hljs-number">0</span>, min_commission=<span class="hljs-number">5</span>),<br>                   <span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;fund&#x27;</span>)<br>    <span class="hljs-comment"># 股票类每笔交易时的手续费是：买入时佣金万分之二，卖出时佣金万分之二，无印花税, 每笔交易佣金最低扣5块钱</span><br>    <span class="hljs-comment"># set_order_cost(OrderCost(close_tax=0.000, open_commission=0.0002, close_commission=0.0002, min_commission=5), type=&#x27;fund&#x27;)</span><br>    <span class="hljs-comment"># 过滤order中低于error级别的日志</span><br>    log.set_level(<span class="hljs-string">&#x27;order&#x27;</span>, <span class="hljs-string">&#x27;error&#x27;</span>)<br>    <span class="hljs-comment"># 初始化各类全局变量</span><br>    <span class="hljs-comment">#股票池</span><br>    g.stock_pool = [<br>        <span class="hljs-string">&#x27;159915.XSHE&#x27;</span>, <span class="hljs-comment"># 易方达创业板ETF</span><br>        <span class="hljs-string">&#x27;510300.XSHG&#x27;</span>, <span class="hljs-comment"># 华泰柏瑞沪深300ETF</span><br>        <span class="hljs-string">&#x27;510500.XSHG&#x27;</span>, <span class="hljs-comment"># 南方中证500ETF</span><br>    ]<br>    <span class="hljs-comment">#动量轮动参数</span><br>    g.stock_num = <span class="hljs-number">1</span> <span class="hljs-comment">#买入评分最高的前stock_num只股票</span><br>    g.momentum_day = <span class="hljs-number">29</span> <span class="hljs-comment">#最新动量参考最近momentum_day的</span><br>    <span class="hljs-comment">#rsrs择时参数</span><br>    g.ref_stock = <span class="hljs-string">&#x27;000300.XSHG&#x27;</span> <span class="hljs-comment">#用ref_stock做择时计算的基础数据</span><br>    g.N = <span class="hljs-number">18</span> <span class="hljs-comment"># 计算最新斜率slope，拟合度r2参考最近N天</span><br>    g.M = <span class="hljs-number">600</span> <span class="hljs-comment"># 计算最新标准分zscore，rsrs_score参考最近M天</span><br>    g.score_threshold = <span class="hljs-number">0.7</span> <span class="hljs-comment"># rsrs标准分指标阈值</span><br>    <span class="hljs-comment">#ma择时参数</span><br>    g.mean_day = <span class="hljs-number">20</span> <span class="hljs-comment">#计算结束ma收盘价，参考最近mean_day</span><br>    g.mean_diff_day = <span class="hljs-number">3</span> <span class="hljs-comment">#计算初始ma收盘价，参考(mean_day + mean_diff_day)天前，窗口为mean_diff_day的一段时间</span><br>    g.slope_series = initial_slope_series()[:-<span class="hljs-number">1</span>] <span class="hljs-comment"># 除去回测第一天的slope，避免运行时重复加入</span><br>    <span class="hljs-comment"># 设置交易时间，每天运行</span><br>    run_daily(my_trade, time=<span class="hljs-string">&#x27;11:30&#x27;</span>, reference_security=<span class="hljs-string">&#x27;000300.XSHG&#x27;</span>)<br>    run_daily(check_lose, time=<span class="hljs-string">&#x27;open&#x27;</span>, reference_security=<span class="hljs-string">&#x27;000300.XSHG&#x27;</span>)<br>    run_daily(print_trade_info, time=<span class="hljs-string">&#x27;15:30&#x27;</span>, reference_security=<span class="hljs-string">&#x27;000300.XSHG&#x27;</span>)<br><br><br><span class="hljs-comment">#1-1 选股模块-动量因子轮动 </span><br><span class="hljs-comment">#基于股票年化收益和判定系数打分,并按照分数从大到小排名</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_rank</span>(<span class="hljs-params">stock_pool</span>):<br>    score_list = []<br>    <span class="hljs-keyword">for</span> stock <span class="hljs-keyword">in</span> g.stock_pool:<br>        data = attribute_history(stock, g.momentum_day, <span class="hljs-string">&#x27;1d&#x27;</span>, [<span class="hljs-string">&#x27;close&#x27;</span>])<br>        y = data[<span class="hljs-string">&#x27;log&#x27;</span>] = np.log(data.close)<br>        x = data[<span class="hljs-string">&#x27;num&#x27;</span>] = np.arange(data.log.size)<br>        slope, intercept = np.polyfit(x, y, <span class="hljs-number">1</span>)<br>        annualized_returns = math.<span class="hljs-built_in">pow</span>(math.exp(slope), <span class="hljs-number">250</span>) - <span class="hljs-number">1</span><br>        r_squared = <span class="hljs-number">1</span> - (<span class="hljs-built_in">sum</span>((y - (slope * x + intercept))**<span class="hljs-number">2</span>) / ((<span class="hljs-built_in">len</span>(y) - <span class="hljs-number">1</span>) * np.var(y, ddof=<span class="hljs-number">1</span>)))<br>        score = annualized_returns * r_squared<br>        score_list.append(score)<br>    stock_dict=<span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(g.stock_pool, score_list))<br>    sort_list=<span class="hljs-built_in">sorted</span>(stock_dict.items(), key=<span class="hljs-keyword">lambda</span> item:item[<span class="hljs-number">1</span>], reverse=<span class="hljs-literal">True</span>) <span class="hljs-comment">#True为降序</span><br>    code_list=[]<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>((<span class="hljs-built_in">len</span>(g.stock_pool))):<br>        code_list.append(sort_list[i][<span class="hljs-number">0</span>])<br>    rank_stock = code_list[<span class="hljs-number">0</span>:g.stock_num]<br>    <span class="hljs-built_in">print</span>(code_list[<span class="hljs-number">0</span>:<span class="hljs-number">5</span>])<br>    <span class="hljs-keyword">return</span> rank_stock<br><br><br><br><span class="hljs-comment">#2-1 择时模块-计算线性回归统计值</span><br><span class="hljs-comment">#对输入的自变量每日最低价x(series)和因变量每日最高价y(series)建立OLS回归模型,返回元组(截距,斜率,拟合度)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_ols</span>(<span class="hljs-params">x, y</span>):<br>    slope, intercept = np.polyfit(x, y, <span class="hljs-number">1</span>)<br>    r2 = <span class="hljs-number">1</span> - (<span class="hljs-built_in">sum</span>((y - (slope * x + intercept))**<span class="hljs-number">2</span>) / ((<span class="hljs-built_in">len</span>(y) - <span class="hljs-number">1</span>) * np.var(y, ddof=<span class="hljs-number">1</span>)))<br>    <span class="hljs-keyword">return</span> (intercept, slope, r2)<br><br><span class="hljs-comment">#2-2 择时模块-设定初始斜率序列</span><br><span class="hljs-comment">#通过前M日最高最低价的线性回归计算初始的斜率,返回斜率的列表</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">initial_slope_series</span>():<br>    data = attribute_history(g.ref_stock, g.N + g.M, <span class="hljs-string">&#x27;1d&#x27;</span>, [<span class="hljs-string">&#x27;high&#x27;</span>, <span class="hljs-string">&#x27;low&#x27;</span>])<br>    <span class="hljs-keyword">return</span> [get_ols(data.low[i:i+g.N], data.high[i:i+g.N])[<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(g.M)]<br><br><span class="hljs-comment">#2-3 择时模块-计算标准分</span><br><span class="hljs-comment">#通过斜率列表计算并返回截至回测结束日的最新标准分</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_zscore</span>(<span class="hljs-params">slope_series</span>):<br>    mean = np.mean(slope_series)<br>    std = np.std(slope_series)<br>    <span class="hljs-keyword">return</span> (slope_series[-<span class="hljs-number">1</span>] - mean) / std<br><br><span class="hljs-comment">#2-4 择时模块-计算综合信号</span><br><span class="hljs-comment">#1.获得rsrs与MA信号,rsrs信号算法参考优化说明，MA信号为一段时间两个端点的MA数值比较大小</span><br><span class="hljs-comment">#2.信号同时为True时返回买入信号，同为False时返回卖出信号，其余情况返回持仓不变信号</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_timing_signal</span>(<span class="hljs-params">stock</span>):<br>    <span class="hljs-comment">#计算MA信号</span><br>    close_data = attribute_history(g.ref_stock, g.mean_day + g.mean_diff_day, <span class="hljs-string">&#x27;1d&#x27;</span>, [<span class="hljs-string">&#x27;close&#x27;</span>])<br>    today_MA = close_data.close[g.mean_diff_day:].mean() <br>    before_MA = close_data.close[:-g.mean_diff_day].mean()<br>    <span class="hljs-comment">#计算rsrs信号</span><br>    high_low_data = attribute_history(g.ref_stock, g.N, <span class="hljs-string">&#x27;1d&#x27;</span>, [<span class="hljs-string">&#x27;high&#x27;</span>, <span class="hljs-string">&#x27;low&#x27;</span>])<br>    intercept, slope, r2 = get_ols(high_low_data.low, high_low_data.high)<br>    g.slope_series.append(slope)<br>    rsrs_score = get_zscore(g.slope_series[-g.M:]) * r2<br>    <span class="hljs-comment">#综合判断所有信号</span><br>    <span class="hljs-keyword">if</span> rsrs_score &gt; g.score_threshold <span class="hljs-keyword">and</span> today_MA &gt; before_MA:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;BUY&#x27;</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;BUY&quot;</span><br>    <span class="hljs-keyword">elif</span> rsrs_score &lt; -g.score_threshold <span class="hljs-keyword">and</span> today_MA &lt; before_MA:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;SELL&#x27;</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;SELL&quot;</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;KEEP&#x27;</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;KEEP&quot;</span><br><br><br><span class="hljs-comment">#3-1 过滤模块-过滤停牌股票</span><br><span class="hljs-comment">#输入选股列表，返回剔除停牌股票后的列表</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">filter_paused_stock</span>(<span class="hljs-params">stock_list</span>):<br>current_data = get_current_data()<br><span class="hljs-keyword">return</span> [stock <span class="hljs-keyword">for</span> stock <span class="hljs-keyword">in</span> stock_list <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> current_data[stock].paused]<br><br><span class="hljs-comment">#3-2 过滤模块-过滤ST及其他具有退市标签的股票</span><br><span class="hljs-comment">#输入选股列表，返回剔除ST及其他具有退市标签股票后的列表</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">filter_st_stock</span>(<span class="hljs-params">stock_list</span>):<br>current_data = get_current_data()<br><span class="hljs-keyword">return</span> [stock <span class="hljs-keyword">for</span> stock <span class="hljs-keyword">in</span> stock_list<br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> current_data[stock].is_st<br><span class="hljs-keyword">and</span> <span class="hljs-string">&#x27;ST&#x27;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> current_data[stock].name<br><span class="hljs-keyword">and</span> <span class="hljs-string">&#x27;*&#x27;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> current_data[stock].name<br><span class="hljs-keyword">and</span> <span class="hljs-string">&#x27;退&#x27;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> current_data[stock].name]<br><br><span class="hljs-comment">#3-3 过滤模块-过滤涨停的股票</span><br><span class="hljs-comment">#输入选股列表，返回剔除未持有且已涨停股票后的列表</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">filter_limitup_stock</span>(<span class="hljs-params">context, stock_list</span>):<br>last_prices = history(<span class="hljs-number">1</span>, unit=<span class="hljs-string">&#x27;1m&#x27;</span>, field=<span class="hljs-string">&#x27;close&#x27;</span>, security_list=stock_list)<br>current_data = get_current_data()<br><span class="hljs-comment"># 已存在于持仓的股票即使涨停也不过滤，避免此股票再次可买，但因被过滤而导致选择别的股票</span><br><span class="hljs-keyword">return</span> [stock <span class="hljs-keyword">for</span> stock <span class="hljs-keyword">in</span> stock_list <span class="hljs-keyword">if</span> stock <span class="hljs-keyword">in</span> context.portfolio.positions.keys()<br><span class="hljs-keyword">or</span> last_prices[stock][-<span class="hljs-number">1</span>] &lt; current_data[stock].high_limit]<br><br><span class="hljs-comment">#3-4 过滤模块-过滤跌停的股票</span><br><span class="hljs-comment">#输入股票列表，返回剔除已跌停股票后的列表</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">filter_limitdown_stock</span>(<span class="hljs-params">context, stock_list</span>):<br>last_prices = history(<span class="hljs-number">1</span>, unit=<span class="hljs-string">&#x27;1m&#x27;</span>, field=<span class="hljs-string">&#x27;close&#x27;</span>, security_list=stock_list)<br>current_data = get_current_data()<br><span class="hljs-keyword">return</span> [stock <span class="hljs-keyword">for</span> stock <span class="hljs-keyword">in</span> stock_list <span class="hljs-keyword">if</span> stock <span class="hljs-keyword">in</span> context.portfolio.positions.keys()<br><span class="hljs-keyword">or</span> last_prices[stock][-<span class="hljs-number">1</span>] &gt; current_data[stock].low_limit]<br><br><br><br><span class="hljs-comment">#4-1 交易模块-自定义下单</span><br><span class="hljs-comment">#报单成功返回报单(不代表一定会成交),否则返回None,应用于</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">order_target_value_</span>(<span class="hljs-params">security, value</span>):<br><span class="hljs-keyword">if</span> value == <span class="hljs-number">0</span>:<br>log.debug(<span class="hljs-string">&quot;Selling out %s&quot;</span> % (security))<br><span class="hljs-keyword">else</span>:<br>log.debug(<span class="hljs-string">&quot;Order %s to value %f&quot;</span> % (security, value))<br><span class="hljs-comment"># 如果股票停牌，创建报单会失败，order_target_value 返回None</span><br><span class="hljs-comment"># 如果股票涨跌停，创建报单会成功，order_target_value 返回Order，但是报单会取消</span><br><span class="hljs-comment"># 部成部撤的报单，聚宽状态是已撤，此时成交量&gt;0，可通过成交量判断是否有成交</span><br><span class="hljs-keyword">return</span> order_target_value(security, value)<br><br><span class="hljs-comment">#4-2 交易模块-开仓</span><br><span class="hljs-comment">#买入指定价值的证券,报单成功并成交(包括全部成交或部分成交,此时成交量大于0)返回True,报单失败或者报单成功但被取消(此时成交量等于0),返回False</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">open_position</span>(<span class="hljs-params">security, value</span>):<br>order = order_target_value_(security, value)<br><span class="hljs-keyword">if</span> order != <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> order.filled &gt; <span class="hljs-number">0</span>:<br><span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br><span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br><br><span class="hljs-comment">#4-3 交易模块-平仓</span><br><span class="hljs-comment">#卖出指定持仓,报单成功并全部成交返回True，报单失败或者报单成功但被取消(此时成交量等于0),或者报单非全部成交,返回False</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">close_position</span>(<span class="hljs-params">position</span>):<br>security = position.security<br>order = order_target_value_(security, <span class="hljs-number">0</span>)  <span class="hljs-comment"># 可能会因停牌失败</span><br><span class="hljs-keyword">if</span> order != <span class="hljs-literal">None</span>:<br><span class="hljs-keyword">if</span> order.status == OrderStatus.held <span class="hljs-keyword">and</span> order.filled == order.amount:<br><span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br><span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br><br><span class="hljs-comment">#4-4 交易模块-调仓</span><br><span class="hljs-comment">#当择时信号为买入时开始调仓，输入过滤模块处理后的股票列表，执行交易模块中的开平仓操作</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">adjust_position</span>(<span class="hljs-params">context, buy_stocks</span>):<br><span class="hljs-keyword">for</span> stock <span class="hljs-keyword">in</span> context.portfolio.positions:<br><span class="hljs-keyword">if</span> stock <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> buy_stocks:<br>log.info(<span class="hljs-string">&quot;[%s]已不在应买入列表中&quot;</span> % (stock))<br>position = context.portfolio.positions[stock]<br>close_position(position)<br><span class="hljs-keyword">else</span>:<br>log.info(<span class="hljs-string">&quot;[%s]已经持有无需重复买入&quot;</span> % (stock))<br><span class="hljs-comment"># 根据股票数量分仓</span><br><span class="hljs-comment"># 此处只根据可用金额平均分配购买，不能保证每个仓位平均分配</span><br>position_count = <span class="hljs-built_in">len</span>(context.portfolio.positions)<br><span class="hljs-keyword">if</span> g.stock_num &gt; position_count:<br>value = context.portfolio.cash / (g.stock_num - position_count)<br><span class="hljs-keyword">for</span> stock <span class="hljs-keyword">in</span> buy_stocks:<br><span class="hljs-keyword">if</span> context.portfolio.positions[stock].total_amount == <span class="hljs-number">0</span>:<br><span class="hljs-keyword">if</span> open_position(stock, value):<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(context.portfolio.positions) == g.stock_num:<br><span class="hljs-keyword">break</span><br><br><span class="hljs-comment">#4-5 交易模块-择时交易</span><br><span class="hljs-comment">#结合择时模块综合信号进行交易</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">my_trade</span>(<span class="hljs-params">context</span>):<br>    <span class="hljs-comment">#获取选股列表并过滤掉:st,st*,退市,涨停,跌停,停牌</span><br>    check_out_list = get_rank(g.stock_pool)<br>    check_out_list = filter_st_stock(check_out_list)<br>    check_out_list = filter_limitup_stock(context, check_out_list)<br>    check_out_list = filter_limitdown_stock(context, check_out_list)<br>    check_out_list = filter_paused_stock(check_out_list)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;今日自选股:&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(check_out_list))<br>    <span class="hljs-comment">#获取综合择时信号</span><br>    timing_signal = get_timing_signal(g.ref_stock)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;今日择时信号:&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(timing_signal))<br>    <span class="hljs-comment">#开始交易</span><br>    <span class="hljs-keyword">if</span> timing_signal == <span class="hljs-string">&#x27;SELL&#x27;</span>:<br>        <span class="hljs-keyword">for</span> stock <span class="hljs-keyword">in</span> context.portfolio.positions:<br>            position = context.portfolio.positions[stock]<br>            close_position(position)<br>    <span class="hljs-keyword">elif</span> timing_signal == <span class="hljs-string">&#x27;BUY&#x27;</span> <span class="hljs-keyword">or</span> timing_signal == <span class="hljs-string">&#x27;KEEP&#x27;</span>:<br>        adjust_position(context, check_out_list)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">pass</span><br><br><span class="hljs-comment">#4-6 交易模块-止损</span><br><span class="hljs-comment">#检查持仓并进行必要的止损操作</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">check_lose</span>(<span class="hljs-params">context</span>):<br>    <span class="hljs-keyword">for</span> position <span class="hljs-keyword">in</span> <span class="hljs-built_in">list</span>(context.portfolio.positions.values()):<br>        securities=position.security<br>        cost=position.avg_cost<br>        price=position.price<br>        ret=<span class="hljs-number">100</span>*(price/cost-<span class="hljs-number">1</span>)<br>        value=position.value<br>        amount=position.total_amount<br>        <span class="hljs-comment">#这里设定80%止损几乎等同不止损，因为止损在指数etf策略中影响不大</span><br>        <span class="hljs-keyword">if</span> ret &lt;=-<span class="hljs-number">20</span>:<br>            order_target_value(position.security, <span class="hljs-number">0</span>)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;！！！！！！触发止损信号: 标的=&#123;&#125;,标的价值=&#123;&#125;,浮动盈亏=&#123;&#125;% ！！！！！！&quot;</span><br>                .<span class="hljs-built_in">format</span>(securities,<span class="hljs-built_in">format</span>(value,<span class="hljs-string">&#x27;.2f&#x27;</span>),<span class="hljs-built_in">format</span>(ret,<span class="hljs-string">&#x27;.2f&#x27;</span>)))<br><br><span class="hljs-comment">#5-1 复盘模块-打印</span><br><span class="hljs-comment">#打印每日持仓信息</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">print_trade_info</span>(<span class="hljs-params">context</span>):<br>    <span class="hljs-comment">#打印当天成交记录</span><br>    trades = get_trades()<br>    <span class="hljs-keyword">for</span> _trade <span class="hljs-keyword">in</span> trades.values():<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;成交记录：&#x27;</span>+<span class="hljs-built_in">str</span>(_trade))<br>    <span class="hljs-comment">#打印账户信息</span><br>    <span class="hljs-keyword">for</span> position <span class="hljs-keyword">in</span> <span class="hljs-built_in">list</span>(context.portfolio.positions.values()):<br>        securities=position.security<br>        cost=position.avg_cost<br>        price=position.price<br>        ret=<span class="hljs-number">100</span>*(price/cost-<span class="hljs-number">1</span>)<br>        value=position.value<br>        amount=position.total_amount    <br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;代码:&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(securities))<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;成本价:&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">format</span>(cost,<span class="hljs-string">&#x27;.2f&#x27;</span>)))<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;现价:&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(price))<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;收益率:&#123;&#125;%&#x27;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">format</span>(ret,<span class="hljs-string">&#x27;.2f&#x27;</span>)))<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;持仓(股):&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(amount))<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;市值:&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">format</span>(value,<span class="hljs-string">&#x27;.2f&#x27;</span>)))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;一天结束&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;———————————————————————————————————————分割线————————————————————————————————————————&#x27;</span>)<br><br><br></code></pre></td></tr></table></figure><p>有一个功能非常有意思，发送消息通过，stmp发送到qq邮箱。<br>email库是 Python 标准库中用于处理电子邮件的模块。它提供了一组类和方法，用于创建、解析、格式化和发送电子邮件。<br>smtaplib库 smtplib 是 Python 标准库中的一个模块，用于发送邮件。它提供了一个简单的接口，允许您连接到 SMTP 服务器并发送电子邮件。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#!/usr/bin/python</span><br><span class="hljs-comment"># -*- coding: UTF-8 -*-</span><br><br><span class="hljs-keyword">import</span> smtplib<br><span class="hljs-keyword">from</span> email.mime.text <span class="hljs-keyword">import</span> MIMEText<br><span class="hljs-keyword">from</span> email.utils <span class="hljs-keyword">import</span> formataddr<br><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime<br><span class="hljs-keyword">import</span> time<br><br>my_sender = <span class="hljs-string">&#x27;&#x27;</span>    <span class="hljs-comment"># 发件人邮箱账号</span><br>my_pass = <span class="hljs-string">&#x27;&#x27;</span>              <span class="hljs-comment"># 发件人邮箱密码</span><br>my_user = <span class="hljs-string">&#x27;&#x27;</span>              <span class="hljs-comment"># 收件人邮箱账号(这里发自己)</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">mail</span>(<span class="hljs-params">message</span>):<br>    ret = <span class="hljs-literal">True</span><br>    <span class="hljs-keyword">try</span>:<br>        current_dt = time.strftime(<span class="hljs-string">&quot;%Y-%m-%d&quot;</span>, time.localtime()) <br>        <span class="hljs-comment"># current_dt = time.strftime(&quot;%Y-%m-%d&quot;, time.localtime())：获取当前日期，并按照&quot;%Y-%m-%d&quot;的格式转换为字符串形式。</span><br>        <br>        <span class="hljs-comment"># current_dt = datetime.strptime(current_dt, &#x27;%Y-%m-%d&#x27;)</span><br>        title = current_dt.split(<span class="hljs-string">&quot; &quot;</span>)[<span class="hljs-number">0</span>] + <span class="hljs-string">&quot;投资操作&quot;</span><br>        msg = MIMEText(message,<span class="hljs-string">&#x27;plain&#x27;</span>,<span class="hljs-string">&#x27;utf-8&#x27;</span>)<br>        msg[<span class="hljs-string">&#x27;From&#x27;</span>] = formataddr([<span class="hljs-string">&quot;**&quot;</span>, my_sender])         <span class="hljs-comment"># 发件人昵称</span><br>        msg[<span class="hljs-string">&#x27;To&#x27;</span>] = formataddr([<span class="hljs-string">&quot;**&quot;</span>, my_user])             <span class="hljs-comment"># 接收人昵称</span><br>        msg[<span class="hljs-string">&#x27;Subject&#x27;</span>] = title                              <span class="hljs-comment"># 邮件的主题</span><br><br>        server = smtplib.SMTP_SSL(<span class="hljs-string">&quot;smtp.qq.com&quot;</span>, <span class="hljs-number">465</span>)       <span class="hljs-comment"># 发件人邮箱中的SMTP服务器，端口是465</span><br>        server.login(my_sender, my_pass)  <span class="hljs-comment"># 发件人邮箱账号、邮箱密码</span><br>        server.sendmail(my_sender, [my_user,], msg.as_string())  <span class="hljs-comment"># 发件人邮箱账号、收件人邮箱账号、发送邮件</span><br>        server.quit()  <span class="hljs-comment"># 关闭连接</span><br>    <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:  <span class="hljs-comment"># 如果 try 中的语句没有执行，则会执行下面的 ret = False</span><br>        ret = <span class="hljs-literal">False</span><br>        <span class="hljs-built_in">print</span>(e)<br>    <span class="hljs-keyword">return</span> ret<br><br><span class="hljs-comment"># 用mail函数发送测试邮件，并根据返回值打印相应的提示信息。</span><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    ret = mail(<span class="hljs-string">&quot;Test&quot;</span>)<br>    <span class="hljs-keyword">if</span> ret:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;邮件发送成功&quot;</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;邮件发送失败&quot;</span>)<br><br><br></code></pre></td></tr></table></figure><p><img src="/pic/stmp.png" alt="stmp"></p><p>框架建立对于一名极客是必须的，错误复现对于一名极客也是必须的。</p><h2 id="推荐书籍"><a href="#推荐书籍" class="headerlink" title="推荐书籍"></a>推荐书籍</h2><p><a href="https://weread.qq.com/web/reader/1b5325907159cacc1b5e0e1">股票大作手回忆录</a></p><h2 id="个人感悟"><a href="#个人感悟" class="headerlink" title="个人感悟"></a>个人感悟</h2><p>炒股就是和自己修炼的过程，在整个过程中需要对抗自己的贪，疑，痴，慢。是使用一个自己来战胜另一个自己的过程。时机，多层次的关系。</p>]]></content>
    
    
    
    <tags>
      
      <tag>填坑</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>填坑-AIGC和数字化新时代</title>
    <link href="/2024/05/16/tiankeng9/"/>
    <url>/2024/05/16/tiankeng9/</url>
    
    <content type="html"><![CDATA[<h2 id="开篇"><a href="#开篇" class="headerlink" title="开篇"></a>开篇</h2><p>2022年在集群式和聚变式的科技革命中，人工智能生成内容（AIGC， AI Generated Content）后来居上，以OpenAI的chatgpt（Chat Generative Pre-trained Transformer）为例，实现了自然语言与人工智能的融合，更进一步的通过大规模训练模型预训练模型，形成人工智能技术理解自然语言和文本生成能力，可以生成文字，语音、代码、图像、视频、而且能完成脚本编写、文案撰写、翻译等任务。GAN（生成对抗网络）的出现加快了AIGC的实现，Transformer在2021年8月被斯坦福大学的众多学者撰写论文，将Transformer架构的模型称为’基础模型’(Foundation model) 又译为大模型。<a href="https://arxiv.org/abs/2108.07258">论文链接</a>,人类大脑皮层有140亿个神经元，触突总数有100万亿个，GPT-3 最大模型有1750个参数，最近chat-gpt-4o出现，融合了多模态的模型。</p><p>1913年埃米尔.博雷尔发表《静力学与不可逆性》论文中提出： 假设猴子学会了任意按下打字机，当无限只猴子在无限台打字机上乱敲，并持续无限长的时间，在某个片刻，将会有猴子能打出莎士比亚的全部著作。其中的条件是无穷的时间量度和随机性。人工智能或许能够缩短这整个的时间量度。<br>万物的智能成本无限降低，人类生产力与创造力得到解放。 AIGC的生成能力极大的解放了人类的内容生产力，从PGC（专业生产，专家创作时代，专业人士来生产高质量内容，在wed1.0时代互联网内容大多是专家生产的。）、UGC（用户生产，用户创作，用户不仅是内容的创作消费者，也是内容的创作者。比如贴吧，豆瓣，微博，微信，抖音，快手）到AIGC（AI生产，人工智能创建文本，音频，图像，视频等各种模态的信息。最初的AIGC通常基于小模型展开，这类模型的一般需要特殊的标注数据，解决特定的问题，通用性较差。后来，大数据量，大参数量，强算法的大模型（Foundation Model）取代，这种形式的AIGC只需要经过微调或经过少量微调（Fine-tuning）就可以迁移到多种生成任务）。生产力是推进社会变革的根本动力，而生产工具则是衡量生产力发展水平的客观尺度，也是划分经济时代的物质标志。<br>2022年美国科罗拉多州博览会上数字艺术类冠军<a href="pic/space_opera_house.jpg">Spaec Opera House</a></p><p>人工智能赋能内容的创作的四大模态——文本、音频、图像、视频四大模态</p><ol><li>文本（Natural Language Processing ， 简称NLP）例子： AI结构化写作 GPT2——NewsTitle， 2017年，微软小冰 人类史上第一部AI编写的诗集《阳光失了玻璃窗》。  故事、剧本和小说， 2016年 人类史上第一部由AI撰写的剧本的电影《阳春》（sunspring）<a href="https://www.bilibili.com/video/BV1dx411879x/?spm_id_from=333.337.search-card.all.click">链接</a>.（看了之后觉得有点抽象。）2021年Netfix 发布了AI创作的电影《谜题先生希望你少活一点》（Mr Puzzles Wants You to Be Less Alive）<a href="https://www.bilibili.com/video/BV1s44y1x742/?vd_source=9814cf6702c46a0b906cb31de22baa58">链接</a>还是抽象，金句 他醉了，但被清醒所困扰。 文字类游戏，《AI 地下城2》 chatgpt </li><li>音频（Audio1） 文本转语音（Test to Speech， 简称：TTS） 短视频配音， AI歌曲生成， 比如腾讯在2020年推出的AI歌姬‘艾灵’ </li><li>图像生成，两种方向 图像编辑工具与图像自主生成。 图像编辑工具的功能包括去除水印、提高分辨率、特定滤镜等。 图像自主生成即 AI绘画，包括创意图像生成（时机或按照特定属性生成画作）与功能性图像生成（生成logo、模特图、营销海报） AI绘画大致可以分为三类： 借助文字描述（Prompt）生成图像、借助已有图像生成新图像，以及两者结合版。 AI绘画工具 Stable DIffusion , Midjourney，文心一格、意间AI绘画、AICreator等  </li><li>AI视频生成， AI技术不仅可以生成图片，也可以生成序列帧，组成一个完整的视频。 2022年10月 AI重置版《幻觉东京》发布， 2022年9月 Meta推出Make-A-video,根据文本描述生成相应短视频的能力。 AI换脸</li></ol><p>AIGC+ 元宇宙 2022年谷歌发布了文本生成3D文本模型DreamFUsion，可以通过生成3D物品模型，AIGC生成制作NFT，绘画风格确权，NFT+AIGC。HiiImeta就是这样一个集艺术风格的确权、授权和使用为一体的AI艺术生态。 </p><p>人们总喜欢活在舒适区内，用出粗暴的断言来安慰自己，例如机器永远无法模仿人类的某些特征。但我给不了这样的安慰，因为我认为并不存在无法模仿的人类特性。——艾伦.图灵 人工智能技术经历了漫长的演进过程，见证了基于规则、机器学习、深度学习、强化学习等领域的兴起。1950年，图灵在《计算机器与智能》提出了图灵测试，为人工智能的实现提供。人工智能于1956年达特茅斯学院举行的人工智能夏季研讨会，人工智能的名字和任务被真正界定下来。<br>符号主义、联结主义和行为主义。机器学习，感知器与神经网络，强化学习<br><a href="https://arxiv.org/abs/1701.07274">Deep Reinforcement Learning: An Overview</a></p><h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><p><a href="https://www.bilibili.com/video/BV1eU411o71r/?spm_id_from=333.337.search-card.all.click">Stable Diffusion</a><br>动漫 [瑞克和莫迪] [爱， 死亡机器人]</p>]]></content>
    
    
    
    <tags>
      
      <tag>填坑</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>高等数学 —— 多元函数微分学。</title>
    <link href="/2024/05/16/gaodengshuxue4/"/>
    <url>/2024/05/16/gaodengshuxue4/</url>
    
    <content type="html"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/348455980">多元函数微分学</a><br><a href="https://blog.csdn.net/Ding_Yifan/article/details/124489841">多元函数微分学-1</a><br>多元函数微分学。<br>多元函数的概念，二元函数的几何意义，二元函数的极限与连续的概念，有界闭区间上二元连续函数的性质，多元函数的偏导数和全微分，多元复合函数、隐函数的求导法，二阶偏导数，多元函数的极值和条件极值、最大值和最小值，二重积分的概念、基本性子和计算。<br><img src="/pic/gdsx-dyhswfx1.png" alt="多元函数微分学"></p><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><table><thead><tr><th align="left"></th></tr></thead><tbody><tr><td align="left"><img src="/pic/gdsx-hbs.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_01.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_02.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_03.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_04.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_05.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_06.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_07.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_08.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_09.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_10.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_11.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_12.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_21.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_22.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_23.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_24.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_25.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_26.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_27.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_28.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_29.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_30.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_31.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_32.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_33.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_34.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_35.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_36.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_37.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_38.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_39.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_40.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_41.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_42.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_43.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_44.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_45.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_46.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_47.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_48.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_49.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_50.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_51.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_52.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_53.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_54.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_55.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_56.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_57.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_58.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_59.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_60.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_61.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_62.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_63.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_64.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_65.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_66.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_67.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_68.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_69.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_70.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_71.png"></td></tr><tr><td align="left"><img src="/pic/gdsx-hbs_72.png"></td></tr></tbody></table>]]></content>
    
    
    
    <tags>
      
      <tag>高等数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>高等数学 —— 一元函数积分学</title>
    <link href="/2024/05/15/gaodengshuxue3/"/>
    <url>/2024/05/15/gaodengshuxue3/</url>
    
    <content type="html"><![CDATA[<p> 一元函数积分学。<br>原函数和不定积分的概念，不定积分的基本性质，基本积分公式，定积分的概念和基本性质，定积分中值定理，积分上限的函数及其导数，牛顿-莱布尼茨（Newton-Leibniz）公式，不定积分和定积分的换元积分法与分部积分法。<br>有理函数、三角函数的有理式和简单无理函数的积分，反常（广义）积分，定积分的应用（平面图形的面积，平面曲线的弧长，旋转体的体积及侧面积，平行截面积为已知的立体体积、功、引力、压力、质心、形心等）及函数平均值。</p><ul><li><p>原函数和不定积分：如果函数F的导数是f，即F’(x)&#x3D;f(x)，则称F是f的一个原函数。不定积分是指函数f(x)的所有原函数的集合，通常表示为∫f(x)dx。</p></li><li><p>不定积分的基本性质：线性性、常数积分、分部积分、换元积分法等。</p></li><li><p>基本积分公式：包括多项式函数、三角函数、指数函数、对数函数等的基本积分公式。</p></li><li><p>定积分的概念和基本性质：定积分表示曲线下面积，具有线性性、积分中值定理等性质。</p></li><li><p>定积分中值定理：若f(x)在[a,b]上连续，则存在ξ∈(a,b)，使得∫[a,b]f(x)dx&#x3D;(b-a)f(ξ)。</p></li><li><p>积分上限的函数及其导数：若f(x)在[a,b]上连续，则F(x)&#x3D;∫[a,x]f(t)dt是[a,b]上的连续可导函数，且F’(x)&#x3D;f(x)。</p></li><li><p>牛顿-莱布尼茨公式：若F(x)是f(x)的一个原函数，则∫[a,b]f(x)dx&#x3D;F(b)-F(a)。</p></li><li><p>换元积分法与分部积分法：换元积分法是利用复合函数的链式法则求不定积分，分部积分法是求不定积分中的乘积。</p></li><li><p>有理函数、三角函数的有理式和简单无理函数的积分：通过分式分解、三角函数的积分性质和简单无理函数的换元等方法求积分。</p></li><li><p>反常（广义）积分：对于某些函数或积分区间无限的情况，需要引入反常积分的概念，如无穷积分、瑕积分等。</p></li><li><p>定积分的应用：包括计算平面图形的面积、平面曲线的弧长、旋转体的体积及侧面积、平行截面积为已知的立体体积、功、引力、压力、质心、形心等。</p></li><li><p>函数平均值：定积分可以用来求函数在某个区间上的平均值，即函数在该区间上的积分除以区间长度。</p></li></ul><h2 id="自我总结"><a href="#自我总结" class="headerlink" title="自我总结"></a>自我总结</h2><p>换元积分法，分步积分法。</p>]]></content>
    
    
    
    <tags>
      
      <tag>高等数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔17</title>
    <link href="/2024/05/15/ganwu17/"/>
    <url>/2024/05/15/ganwu17/</url>
    
    <content type="html"><![CDATA[<p>实践的过程中取决于动机，今天的招聘会给我带来的感受是，虽然企业众多但是对于我的就业面却很窄，感受到现实和想法之间的差距。不过也挺好的，把差距看为进步的方向，自强的心态就是这样使用的。对于每个人都是立场的，都有自己的利益观点，做人不要尽可能的不要去侵犯他人的利益，和人交好要先给后取，切记只取不予。面试企业也是一样的，企业看重的是你能为企业解决什么问题，在我的立场中我就是为了找份事情干，能养活自己，先走一步看一步。<br>对应的书籍为:《原则：应对变化中的世界秩序》<a href="https://weread.qq.com/web/reader/19332dd0728b621d193d571k02e32f0021b02e74f10ece8">链接</a><br>世上聪明之人不少，看得透彻之人也不少，但聪明人往往狷介有余，宽厚不足。要知道，厚德载物比自强不息难上千万倍。越年长之人，当越对这种美好又脆弱的东西怀有柔情。唯有中二少年，才自以为看透了社会黑暗，嘲笑一切美好事物，事事都要发一番政治狂热。所谓心结，就是像这样执着于一种观念，乃至为之仇视鲜活的真情与生命。</p><p>之前有一种态度，觉得什么都很水，我自己去做一定能做的更好，这不是傲慢是什么？ </p><h2 id="挖坑：重看原则这本书。"><a href="#挖坑：重看原则这本书。" class="headerlink" title="挖坑：重看原则这本书。"></a>挖坑：重看原则这本书。</h2><p><a href="https://weread.qq.com/web/bookDetail/694329f0813ab7c0dg0179a5">原则（实践版）</a><br><a href="https://weread.qq.com/web/reader/19332dd0728b621d193d571k02e32f0021b02e74f10ece8">原则：应对变化中的世界秩序</a></p><p>我打电话找遍附近五个州，我说只有这样能让我老婆嫁给我。-你甚至还不认识我。-我有一辈子可以认识你。-I called everywhere in five states. I told them it was the only way to get my wife to marry me. -You don’t even know me. -I have the rest of my life to find out.</p><p>生命就是这样。说真的，走远路比较简单，但那比较长。Life will do that to you. And truthfully, the long way is easier. But it’s longer.</p><p>人们说当你遇上你的挚爱，时间会暂停，那是真的，但人们没有告诉你，当时间再度恢复转动，它会无比飞快，让人无法赶上。They say when you meet the love of your life, time stops. And that’s true. What they don’t tell you is that once time starts again……it moves extra fast to catch up.</p><p>就在当晚，我发现，你觉得最邪恶或最坏的事物，其实只是孤独，缺乏融洽的个性。That night, I discovered that most things you consider evil or wicked……are simply lonely and lacking in social niceties.</p><p>懂道理的人，终会有按下自尊，坦承他犯下严重错误的时刻。事实是，我一直都不是讲道理的人，我记得主日学都这么讲，事情愈艰难，最后愈能得到丰厚的果实。Now, there comes a point when a reasonable man……will swallow his pride and admit that he’s made a terrible mistake. The truth is, I was never a reasonable man. And what I recall of Sunday school was that……the more difficult something is, the more rewarding it is in the end.</p>]]></content>
    
    
    
    <tags>
      
      <tag>感悟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>目标检测——Fast R-CNN</title>
    <link href="/2024/05/15/deeplearnpaper8/"/>
    <url>/2024/05/15/deeplearnpaper8/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
    <tags>
      
      <tag>深度学习论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>目标检测——RCNN</title>
    <link href="/2024/05/15/deeplearnpaper7/"/>
    <url>/2024/05/15/deeplearnpaper7/</url>
    
    <content type="html"><![CDATA[<p>目标检测，最为经典的项目实例就是人脸检测，在paper with code<a href="https://paperswithcode.com/sota">链接</a> 网站中在Object Decection中包含大量案例，但是最为经典的还是RCNN，开山之作。</p><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>论文链接<a href="https://arxiv.org/abs/1311.2524">Rich feature hierarchies for accurate object detection and semantic segmentation</a><br><a href="https://zhuanlan.zhihu.com/p/23006190">参考链接</a><br><a href="https://github.com/yangxue0827/RCNN">代码实现</a></p><h2 id="算法过程"><a href="#算法过程" class="headerlink" title="算法过程"></a>算法过程</h2><p>CNN算法分为4个步骤</p><p>候选区域生成： 一张图像生成1K~2K个候选区域 （采用Selective Search 方法）<br>特征提取： 对每个候选区域，使用深度卷积网络提取特征 （CNN）<br>类别判断： 特征送入每一类的SVM 分类器，判别是否属于该类<br>位置精修： 使用回归器精细修正候选框位置</p>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>英语-作文</title>
    <link href="/2024/05/14/English/"/>
    <url>/2024/05/14/English/</url>
    
    <content type="html"><![CDATA[<p>一般来讲：英语作文分成三段就可以了。首段： 第一句话题引入，第二句，主题阐述。 中间段：过渡句。一方面，背景句+论据+论点。另一方面， not only, but also + 举例。 尾段： 总结， 建议措施（2个）</p><p>六级作文一般可以分为议论文，议论文——意义措施类， 议论文——观点选择类， 议论文——现象解释类， 议论文——谚语解释类， 议论文——图画类</p><h2 id="议论文——意义措施类"><a href="#议论文——意义措施类" class="headerlink" title="议论文——意义措施类"></a>议论文——意义措施类</h2><p>介绍，Your essay should include the importance of innovation and measures to be taken to encourage innovation&#x2F;creation&#x2F;invention. （关键词： innovation 创新。）</p><p>In a rapidly developing society,It is generally accepted that innovation plays a fundamental role in personal progress and national development.（话题引入句子，首段第一句， + 介词短语引入）Innovation,which is held by many to be core competitiveness,has captured a great deal of public attention.（首段第二句，话题阐述。 结构：主题词+ which（非限定性定语从句）+ 模板句）</p><p>在一个快速发展的社会中，人们普遍认为创新对个人进步和国家发展起着基础性作用发展、创新被许多人认为是核心竞争力的，引起了公众的极大关注。</p><p>As regards to the social implication of innovation,my discussion on the issue is mainly twofold.（过渡句）On the one hand,in a society where competition in job markets becomes increasingly fierce(stiff),an increasing number of people find it helpful to enhance our competitiveness.Thus,continuous self innovation is not a choice, but a must to meet the ever-growing demands of our society.（中间段第一方面:背景句+ 论据+ 论点）On the other hand,People with the spirit of innovation can not only accumulate various knowledge,but also can promote social science and technology innovation. For example,Einstein,honored for his success in the theory of relativism,is always remembered for the spirit of innovation,which makes him one of the greatest scientists.（另一方面，not noly，but also一定要分两个方面（一小一大）,小就是对于咱们个人，或者对于我们自己有什么影响；大就是对社会，对国家，乃至对于全人类有什么影响。）<br>关于创新的社会内涵，我的讨论有如下两个方面。第一一方面，在一个就业市场竞争日益激烈的社会中，越来越多的人发现这有助于提高我们的竞争力竞争力。因此，不断的自主创新不是一种选择，但必须满足我们国家日益增长的需求社会。另一方面，具有创新精神的人不仅可以积累各种知识，而且可以推动社会科技进步创新。为了例如，爱因斯坦因其在相对主义理论上的成功而受到尊敬，他以创新精神而被人们铭记，这使他成为最伟大的科学家之一。</p><p>To sum up, it is of great benefit for us to cultivate innovative spirit during college and learn how to create some new inventions.（总结： 直接套用）Specifically,The fundamental way in which the government advocates this spirit is to enhance people’s awareness.Meanwhile,the school should also join in the efforts in promoting quality-oriented education。（建议措施2个）<br>综上所述，在大学期间培养创新精神，学会创造新发明，对我们有很大好处。具体而言，政府倡导这种精神的根本途径是提高人民的意识。同时，学校也应该参与到推进素质教育的工作中来。</p><ol><li>首段的结构中，分为两个部分，话题引入+ 主题阐述。<br>首先，话题引入，主从句开头,从下面选取一个可以用来作为开头<br>There is little doubt that… 毫无疑问…<br>It cannot be denied that… 不可否认…<br>It is beyond doubt that… 毫无疑问…<br>It is generally accepted that… 人们普遍认为…<br>There is a growing recognition that… 人们越来越认识到…<br>It has been widely noted that… 人们普遍注意到…<br>It goes without saying that… 不用说的是…</li></ol><p>主题阐述：结构，主题词 + ,which(非限定性定语从句) + 模板句。（注： 主题词即议论文中的主题，比如上面的模板文章中的主题是innovation，）<br>which(非限定定语从句)<br>选择1：人们认为该现象… ,which is held by many to be…（be动词后面要么名词，要么加形容词）<br>选择2：带来…影响 ,which exerts a great impact&#x2F;a positive influence&#x2F;a negative impact on…</p><p>模板句<br>选择1：sth has&#x2F;have captured&#x2F;drawn one’s attention.某事吸引了某人的注意力<br>选择2：sth has&#x2F;have emerged into our vision.某事出现在我们的视野中。</p><ol start="2"><li>中间段：，包括，过渡句， 一方面（背景句+论据+论点），另一方面（not only， but aslo）</li></ol><p>过渡句<br>选择1：There are two fundamental factors contributing to this phenomenon.造成这种现象有两个基本因素。<br>选择2：As regards to the social implication of innovation,my discussion on the issue is mainly twofold.关于创新的社会影响，我的讨论主要有两个方面。</p><p>一方面（背景句+论据+论点）<br>背景句<br>社会竞争:In a society where competition in job markets becomes increasingly fierce(stiff),在一个就业市场竞争日益激烈的社会里，<br>发展(科技):In an age where globalization and information technology revolution are developing(advancing) rapidly,在全球化和信息技术革命迅猛发展的时代，<br>发展(经济):In an age where people’s standard of living has been raised significantly,在人民生活水平大幅度提高的时代，<br>教育:In an age where parents and educators always focus on sth，在一个父母和教育者总是关注某件事的时代，<br>媒体:In an age where sth have（not）been highly advocated in mass media,在一个大众传媒一直大力提倡某事的时代，</p><p>论据<br>an increasing number of people find it helpful&#x2F;difficult&#x2F;harmful to enhance our competitiveness.（竞争力）越来越多的人发现提高我们的竞争力是有益的。<br>这个句型的基本结构是sb find it +形容词+ to do sth。<br>“紧跟不断变化的社会（to to keep up with the change of society）”</p><p>论点<br>Thus continuous self innovation is not a choice, but a must to meet the ever-growing demands of our society.因此，不断的自主创新不是一种选择，而是满足社会日益增长的需求的必然选择。（语气较强烈）<br>另一方面（（not only， but aslo）一大一小）<br>小<br>not only，but also你可能用到的语句我给你总结出来了：（写作素材）<br>overcome difficulties and challenges 克服困难和挑战<br>achieve success 取得成功<br>accumulate knowledge 增长知识 broaden our horizons 开拓视野 expand social circle 扩大社交圈<br>enrich our minds(lives) 丰富我们的思想（生活）<br>protect our living environment and conserve energy 保护环境，节约能源<br>promote social harmony 增进社会和谐<br>preserve and carry forward traditional Chinese culture 保护和发扬中国传统文化</p><p>大<br>大家举例时要注意，举具体的人或事，比如姚明，屠呦呦，华为，苹果等这些具体的事物，然后套用举例模板：<br>1.创新话题：For example,Einstein,honored for his success in the theory of relativism,is always remembered for the spirit of innovation,which makes him one of the greatest scientists.（划线的地方是你要结合话题写的，其他的地方直接套用即可。）例如，爱因斯坦因其在相对主义理论上的成功而受到表彰，他因其创新精神而被人们铭记，这使他成为最伟大的科学家之一。<br>我作为阅卷老师，只需要看到你与话题结合即可，至于你具体写的啥内容我不是很在意。再举一个例子：<br>2.合作话题：For instance,Apple,honored for its success in mobile phone and personal computer,is always remembered for its collaboration with Google in software,which makes them the most competitive technology company in the world.例如，苹果公司因其在手机和个人电脑领域的成功而备受赞誉，却因其与谷歌在软件领域的合作而被人们铭记，这使他们成为世界上最具竞争力的科技公司。（只需要在划线部分与话题结合即可）<br>3.教育：For instance,Confucius,honored for his success in education and philosophy in ancient times,is always remembered for showing a great respect to others,which makes him the most famous educator and philosopher.例如，孔子在古代因其在教育和哲学方面的成就而受到尊崇，他因对他人的尊重而被人们铭记，这使他成为最著名的教育家和哲学家。</p><ol start="3"><li>尾段（总结，建议措施）<br>总结<br>To sum up&#x2F;Based on the reasons above, it is of great benefit for us to cultivate innovative spirit during college and learn how to create some new inventions. 综上所述，在大学期间培养创新精神，学会创造新发明，对我们有很大好处。</li></ol><p>建议措施<br>措施1：Specifically,The fundamental way in which the government advocates this spirit is to enhance people’s awareness.具体来说，政府倡导这一精神的根本途径就是增强人们的觉悟。（模板句直接套用，也可以在划线部分体现出主题词，任何话题都可以从政府的角度去写）<br>措施2：Meanwhile,the school should also join in the efforts in promoting quality-oriented education.同时，学校也要参与到素质教育的推进中来。（学校或媒体，直接套用即可）</p><h2 id="议论文——观点选择类"><a href="#议论文——观点选择类" class="headerlink" title="议论文——观点选择类"></a>议论文——观点选择类</h2><p>观点选择类，顾名思义，就是两个观点二选一。例如：Directions: Suppose you are asked to give advice on whether to major in humanities or science, write an essay to state your opinion. You are required to write at least 150 words but no more than 200 words.选文科还是选理科？</p><p>观点选择类完整模板演示：<br>In modern society,it is generally accepted that higher education plays a fundamental role in personal progress and national development.（话题引入（依然是介词短语+主语从句引导））Opinions vary greatly when it comes to whether one should choose science or humanities at college.If I were you,I would like to take science as my major.（话题阐述（观点选择类特有阐述框架））<br>在现代社会，人们普遍认为高等教育对个人进步和国家发展起着基础性作用.意见在选择科学还是人文科学的问题上，差别很大。如果我是你，我想主修理科。</p><p>There are two fundamental factors contributing to my preference.（中间段第一句（过渡句，直接套用之前的模板即可）） In a society where competition in job markets becomes increasingly fierce,an increasing number of teenagers find it helpful that learning science can obtain a decent job.Thus,majoring scientic knowledge is a wise choice to meet the ever-growing demands of our society.（中间段第一方面：背景句+论据+论点（3个部分）） science not only can improve ourselves to meet the ever-growing demands of our society,but also can push the whole human race forward. If it were not for the science and technology,our daily life today would not be so convenient and colorful.（中间段第二方面：not only,but also+if虚拟语气）<br>有两个基本因素解释了我的偏好。一方面，在就业市场竞争日益激烈的社会中，越来越多的青少年发现学习科学能获得体面的工作是有帮助的工作。因此,主修理科是满足我们社会日益增长的需求的明智选择。另一方面，科学不仅可以提高我们自己，以满足我们社会日益增长的需求，而且可以推动整个人类向前发展。如果没有理科和科学技术，我们今天的日常生活就不会如此方便多彩。</p><p>To sum up, it is of great benefit for our college students to choose siience as our major in university and learn actively more innovative knowledge in technology and science.（尾段第一句：总结）Specifically,The fundamental way in which the government and school advocate students from different backgrounds is to study science.（题目中并没有明确要求我们写措施，所以我们写“一个措施”即可，如果字数不够，可以写两个措施）<br>综上所述，选择理科作为大学的专业，积极学习更多的科技创新知识，对我国大学生有很大的帮助。具体而言，根本途径是政府和学校倡导不同背景的学生学习理科。</p><h2 id="议论文——现象解释类"><a href="#议论文——现象解释类" class="headerlink" title="议论文——现象解释类"></a>议论文——现象解释类</h2><p>Directions：For this part, you are allowed 30 minutes to write a short essay on the use of robots. Try to imagine what will happen when more and more robots take the place of human beings in industry as well as people’s daily lives. You are required to write at least 150 words but no more than 200 words.想象越来越多的机器人替代人类的工作和生活会发生什么。</p><p>In a rapidly developing society, There is little doubt that the development of technology plays an increasingly important role in our life. （话题引入（依然是介词短语+主语从句引导）Robots,which is held by many to be controversial,has captured a great deal of public attention if robots replace human beings in the future.（话题阐述，结构：主题词+,which(非限制性定语从句)+模板句）<br>在一个快速发展的社会中，毫无疑问，科技的发展在我们的生活中扮演着越来越重要的角色。机器人被许多人认为是有争议的，如果机器人在未来取代人类的话，会引起公众的极大关注。（注意“话题阐述”部分的区别）</p><p>As regards to the social implication of robots,my discussion on the issue is mainly twofold. （中间段第一句（过渡句，直接套用之前的模板即可））In an age where globalization and information technology revolution are developing(advancing) rapidly,an increasing number of people find it increasingly difficult to find a proper job for them. Thus,Changing traditional way of thinking in work is not a choice,but a must to meet the ever-growing demands of our society.（中间段第一方面：背景句+论据+论点（3个部分）） High-skilled working abilities not only can give people an opportunity to increase your income,but also will not be replaced by robots. If people always work with traditional thinking, they will be replaced by robots.（中间段第二方面：not only,but also+if条件状语（依然是用”if”替代“举例”的方案，但是大家一定要搞清楚“条件状语从句”和“虚拟语气”的区别，）<br>关于机器人的社会影响，我对这个问题的讨论主要有两个方面。在全球化和信息技术革命迅猛发展的时代，越来越多的人发现找一份适合自己的工作越来越困难。因此，改变传统的工作方式不是一种选择，而是必须，从而满足我们社会日益增长的需求。高技能的工作能力不仅能给人们增加收入的机会，而且不会被机器人取代。如果人们总是用传统的思维方式工作，他们将被机器人所取代。</p><p>To sum up, it is of great benefit for us to cultivate innovative thinking when we work and learn how to learn knowledge in high-skilled jobs.（尾段第一句：总结）Specifically,The fundamental way is that the government advocates sensible use of robots balance the relationship between human beings and robots.Meanwhile,the school should also join in the efforts in studying innovative knowledge.<br>综上所述，在工作中培养创新思维，学习如何在高技能工作中学习知识，对我们大有好处(尾段第一句:总结)具体来说，根本的方法是政府提倡合理使用机器人，平衡人与机器人的关系。同时，学校也应该参与到创新知识的学习中来。</p><h2 id="议论文——谚语警句类"><a href="#议论文——谚语警句类" class="headerlink" title="议论文——谚语警句类"></a>议论文——谚语警句类</h2><p>Directions: For this part, you are allowed 30 minutes to write an essay commenting on the saying “Respect others, and you will be respected. “ You can cite examples to illustrate your views. You should write at least 150 words but no more than 200 words.</p><p>In modern society, There is little doubt that the respect plays an increasingly important role in interpersonal relationship. Just as the saying goes, “Respect others, and you will be respected”,which exerts a positive influence on daily communication.<br>人际关系中扮演着越来越重要的角色。正如俗话所说，“尊重别人，你就会被尊重”，这对日常交流产生了积极的影响。</p><p>There are two fundamental factors cited to account for this saying.On the one hand,In an age where people’s standard of living has been raised significantly,an increasing number of people find it helpful to bring people closer. Thus respecting others is not a choice,but a must to satisfy the need of people‘s self-esteem.On the other hand,Being respected not only plays an indispensable role in gaining respect from others but also contributes to the construction of a harmonious society.For instance, Confucius, a great philosopher of ancient times in China, was very polite and showed a great respect to Laozi,and Laozi treated Confucius in a respective manner in return.<br>有两个基本因素可以用来解释这句话。在人民生活水平大幅度提高的时代，越来越多的人发现尊重帮助拉近人们的距离。因此，尊重他人不是一种选择，而是满足人们自尊需要的必要条件。尊重他人不仅对赢得他人的尊重起着不可或缺的作用，而且有助于构建和谐社会。例如，孔子在古代因其在教育和哲学方面的成就而受到尊崇，他因对他人的尊重而被人们铭记，这使他成为最著名的教育家和哲学家。</p><p>To sum up,it is of great benefit for us to cultivate equal thinking and learn how to repsect others.Specifically,The fundamental way is that the government advocates a wholesome atmosphere to publicize the importance of mutual respect.Meanwhile,the school should also join in the efforts in promoting quality-oriented education.<br>综上所述，培养平等思维，学会代表他人，对我们非常有好处。具体而言，根本途径是政府倡导一种健康的氛围，以强调相互尊重的重要性。同时，学校也要参与到素质教育的推进中来。</p>]]></content>
    
    
    
    <tags>
      
      <tag>英语</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>英语-单词</title>
    <link href="/2024/05/14/English2-1/"/>
    <url>/2024/05/14/English2-1/</url>
    
    <content type="html"><![CDATA[<p>Babies suck their thumbs for comfort. (Suck: 吮吸)<br>  婴儿吮吸他们的拇指以获得安慰。</p><ul><li><p>She wrote a biography of the famous artist. (Biography: 传记)<br>她写了一部著名艺术家的传记。</p></li><li><p>They went canoeing on the river. (Canoe: 独木舟)<br>他们在河上划独木舟。</p></li><li><p>He gazed out of the window at the beautiful view. (Gaze: 凝视)<br>他凝视着窗外美丽的景色。</p></li><li><p>She sipped her drink through a straw. (Straw: 吸管)<br>她用吸管慢慢地喝着饮料。</p></li><li><p>The total cost of the project was much higher than expected. (Total: 总的)<br>项目的总成本远远超出了预期。</p></li><li><p>I feel happy when I’m with my friends. (Feel: 感觉)<br>和朋友在一起时，我感觉很开心。</p></li><li><p>Hold the rope tightly so it doesn’t slip. (Hold: 抓住)<br>抓紧绳子，不要让它滑掉。</p></li><li><p>Iron deficiency can lead to fatigue and weakness. (Deficiency: 缺乏)<br>缺铁会导致疲劳和虚弱。</p></li><li><p>According to the weather forecast, it will rain tomorrow. (According to: 根据)<br>根据天气预报，明天会下雨。</p></li><li><p>The cut on his hand started to bleed. (Bleed: 流血)<br>他手上的伤口开始流血。</p></li><li><p>The fields were full of golden wheat. (Wheat: 小麦)<br>田野里满是金黄色的小麦。</p></li><li><p>He was seen as a traitor by his former colleagues. (Traitor: 叛徒)<br>他被他以前的同事视为叛徒。</p></li></ul><ol start="2"><li></li></ol><ul><li><p>She has a deep understanding of the subject. (Understanding: 理解)<br>她对这个课题有着深刻的理解。</p></li><li><p>The children dressed up as fairies for the party. (Fairy: 仙女)<br>孩子们为派对装扮成了仙女。</p></li><li><p>The walls were painted a bright yellow. (Yellow: 黄色)<br>墙壁被涂成了明亮的黄色。</p></li><li><p>They sailed to a remote isle for their vacation. (Isle: 小岛)<br>他们航行到了一个偏远的小岛度假。</p></li><li><p>The project is in the final phase now. (Phase: 阶段)<br>该项目现在进入了最后阶段。</p></li><li><p>The bed was comfortable and soft. (Comfortable: 舒适的)<br>床又舒适又软。</p></li><li><p>The statue was made of metal. (Metal: 金属)<br>雕像是用金属制成的。</p></li><li><p>There has been an increase in the incidence of flu this year. (Incidence: 发生率)<br>今年流感发病率有所增加。</p></li><li><p>The technician repaired the computer quickly. (Technician: 技术员)<br>技术员很快修好了电脑。</p></li><li><p>They went to the temple to worship. (Worship: 崇拜)<br>他们去寺庙做礼拜。</p></li><li><p>We need to decide on a date for the meeting. (Decide: 决定)<br>我们需要决定一个会议日期。</p></li><li><p>She was an eloquent speaker, captivating the audience with her words. (Eloquent: 雄辩的)<br>她是一个雄辩的演讲者，她的话语让听众着迷。</p></li><li><p>They took shelter from the rain under a tree. (Shelter: 庇护所)<br>他们在树下避雨。</p></li><li><p>The historian wrote a detailed account of the war. (Historian: 历史学家)<br>历史学家详细记录了这场战争。</p></li><li><p>The concert was held in a large auditorium. (Auditorium: 礼堂)<br>音乐会在一个大礼堂举行。</p></li></ul><ol start="3"><li></li></ol><ul><li><p>The proposal was approved by a majority of the members. (Majority: 多数)<br>提案获得了大多数成员的批准。</p></li><li><p>The painting turned out to be a fake. (Fake: 伪造的)<br>这幅画原来是假的。</p></li><li><p>The exam was difficult, but I managed to pass. (Difficult: 困难的)<br>考试很难，但我设法通过了。</p></li><li><p>They walked along the shore, enjoying the sound of the waves. (Shore: 海岸)<br>他们沿着海岸走，享受着海浪的声音。</p></li><li><p>His opinion on the matter is purely subjective. (Subjective: 主观的)<br>他对这个问题的看法纯粹是主观的。</p></li><li><p>She used a sponge to clean the kitchen counter. (Sponge: 海绵)<br>她用海绵擦洗厨房台面。</p></li><li><p>The queen visited the school to meet the students. (Queen: 女王)<br>女王访问了学校，见到了学生们。</p></li><li><p>The country celebrated the anniversary of its conquest. (Conquest: 征服)<br>这个国家庆祝征服周年纪念。</p></li><li><p>He was praised for his saving of the child from the fire. (Saving: 挽救)<br>他因为从火灾中挽救孩子而受到表扬。</p></li><li><p>There was a minor incident at the factory, but no one was hurt. (Minor: 微小的)<br>工厂发生了一起小事故，但没有人受伤。</p></li><li><p>The ancient artifacts were found intact in the tomb. (Intact: 完整的)<br>古代文物在墓穴中被发现完好无损。</p></li><li><p>The citizens showed their patriotic spirit during the national anthem. (Patriotic: 爱国的)<br>公民们在国歌响起时展现了他们的爱国精神。</p></li><li><p>The explosive device was safely removed by the bomb squad. (Explosive: 爆炸性的)<br>爆炸装置被爆炸物处理小组安全地移除了。</p></li><li><p>The scientist used a complex apparatus to conduct the experiment. (Apparatus: 设备)<br>科学家使用复杂的设备进行实验。</p></li><li><p>His account of the events corresponded with the witness’s testimony. (Correspond: 符合)<br>他对事件的描述与证人的证词相符。</p></li></ul><ol start="4"><li></li></ol><ul><li><p>He spoke loudly, emphasizing each word. (Adverb: 副词)<br>他大声说话，强调每个词。</p></li><li><p>Please provide a sample of your work for our review. (Sample: 样本)<br>请提供您的一份工作样本供我们审查。</p></li><li><p>He was idle for most of the day, just lounging around. (Idle: 懒散的)<br>他大部分时间都很懒散，整天无所事事。</p></li><li><p>The pump was used to remove water from the basement. (Pump: 泵)<br>泵被用来将地下室的水抽出。</p></li><li><p>The lateral movement of the car caused it to skid off the road. (Lateral: 侧面的)<br>汽车的横向移动导致它滑出了道路。</p></li><li><p>The chamber was filled with smoke after the explosion. (Chamber: 室，腔)<br>爆炸后，房间里充满了烟雾。</p></li><li><p>The circular shape of the table made it easy to fit in the corner. (Circular: 圆形的)<br>桌子的圆形使其容易放在角落里。</p></li><li><p>I bumped into an old classmate at the grocery store. (Classmate: 同学)<br>我在杂货店里碰到了一个老同学。</p></li><li><p>The price of the product is ten cents. (Cent: 分)<br>这个产品的价格是十分之一美元。</p></li><li><p>The general consensus was that the plan needed to be revised. (General: 一般的)<br>普遍的共识是需要修改计划。</p></li><li><p>There was a small slit in the curtain, allowing a beam of light to enter the room. (Slit: 狭缝)<br>窗帘上有一个小狭缝，允许一束光进入房间。</p></li><li><p>He injured his shoulder while playing football. (Shoulder: 肩膀)<br>他在踢足球时伤到了肩膀。</p></li><li><p>She always carries a notebook with her to jot down ideas. (Notebook: 笔记本)<br>她总是随身携带一个笔记本来记录想法。</p></li><li><p>The statute of limitations for the crime had expired. (Statute: 法令)<br>该犯罪的诉讼时效已过。</p></li><li><p>The kid was excited to go to the zoo for the first time. (Kid: 孩子)<br>孩子第一次去动物园很兴奋。</p></li></ul><ol start="5"><li></li></ol><ul><li><p>She is a famous actress known for her award-winning performances. (Famous: 著名的)<br>她是一位著名的女演员，以她屡获殊荣的表演而闻名。</p></li><li><p>The recipient of the scholarship was announced at the ceremony. (Recipient: 接受者)<br>奖学金的获得者在仪式上宣布。</p></li><li><p>I owe you an apology for my behavior yesterday. (Owe: 欠)<br>我应该为昨天的行为向你道歉。</p></li><li><p>The external appearance of the building was impressive. (External: 外部的)<br>建筑物的外部外观令人印象深刻。</p></li><li><p>He had a nightmare about being chased by a monster. (Nightmare: 噩梦)<br>他做了一个被怪物追赶的噩梦。</p></li><li><p>She uses her laptop to work remotely from home. (Laptop: 笔记本电脑)<br>她用笔记本电脑在家远程工作。</p></li><li><p>The longitude and latitude coordinates were used to pinpoint the location. (Longitude: 经度)<br>经度和纬度坐标被用来确定位置。</p></li><li><p>The computer chip is responsible for processing information. (Chip: 芯片)<br>计算机芯片负责处理信息。</p></li><li><p>The theory behind the experiment was complex. (Theory: 理论)<br>实验背后的理论很复杂。</p></li><li><p>How do you relate to the characters in this novel? (Relate: 关联)<br>你如何与这本小说中的角色产生共鸣？</p></li><li><p>There is a wide variety of fruits available at the market. (Variety: 种类)<br>市场上有各种各样的水果。</p></li><li><p>His speech left a lasting impression on the audience. (Impression: 印象)<br>他的演讲给观众留下了深刻的印象。</p></li><li><p>He decided to run for mayor in the upcoming election. (Run: 竞选)<br>他决定在即将到来的选举中竞选市长。</p></li><li><p>All that remains of the ancient city are its ruins. (Remains: 遗迹)<br>古城的遗迹是它的一切。</p></li></ul><ol start="6"><li></li></ol><ul><li><p>We boarded the ship and set sail for our destination. (Aboard: 在船上)<br>我们登上船，启航前往目的地。</p></li><li><p>She decided to skim through the report to get a general idea. (Skim: 略读)<br>她决定略读报告，获取一个大致的了解。</p></li><li><p>The vertical lines on the paper formed a grid. (Vertical: 垂直的)<br>纸张上的垂直线形成了一个网格。</p></li><li><p>The company plans to promote several employees to management positions. (Promote: 提升)<br>公司计划将几名员工提升为管理职位。</p></li><li><p>Please boil the water before drinking it. (Boil: 煮沸)<br>请把水煮沸后再喝。</p></li><li><p>The weather forecast is gloomy, predicting rain for the next few days. (Gloomy: 阴沉的)<br>天气预报很阴沉，预测接下来几天会下雨。</p></li><li><p>The term “Negro” is now considered outdated and offensive. (Negro: 黑人)<br>“Negro”这个词现在被认为是过时和冒犯性的。</p></li><li><p>Add salt and pepper to taste. (Add: 添加)<br>按口味加盐和胡椒。</p></li><li><p>He suffered from acute pain in his back. (Acute: 急性的)<br>他背部剧烈疼痛。</p></li><li><p>Please make a note of the meeting time. (Note: 记录)<br>请记下会议时间。</p></li><li><p>She mashed the potatoes and served them with butter. (Potato: 马铃薯)<br>她把马铃薯捣碎，加上黄油。</p></li><li><p>The doctor will induce labor to help with the delivery. (Induce: 诱导)<br>医生将诱导分娩来帮助分娩。</p></li><li><p>The two countries agreed to increase trade between them. (Trade: 贸易)<br>这两个国家同意增加彼此之间的贸易。</p></li></ul><ol start="7"><li></li></ol><ul><li><p>My surname is Smith. (Surname: 姓氏)<br>我的姓氏是史密斯。</p></li><li><p>The old building is being used as a community center. (Used: 被使用)<br>这座旧建筑被用作社区中心。</p></li><li><p>She gave the bucket a whirl and watched it spin. (Whirl: 旋转)<br>她使桶快速旋转，并观察它旋转。</p></li><li><p>The company’s security breach compromised thousands of customer accounts. (Breach: 违反，裂缝)<br>公司的安全漏洞影响了数千个客户账户。</p></li><li><p>The house is well insulated, so it stays warm in the winter. (Insulate: 隔离，使绝缘)<br>这座房子隔热效果很好，所以冬天保持温暖。</p></li><li><p>Eggs are a common ingredient in many recipes. (Ingredient: 成分，原料)<br>鸡蛋是许多食谱中常见的成分。</p></li><li><p>It’s normal to feel nervous before a big exam. (Normal: 正常的)<br>在一次重要考试之前感到紧张是正常的。</p></li><li><p>The path through the forest was overgrown and hard to follow. (Path: 路径)<br>穿过森林的小路长满了草，很难跟随。</p></li><li><p>The word “home” has different meanings for different people. (Meaning: 意义)<br>“家”这个词对不同的人有不同的意义。</p></li><li><p>Marine life refers to organisms that live in the sea. (Marine: 海洋的)<br>海洋生物指的是生活在海洋中的生物。</p></li><li><p>She received a letter from her friend who was studying abroad. (Letter: 信件)<br>她收到了一封来自正在国外留学的朋友的信。</p></li><li><p>The controversial decision sparked heated debate among the members. (Controversy: 争议)<br>这个有争议的决定引发了成员之间的激烈争论。</p></li><li><p>The hawk soared high in the sky, searching for its next meal. (Hawk: 鹰，掠夺者)<br>鹰在天空中高飞，寻找下一顿食物。</p></li></ul><ol start="8"><li></li></ol><ul><li><p>Many people emigrate from their home countries in search of better opportunities. (Emigrate: 移民)<br>许多人为了寻找更好的机会而移民到其他国家。</p></li><li><p>Nuts are a good source of protein and healthy fats. (Nut: 坚果)<br>坚果是蛋白质和健康脂肪的良好来源。</p></li><li><p>The voyage across the ocean took several weeks. (Voyage: 航行)<br>穿越海洋的航行持续了几个星期。</p></li><li><p>It’s important to use proper grammar when writing formal documents. (Proper: 适当的)<br>在撰写正式文件时使用正确的语法很重要。</p></li><li><p>She was exceedingly happy to hear the good news. (Exceedingly: 极其)<br>她听到好消息后非常高兴。</p></li><li><p>I’m going to bake a pie for dessert. (Pie: 派)<br>我打算做一个派作为甜点。</p></li><li><p>The study focused on quantitative analysis of the data. (Quantitative: 定量的)<br>这项研究着重于对数据的定量分析。</p></li><li><p>The company’s stock prices have been steadily increasing. (Stock: 股票)<br>公司的股价一直在稳步上升。</p></li><li><p>The opposite of “hot” is “cold”. (Opposite: 相反的)<br>“热”的反义词是“冷”。</p></li><li><p>I intend to finish reading this book by the end of the week. (Intend: 打算)<br>我打算在本周结束前读完这本书。</p></li><li><p>“Break a leg” is an idiom that means good luck. (Idiom: 成语)<br>“祝你好运”是一个意为好运的成语。</p></li><li><p>She received her diploma after completing her studies. (Diploma: 文凭)<br>她在完成学业后获得了文凭。</p></li></ul><ol start="9"><li></li></ol><ul><li><p>The region has its own unique dialect that differs from standard language. (Dialect: 方言)<br>这个地区有着与标准语言不同的独特方言。</p></li><li><p>They arrived in the afternoon, just in time for lunch. (Afternoon: 下午)<br>他们在下午抵达，正好赶上午饭时间。</p></li><li><p>The helicopter landed on the rooftop to evacuate the injured. (Helicopter: 直升机)<br>直升机降落在屋顶上，撤离受伤者。</p></li><li><p>Can you answer the phone while I’m away? (Answer: 回答)<br>我不在的时候，你能接电话吗？</p></li><li><p>She tied a knot in the rope to secure it. (Knot: 结)<br>她在绳子上打了个结来固定它。</p></li><li><p>The pie crust was perfectly golden and crispy. (Crust: 面包皮)<br>派饼皮呈现出完美的金黄色，脆脆的。</p></li><li><p>He was known for his evil deeds and cruel intentions. (Evil: 邪恶)<br>他以邪恶的行为和残忍的意图而闻名。</p></li><li><p>The train was delayed due to track maintenance. (Delay: 延迟)<br>火车因轨道维护而延误了。</p></li><li><p>The new product received a lot of publicity before its launch. (Publicity: 宣传)<br>这个新产品在推出前受到了很多宣传。</p></li><li><p>Please keep this information confidential. (Keep: 保持)<br>请保密这些信息。</p></li><li><p>The professor’s counterpart in the other department is equally respected. (Counterpart: 对应物)<br>另一个部门的教授同样受到尊敬。</p></li><li><p>The party had a medieval theme with costumes and decorations. (Theme: 主题)<br>派对以中世纪为主题，有着服装和装饰。</p></li><li><p>The old mill by the river has been converted into a museum. (Mill: 磨坊)<br>河边的老磨坊已经改建成了博物馆。</p></li><li><p>He hurled the ball across the field in a powerful throw. (Hurl: 猛投)<br>他用力将球投向球场的另一边。</p></li><li><p>Her answer was accurate and well-researched. (Accurate: 准确的)<br>她的回答准确无误，经过深入研究。</p></li><li><p>The bathroom is located at the end of the hallway. (Bathroom: 浴室)<br>浴室位于走廊的尽头。</p></li></ul><ol start="10"><li></li></ol><ul><li><p>The video player allows you to embed videos directly into your website. (Embed: 嵌入)<br>视频播放器允许您将视频直接嵌入到您的网站中。</p></li><li><p>The community came together to sustain each other during the difficult times. (Sustain: 支撑)<br>社区在艰难时期团结一致，互相支持。</p></li><li><p>They decided to alternate the leadership role every month. (Alternate: 交替)<br>他们决定每个月轮流担任领导角色。</p></li><li><p>The new technology is designed to propel the spacecraft forward. (Propel: 推进)<br>新技术旨在推进航天器前进。</p></li><li><p>The literacy rate in the region has seen a significant improvement. (Literacy: 识字能力)<br>该地区的识字率有了显著提高。</p></li><li><p>She used art to express her emotions and thoughts. (Express: 表达)<br>她用艺术来表达自己的情感和思想。</p></li><li><p>The assembly of the furniture took several hours. (Assembly: 装配)<br>家具的组装花了几个小时的时间。</p></li><li><p>The ox pulled the heavy cart with ease. (Ox: 牛)<br>牛轻松地拉着沉重的车。</p></li><li><p>The fare for the bus ride was quite reasonable. (Fare: 车费)<br>公交车费相当合理。</p></li><li><p>After careful consideration, she decided to accept the job offer. (Consideration: 考虑)<br>经过仔细考虑，她决定接受这份工作。</p></li><li><p>She stood out from the crowd with her vibrant presence. (Presence: 出现)<br>她以她充满活力的存在感脱颖而出。</p></li><li><p>The clerk at the store was busy attending to customers. (Clerk: 店员)<br>商店的店员忙着接待顾客。</p></li><li><p>He had to yell to be heard over the noise of the crowd. (Yell: 大声喊叫)<br>他不得不大声喊叫才能在人群的嘈杂声中被听到。</p></li></ul><ol start="11"><li></li></ol><ul><li><p>The town is located in the middle of the valley. (Middle: 中间)<br>小镇位于山谷中间。</p></li><li><p>Aluminum is a lightweight metal commonly used in aerospace applications. (Aluminum: 铝)<br>铝是一种轻质金属，常用于航空航天应用。</p></li><li><p>I reckon it will take us about an hour to reach the destination. (Reckon: 估计)<br>我估计我们到达目的地需要大约一个小时。</p></li><li><p>The device is designed to monitor heart rate during exercise. (Device: 设备)<br>这个设备旨在监测运动期间的心率。</p></li><li><p>She was able to recognize her old friend despite not having seen him in years. (Recognize: 认出)<br>尽管多年未见，她仍能认出她的老朋友。</p></li><li><p>He couldn’t stop the sudden sneeze. (Sneeze: 打喷嚏)<br>他无法阻止突然的打喷嚏。</p></li><li><p>It’s polite to greet someone when you meet them. (Greet: 问候)<br>见到别人时打招呼是礼貌的。</p></li><li><p>He was labeled a coward for refusing to confront his fears. (Coward: 胆小鬼)<br>他因拒绝面对自己的恐惧而被贴上懦夫的标签。</p></li><li><p>The magazine publishes quarterly, with a new issue every three months. (Quarterly: 季度)<br>该杂志每季度出版一次，每三个月发布一期。</p></li><li><p>The police made an arrest in connection with the robbery. (Arrest: 逮捕)<br>警方因抢劫案逮捕了一人。</p></li><li><p>The temperature dropped significantly overnight. (Temperature: 温度)<br>温度在一夜之间大幅下降。</p></li><li><p>The museum welcomes thousands of visitors each year. (Visitor: 访客)<br>博物馆每年迎来成千上万的访客。</p></li><li><p>The antenna on the roof receives television signals. (Antenna: 天线)<br>屋顶上的天线接收电视信号。</p></li><li><p>The circumference of a circle is calculated using the formula 2πr. (Circumference: 圆周)<br>圆的周长用公式2πr来计算。</p></li><li><p>She is a well-known actress with a long list of successful films. (Well-known: 知名的)<br>她是一位知名的女演员，出演了一系列成功的电影。</p></li></ul><ol start="12"><li></li></ol><ul><li><p>She enjoys painting landscapes in her free time. (Painting: 绘画)<br>她喜欢在空闲时间里画风景。</p></li><li><p>The old house looked shabby and in need of repair. (Shabby: 破旧的)<br>这座老房子看起来破烂不堪，需要修理。</p></li><li><p>He plays golf every Saturday morning. (Golf: 高尔夫球)<br>他每个星期六早上打高尔夫球。</p></li><li><p>They decided to ride their bikes to the park. (Ride: 骑)<br>他们决定骑自行车去公园。</p></li><li><p>He’s an amateur photographer who enjoys taking pictures as a hobby. (Amateur: 业余的)<br>他是一位业余摄影师，喜欢摄影作为业余爱好。</p></li><li><p>She is the reigning champion of the tennis tournament. (Champion: 冠军)<br>她是这次网球比赛的卫冕冠军。</p></li><li><p>Don’t forget to feed the cat while we’re away. (Feed: 喂养)<br>我们离开时别忘了喂猫。</p></li><li><p>It’s cruel to treat animals poorly. (Cruel: 残忍的)<br>对待动物不好是残忍的。</p></li><li><p>The knight raised his shield to block the attack. (Shield: 盾牌)<br>骑士举起盾牌挡住了攻击。</p></li><li><p>They went on a cruise around the Caribbean. (Cruise: 巡航)<br>他们环加勒比海进行了一次巡航。</p></li><li><p>Kindness is a virtue that should be practiced every day. (Kindness: 仁慈)<br>仁慈是一种应该每天都要实践的美德。</p></li><li><p>The waitress brought us our drinks with a smile. (Waitress: 女服务员)<br>女服务员面带微笑地给我们端来了饮料。</p></li><li><p>The car ran out of gas on the way to the gas station. (Gas: 汽油)<br>车在去加油站的路上没油了。</p></li><li><p>Climbing Mount Everest was a huge challenge, but he did it. (Challenge: 挑战)<br>爬珠穆朗玛峰是一个巨大的挑战，但他做到了。</p></li></ul><ol start="13"><li></li></ol><ul><li><p>Each of the students received a prize for their hard work. (Each: 每个)<br>每个学生因为他们的努力工作都获得了奖品。</p></li><li><p>The mortal remains of the king were laid to rest in a grand ceremony. (Mortal: 凡人的)<br>国王的遗体在一场盛大的仪式上被安葬。</p></li><li><p>The country declared itself a republic after years of monarchy. (Republic: 共和国)<br>经过多年的君主制统治，这个国家宣布成为共和国。</p></li><li><p>The stadium was filled with cheering fans during the final match. (Stadium: 体育场)<br>决赛比赛期间，体育场挤满了欢呼的球迷。</p></li><li><p>The warranty on the product will expire next month. (Expire: 到期)<br>该产品的保修期将在下个月到期。</p></li><li><p>There was a murmur of excitement in the crowd as the performer took the stage. (Murmur: 低语)<br>当表演者登台时，人群中传来一阵兴奋的低语声。</p></li><li><p>I will follow you wherever you go. (Wherever: 无论哪里)<br>无论你去哪里，我都会跟着你。</p></li><li><p>The fallen tree obstructed the path, so we had to find another way. (Obstruct: 阻碍)<br>倒下的树木挡住了路，所以我们不得不另找道路。</p></li><li><p>The farmer loaded the wagon with hay to feed the animals. (Wagon: 四轮马车)<br>农民把马车装满了干草喂动物。</p></li><li><p>The descent down the mountain was more challenging than the climb up. (Descent: 下降)<br>下山比上山更具挑战性。</p></li><li><p>He accidentally touched the hot stove and got a burn on his hand. (Burn: 烧伤)<br>他不小心碰到了热炉子，手上烧伤了。</p></li><li><p>Gold has been a valuable commodity for centuries. (Commodity: 商品)<br>金子几个世纪以来一直是一种有价值的商品。</p></li><li><p>She can smell the delicious aroma with her nose. (Nose: 鼻子)<br>她用鼻子闻到了美味的香气。</p></li><li><p>The old bridge was able to withstand the weight of the heavy truck. (Withstand: 承受)<br>老桥能够承受重型卡车的重量。</p></li><li><p>He grabbed a handful of nuts and started snacking. (Handful: 一把)<br>他抓了一把坚果开始吃零食。</p></li></ul><ol start="14"><li></li></ol><ul><li><p>They met and fell in love, beginning a beautiful romance. (Romance: 浪漫)<br>他们相遇并坠入爱河，开始了一段美丽的浪漫。</p></li><li><p>She slammed the door in anger. (Slam: 砰然关闭)<br>她生气地砰地关上了门。</p></li><li><p>The government imposed a new tariff on imported goods. (Tariff: 关税)<br>政府对进口商品征收了新的关税。</p></li><li><p>The event happened long ago, but its effects are still felt today. (Ago: 以前)<br>这件事情发生在很久以前，但其影响仍然在今天被感受到。</p></li><li><p>The article exposed the corruption within the company. (Expose: 揭露)<br>这篇文章揭露了公司内部的腐败现象。</p></li><li><p>The coach helped the team develop their skills and strategy. (Coach: 教练)<br>教练帮助团队发展他们的技能和战略。</p></li><li><p>Optical illusions can trick the brain into seeing things that aren’t there. (Optical: 光学的)<br>光学幻觉可以欺骗大脑，使其看到不存在的事物。</p></li><li><p>She tried to convince him to change his mind, but he wouldn’t budge. (Convince: 说服)<br>她试图说服他改变主意，但他不肯让步。</p></li><li><p>The transaction was completed smoothly and both parties were satisfied. (Transaction: 交易)<br>交易顺利完成，双方都很满意。</p></li><li><p>The Christmas tree was decorated with beautiful ornaments. (Ornament: 装饰物)<br>圣诞树上装饰着漂亮的装饰品。</p></li><li><p>English is a widely spoken language around the world. (Language: 语言)<br>英语是世界上广泛使用的语言之一。</p></li><li><p>She couldn’t think of the right phrase to describe her feelings. (Phrase: 短语)<br>她想不出合适的短语来描述自己的感受。</p></li><li><p>The organ in the body performs a vital function. (Organ: 器官)<br>身体中的器官执行着重要的功能。</p></li><li><p>The elder of the two sisters was always looking out for her younger sibling. (Elder: 年长的)<br>这两个姐妹中年长的总是照顾着她更年幼的妹妹。</p></li><li><p>He pulled the rope and the curtain opened to reveal the stage. (Pull: 拉)<br>他拉着绳子，帷幕拉开，露出了舞台。</p></li></ul><ol start="15"><li></li></ol><ul><li><p>He tied the rope tightly around the package. (Rope: 绳子)<br>他把绳子牢牢地绑在包裹上。</p></li><li><p>The party was a lot of fun. (Fun: 有趣)<br>派对很有趣。</p></li><li><p>Let’s meet on Wednesday to discuss the project. (Wednesday: 星期三)<br>我们星期三见面讨论项目。</p></li><li><p>The book is protected by copyright law. (Copyright: 版权)<br>这本书受版权法保护。</p></li><li><p>The two teams will compete against each other in the final match. (Compete: 竞争)<br>两支队伍将在决赛中互相竞争。</p></li><li><p>His behavior was bizarre and unpredictable. (Bizarre: 奇异的)<br>他的行为古怪而不可预测。</p></li><li><p>The atmosphere in the room was tense before the exam. (Tense: 紧张的)<br>考试前房间里的气氛很紧张。</p></li><li><p>She has a mild headache. (Mild: 轻微的)<br>她头痛得很轻。</p></li><li><p>The cake is baking in the oven. (Oven: 烤箱)<br>蛋糕正在烤箱里烤。</p></li><li><p>The wire was used to connect the two devices. (Wire: 电线)<br>这根电线用于连接两台设备。</p></li><li><p>The surgeon made an incision in the patient’s abdomen. (Abdomen: 腹部)<br>外科医生在患者的腹部做了一个切口。</p></li><li><p>The wolf howled at the moon. (Wolf: 狼)<br>狼对着月亮嚎叫。</p></li><li><p>The job will require a lot of hard work. (Require: 需要)<br>这份工作需要很多努力。</p></li><li><p>She looked at him with reproach in her eyes. (Reproach: 责备)<br>她眼中带着责备地看着他。</p></li></ul><ol start="16"><li></li></ol><ul><li><p>His smile was indicative of his happiness. (Indicative: 表示的)<br>他的微笑表明他很开心。</p></li><li><p>The bush was full of colorful flowers. (Bush: 灌木丛)<br>灌木丛上开满了五彩缤纷的花朵。</p></li><li><p>The submarine began to submerge beneath the surface of the water. (Submerge: 潜水)<br>潜艇开始在水面下潜水。</p></li><li><p>The war lasted for several years. (War: 战争)<br>战争持续了几年。</p></li><li><p>The car broke down, so we had to tow it to the mechanic. (Tow: 拖)<br>汽车抛锚了，所以我们不得不把它拖到修理厂。</p></li><li><p>The detective was able to detect the hidden clues. (Detect: 发现)<br>侦探能够发现隐藏的线索。</p></li><li><p>She decided to stay home instead of going out. (Instead: 代替)<br>她决定呆在家里，而不是出去。</p></li><li><p>The juvenile delinquent was sent to a correctional facility. (Juvenile: 少年的)<br>青少年罪犯被送到了矫正设施。</p></li><li><p>The old man’s voice was feeble and weak. (Feeble: 虚弱的)<br>老人的声音虚弱而无力。</p></li><li><p>The astronaut floated in space. (Astronaut: 宇航员)<br>宇航员在太空中漂浮。</p></li><li><p>The heavy rain caused a flood in the city. (Flood: 洪水)<br>暴雨导致城市发生了洪水。</p></li><li><p>She has a great skill in painting. (Skill: 技能)<br>她在绘画方面有着很高的技能。</p></li><li><p>The doctor explained how to prevent the spread of germs. (Germ: 细菌)<br>医生解释了如何防止细菌传播。</p></li><li><p>There are millions of stars in the sky. (Million: 百万)<br>天空中有数以百万计的星星。</p></li><li><p>She has always been keen on learning new things. (Keen: 热衷的)<br>她一直热衷于学习新事物。</p></li></ul><ol start="17"><li></li></ol><ul><li><p>The TV show has become a popular serial. (Serial: 连续剧)<br>这个电视节目已经成为一部受欢迎的连续剧。</p></li><li><p>It’s not polite to constantly criticize others. (Criticize: 批评)<br>经常批评别人是不礼貌的。</p></li><li><p>The sky was a beautiful shade of blue. (Blue: 蓝色)<br>天空是一种美丽的蓝色。</p></li><li><p>Good leadership is essential for any successful organization. (Leadership: 领导)<br>良好的领导对于任何成功的组织都是至关重要的。</p></li><li><p>The sheer size of the building was impressive. (Sheer: 纯粹的)<br>建筑物的规模之大令人印象深刻。</p></li><li><p>His expectations for the project were high. (Expectation: 期望)<br>他对这个项目的期望很高。</p></li><li><p>Buying in bulk can be more economical in the long run. (Economical: 节约的)<br>长期来看，大宗购买可能更经济。</p></li><li><p>I’m just going to take a quick nap. (Nap: 小睡)<br>我只是打算小睡一会儿。</p></li><li><p>The dean of the university announced new policies. (Dean: 院长)<br>大学院长宣布了新政策。</p></li><li><p>Can you pass me a napkin, please? (Napkin: 餐巾纸)<br>请递给我一张餐巾纸，好吗？</p></li><li><p>They decided to dump the old furniture. (Dump: 倾倒)<br>他们决定倾倒旧家具。</p></li><li><p>The country adopted communism as its political system. (Communism: 共产主义)<br>这个国家采纳了共产主义作为其政治制度。</p></li><li><p>The police used force to control the situation. (Force: 力量)<br>警察使用武力控制局势。</p></li><li><p>The company was involved in a massive fraud scheme. (Fraud: 欺诈)<br>公司卷入了一场大规模的欺诈计划。</p></li></ul><ol start="18"><li></li></ol><ul><li><p>He used a wrench to tighten the bolt. (Wrench: 扳手)<br>他用扳手拧紧螺栓。</p></li><li><p>The instructions were ambiguous and hard to understand. (Ambiguous: 模糊的)<br>这些说明含糊不清，难以理解。</p></li><li><p>The cake was delicious, everyone loved it. (Delicious: 美味的)<br>这个蛋糕很美味，大家都喜欢。</p></li><li><p>She took a capsule to relieve her headache. (Capsule: 胶囊)<br>她服用了一粒胶囊缓解头痛。</p></li><li><p>The country has made progressive strides in healthcare. (Progressive: 先进的)<br>这个国家在医疗保健方面取得了不断进步。</p></li><li><p>The band recorded their new album in the studio. (Record: 录制)<br>乐队在录音室录制了他们的新专辑。</p></li><li><p>The liquid spilled all over the floor. (Liquid: 液体)<br>液体洒在了地板上。</p></li><li><p>The government condemned the violent protests. (Condemn: 谴责)<br>政府谴责了这场暴力抗议活动。</p></li><li><p>She grew up in the countryside, surrounded by nature. (Countryside: 乡村)<br>她在乡村长大，周围是大自然。</p></li><li><p>We need to coordinate our efforts to achieve success. (Coordinate: 协调)<br>我们需要协调我们的努力以取得成功。</p></li><li><p>The flowers began to bloom in the spring. (Bloom: 开花)<br>花朵在春天开始绽放。</p></li><li><p>He studied geology to learn about the Earth’s structure. (Geology: 地质学)<br>他学习地质学来了解地球的结构。</p></li><li><p>Hurry, we’re going to be late! (Hurry: 匆忙)<br>快点，我们要迟到了！</p></li><li><p>The farmer used a plough to prepare the soil for planting. (Plough: 犁)<br>农民用犁耕地准备种植。</p></li></ul><ol start="19"><li></li></ol><ul><li><p>Regular exercise can help prevent many health problems. (Prevent: 预防)<br>经常锻炼可以帮助预防许多健康问题。</p></li><li><p>The helicopter hovered above the building. (Hover: 盘旋)<br>直升机在建筑物上空盘旋。</p></li><li><p>I’ve almost finished the book. (Almost: 几乎)<br>我几乎看完这本书了。</p></li><li><p>She used an iron to press her clothes. (Iron: 熨斗)<br>她用熨斗熨衣服。</p></li><li><p>Bacterium can be both helpful and harmful. (Bacterium: 细菌)<br>细菌既可以有益也可以有害。</p></li><li><p>He told us a funny anecdote about his trip. (Anecdote: 轶事)<br>他告诉我们关于他旅行的一个有趣的轶事。</p></li><li><p>The bomb exploded with a loud bang. (Bomb: 炸弹)<br>炸弹爆炸发出巨大的声响。</p></li><li><p>Let’s meet at the cafe for lunch. (Cafe: 咖啡馆)<br>我们一起在咖啡馆吃午饭吧。</p></li><li><p>The cost of living has increased significantly. (Cost: 成本)<br>生活成本已经大幅上升。</p></li><li><p>The accountant is responsible for managing the company’s finances. (Accountant: 会计)<br>会计负责管理公司的财务。</p></li><li><p>I hope you have a great day! (Hope: 希望)<br>希望你有个愉快的一天！</p></li><li><p>The temperature dropped to zero degrees Celsius. (Zero: 零)<br>温度降到了零度。</p></li><li><p>The table is sturdy and can hold a lot of weight. (Sturdy: 结实的)<br>这张桌子很结实，能承受很重的重量。</p></li><li><p>The introduction of the new product was well-received. (Introduction: 介绍)<br>新产品的推介受到了良好的反响。</p></li><li><p>Today is a beautiful day to go for a walk. (Today: 今天)<br>今天是个出去散步的好日子。</p></li></ul><ol start="20"><li></li></ol><ul><li><p>Many people hold a strong belief in the power of positive thinking. (Belief: 信念)<br>许多人坚信积极思考的力量。</p></li><li><p>He walked in a straight line to the door. (Straight: 直的)<br>他径直走向门口。</p></li><li><p>Let’s go see a movie this weekend. (Movie: 电影)<br>这个周末我们去看电影吧。</p></li><li><p>I miss my family when I’m away from home. (Miss: 想念)<br>离家时我想念我的家人。</p></li><li><p>She has very liberal views on social issues. (Liberal: 自由开放的)<br>她在社会问题上持有非常开放的观点。</p></li><li><p>The owner of the company is retiring next year. (Owner: 所有者)<br>公司的所有者明年将退休。</p></li><li><p>In this painting, the dominant color is blue. (Dominant: 主导的)<br>在这幅画中，主导色是蓝色。</p></li><li><p>I need to go to the department store to buy some clothes. (Department: 部门)<br>我需要去百货商店买些衣服。</p></li><li><p>The queen wore a beautiful crown on her head. (Crown: 王冠)<br>女王头上戴着一顶美丽的王冠。</p></li><li><p>A corporation is considered a separate legal entity. (Entity: 实体)<br>公司被视为独立的法律实体。</p></li><li><p>She twisted her ankle and hurt her heel. (Heel: 脚后跟)<br>她扭伤了脚踝，伤到了脚后跟。</p></li><li><p>The magician created the illusion of a disappearing rabbit. (Illusion: 幻觉)<br>魔术师制造了兔子消失的幻觉。</p></li><li><p>My nephew is learning to play the piano. (Nephew: 侄子)<br>我的侄子正在学钢琴。</p></li><li><p>The doctor will inject the vaccine into your arm. (Inject: 注射)<br>医生将在你的手臂上注射疫苗。</p></li><li><p>I’m waiting for a reply to my email. (Reply: 回复)<br>我在等待对我的电子邮件的回复。</p></li><li><p>Shareholders receive a dividend from the company’s profits. (Dividend: 红利)<br>股东从公司利润中获得红利。</p></li><li><p>We need to constantly improve our processes to stay competitive. (Improve: 改善)<br>我们需要不断改善我们的流程以保持竞争力。</p></li><li><p>The twins look almost identical. (Identical: 相同的)<br>这对双胞胎看起来几乎一模一样。</p></li><li><p>Hydrogen is the lightest and most abundant element in the universe. (Hydrogen: 氢)<br>氢是宇宙中最轻、最丰富的元素。</p></li></ul><ol start="21"><li></li></ol><ul><li><p>Let’s conclude the meeting with a summary of our discussion. (Conclude: 结束)<br>让我们通过总结讨论内容来结束会议。</p></li><li><p>The thief was sent to gaol for his crimes. (Gaol: 监狱)<br>这名小偷因犯罪被送进了监狱。</p></li><li><p>Each snowflake is unique, just like a fingerprint. (Unique: 独特的)<br>每片雪花都是独一无二的，就像指纹一样。</p></li><li><p>I’ll make dinner tonight; what would you like to eat? (Make: 做)<br>今晚我来做晚饭，你想吃什么？</p></li><li><p>She always puts in a great endeavor in everything she does. (Endeavor: 努力)<br>她做的每件事都付出了极大的努力。</p></li><li><p>The earth is a sphere. (Sphere: 球体)<br>地球是一个球体。</p></li><li><p>The declaration of independence was a significant moment in history. (Declaration: 宣言)<br>独立宣言是历史上一个重要的时刻。</p></li><li><p>The pope is the leader of the Roman Catholic Church. (Pope: 教皇)<br>教皇是罗马天主教会的领袖。</p></li><li><p>These rules are only applicable to students living on campus. (Applicable: 适用的)<br>这些规定只适用于住校的学生。</p></li><li><p>I declare this meeting adjourned. (Declare: 宣布)<br>我宣布会议结束。</p></li><li><p>The possession of illegal drugs is a serious crime. (Possession: 拥有)<br>拥有非法药物是一种严重的犯罪。</p></li><li><p>Make sure you equip yourself with the necessary tools before starting the project. (Equip: 装备)<br>在开始项目之前，确保自己装备好必要的工具。</p></li></ul><ol start="22"><li></li></ol><ul><li><p>He used a hook to hang the picture on the wall. (Hook: 钩子)<br>他用钩子把图片挂在墙上。</p></li><li><p>This jacket is waterproof, so you can wear it in the rain. (Waterproof: 防水的)<br>这件夹克衫是防水的，所以你可以在雨中穿它。</p></li><li><p>The view from the top of the mountain was bleak and desolate. (Bleak: 荒凉的)<br>山顶的景色荒凉而凄凉。</p></li><li><p>The essence of the story lies in its moral message. (Essence: 精华)<br>故事的精髓在于它的道德寓意。</p></li><li><p>She tried to hide her disappointment with a smile. (Hide: 隐藏)<br>她试图用微笑掩饰自己的失望。</p></li><li><p>The audience applauded enthusiastically at the end of the performance. (Audience: 观众)<br>演出结束时，观众们热烈鼓掌。</p></li><li><p>According to legend, dragons are powerful mythical creatures. (Dragon: 龙)<br>根据传说，龙是强大的神秘生物。</p></li><li><p>He gave the ball a hard kick and it flew into the goal. (Kick: 踢)<br>他重重地踢了一脚球，它飞入了球门。</p></li><li><p>The athlete made a high jump over the bar. (Jump: 跳跃)<br>运动员跳过了栏杆。</p></li><li><p>Additional information can be found in the appendix. (Additional: 附加的)<br>附录中可以找到额外的信息。</p></li><li><p>The procession of cars stretched for miles along the highway. (Procession: 行列)<br>汽车的队列沿着公路延伸了几英里。</p></li><li><p>The colors of the painting began to fade over time. (Fade: 褪色)<br>随着时间的推移，这幅画的颜色开始褪色。</p></li><li><p>She took a long bath to relax after a busy day. (Bath: 洗澡)<br>在繁忙的一天过后，她洗了个长长的澡。</p></li><li><p>Plants produce oxygen as a byproduct of photosynthesis. (Oxygen: 氧气)<br>植物在光合作用中产生氧气作为副产品。</p></li></ul><ol start="23"><li></li></ol><ul><li><p>The match will be a showdown between Team A versus Team B. (Versus: 对抗)<br>这场比赛将是A队对阵B队的对决。</p></li><li><p>The train travels along the rail at high speed. (Rail: 铁轨)<br>火车以高速沿着铁轨行驶。</p></li><li><p>The spider built its nest in the corner near the ceiling. (Ceiling: 天花板)<br>蜘蛛在靠近天花板的角落筑巢。</p></li><li><p>The teacher gave a quiz to test the students’ understanding of the material. (Quiz: 测验)<br>老师出了一份测验，以测试学生对知识的理解。</p></li><li><p>It can be difficult to distinguish between the two species of birds. (Distinguish: 区分)<br>很难区分这两种鸟类。</p></li><li><p>The baby fell asleep in her mother’s lap. (Lap: 膝盖)<br>宝宝在妈妈的膝盖上睡着了。</p></li><li><p>There’s nothing in the fridge. (Nothing: 没有东西)<br>冰箱里什么都没有。</p></li><li><p>His comments were not relevant to the discussion. (Relevant: 相关的)<br>他的评论与讨论无关。</p></li><li><p>The company announced new employment opportunities. (Employment: 就业)<br>公司宣布了新的就业机会。</p></li><li><p>The birds built a nest in the tree. (Nest: 巢)<br>鸟儿在树上筑巢。</p></li><li><p>She tried to recall where she had left her keys. (Recall: 回忆起)<br>她试图回忆她把钥匙放在哪里了。</p></li><li><p>Remember to lock the door when you leave. (Remember: 记得)<br>离开时记得锁门。</p></li><li><p>The police enforce the law to maintain order. (Enforce: 执行)<br>警察执行法律以维护秩序。</p></li><li><p>The economic downturn led to a rise in unemployment. (Unemployment: 失业)<br>经济衰退导致失业率上升。</p></li><li><p>She had a happy childhood filled with laughter and play. (Childhood: 童年)<br>她有一个幸福的童年，充满了笑声和游戏。</p></li></ul><p>2024&#x2F;4&#x2F;26</p><p>1. </p><ul><li><p>The singer gained fame after winning the talent show. (Fame: 名声)<br>这位歌手在赢得才艺表演比赛后赢得了名声。</p></li><li><p>She fell and scraped her knee. (Knee: 膝盖)<br>她摔倒了，擦伤了膝盖。</p></li><li><p>The group was diverse, consisting of people from different backgrounds. (Diverse: 多样的)<br>这个团体多样性很大，由来自不同背景的人组成。</p></li><li><p>He always carries an umbrella in case it rains. (Umbrella: 雨伞)<br>他总是带着一把伞，以防下雨。</p></li><li><p>She was unable to utter a single word due to shock. (Utter: 说)<br>她由于震惊而无法说出一句话。</p></li><li><p>I have a cold, so I’m not feeling well. (So: 所以)<br>我感冒了，所以感觉不舒服。</p></li><li><p>The intension of his remarks was unclear. (Intension: 意图)<br>他讲话的意图不明确。</p></li><li><p>The restaurant serves delicious food. (Food: 食物)<br>这家餐馆供应美味的食物。</p></li><li><p>The company released a new software update. (Software: 软件)<br>公司发布了新的软件更新。</p></li><li><p>The project faced a setback when funding was cut. (Setback: 挫折)<br>项目在资金被削减时遇到了挫折。</p></li><li><p>The doctor checked her pulse to measure her heart rate. (Pulse: 脉搏)<br>医生检查了她的脉搏以测量她的心率。</p></li><li><p>The country has a strong naval presence. (Naval: 海军的)<br>这个国家在海军上有很强的存在感。</p></li><li><p>There was no evidence to support his claims. (Evidence: 证据)<br>没有证据支持他的说法。</p></li><li><p>She felt like a stranger in the new city. (Stranger: 陌生人)<br>她在新城市感到像个陌生人。</p></li></ul><ol start="2"><li></li></ol><ul><li><p>The aircraft landed safely at the airport. (Aircraft: 飞机)<br>飞机安全降落在机场。</p></li><li><p>They decided to postpone the meeting until next week. (Postpone: 推迟)<br>他们决定将会议推迟到下周。</p></li><li><p>He didn’t respond to my question. (Respond: 回答)<br>他没有回答我的问题。</p></li><li><p>Perhaps we should consider another approach. (Perhaps: 或许)<br>或许我们应该考虑另一种方法。</p></li><li><p>The new policy will be effective henceforth. (Henceforth: 从此以后)<br>新政策从现在起将生效。</p></li><li><p>What is your opinon on this matter? (Opinon: 意见)<br>你对这件事情有什么看法？</p></li><li><p>Let’s begin our journey. (Begin: 开始)<br>让我们开始我们的旅程。</p></li><li><p>The sun will rise in the east. (Rise: 升起)<br>太阳将从东方升起。</p></li><li><p>The lion was tame and could be petted. (Tame: 温顺的)<br>那只狮子很温顺，可以摸。</p></li><li><p>Their house is located near the park. (Their: 他们的)<br>他们的房子靠近公园。</p></li><li><p>He tried to blame others for his mistake. (Blame: 责怪)<br>他试图把自己的错误归咎于别人。</p></li><li><p>She is aware of the risks involved. (Aware: 意识到)<br>她意识到涉及的风险。</p></li><li><p>The doctor put plaster on his broken arm. (Plaster: 膏药)<br>医生在他的断臂上敷了膏药。</p></li><li><p>Learning basic skills is important. (Basic: 基础的)<br>学习基本技能是很重要的。</p></li></ul><ol start="3"><li></li></ol><ul><li><p>Her income has increased significantly over the past year. (Income: 收入)<br>她的收入在过去一年里显著增加了。</p></li><li><p>She is a successful female entrepreneur. (Female: 女性)<br>她是一位成功的女性企业家。</p></li><li><p>I believe we can achieve our goals if we work hard. (Believe: 相信)<br>我相信如果我们努力工作，我们可以实现我们的目标。</p></li><li><p>He waved goodbye as the train pulled away. (Goodbye: 再见)<br>火车启动时，他挥手告别。</p></li><li><p>The children flew a kite in the park. (Kite: 风筝)<br>孩子们在公园里放风筝。</p></li><li><p>He wore a suit to the interview. (Suit: 西装)<br>他穿着西装去面试。</p></li><li><p>She gave a nod of approval. (Nod: 点头)<br>她点了点头表示同意。</p></li><li><p>Please correct me if I’m wrong. (Correct: 纠正)<br>如果我错了，请纠正我。</p></li><li><p>He likes to listen to music in his free time. (Listen: 听)<br>他喜欢在空闲时间听音乐。</p></li><li><p>She inherited a large estate from her grandfather. (Estate: 财产)<br>她从祖父那里继承了一大笔财产。</p></li><li><p>He sprained his ankle while playing basketball. (Ankle: 踝关节)<br>他在打篮球时扭伤了脚踝。</p></li><li><p>She put a patch on the tear in her jeans. (Patch: 补丁)<br>她在牛仔裤上的破洞处贴了个补丁。</p></li><li><p>The outer layer of the Earth is called the crust. (Outer: 外部的)<br>地球的外层称为地壳。</p></li><li><p>Latin is no longer spoken as a native language. (Latin: 拉丁语)<br>拉丁语不再作为一种母语而被使用。</p></li></ul><ol start="4"><li></li></ol><ul><li><p>The association aims to promote cultural exchange. (Association: 协会)<br>这个协会旨在促进文化交流。</p></li><li><p>The plane ascended to a high altitude. (Altitude: 海拔高度)<br>飞机上升到高海拔。</p></li><li><p>The land was barren and unfit for farming. (Barren: 贫瘠的)<br>这片土地贫瘠，不适合耕种。</p></li><li><p>She slipped on the wet floor. (Slipper: 滑倒)<br>她在湿地板上滑倒了。</p></li><li><p>It is unlikely that he will arrive on time. (Unlikely: 不太可能)<br>他不太可能准时到达。</p></li><li><p>The sheriff’s deputy arrived at the scene. (Deputy: 副手)<br>警长的副手到达了现场。</p></li><li><p>Take one dose of this medicine before bed. (Dose: 剂量)<br>每晚睡前服用一剂这种药物。</p></li><li><p>The siren wailed loudly in the distance. (Siren: 警笛)<br>警报器在远处响起。</p></li><li><p>Can you provide proof of your identity? (Proof: 证据)<br>你能提供你的身份证明吗？</p></li><li><p>She kept her money in her wallet. (Wallet: 钱包)<br>她把钱放在钱包里。</p></li><li><p>The goat grazed in the field. (Goat: 山羊)<br>山羊在田里吃草。</p></li><li><p>I’ll give them a call later. (Them: 他们&#x2F;她们)<br>我稍后会给他们打电话。</p></li></ul><ol start="5"><li></li></ol><ul><li><p>She likes to decorate her house with flowers. (Decorate: 装饰)<br>她喜欢用花装饰她的房子。</p></li><li><p>He swept the floor with a broom. (Broom: 扫帚)<br>他用扫帚扫地。</p></li><li><p>The spider began to creep along the wall. (Creep: 爬行)<br>蜘蛛开始沿着墙壁爬行。</p></li><li><p>The police arrived at the scene of the crime. (Police: 警察)<br>警察到达了犯罪现场。</p></li><li><p>Be careful not to spill the milk. (Spill: 溢出)<br>小心别把牛奶洒出来。</p></li><li><p>He chopped wood with an axe. (Axe: 斧头)<br>他用斧头劈木头。</p></li><li><p>Please provide your address. (Address: 地址)<br>请提供你的地址。</p></li><li><p>The decision was unanimous. (Unanimous: 一致的)<br>决定是一致的。</p></li><li><p>The neighborhood is quiet and peaceful. (Neighborhood: 社区)<br>这个社区安静而和平。</p></li><li><p>The diversion caused a delay in our journey. (Diversion: 转移)<br>这个转移导致我们的旅程延误。</p></li><li><p>She cooked some sausages for breakfast. (Sausage: 香肠)<br>她煮了些香肠作为早餐。</p></li><li><p>The waiter brought the menu to the table. (Waiter: 服务员)<br>服务员把菜单端到桌子上。</p></li><li><p>What’s your favorite color? (Favorite: 最喜爱的)<br>你最喜欢的颜色是什么？</p></li></ul><ol start="6"><li></li></ol><ul><li><p>The outbreak of the disease was sudden and severe. (Outbreak: 爆发)<br>疾病的爆发突然而严重。</p></li><li><p>The regime implemented new policies to improve the economy. (Regime: 政权)<br>政权实施了新的政策来改善经济。</p></li><li><p>She’s a smart girl who excels in math. (Girl: 女孩)<br>她是一个数学学得很好的聪明女孩。</p></li><li><p>The birds were looking for a mate. (Mate: 伴侣)<br>鸟儿在寻找伴侣。</p></li><li><p>He put the food on the plate. (Plate: 盘子)<br>他把食物放在盘子里。</p></li><li><p>The participant won a prize for his performance. (Participant: 参与者)<br>参与者因为他的表现而获得了奖品。</p></li><li><p>There was a shortage of food during the drought. (Shortage: 短缺)<br>干旱期间食物短缺。</p></li><li><p>She has a powerful voice that can fill a room. (Powerful: 强大的)<br>她有一种强大的声音，可以填满整个房间。</p></li><li><p>His apology seemed genuine. (Genuine: 真诚的)<br>他的道歉似乎是真诚的。</p></li><li><p>The plant began to sprout after the rain. (Sprout: 发芽)<br>这棵植物在雨后开始发芽。</p></li><li><p>She had to persevere through many challenges to reach her goal. (Persevere: 坚持)<br>她不得不经历许多挑战才能达到她的目标。</p></li><li><p>He used an amplifier to make his voice louder. (Amplifier: 放大器)<br>他用放大器把声音放大。</p></li><li><p>He pounded the meat to make it tender. (Pound: 捣碎)<br>他捣碎肉使其变嫩。</p></li><li><p>They agreed to refund the money. (Refund: 退款)<br>他们同意退还钱款。</p></li></ul><ol start="7"><li></li></ol><ul><li><p>The sweater shrank in the wash. (Shrink: 收缩)<br>毛衣在洗衣时缩水了。</p></li><li><p>The vase is very fragile, so be careful with it. (Fragile: 易碎的)<br>这个花瓶非常脆弱，所以要小心。</p></li><li><p>He’s always punctual and arrives on time. (Punctual: 准时的)<br>他总是很准时，按时到达。</p></li><li><p>The encyclopedia contains a wealth of information. (Encyclopedia: 百科全书)<br>这本百科全书包含了丰富的信息。</p></li><li><p>They watched a live performance of the play. (Live: 现场的)<br>他们观看了这部戏剧的现场表演。</p></li><li><p>Be careful with the fragile items. (Careful: 小心的)<br>对易碎物品要小心。</p></li><li><p>The issue is too trivial to be of any real importance. (Trivial: 琐碎的)<br>这个问题太琐碎，没有任何真正的重要性。</p></li><li><p>She painted the room a bright color. (Color: 颜色)<br>她把房间涂成了明亮的颜色。</p></li><li><p>The building’s design includes a pillar in the center. (Pillar: 柱子)<br>这座建筑的设计包括中间的一根柱子。</p></li><li><p>He sawed the wood to make it fit. (Saw: 锯子；锯)<br>他用锯子锯木头使之合适。</p></li><li><p>The offer was tempting, but she decided not to accept it. (Tempt: 引诱)<br>这个报价很诱人，但她决定不接受。</p></li><li><p>He demonstrated how to use the new software. (Demonstrate: 示范)<br>他演示了如何使用新软件。</p></li><li><p>They enjoyed a glass of wine with their meal. (Wine: 葡萄酒)<br>他们在用餐时喝了一杯葡萄酒。</p></li><li><p>She walked up the stairs to the second floor. (Stair: 楼梯)<br>她走上楼梯到二楼。</p></li></ul><ol start="8"><li></li></ol><ul><li><p>She teaches drama at the secondary school. (Secondary: 中等的)<br>她在中学教戏剧课程。</p></li><li><p>He plays the guitar in a band. (Guitar: 吉他)<br>他在一个乐队里弹吉他。</p></li><li><p>They were cordial hosts and made us feel welcome. (Cordial: 热诚的)<br>他们是热情的主人，让我们感到受欢迎。</p></li><li><p>Please pass me the soap. (Soap: 肥皂)<br>请递给我肥皂。</p></li><li><p>This is the best cake I’ve ever tasted. (Best: 最好的)<br>这是我尝过的最好吃的蛋糕。</p></li><li><p>The museum features a collection of modern art. (Modern: 现代的)<br>博物馆展示了一系列现代艺术品。</p></li><li><p>The fireworks display was spectacular. (Spectacular: 壮观的)<br>烟火表演非常壮观。</p></li><li><p>The actors wore elaborate costume for the play. (Costume: 服装)<br>演员们在剧中穿着精致的服装。</p></li><li><p>The store had its grand opening last week. (Opening: 开张)<br>这家商店上周开张。</p></li><li><p>She didn’t hesitate to speak her mind. (Hesitate: 犹豫)<br>她毫不犹豫地说出了自己的想法。</p></li><li><p>His expression of satisfaction told us he was pleased. (Satisfaction: 满意)<br>他满意的表情告诉我们他很高兴。</p></li><li><p>She asked the waiter to serve the meal. (Serve: 服务)<br>她要求服务员端上餐点。</p></li></ul><ol start="9"><li></li></ol><ul><li><p>The leaves fall from the trees in autumn. (Fall: 掉落)<br>秋天树叶从树上落下来。</p></li><li><p>Have you ever been to Paris? (Ever: 曾经)<br>你曾经去过巴黎吗？</p></li><li><p>I need to get some groceries from the store. (Get: 获得)<br>我需要从商店买些杂货。</p></li><li><p>Please keep quiet during the movie. (Quiet: 安静)<br>请在电影放映期间保持安静。</p></li><li><p>The brisk wind made her shiver. (Brisk: 轻快的)<br>清风使她打了个寒颤。</p></li><li><p>She reached out to touch the painting. (Touch: 触摸)<br>她伸手去触摸画作。</p></li><li><p>He filled up the car with gasoline. (Gasoline: 汽油)<br>他给车加满了汽油。</p></li><li><p>The mountain was covered in mist. (Mist: 薄雾)<br>山上笼罩着薄雾。</p></li><li><p>The team showed great unity in their efforts. (Unity: 团结)<br>团队在努力中表现出极大的团结。</p></li><li><p>They talked about events from the past. (Past: 过去)<br>他们谈论过去发生的事情。</p></li><li><p>He loaded the cart with boxes. (Cart: 手推车)<br>他把箱子装满了手推车。</p></li><li><p>One drawback of the plan was its high cost. (Drawback: 缺点)<br>这个计划的一个缺点是成本很高。</p></li></ul><ol start="10"><li></li></ol><ul><li><p>It’s important to classify the documents correctly. (Classify: 分类)<br>很重要将文件正确分类。</p></li><li><p>His behavior at the party was unacceptable. (Behavior: 行为)<br>他在派对上的行为是不可接受的。</p></li><li><p>The fog was so thick that you couldn’t see anything. (Thick: 浓厚的)<br>雾很大，你什么都看不见。</p></li><li><p>She wrote him a cheque for the rent. (Cheque: 支票)<br>她给他写了一张付房租的支票。</p></li><li><p>The manager supervises the team’s work. (Supervise: 监督)<br>经理监督团队的工作。</p></li><li><p>This is a significant moment in history. (Significant: 重要的)<br>这是历史上一个重要的时刻。</p></li><li><p>Mercury is a toxic metal. (Mercury: 汞)<br>汞是一种有毒金属。</p></li><li><p>Are you sure about your decision? (Sure: 确定的)<br>你对你的决定有把握吗？</p></li><li><p>The conference had an international audience. (International: 国际的)<br>会议的观众来自国际。</p></li><li><p>They’re planning an extension to the building. (Extension: 扩建)<br>他们计划对建筑进行扩建。</p></li><li><p>He affirmed his commitment to the project. (Affirm: 肯定)<br>他肯定了他对这个项目的承诺。</p></li><li><p>The architect showed them the blueprint for the new house. (Blueprint: 蓝图)<br>建筑师向他们展示了新房子的蓝图。</p></li><li><p>The rain was intermittent, with short periods of heavy rain. (Intermittent: 间歇的)<br>雨势间歇，时而大时而小。</p></li><li><p>Responsibility comes with leadership. (Responsibility: 责任)<br>领导责任伴随而来。</p></li></ul><p>11. </p><ul><li><p>The coach used a whip to urge the horses to run faster. (Whip: 鞭子)<br>教练用鞭子督促马儿跑得更快。</p></li><li><p>His remarks carried an implicit criticism of the government. (Implicit: 含蓄的)<br>他的言论暗含对政府的批评。</p></li><li><p>The government decided to isolate the infected area. (Isolate: 隔离)<br>政府决定将受感染区域隔离。</p></li><li><p>The Earth rotates on its axis. (Rotate: 旋转)<br>地球围绕着自己的轴旋转。</p></li><li><p>Freedom is a fundamental human right. (Liberty: 自由)<br>自由是一项基本人权。</p></li><li><p>As she read, the story began to unfold. (Unfold: 展开)<br>随着她的阅读，故事开始展开。</p></li><li><p>The branch snapped under the weight of the snow. (Snap: 断裂)<br>分支在雪的重压下折断了。</p></li><li><p>The quality of the product is inferior to what was promised. (Inferior: 劣质的)<br>产品的质量低于承诺的水平。</p></li><li><p>Nowadays, technology is advancing at a rapid pace. (Nowadays: 如今)<br>如今，科技正以迅猛的速度发展。</p></li><li><p>Would you like some tea? (Tea: 茶)<br>你想要喝点茶吗？</p></li><li><p>He lived a solitary life in the mountains. (Solitary: 孤独的)<br>他在山里过着孤独的生活。</p></li><li><p>I heard the tick of the clock in the quiet room. (Tick: 滴答声)<br>我听到了安静房间里时钟的滴答声。</p></li><li><p>It’s important to break the habit of smoking. (Habit: 习惯)<br>戒掉吸烟的习惯很重要。</p></li><li><p>She decided to donate some money to charity. (Donate: 捐赠)<br>她决定向慈善机构捐款。</p></li><li><p>The general’s aim was to humiliate his opponent. (Humiliate: 羞辱)<br>将军的目的是羞辱对手。</p></li><li><p>The floor was covered in dirt and dust. (Dirt: 污垢)<br>地板上布满了污垢和灰尘。</p></li><li><p>They came to visit us last summer. (Visit: 访问)<br>他们去年夏天来访问我们。</p></li><li><p>He shoved the door open and entered the room. (Shove: 推)<br>他用力推开门，走进了房间。</p></li><li><p>She cradled the baby in her arms. (Baby: 婴儿)<br>她抱着婴儿。</p></li><li><p>The doctor diagnosed him with a disorder of the nervous system. (Disorder: 失调)<br>医生诊断出他患有神经系统失调。</p></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>英语</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>github</title>
    <link href="/2024/05/13/tiankeng8/"/>
    <url>/2024/05/13/tiankeng8/</url>
    
    <content type="html"><![CDATA[<p><a href="https://ndpsoftware.com/git-cheatsheet.html#loc=index;">github工作流程代码解释</a></p><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>GitHub是一个代码托管平台。一个共享和开源软件的流行平台</p><ol><li>软件开源，即编写软件的代码对所有人公开，所有人可以在现有代码的基础上进行二次开发，减少不必要的重复劳动（ IT 行话简称不要重复「造轮子」）</li><li>方便团队协作。这个过程有点像是我们把文档放在石墨或语雀这类支持团队协作的平台上，而 GitHub 上存放的是代码，参与编写软件的人可以通过 Git（版本控制工具）从 GitHub 拉取或往 GitHub 上传代码</li></ol><p>类似的代码托管平台还有gitee，开源中国。</p><p>仓库（Repository） 仓库 是 GitHub 最基本的元素。 它们很容易被想象为项目的文件夹。 仓库包含所有项目文件（包括文档），并存储每个文件的修改历史记录。 仓库可以有多个协作者，仓库可以是公开的，也可以设置为私有的。更详细的请看<a href="https://docs.github.com/en/repositories/creating-and-managing-repositories/about-repositories">参考文档</a><br>分支（Branch） 分支是仓库的并行版本。默认情况下，您的仓库具有一个名为 main 的主分支。我们可以复制主分支创建其他分支，您安全地进行任何更改而不会影响”线上“主分支。 完成所需更改后，可以将分支合并回主分支以发布你的更改。<br>README：GitHub 个人主页资料上 “关于我” 的介绍。 内容一般包含：介绍您的工作和兴趣，您引以为豪的贡献以及这些贡献的背景信息，在您参与的社区获得帮助的指南</p><h2 id="配套软件"><a href="#配套软件" class="headerlink" title="配套软件"></a>配套软件</h2><p><a href="https://git-scm.com/download/win">git for windown </a></p><h2 id="使用命令"><a href="#使用命令" class="headerlink" title="使用命令"></a>使用命令</h2><p>初始命令，建立.git文件</p><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs csharp">git <span class="hljs-keyword">init</span> <br></code></pre></td></tr></table></figure><p>选取上传文件，如果需要选取所有则使用<code>git add .</code></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros">git <span class="hljs-built_in">add</span> README.md<br>git <span class="hljs-built_in">add</span> .<br></code></pre></td></tr></table></figure><p>书写提交信息</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">git</span> commit -m <span class="hljs-string">&quot;first commit              &quot;</span><br></code></pre></td></tr></table></figure><p>选取分支</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">git branch -M <span class="hljs-selector-tag">main</span><br></code></pre></td></tr></table></figure><p>添加目标位置，</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile">git remote <span class="hljs-keyword">add</span><span class="language-bash"> origin git@github.com:changjingzhi/test.git</span><br></code></pre></td></tr></table></figure><p>(origin 表示名字)<br>git push 提交文件到远端仓库</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs maxima">git <span class="hljs-built_in">push</span> -u <span class="hljs-built_in">origin</span> main<br></code></pre></td></tr></table></figure><p>git clone 克隆远端仓库。</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">git <span class="hljs-keyword">clone</span> <span class="hljs-title">远端仓库地址</span><br></code></pre></td></tr></table></figure><h2 id="python"><a href="#python" class="headerlink" title="python"></a>python</h2><p>使用pip freeze命令生成requirements.txt文件：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">pip <span class="hljs-keyword">freeze</span> &gt; requirements.txt<br><br></code></pre></td></tr></table></figure><p>model环境</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">absl</span>-py==<span class="hljs-number">2</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">addict</span>==<span class="hljs-number">2</span>.<span class="hljs-number">4</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">asttokens</span>==<span class="hljs-number">2</span>.<span class="hljs-number">4</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">backcall</span>==<span class="hljs-number">0</span>.<span class="hljs-number">2</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">cachetools</span>==<span class="hljs-number">5</span>.<span class="hljs-number">3</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">certifi</span>==<span class="hljs-number">2023</span>.<span class="hljs-number">7</span>.<span class="hljs-number">22</span><br><span class="hljs-attribute">chardet</span>==<span class="hljs-number">5</span>.<span class="hljs-number">2</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">charset</span>-normalizer==<span class="hljs-number">3</span>.<span class="hljs-number">3</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">click</span>==<span class="hljs-number">8</span>.<span class="hljs-number">1</span>.<span class="hljs-number">7</span><br><span class="hljs-attribute">colorama</span>==<span class="hljs-number">0</span>.<span class="hljs-number">4</span>.<span class="hljs-number">6</span><br><span class="hljs-attribute">comm</span>==<span class="hljs-number">0</span>.<span class="hljs-number">2</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">contourpy</span>==<span class="hljs-number">1</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">cycler</span>==<span class="hljs-number">0</span>.<span class="hljs-number">12</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">debugpy</span>==<span class="hljs-number">1</span>.<span class="hljs-number">8</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">decorator</span>==<span class="hljs-number">5</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">defusedxml</span>==<span class="hljs-number">0</span>.<span class="hljs-number">7</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">executing</span>==<span class="hljs-number">2</span>.<span class="hljs-number">0</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">filelock</span>==<span class="hljs-number">3</span>.<span class="hljs-number">13</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">fonttools</span>==<span class="hljs-number">4</span>.<span class="hljs-number">45</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">fsspec</span>==<span class="hljs-number">2023</span>.<span class="hljs-number">10</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">google</span>-auth==<span class="hljs-number">2</span>.<span class="hljs-number">23</span>.<span class="hljs-number">4</span><br><span class="hljs-attribute">google</span>-auth-oauthlib==<span class="hljs-number">1</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">graphviz</span>==<span class="hljs-number">0</span>.<span class="hljs-number">20</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">grpcio</span>==<span class="hljs-number">1</span>.<span class="hljs-number">59</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">huggingface</span>-hub==<span class="hljs-number">0</span>.<span class="hljs-number">19</span>.<span class="hljs-number">4</span><br><span class="hljs-attribute">idna</span>==<span class="hljs-number">3</span>.<span class="hljs-number">4</span><br><span class="hljs-attribute">imageio</span>==<span class="hljs-number">2</span>.<span class="hljs-number">33</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">importlib</span>-metadata==<span class="hljs-number">6</span>.<span class="hljs-number">8</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">importlib</span>-resources==<span class="hljs-number">6</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">ipykernel</span>==<span class="hljs-number">6</span>.<span class="hljs-number">26</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">ipython</span>==<span class="hljs-number">8</span>.<span class="hljs-number">12</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">jedi</span>==<span class="hljs-number">0</span>.<span class="hljs-number">19</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">Jinja2</span>==<span class="hljs-number">3</span>.<span class="hljs-number">1</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">joblib</span>==<span class="hljs-number">1</span>.<span class="hljs-number">3</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">jupyter_client</span>==<span class="hljs-number">8</span>.<span class="hljs-number">6</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">jupyter_core</span>==<span class="hljs-number">5</span>.<span class="hljs-number">5</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">kiwisolver</span>==<span class="hljs-number">1</span>.<span class="hljs-number">4</span>.<span class="hljs-number">5</span><br><span class="hljs-attribute">lazy_loader</span>==<span class="hljs-number">0</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">lxml</span>==<span class="hljs-number">4</span>.<span class="hljs-number">9</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">Markdown</span>==<span class="hljs-number">3</span>.<span class="hljs-number">5</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">MarkupSafe</span>==<span class="hljs-number">2</span>.<span class="hljs-number">1</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">matplotlib</span>==<span class="hljs-number">3</span>.<span class="hljs-number">7</span>.<span class="hljs-number">4</span><br><span class="hljs-attribute">matplotlib</span>-inline==<span class="hljs-number">0</span>.<span class="hljs-number">1</span>.<span class="hljs-number">6</span><br><span class="hljs-attribute">mne</span>==<span class="hljs-number">1</span>.<span class="hljs-number">6</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">nest</span>-asyncio==<span class="hljs-number">1</span>.<span class="hljs-number">5</span>.<span class="hljs-number">8</span><br><span class="hljs-attribute">netron</span>==<span class="hljs-number">7</span>.<span class="hljs-number">2</span>.<span class="hljs-number">9</span><br><span class="hljs-attribute">networkx</span>==<span class="hljs-number">3</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">nltk</span>==<span class="hljs-number">3</span>.<span class="hljs-number">8</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">numpy</span>==<span class="hljs-number">1</span>.<span class="hljs-number">24</span>.<span class="hljs-number">4</span><br><span class="hljs-attribute">oauthlib</span>==<span class="hljs-number">3</span>.<span class="hljs-number">2</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">opencv</span>-python==<span class="hljs-number">4.2.0.32</span><br><span class="hljs-attribute">packaging</span>==<span class="hljs-number">23</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">pandas</span>==<span class="hljs-number">2</span>.<span class="hljs-number">0</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">parso</span>==<span class="hljs-number">0</span>.<span class="hljs-number">8</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">pickleshare</span>==<span class="hljs-number">0</span>.<span class="hljs-number">7</span>.<span class="hljs-number">5</span><br><span class="hljs-attribute">Pillow</span>==<span class="hljs-number">10</span>.<span class="hljs-number">1</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">platformdirs</span>==<span class="hljs-number">4</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">pooch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">8</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">prompt</span>-toolkit==<span class="hljs-number">3</span>.<span class="hljs-number">0</span>.<span class="hljs-number">41</span><br><span class="hljs-attribute">protobuf</span>==<span class="hljs-number">4</span>.<span class="hljs-number">25</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">psutil</span>==<span class="hljs-number">5</span>.<span class="hljs-number">9</span>.<span class="hljs-number">6</span><br><span class="hljs-attribute">pure</span>-eval==<span class="hljs-number">0</span>.<span class="hljs-number">2</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">pyasn1</span>==<span class="hljs-number">0</span>.<span class="hljs-number">5</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">pyasn1</span>-modules==<span class="hljs-number">0</span>.<span class="hljs-number">3</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">pycocotools</span>==<span class="hljs-number">2</span>.<span class="hljs-number">0</span>.<span class="hljs-number">7</span><br><span class="hljs-attribute">pygame</span>==<span class="hljs-number">2</span>.<span class="hljs-number">5</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">Pygments</span>==<span class="hljs-number">2</span>.<span class="hljs-number">16</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">pyparsing</span>==<span class="hljs-number">3</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">python</span>-dateutil==<span class="hljs-number">2</span>.<span class="hljs-number">8</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">pytz</span>==<span class="hljs-number">2024</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">PyWavelets</span>==<span class="hljs-number">1</span>.<span class="hljs-number">4</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">pywin32</span>==<span class="hljs-number">306</span><br><span class="hljs-attribute">PyYAML</span>==<span class="hljs-number">6</span>.<span class="hljs-number">0</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">pyzmq</span>==<span class="hljs-number">25</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">regex</span>==<span class="hljs-number">2023</span>.<span class="hljs-number">10</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">requests</span>==<span class="hljs-number">2</span>.<span class="hljs-number">31</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">requests</span>-oauthlib==<span class="hljs-number">1</span>.<span class="hljs-number">3</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">rsa</span>==<span class="hljs-number">4</span>.<span class="hljs-number">9</span><br><span class="hljs-attribute">safetensors</span>==<span class="hljs-number">0</span>.<span class="hljs-number">4</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">scikit</span>-image==<span class="hljs-number">0</span>.<span class="hljs-number">21</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">scikit</span>-learn==<span class="hljs-number">1</span>.<span class="hljs-number">3</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">scipy</span>==<span class="hljs-number">1</span>.<span class="hljs-number">10</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">seaborn</span>==<span class="hljs-number">0</span>.<span class="hljs-number">13</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">six</span>==<span class="hljs-number">1</span>.<span class="hljs-number">16</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">stack</span>-data==<span class="hljs-number">0</span>.<span class="hljs-number">6</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">summary</span>==<span class="hljs-number">0</span>.<span class="hljs-number">2</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">tensorboard</span>==<span class="hljs-number">2</span>.<span class="hljs-number">14</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">tensorboard</span>-data-server==<span class="hljs-number">0</span>.<span class="hljs-number">7</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">thop</span>==<span class="hljs-number">0</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span>.post2209072238<br><span class="hljs-attribute">threadpoolctl</span>==<span class="hljs-number">3</span>.<span class="hljs-number">2</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">tifffile</span>==<span class="hljs-number">2023</span>.<span class="hljs-number">7</span>.<span class="hljs-number">10</span><br><span class="hljs-attribute">timm</span>==<span class="hljs-number">0</span>.<span class="hljs-number">6</span>.<span class="hljs-number">13</span><br><span class="hljs-attribute">torch</span>==<span class="hljs-number">1</span>.<span class="hljs-number">12</span>.<span class="hljs-number">1</span>+cu116<br><span class="hljs-attribute">torch</span>-tb-profiler==<span class="hljs-number">0</span>.<span class="hljs-number">4</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">torchaudio</span>==<span class="hljs-number">0</span>.<span class="hljs-number">12</span>.<span class="hljs-number">1</span>+cu116<br><span class="hljs-attribute">torchsummary</span>==<span class="hljs-number">1</span>.<span class="hljs-number">5</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">torchvision</span>==<span class="hljs-number">0</span>.<span class="hljs-number">13</span>.<span class="hljs-number">1</span>+cu116<br><span class="hljs-attribute">torchviz</span>==<span class="hljs-number">0</span>.<span class="hljs-number">0</span>.<span class="hljs-number">2</span><br><span class="hljs-attribute">tornado</span>==<span class="hljs-number">6</span>.<span class="hljs-number">3</span>.<span class="hljs-number">3</span><br><span class="hljs-attribute">tqdm</span>==<span class="hljs-number">4</span>.<span class="hljs-number">66</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">traitlets</span>==<span class="hljs-number">5</span>.<span class="hljs-number">13</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">typing_extensions</span>==<span class="hljs-number">4</span>.<span class="hljs-number">8</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">tzdata</span>==<span class="hljs-number">2024</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">urllib3</span>==<span class="hljs-number">2</span>.<span class="hljs-number">1</span>.<span class="hljs-number">0</span><br><span class="hljs-attribute">wcwidth</span>==<span class="hljs-number">0</span>.<span class="hljs-number">2</span>.<span class="hljs-number">10</span><br><span class="hljs-attribute">Werkzeug</span>==<span class="hljs-number">3</span>.<span class="hljs-number">0</span>.<span class="hljs-number">1</span><br><span class="hljs-attribute">zipp</span>==<span class="hljs-number">3</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span><br><br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>填坑</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文思路——论文结构</title>
    <link href="/2024/05/11/paper-idear5/"/>
    <url>/2024/05/11/paper-idear5/</url>
    
    <content type="html"><![CDATA[<p>鉴于论文大修，所以我打算重新构建一下思路。</p><ol><li><p>标题</p></li><li><p>摘要 （介绍基础背景，解决什么问题，做了什么工作。）</p></li><li><p>关键词</p></li><li><p>介绍</p></li><li><p>数据和方法</p></li><li><p>结果</p></li><li><p>讨论</p></li><li><p>参考文献</p></li></ol><h2 id="论文选题方向"><a href="#论文选题方向" class="headerlink" title="论文选题方向"></a>论文选题方向</h2><ol><li>抑郁症分类 （已经尝试过了）</li><li>情绪检测，使用 DEAP数据集和SEED （代码和论文全套）</li><li>新开分类——基于公开数据集来做实验</li><li>扩大脑电数据集-训练模型</li></ol><h2 id="现在有的论文思路"><a href="#现在有的论文思路" class="headerlink" title="现在有的论文思路"></a>现在有的论文思路</h2><ol><li>抑郁症分类</li><li>AD-CN——FDT公开数据集优化问题(使用MateFormer来验证扩大数据集的思路)</li><li>研究公开数据集的论文，进行更改调优。</li></ol><h2 id="基础网站"><a href="#基础网站" class="headerlink" title="基础网站"></a>基础网站</h2><p><a href="https://openneuro.org/">医学数据获取网站</a><br><a href="https://paperswithcode.com/">代码寻找网站</a><br><a href="https://ac.scmor.com/">论文查找网站</a></p><h2 id="论文待办"><a href="#论文待办" class="headerlink" title="论文待办"></a>论文待办</h2><ol><li>证明时间剪切长度的优良性</li><li>编写自动化代码，在十则交叉验证中.第一，训练代码要保存loss和acc，使用早停。(深度学习自动化训练)，加入日志功能，封装训练代码</li></ol><p>自动化代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">from</span> dataset <span class="hljs-keyword">import</span> EEGDataset, transform1,transform3<br><span class="hljs-keyword">from</span> net <span class="hljs-keyword">import</span> IntegratedNet<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> logging<br><br>logging.basicConfig(filename=<span class="hljs-string">&#x27;training.log&#x27;</span>, level=logging.INFO, <span class="hljs-built_in">format</span>=<span class="hljs-string">&#x27;%(asctime)s - %(levelname)s - %(message)s&#x27;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_identityformer_model</span>(<span class="hljs-params">model, model_name, num_epochs=<span class="hljs-number">100</span>, num_classes=<span class="hljs-number">3</span>, batch_size=<span class="hljs-number">8</span>, learning_rate=<span class="hljs-number">0.0005</span>, w_wight=<span class="hljs-number">2560</span>, chennal=<span class="hljs-number">32</span>,load =<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-comment"># Checking CUDA availability</span><br>    <span class="hljs-keyword">if</span> torch.cuda.is_available():<br>        device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>)<br>    <span class="hljs-keyword">else</span>:<br>        device = torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)<br>    m = nn.Softmax(dim=<span class="hljs-number">1</span>)  <span class="hljs-comment"># 只对样本的维度做softmax</span><br>    <span class="hljs-comment"># Creating datasets and data loaders</span><br>    train_dataset = EEGDataset(csv_file=<span class="hljs-string">&#x27;train_data.csv&#x27;</span>, transform=transform1)<br>    test_dataset = EEGDataset(csv_file=<span class="hljs-string">&#x27;test_data.csv&#x27;</span>, transform=transform1)<br><br>    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>, drop_last=<span class="hljs-literal">True</span>)<br>    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">False</span>, drop_last=<span class="hljs-literal">True</span>)<br><br>    model.to(device)<br>    loss_fn = nn.CrossEntropyLoss()<br>    optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)<br><br>    save_dir = os.path.join(<span class="hljs-string">&#x27;model&#x27;</span>, model_name)<br>    os.makedirs(save_dir, exist_ok=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-keyword">if</span> load == <span class="hljs-literal">True</span>:<br>        model.load_state_dict(torch.load(<span class="hljs-string">&#x27;三分类预训练模型-0.99.pth&#x27;</span>))<br>        <span class="hljs-comment"># num_ftrs = model.final_linear.in_features</span><br>        <span class="hljs-comment"># model.final_linear = nn.Linear(num_ftrs,2)</span><br>        <span class="hljs-comment"># model.to(device)</span><br>    best_val_acc = <span class="hljs-number">0</span><br>    best_model_path = os.path.join(save_dir, <span class="hljs-string">&quot;&#123;&#125;_best_model.pth&quot;</span>.<span class="hljs-built_in">format</span>(model_name))<br><br>    <span class="hljs-comment"># 训练</span><br>    train_loss_arr = []<br>    train_acc_arr = []<br>    val_loss_arr = []<br>    val_acc_arr = []<br><br><br>    early_stop = <span class="hljs-literal">False</span><br>    patience = <span class="hljs-number">5</span>  <span class="hljs-comment"># 容忍次数，超过这个次数准确率不再提升就停止</span><br>    counter = <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        train_loss_total = <span class="hljs-number">0</span>  <span class="hljs-comment"># 所有batch的loss累加值</span><br>        train_acc_total = <span class="hljs-number">0</span>   <span class="hljs-comment"># 所有batch的acc累加值`</span><br>        val_loss_total = <span class="hljs-number">0</span><br>        val_acc_total = <span class="hljs-number">0</span><br><br>        model.train()    <span class="hljs-comment"># 标志模型的模式是什么，因为dropout只在训练时启用</span><br>        <span class="hljs-keyword">for</span> i, (train_x, train_y) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(tqdm(train_loader, desc=<span class="hljs-string">f&quot;Epoch <span class="hljs-subst">&#123;epoch+<span class="hljs-number">1</span>&#125;</span>/<span class="hljs-subst">&#123;num_epochs&#125;</span>&quot;</span>)):<br>            train_x = train_x.to(device)<br>            <span class="hljs-comment"># print(&#x27;train_x shape&#x27;,train_x.shape)</span><br>            train_y = train_y.to(device)<br>            train_x = train_x.unsqueeze(<span class="hljs-number">1</span>)<br>            train_x = train_x.view(batch_size, <span class="hljs-number">1</span>, chennal, w_wight)<br>            <span class="hljs-comment"># 前向传播</span><br>            train_y_pred = model(train_x)<br>            train_loss = loss_fn(train_y_pred, train_y)<br><br>            <span class="hljs-comment"># 通过模型每个样本得到4个实数值（train_y_pred）,通过softmax将实数值转换成概率值，通过max取概率最大的下标，最后用下标和标签做比较</span><br>            train_acc = (m(train_y_pred).<span class="hljs-built_in">max</span>(dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>] == train_y).<span class="hljs-built_in">sum</span>()/train_y.shape[<span class="hljs-number">0</span>]<br>            train_loss_total += train_loss.data.item()<br>            train_acc_total += train_acc.data.item()<br>            <span class="hljs-comment"># 反向传播</span><br>            train_loss.backward()<br>            <span class="hljs-comment"># 梯度下降</span><br>            optimizer.step()<br>            optimizer.zero_grad()<br><br>            <span class="hljs-comment"># print(&quot;epoch:&#123;&#125; train_loss:&#123;&#125; train_acc:&#123;&#125;&quot;.format(epoch, train_loss.data.item(), train_acc.data.item()))</span><br><br>        train_loss_arr.append(train_loss_total / <span class="hljs-built_in">len</span>(train_loader))  <span class="hljs-comment"># 平均值</span><br>        train_acc_arr.append(train_acc_total / <span class="hljs-built_in">len</span>(train_loader))<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;epoch:&#123;&#125; train_loss:&#123;&#125; train_acc:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(epoch, train_loss_arr[-<span class="hljs-number">1</span>], train_acc_arr[-<span class="hljs-number">1</span>]))<br>        <br><br>       <br>        <span class="hljs-comment"># 测试集</span><br>        model.<span class="hljs-built_in">eval</span>()<br>        <span class="hljs-keyword">for</span> j, (val_x, val_y) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(test_loader):<br>            val_x = val_x.to(device)<br>            val_y = val_y.to(device)<br>            val_x = val_x.unsqueeze(<span class="hljs-number">1</span>)<br>            val_x = val_x.view(batch_size, <span class="hljs-number">1</span>, chennal, w_wight)<br>            <span class="hljs-comment"># 前向传播</span><br>            val_y_pred = model(val_x)<br>            val_loss = loss_fn(val_y_pred, val_y)<br>            val_acc = (m(val_y_pred).<span class="hljs-built_in">max</span>(dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>] == val_y).<span class="hljs-built_in">sum</span>()/val_y.shape[<span class="hljs-number">0</span>]<br>            val_loss_total += val_loss.data.item()<br>            val_acc_total += val_acc.data.item()<br><br>        val_loss_arr.append(val_loss_total / <span class="hljs-built_in">len</span>(test_loader)) <span class="hljs-comment"># 平均值</span><br>        val_acc_arr.append(val_acc_total / <span class="hljs-built_in">len</span>(test_loader))<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;epoch:&#123;&#125; val_loss:&#123;&#125; val_acc:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(epoch, val_loss_arr[-<span class="hljs-number">1</span>], val_acc_arr[-<span class="hljs-number">1</span>]))<br><br>        logging.info(<span class="hljs-string">f&quot;Epoch <span class="hljs-subst">&#123;epoch&#125;</span>: Train Loss: <span class="hljs-subst">&#123;train_loss_arr[-<span class="hljs-number">1</span>]&#125;</span>, Train Acc: <span class="hljs-subst">&#123;train_acc_arr[-<span class="hljs-number">1</span>]&#125;</span>, Val Loss: <span class="hljs-subst">&#123;val_loss_arr[-<span class="hljs-number">1</span>]&#125;</span>, Val Acc: <span class="hljs-subst">&#123;val_acc_arr[-<span class="hljs-number">1</span>]&#125;</span>&quot;</span>)<br>        <span class="hljs-comment"># 保存最佳模型</span><br>        <span class="hljs-keyword">if</span> val_acc_arr[-<span class="hljs-number">1</span>] &gt; best_val_acc:<br>            best_val_acc = val_acc_arr[-<span class="hljs-number">1</span>]<br>            torch.save(model.state_dict(), best_model_path)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;保存模型成功!&quot;</span>)<br>            counter = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">else</span>:<br>            counter += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> counter &gt;= patience:<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Early stopping&quot;</span>)<br>                early_stop = <span class="hljs-literal">True</span><br>                <span class="hljs-keyword">break</span><br><br>        <span class="hljs-comment"># 保存训练和验证过程中的loss和acc</span><br>        np.save(os.path.join(save_dir, <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;model_name&#125;</span>_train_loss.npy&quot;</span>), np.array(train_loss_arr))<br>        np.save(os.path.join(save_dir, <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;model_name&#125;</span>_train_acc.npy&quot;</span>), np.array(train_acc_arr))<br>        np.save(os.path.join(save_dir, <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;model_name&#125;</span>_val_loss.npy&quot;</span>), np.array(val_loss_arr))<br>        np.save(os.path.join(save_dir, <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;model_name&#125;</span>_val_acc.npy&quot;</span>), np.array(val_acc_arr))<br><br><br>        <span class="hljs-keyword">if</span> early_stop:<br>            <span class="hljs-keyword">break</span><br>   <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Training completed!&#x27;</span>)<br><br><br><span class="hljs-comment"># 创建模型</span><br>model = IntegratedNet(input_size=<span class="hljs-number">1</span>, in_feature=<span class="hljs-number">320</span>, num_classes=<span class="hljs-number">3</span>)<br><br><span class="hljs-comment"># 训练参数</span><br>num_epochs = <span class="hljs-number">100</span><br>num_classes = <span class="hljs-number">3</span><br>batch_sizes = [<span class="hljs-number">8</span>,<span class="hljs-number">16</span>,<span class="hljs-number">16</span>,<span class="hljs-number">16</span>]<br>learning_rates = [<span class="hljs-number">0.0005</span>, <span class="hljs-number">0.0005</span>, <span class="hljs-number">0.0005</span>, <span class="hljs-number">0.0005</span>]<br>chennal = <span class="hljs-number">11</span><br>w_wight = <span class="hljs-number">5120</span><br><br><span class="hljs-comment"># 在训练前加入日志记录</span><br>logging.info(<span class="hljs-string">&quot;Start training&quot;</span>)<br><br><span class="hljs-comment"># 多次训练</span><br><span class="hljs-keyword">for</span> i, (learning_rate, batch_size) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(<span class="hljs-built_in">zip</span>(learning_rates, batch_sizes)):<br>    <span class="hljs-comment"># 生成当前训练的 model_name</span><br>    model_name = <span class="hljs-string">f&quot;混合数据集-第<span class="hljs-subst">&#123;i + <span class="hljs-number">1</span>&#125;</span>次-AD-CN-MCI-10秒-learning-<span class="hljs-subst">&#123;learning_rate&#125;</span>bitch-<span class="hljs-subst">&#123;batch_size&#125;</span>&quot;</span><br>    logging.info(<span class="hljs-string">f&quot;Training parameters - Model: <span class="hljs-subst">&#123;model_name&#125;</span>, Num Epochs: <span class="hljs-subst">&#123;num_epochs&#125;</span>, Num Classes: <span class="hljs-subst">&#123;num_classes&#125;</span>, Batch Size: <span class="hljs-subst">&#123;batch_size&#125;</span>, Learning Rate: <span class="hljs-subst">&#123;learning_rate&#125;</span>, Chennal: <span class="hljs-subst">&#123;chennal&#125;</span>, W Weight: <span class="hljs-subst">&#123;w_wight&#125;</span>&quot;</span>)<br>    <span class="hljs-comment"># 创建并训练模型</span><br>    train_identityformer_model(model, model_name=model_name, num_epochs=num_epochs, num_classes=num_classes, batch_size=batch_size, learning_rate=learning_rate, chennal=chennal, w_wight=w_wight, load=<span class="hljs-literal">False</span>)<br><br><span class="hljs-comment"># 训练结束后记录日志</span><br>logging.info(<span class="hljs-string">&quot;Training completed&quot;</span>)<br></code></pre></td></tr></table></figure><h2 id="防止模型过拟合的方法"><a href="#防止模型过拟合的方法" class="headerlink" title="防止模型过拟合的方法"></a>防止模型过拟合的方法</h2><p>过拟合: </p><p>根据数据集的简单和复杂的程度来选取对应的模型容量</p><p>模型容量： ·拟合各种函数的能力 ·低容量的模型难以拟合训练数据·高容量的模型可以记住所有的训练数据<br>评估模型容量的两个指标： 参数的个数，参数值的选择范围。<br><img src="/pic/paper-idear5-1.png" alt="数据复杂时应该选择复杂的模型"><br><img src="/pic/paper-idear5-2.png" alt="模型容量和误差之间的关系"><br>深度学习的核心任务将泛化误差往下降低。</p><p>了解数据的复杂度： 1. 样本个数。 2.  每个样本的元素个数。 3. 样本的时间、空间结构。 4. 样本的多样性。<br>VC维：对于一个分类模型，VC等于一个最大的数据集的大小，不管如何给定标号，都存在一个模型来对它进行完美分类<br>·模型容量需要匹配数据复杂度，否则可能导致欠拟合和过拟合<br>·统计机器学习提供数学工具来衡量模型复杂度·实际中一般靠观察训练误差和验证误差</p><p>神经网络是一种语言，一种使用各个层来解释我的数据的语言，</p><h3 id="解决拟合的思路。"><a href="#解决拟合的思路。" class="headerlink" title="解决拟合的思路。"></a>解决拟合的思路。</h3><ol><li>数据集划分</li><li>正则化 (L1,l2正则化。)</li><li>增加训练数据</li><li>特征选择</li><li>交叉验证</li><li>提前停止 (Early stopping)</li><li>Dropout</li><li>网络结构 Architecture （模型容量） 特征提取器更换，分类器（SVM）</li><li>限制权值&#x2F;权重衰减 weight-decay</li><li>增加噪声 Noise</li><li>数据增强 （空间特征 + 时间特征）</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>论文思路</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔16</title>
    <link href="/2024/05/10/ganwu16/"/>
    <url>/2024/05/10/ganwu16/</url>
    
    <content type="html"><![CDATA[<p>死亡赋予我生活的希望，忧虑是没有用的，发掘自己内在的价值，应该有梦想有内在的动机，想好今天我应该收获什么，收获进步，一点点，坚持自己想法的人和随波逐流的人，生命将有不同。所谓成长，就是实现独立生存、完成独立思考能力的自我奋斗。所谓成熟，就是对内消除傲慢，对外消除偏见的自我修行。你问我有哪些进步，我开始成为自己的朋友开始时。我才20岁，我可以成为任何我想成为的人，生命是用来感受而不是用来忧虑的，我能在浪费时间中获得乐趣，就不是浪费时间。生命并没有什么意义，但是活着的话就可能遇见有意思的事，就像你遇见那朵花，就像我遇见了你。改变总是慢慢发生的，人们总说时间可以改变很多事情，但事实上必须由你自己做出哪些改变。</p><p>对待不同的人，不同的事，不必要过多的去带入情感，人之所以言之凿凿，是因为知道的太少，所有的生活都是合理的，我们没必要相互理解。在世间 本就是各人下雪 各人有各人的隐晦和皎洁。最难沟通的，不是没有文化的人，而是那些满脑子都被灌输了标准答案的人。每个人都不是一座孤岛，一个人必须事这世界最坚固的岛屿，然后才能成为大陆的一部分。  ​​</p><p>迷茫的原因在于读书太少而想的太多。但读那么多书干嘛，读得多想得多，烦恼就多。这不能说没道理，但我总觉得哪不对劲，直到后来读到法国诗人勒内.夏尔一席话方才释然，他说:“理解得越多就越痛苦。知道得越多就越撕裂。但他有着同痛苦相对称的清澈，与绝望相均衡的坚韧。</p><h2 id="内心的秩序"><a href="#内心的秩序" class="headerlink" title="内心的秩序"></a>内心的秩序</h2><p>内心也是需要秩序的，儒家讲内圣外王，要想外王，首先得内圣，怎么内圣是个问题。世界纷纷扰扰，认识论指出对于世界的认知是从没有到感性的认知的，然后经过不断的实践，不断的反复论证深化成理性的认知。问题在于在认识的过程中，由无到有，由感性到理性的过程中，在实践的过程中，内心会经历巨大的变化，这个变化是客观的，必然的，不是特例的。</p><p>那么为什么在实践的过程中，不同的人会产生不同的认知，产生不同的结果？第一，对于不同的人来讲，每个人所处的环境，条件是不同的，这是客观的事实（实事求是）。第二，由于不同的人有不同的条件，对于环境的认知是不同的，举个例子，何不食肉糜，为什么不吃肉勒，这就是不同的人有不同的条件，条件的不同产生了不同的认识，这样就产生的各种各样的人。人类物种的多样性就是这样的，这是规律，对于不同的人，对于不同的立场，我的态度是包容，但是这个观点践行起来却是有点困难的。人是立场的，好恶的，我们总是只相信自己愿意相信的东西。我们习惯于先形成观点，然后再寻找既有立场的正面证据，在不知不觉中偏离真实对于与我不同的观点，我的第一想法是对立，辩驳对方的观点，来维护自己的观点，这是正常的，如果我有一点能力，我就能与对方辩驳一下。在与人辩驳的过程中，会有很多州情况，其中一种是友好交流，互相进步，一种是懒得和对方争辩，处于自己的世界中（固步自封），一种是锋芒相对，互相博弈，带动情绪，劳损身体（怒发冲冠）。大部分情况中我是第二种情况固步自封，争辩的勇气都是没有的，稍微好一点的是怒发冲冠，勇气可嘉，捍卫立场，这里需要指出的是立场是没有对错的，只不过是矛盾而已，矛盾就是此消彼长，至于对错（小孩子才在乎）。</p><p>怎么来提升自己的认识？实践，简单来说就是做事，不断反思，但是在实践的过程中，内心是矛盾的，一种情况是觉得这件事情是困难的，我能不能做好，失败了怎么办。一种情况是觉得这件事情做了我也没有什么收获，不如不做。一种情况是在做的过程中不断的内耗。对于第一种情况，需要说明的是，在以前的实践过程中，我形成许多的观点是错误的，比如认为做事只做大事，做人只做大人物。我想这种观点的形成与小时候看的电影，电视有关吧，背景都是什么宫廷争斗剧场，三国演义（刘关张），楚汉争霸（项羽与刘邦），当英雄，做刘备，项羽之类的人物，这样的想法形成后就没有了下文，其实有了想法后应该想怎么成为这样的人，但是大部分想法实际上是胎死腹中了。现在觉得，做事就做事，管他难不难，先做了再说，失败了有经验，成功了最好。在做事的过程中应该有一种心态是，天下难事必作于易，天下大事必作于细。对于第一种心态，能不能做好，其实很多时候接触没有接触过的事物，能做好的概率微乎其微，没有认识，没有经历怎么能够做好，这种情况应该不要畏难，从我不会变成我可以学。</p><p>貌似有点跑题了，标题是内心的秩序，为啥取这个标题，因为互联网的一大好处是看到许多不同的人发生的不同的事，许多不同的价值观，世界观，人生观在交融，在对立。这样是很好的，但是对立不免就有纷争，有暴力（这里的暴力是指语言暴力）。不同的视频反应的是现象，背后更反映着互联网的多元化的价值观。举个例子，小红书，微博，抖音，b站，推特，知乎，默默，快手，百度贴吧，透过这些窗口我能看到世界是分层的，热爱生活的，消极生活的，有钱的，没钱的，美丽的，丑陋的。不同的人展现出不同的现象，而我不经自问，我以什么样的态度来面对这样多元的世界，遇到好的，坏的（注：没有好坏之分，只有矛盾对立）。我想是需要建立内心的秩序去面对这多元的世界了。<br>怎么建立内心的秩序？ 熵增，熵是衡量一个系统的混乱程度，心流这本书中提出了精神熵，用来衡量内心的秩序。我想我的精神熵不是很高吧，在随笔2中我指出，心法胜于法则，法则胜于技术（方法）。法则中基于法则可以诞生出方法（技术）来应对不同的事情，技术则可以统领知识。问题便被缩小为我的心法是什么，怎么使用心法来诞生一个法则来应对多元化的世界。（注意这里是专门建立一个法则来应对多元化的世界不是通用的），我的心法统御着我认知到的法则和方法。（法则有内心的法则和世界的法则，内心的法则和世界的法则相关，但是不对等，比如说做事要慢慢来，一步一步来是做事的法则，但是自己内心的法则不是这样的，和世界的法则不是对等的，因此要改变自己内心的法则），那么选取什么来作为我的心法（有点像武林秘籍了）是一个问题，目前我探寻到一个心法，在随笔14中我写道，死亡指引我方向，赋予我战胜一切的勇气，未知死，焉知生。从死亡中我领悟到自强，天行建，君子以自强不息。地势坤，君子以厚德载物。遥远的救世主，不要去追寻救世主了，自己就是自己的救世主，自强，君子处事，应像天一样，自我力求进步，刚毅坚卓，发奋图强，永不停息；大地的气势厚实和顺，君子应增厚美德，容载万物。选自强做心法的好处是有目标，目标就是变强，进步，获取解决问题的能力，这是很好的。而其他的一切问题都可以根据自强来统御法则，法则来统御方法。而我自己就是方法的践行者，一个人人的组成是多元的，物质的，精神的。<br>需要指出的是可以通过方法看到法则，可以通过法则看到心法。只要不断实践不断反思就能行。<br>还有就是可以参考别人的法则和心法，但不一定使用，因为见路不走，实事求是（这个感觉比心法低一层，比能基本法则高一层）</p><p>参考法则和方法</p><ol><li>天下难事必作于易，天下大事必作于细。 诱导方法， 微行为，微习惯。 </li><li>做事时清楚的明白自己在干嘛，诱导方法，坚持每天写手帐记录的目的就在于使得我们在任何一个给定时间，能够做出最好的选择：现在要采取哪个行动。这样我们做任何事情的时候都明白这个是现在最应该做的事，而不必担心有什么重要的事情没做。我们的心态就永远平静。诱导方法2，坚持写作，你会越来越注重内在，当某一天，你回头看着每一篇文章，全部都是收获和回忆，内心充实而感动。文章写的也许不够好，但都是你亲手写的。一篇篇文章见证了你的成长和进步，也成为了你生活的一部分。这种充实，是无法用言语来描述的。写作，可以深入内心，直接和自己对话。生活本身，其实不是最好的生活方式，我们可以用写作，来质疑和反抗。 诱导法则3， 随时记录下脑海中的灵感， 只要能够令人产生情绪波动的，都是值得捕捉的故事”，“三分眼睛，七分内心”，平时读书，阅读文章，总有一些感动得故事和金句，心灵触动，都要记录下来，慢慢刻意去练习，自己慢慢也能写出想写的内容了。</li><li>法则和方法是可以参考和获取的，诱导方法，坚持阅读，会越来越通透。通过阅读能将自己的内心简化，将自己对待世界的方法简化。不要以为学生生涯结束了，就可以不用再读书（傻孩子，好日子才刚刚开始勒！！！）阅读好书，就是和世界上最优秀的人物进行对话，向他们学习，成为掌握新知识，新信息，新兴趣的起点，可以从他们身上吸收正能量，还能像吸水纸一样，吸走我们身上的负能量，整个人的思想和灵魂都会得到净化，变得通透，丰富，有内涵。整个人生都是我们的学习之路，这条路不会停下来，若是强行停止，那么在停止的那一瞬间我们就已经开启了死亡倒计时。</li><li>身体是最重要的，马克思都说，物质是第一性的，精神是第二性的。 诱导方法，坚持锻炼，越来越年轻，骑行，跑步，行走。坚持锻炼，不仅是为了更健康地生活，更是为了愉快地与自己相处，享受“一个人的喜悦”。感受生命的惬意。 我自己的方法，一个俯卧撑，每天做一个俯卧撑，慢慢来（此方法为做事法则和身体法则推导出的方法的融合版本，一天做一个，不容易失败，即使做不到也没有负罪感。）</li><li>内心不需要减熵，一个系统到达一定程度时会出现自毁的倾向，减少熵是必要的。 诱导方法，坚持断舍离，明确自己的需要，想要和必要，不放纵欲望，把钱花在刀刃。 诱导法则2，冥想，每天关掉手机，闭上眼睛，留给自己一个和“自己独处的时间”，是一件特别重要且必要的事情，让我们平静内心，自在呼吸。不在意别人走多快，专注于自己走多远。专注你想做的事，心无旁骛，你会发现自己控制情绪的能力，专注力，对未来的规划，都会越来越成效，还会乐在其中。</li><li>培养自己的能力是必要的。（法则也分等级的）诱导法则，建立财商观， 你不理财，财不理你， 诱导方法， 坚持记账，做好定投， 手上的纸币某种程度上是负债，流动的纸币才是资产，虽然可能变成负资产。做一名终生定投者，掌握方法，增加本金，提高收益率，让钱生钱的威力争取发挥最大化。</li><li>实践是认识的来源，理论指导实践。诱导方法，每天，每周，每月，每年都要复盘，不抽象，就无法深入思考，不还原，就看不到本来面目。进行复盘，总有一天你就是那个可以看到事情真相的人。 诱导方法， 做一个行动者，你和梦想之间就差一个行动，为了靠近或者实现梦想，除了行动就是行动。唯有行动才能解除所有的不安，焦虑，怀疑，懒惰，拖延。</li><li>不要自己禁锢自己。 推导法则： 自己以为不行是不行，那就是真的不行，但是还是要试一下才能知道行不行。 推导法则2： 不要让别人来禁锢你自己，别人告诉你要干嘛，我就干嘛，那是傻逼，要有自己的想法，自己的思想，被别人买了还帮人数钱。别人凭什么来为你服务，别人没有义务，也没有责任，不要把人想的太好了，也不要把人想的太差。天下没有白来的好处，靠人人倒。靠山山倒。 推导公式3，问题在于不要说自己学了这个专业就要干这个专业的事情，要跨界而行。</li><li>给自己穿件衣服：下意识的看轻你，人的第一印象是最难改变的，预设一旦完成，轻则被怠慢，重则被人故意为难。而假如你衣着体面，从某种程度上其实是在保护自己、方便自己。而懂得游戏规则本身，就是在给自己穿上一件“体面的衣服”，它的目的不是为了“虚荣”，而是为了保护自己、避免一些不必要的麻烦。控制自己需要阐述的欲望，“学会保护好自己，不管在什么环境，首先都要确保自己能应对周围不同的人与事，比如你从来没有把别人当对手，但别人会把你当做对手，对此，你要有所准备，以及要有对应方法。”<br><a href="https://www.zhihu.com/question/31756387/answer/2146825423">参考博客-永生</a><br><a href="https://www.zhihu.com/question/301793024/answer/786846336">参考博客-有哪些可以坚持下去的好习惯</a></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>感悟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文思路——代码</title>
    <link href="/2024/05/09/paper-idear4/"/>
    <url>/2024/05/09/paper-idear4/</url>
    
    <content type="html"><![CDATA[<h2 id="数据划分"><a href="#数据划分" class="headerlink" title="数据划分"></a>数据划分</h2><ol><li>数据集分类</li></ol><p>将set的文件转换为npy格式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> mne<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">find_set_files</span>(<span class="hljs-params">root_folder</span>):<br>    set_files = []<br>    <span class="hljs-keyword">for</span> root, dirs, files <span class="hljs-keyword">in</span> os.walk(root_folder):<br>        <span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> files:<br>            <span class="hljs-keyword">if</span> file.endswith(<span class="hljs-string">&#x27;.set&#x27;</span>):<br>                set_files.append(os.path.join(root, file))<br>    <span class="hljs-keyword">return</span> set_files<br><br><span class="hljs-comment"># 指定您的 AD 文件夹路径</span><br>ad_folder = <span class="hljs-string">r&#x27;FDT&#x27;</span><br><br><span class="hljs-comment"># 指定保存 .npy 文件的新文件夹路径</span><br>output_folder = <span class="hljs-string">r&#x27;data_onremove_npy/FDT&#x27;</span><br>os.makedirs(output_folder, exist_ok=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 找到所有的 .set 文件</span><br>set_files = find_set_files(ad_folder)<br><br><span class="hljs-comment"># 读取 .set 文件并保存为 .npy 文件</span><br><span class="hljs-keyword">for</span> file_path <span class="hljs-keyword">in</span> set_files:<br>    <span class="hljs-comment"># 读取 .set 文件</span><br>    raw = mne.io.read_raw_eeglab(file_path, preload=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-comment"># 获取原始数据</span><br>    data = raw.get_data()<br><br>    <span class="hljs-comment"># 构造新的文件路径</span><br>    npy_file_name = os.path.basename(file_path).replace(<span class="hljs-string">&#x27;.set&#x27;</span>, <span class="hljs-string">&#x27;.npy&#x27;</span>)<br>    npy_file_path = os.path.join(output_folder, npy_file_name)<br><br>    <span class="hljs-comment"># 保存为 .npy 文件</span><br>    np.save(npy_file_path, data)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Saved <span class="hljs-subst">&#123;npy_file_path&#125;</span>&#x27;</span>)<br><br></code></pre></td></tr></table></figure><p>将npy数据剪切到想要的长度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> mne<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">find_set_files</span>(<span class="hljs-params">root_folder</span>):<br>    set_files = []<br>    <span class="hljs-keyword">for</span> root, dirs, files <span class="hljs-keyword">in</span> os.walk(root_folder):<br>        <span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> files:<br>            <span class="hljs-keyword">if</span> file.endswith(<span class="hljs-string">&#x27;.set&#x27;</span>):<br>                set_files.append(os.path.join(root, file))<br>    <span class="hljs-keyword">return</span> set_files<br><br><span class="hljs-comment"># 指定您的 AD 文件夹路径</span><br>ad_folder = <span class="hljs-string">r&#x27;FDT&#x27;</span><br><br><span class="hljs-comment"># 指定保存 .npy 文件的新文件夹路径</span><br>output_folder = <span class="hljs-string">r&#x27;data_onremove_npy/FDT&#x27;</span><br>os.makedirs(output_folder, exist_ok=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 找到所有的 .set 文件</span><br>set_files = find_set_files(ad_folder)<br><br><span class="hljs-comment"># 读取 .set 文件并保存为 .npy 文件</span><br><span class="hljs-keyword">for</span> file_path <span class="hljs-keyword">in</span> set_files:<br>    <span class="hljs-comment"># 读取 .set 文件</span><br>    raw = mne.io.read_raw_eeglab(file_path, preload=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-comment"># 获取原始数据</span><br>    data = raw.get_data()<br><br>    <span class="hljs-comment"># 构造新的文件路径</span><br>    npy_file_name = os.path.basename(file_path).replace(<span class="hljs-string">&#x27;.set&#x27;</span>, <span class="hljs-string">&#x27;.npy&#x27;</span>)<br>    npy_file_path = os.path.join(output_folder, npy_file_name)<br><br>    <span class="hljs-comment"># 保存为 .npy 文件</span><br>    np.save(npy_file_path, data)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Saved <span class="hljs-subst">&#123;npy_file_path&#125;</span>&#x27;</span>)<br><br><br></code></pre></td></tr></table></figure><p>对数据进行fft变换</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">import os<br>import numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-built_in">from</span> tqdm import tqdm<br><br><span class="hljs-comment"># 定义输入和输出文件夹路径</span><br>input_folder = <span class="hljs-string">&#x27;data_cut_npy/AD&#x27;</span>  <span class="hljs-comment"># 输入文件夹路径，包含要进行 FFT 变换的 .npy 文件</span><br>output_folder = <span class="hljs-string">&#x27;data_FFT_npy/AD&#x27;</span>  <span class="hljs-comment"># 输出文件夹路径，用于保存变换后的数据</span><br><br><span class="hljs-comment"># 确保输出文件夹存在</span><br>os.makedirs(output_folder, exist_ok=True)<br><br><span class="hljs-comment"># 获取输入文件夹中的所有 .npy 文件</span><br>file_list = os.listdir(input_folder)<br>npy_files = [<span class="hljs-built_in">file</span> <span class="hljs-keyword">for</span> <span class="hljs-built_in">file</span> <span class="hljs-keyword">in</span> file_list <span class="hljs-keyword">if</span> <span class="hljs-built_in">file</span>.endswith(<span class="hljs-string">&#x27;.npy&#x27;</span>)]<br><br><span class="hljs-comment"># 遍历每个 .npy 文件进行 FFT 变换并保存</span><br><span class="hljs-keyword">for</span> file_name <span class="hljs-keyword">in</span> tqdm(npy_files, desc=<span class="hljs-string">&#x27;Processing&#x27;</span>, unit=<span class="hljs-string">&#x27;file&#x27;</span>):<br>    <span class="hljs-comment"># 读取 .npy 文件</span><br>    file_path = os.path.join(input_folder, file_name)<br>    data = np.<span class="hljs-built_in">load</span>(file_path)<br><br>    <span class="hljs-comment"># 对数据中的每一行进行 FFT 变换</span><br>    fft_data = np.apply_along_axis(np.fft.fft, axis=<span class="hljs-number">0</span>, arr=data)<br><br>    <span class="hljs-comment"># 获取 FFT 结果的幅值</span><br>    fft_magnitude = np.<span class="hljs-built_in">abs</span>(fft_data)<br><br>    <span class="hljs-comment"># 构造输出文件路径</span><br>    output_file_name = file_name.<span class="hljs-built_in">replace</span>(<span class="hljs-string">&#x27;.npy&#x27;</span>, <span class="hljs-string">&#x27;_fft.npy&#x27;</span>)<br>    output_file_path = os.path.join(output_folder, output_file_name)<br><br>    <span class="hljs-comment"># 保存 FFT 结果</span><br>    np.save(output_file_path, fft_magnitude)<br><br></code></pre></td></tr></table></figure><p>显示fft数据</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs clean"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> os<br><br># 替换为包含.npy文件的文件夹路径列表<br>folder_paths = [<span class="hljs-string">&quot;data_FFT_npy/AD&quot;</span>, <span class="hljs-string">&quot;data_FFT_npy/CN&quot;</span>,<span class="hljs-string">&quot;data_FFT_npy/FDT&quot;</span>]  # 替换为实际的文件夹路径列表<br># [<span class="hljs-string">&quot;normal_save&quot;</span>, <span class="hljs-string">&quot;open_normal_save&quot;</span>, <span class="hljs-string">&quot;open_patient_save&quot;</span>,<span class="hljs-string">&#x27;patient_save&#x27;</span>]<br># 循环遍历每个文件夹<br>for folder_path <span class="hljs-keyword">in</span> folder_paths:<br>    # 获取文件夹中的所有.npy文件<br>    npy_files = [file for file <span class="hljs-keyword">in</span> os.listdir(folder_path) <span class="hljs-keyword">if</span> file.endswith(<span class="hljs-string">&#x27;.npy&#x27;</span>)]<br><br>    # 循环加载每个.npy文件并显示其形状<br>    for npy_file <span class="hljs-keyword">in</span> npy_files:<br>        npy_file_path = os.path.join(folder_path, npy_file)<br>        data = np.load(npy_file_path)<br>        print(f<span class="hljs-string">&quot;Folder: &#123;folder_path&#125;, File: &#123;npy_file&#125;, Shape: &#123;data.shape&#125;&quot;</span>)<br><br></code></pre></td></tr></table></figure><h2 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h2><p>训练代码</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><code class="hljs css">import os<br>import numpy as np<br>import torch<br>import torch<span class="hljs-selector-class">.nn</span> as nn<br>import torch<span class="hljs-selector-class">.optim</span> as optim<br><span class="hljs-selector-tag">from</span> torch<span class="hljs-selector-class">.utils</span><span class="hljs-selector-class">.data</span> import DataLoader<br><span class="hljs-selector-tag">from</span> torchvision import transforms<br><span class="hljs-selector-tag">from</span> tqdm import tqdm<br><span class="hljs-selector-tag">from</span> dataset import EEGDataset,EEGDataset_Batch_normal<br><span class="hljs-selector-tag">from</span> net import IntegratedNet<br><span class="hljs-selector-tag">from</span> sklearn<span class="hljs-selector-class">.metrics</span> import classification_report<br><span class="hljs-selector-tag">from</span> matplotlib import pyplot as plt<br><br><br># 定义归一化操作<br>def normalize(data):<br>    mean = np.<span class="hljs-built_in">mean</span>(data)<br>    std = np.<span class="hljs-built_in">std</span>(data)<br>    return (data - mean) / std<br><br>transform = transforms.<span class="hljs-built_in">Compose</span>([<br>        transforms.<span class="hljs-built_in">Lambda</span>(normalize),  # 使用Lambda函数应用自定义归一化操作<br>        transforms.<span class="hljs-built_in">ToTensor</span>()<br>    ])<br><br>def <span class="hljs-built_in">train_identityformer_model</span>(model, model_name, num_epochs=<span class="hljs-number">100</span>, num_classes=<span class="hljs-number">3</span>, batch_size=<span class="hljs-number">16</span>, learning_rate=<span class="hljs-number">0.0001</span>, w_wight=<span class="hljs-number">1025</span>, chennal=<span class="hljs-number">33</span>):<br>    if torch.cuda.<span class="hljs-built_in">is_available</span>():<br>        device = torch.<span class="hljs-built_in">device</span>(<span class="hljs-string">&quot;cuda&quot;</span>)<br>    else:<br>        device = torch.<span class="hljs-built_in">device</span>(<span class="hljs-string">&quot;cpu&quot;</span>)<br>    m = nn.<span class="hljs-built_in">Softmax</span>(dim=<span class="hljs-number">1</span>)<br><br>    train_dataset = <span class="hljs-built_in">EEGDataset</span>(csv_file=<span class="hljs-string">&#x27;train_data.csv&#x27;</span>, transform=transform)<br>    test_dataset = <span class="hljs-built_in">EEGDataset</span>(csv_file=<span class="hljs-string">&#x27;test_data.csv&#x27;</span>, transform=transform)<br><br>    train_loader = <span class="hljs-built_in">DataLoader</span>(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)<br>    test_loader = <span class="hljs-built_in">DataLoader</span>(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)<br><br>    model.<span class="hljs-built_in">to</span>(device)<br>    loss_fn = nn.<span class="hljs-built_in">CrossEntropyLoss</span>()<br>    optimizer = optim.<span class="hljs-built_in">RMSprop</span>(model.<span class="hljs-built_in">parameters</span>(), lr=learning_rate)<br><br>    save_dir = <span class="hljs-string">&#x27;loss&#x27;</span><br>    os.<span class="hljs-built_in">makedirs</span>(save_dir, exist_ok=True)<br><br>    train_loss_arr = []<br>    train_acc_arr = []<br>    val_loss_arr = []<br>    val_acc_arr = []<br><br>    best_val_acc = <span class="hljs-number">0.0</span><br>    best_epoch = <span class="hljs-number">0</span><br><br>    for epoch in <span class="hljs-built_in">range</span>(num_epochs):<br>        train_loss_total = <span class="hljs-number">0</span><br>        train_acc_total = <span class="hljs-number">0</span><br>        val_loss_total = <span class="hljs-number">0</span><br>        val_acc_total = <span class="hljs-number">0</span><br><br>        model.<span class="hljs-built_in">train</span>()<br>        progress_bar = <span class="hljs-built_in">tqdm</span>(<span class="hljs-built_in">enumerate</span>(train_loader), total=<span class="hljs-built_in">len</span>(train_loader))<br>        for i, (train_x, train_y) in progress_bar:<br>            train_x = train_x.<span class="hljs-built_in">to</span>(device)<br>            train_y = train_y.<span class="hljs-built_in">to</span>(device)<br>            train_x = train_x.<span class="hljs-built_in">unsqueeze</span>(<span class="hljs-number">1</span>)<br>            train_x = train_x.<span class="hljs-built_in">view</span>(batch_size, <span class="hljs-number">1</span>, chennal, w_wight)<br><br>            train_y_pred = <span class="hljs-built_in">model</span>(train_x)<br>            train_loss = <span class="hljs-built_in">loss_fn</span>(train_y_pred, train_y)<br><br>            train_acc = (<span class="hljs-built_in">m</span>(train_y_pred).<span class="hljs-built_in">max</span>(dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>] == train_y).<span class="hljs-built_in">sum</span>() / train_y.shape[<span class="hljs-number">0</span>]<br>            train_loss_total += train_loss.data.<span class="hljs-built_in">item</span>()<br>            train_acc_total += train_acc.data.<span class="hljs-built_in">item</span>()<br><br>            train_loss.<span class="hljs-built_in">backward</span>()<br>            optimizer.<span class="hljs-built_in">step</span>()<br>            optimizer.<span class="hljs-built_in">zero_grad</span>()<br><br>            progress_bar.<span class="hljs-built_in">set_description</span>(f<span class="hljs-string">&quot;Epoch &#123;epoch+1&#125;/&#123;num_epochs&#125;, Batch &#123;i+1&#125;/&#123;len(train_loader)&#125;, Train Loss: &#123;train_loss.data.item():.4f&#125;, Train Acc: &#123;train_acc.data.item():.4f&#125;&quot;</span>)<br><br>        train_loss_arr.<span class="hljs-built_in">append</span>(train_loss_total / <span class="hljs-built_in">len</span>(train_loader))<br>        train_acc_arr.<span class="hljs-built_in">append</span>(train_acc_total / <span class="hljs-built_in">len</span>(train_loader))<br><br>        model.<span class="hljs-built_in">eval</span>()<br>        for j, (val_x, val_y) in <span class="hljs-built_in">enumerate</span>(test_loader):<br>            val_x = val_x.<span class="hljs-built_in">to</span>(device)<br>            val_y = val_y.<span class="hljs-built_in">to</span>(device)<br>            val_x = val_x.<span class="hljs-built_in">unsqueeze</span>(<span class="hljs-number">1</span>)<br>            val_x = val_x.<span class="hljs-built_in">view</span>(batch_size, <span class="hljs-number">1</span>, chennal, w_wight)<br><br>            val_y_pred = <span class="hljs-built_in">model</span>(val_x)<br>            val_loss = <span class="hljs-built_in">loss_fn</span>(val_y_pred, val_y)<br>            val_acc = (<span class="hljs-built_in">m</span>(val_y_pred).<span class="hljs-built_in">max</span>(dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>] == val_y).<span class="hljs-built_in">sum</span>() / val_y.shape[<span class="hljs-number">0</span>]<br>            val_loss_total += val_loss.data.<span class="hljs-built_in">item</span>()<br>            val_acc_total += val_acc.data.<span class="hljs-built_in">item</span>()<br><br>        val_loss_arr.<span class="hljs-built_in">append</span>(val_loss_total / <span class="hljs-built_in">len</span>(test_loader))<br>        val_acc_arr.<span class="hljs-built_in">append</span>(val_acc_total / <span class="hljs-built_in">len</span>(test_loader))<br><br>        if val_acc_arr[-<span class="hljs-number">1</span>] &gt; best_val_acc:<br>            best_val_acc = val_acc_arr[-<span class="hljs-number">1</span>]<br>            best_epoch = epoch<br>            torch.<span class="hljs-built_in">save</span>(model.<span class="hljs-built_in">state_dict</span>(), f<span class="hljs-string">&quot;&#123;model_name&#125;_best.pth&quot;</span>)<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;epoch:&#123;&#125; val_loss:&#123;&#125; val_acc:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(epoch, val_loss_arr[-<span class="hljs-number">1</span>], val_acc_arr[-<span class="hljs-number">1</span>]))<br><br>    np.<span class="hljs-built_in">save</span>(os.path.<span class="hljs-built_in">join</span>(save_dir, <span class="hljs-string">&#x27;train_loss_arr.npy&#x27;</span>), np.<span class="hljs-built_in">array</span>(train_loss_arr))<br>    np.<span class="hljs-built_in">save</span>(os.path.<span class="hljs-built_in">join</span>(save_dir, <span class="hljs-string">&#x27;train_acc_arr.npy&#x27;</span>), np.<span class="hljs-built_in">array</span>(train_acc_arr))<br>    np.<span class="hljs-built_in">save</span>(os.path.<span class="hljs-built_in">join</span>(save_dir, <span class="hljs-string">&#x27;val_loss_arr.npy&#x27;</span>), np.<span class="hljs-built_in">array</span>(val_loss_arr))<br>    np.<span class="hljs-built_in">save</span>(os.path.<span class="hljs-built_in">join</span>(save_dir, <span class="hljs-string">&#x27;val_acc_arr.npy&#x27;</span>), np.<span class="hljs-built_in">array</span>(val_acc_arr))<br><br>    plt.<span class="hljs-built_in">subplot</span>(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)<br>    plt.<span class="hljs-built_in">title</span>(<span class="hljs-string">&quot;loss&quot;</span>)<br>    plt.<span class="hljs-built_in">plot</span>(train_loss_arr, <span class="hljs-string">&quot;r&quot;</span>, label=<span class="hljs-string">&quot;train&quot;</span>)<br>    plt.<span class="hljs-built_in">plot</span>(val_loss_arr, <span class="hljs-string">&quot;b&quot;</span>, label=<span class="hljs-string">&quot;val&quot;</span>)<br>    plt.<span class="hljs-built_in">legend</span>()<br><br>    plt.<span class="hljs-built_in">subplot</span>(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>    plt.<span class="hljs-built_in">title</span>(<span class="hljs-string">&quot;acc&quot;</span>)<br>    plt.<span class="hljs-built_in">plot</span>(train_acc_arr, <span class="hljs-string">&quot;r&quot;</span>, label=<span class="hljs-string">&quot;train&quot;</span>)<br>    plt.<span class="hljs-built_in">plot</span>(val_acc_arr, <span class="hljs-string">&quot;b&quot;</span>, label=<span class="hljs-string">&quot;val&quot;</span>)<br>    plt.<span class="hljs-built_in">legend</span>()<br><br>    plt.<span class="hljs-built_in">savefig</span>(<span class="hljs-string">&quot;loss_acc.png&quot;</span>)<br>    plt.<span class="hljs-built_in">show</span>()<br><br>    <span class="hljs-built_in">print</span>(f<span class="hljs-string">&quot;Best model at epoch &#123;best_epoch+1&#125;, val_acc=&#123;best_val_acc:.4f&#125;&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Training completed!&#x27;</span>)<br><br><br># 创建模型并训练<br>model = <span class="hljs-built_in">IntegratedNet</span>(input_size=<span class="hljs-number">1</span>,in_feature=<span class="hljs-number">157</span>,num_classes=<span class="hljs-number">2</span>)  # 确保模型的输出层适用于三分类问题<br><span class="hljs-built_in">train_identityformer_model</span>(model, model_name=<span class="hljs-string">&#x27;MLPFormer_betch_16_fft_opendata&#x27;</span>,chennal=<span class="hljs-number">19</span>,w_wight=<span class="hljs-number">2500</span>)<br><br><br></code></pre></td></tr></table></figure><p>测试代码</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><code class="hljs routeros">import torch.cuda<br><span class="hljs-keyword">from</span> torchvision import models<br><span class="hljs-keyword">from</span> dataset import *<br><span class="hljs-keyword">from</span> torch.utils.data import DataLoader<br><span class="hljs-keyword">from</span> torch import optim, nn<br><span class="hljs-keyword">from</span> dataset import *<br><span class="hljs-keyword">from</span> sklearn.metrics import recall_score, f1_score, precision_score, confusion_matrix, accuracy_score<br><span class="hljs-keyword">from</span> matplotlib import rcParams<br>import os<br><span class="hljs-keyword">from</span> net import *<br><br>labels = os.listdir(<span class="hljs-string">&quot;data_FFT_npy&quot;</span>)<br>m = nn.Softmax(<span class="hljs-attribute">dim</span>=1)<br>rcParams[<span class="hljs-string">&#x27;font.family&#x27;</span>] = <span class="hljs-string">&#x27;SimHei&#x27;</span><br>def val(<span class="hljs-attribute">batch_size</span>=16,w_wight=2500):<br>    # 数据集和数据加载器<br>    val_dataset = EEGDataset(<span class="hljs-attribute">csv_file</span>=<span class="hljs-string">&#x27;test_data.csv&#x27;</span>,transform=transform)<br><br>    val_data_loader = DataLoader(val_dataset, batch_size, <span class="hljs-attribute">shuffle</span>=<span class="hljs-literal">True</span>, <span class="hljs-attribute">drop_last</span>=<span class="hljs-literal">True</span>)<br>    device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>    model = IntegratedNet(<span class="hljs-attribute">input_size</span>=1,in_feature=157,num_classes=2).to(device)<br>    model.load_state_dict(torch.load(<span class="hljs-string">&quot;MLPFormer_betch_16_fft_opendata.pth&quot;</span>))<br><br>    arr_y = []<br>    arr_y_pred = []<br>    <span class="hljs-keyword">for</span> val_x, val_y <span class="hljs-keyword">in</span> val_data_loader:<br>        val_x = val_x.<span class="hljs-keyword">to</span>(device)<br>        val_y = val_y.<span class="hljs-keyword">to</span>(device)<br>        val_x = val_x.unsqueeze(1)<br>        val_x = val_x.view(batch_size, 1, 19, w_wight)<br>        val_y_pred = model(val_x)<br>        arr_y.extend(val_y.cpu().numpy())<br>        pred_result = m(val_y_pred).max(<span class="hljs-attribute">dim</span>=1)[1]<br>        arr_y_pred.extend(pred_result.cpu().numpy())<br><br>    p = precision_score(arr_y, arr_y_pred, <span class="hljs-attribute">average</span>=<span class="hljs-string">&quot;macro&quot;</span>)<br>    recall = recall_score(arr_y, arr_y_pred, <span class="hljs-attribute">average</span>=<span class="hljs-string">&quot;macro&quot;</span>)<br>    f1 = f1_score(arr_y, arr_y_pred, <span class="hljs-attribute">average</span>=<span class="hljs-string">&quot;macro&quot;</span>)<br><br>    cm = confusion_matrix(arr_y, arr_y_pred)<br>    tn, fp, fn, tp = cm.ravel()<br>    specificity = tn / (tn + fp)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Precision: &#123;:.5f&#125;, Recall: &#123;:.5f&#125;, F1-score: &#123;:.5f&#125;, Specificity: &#123;:.5f&#125;&quot;</span>.format(p, recall, f1, specificity))<br><br>    plt.imshow(cm, <span class="hljs-attribute">cmap</span>=<span class="hljs-string">&quot;Blues&quot;</span>)<br>    plt.xticks(range(2), <span class="hljs-attribute">labels</span>=labels)<br>    plt.yticks(range(2), <span class="hljs-attribute">labels</span>=labels)<br><br>    plt.colorbar()<br>    plt.xlabel(<span class="hljs-string">&quot;Predicted&quot;</span>)<br>    plt.ylabel(<span class="hljs-string">&quot;Actual&quot;</span>)<br>    thresh = cm.mean()<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(2):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(2):<br>            <span class="hljs-built_in">info</span> = cm[j, i]<br>            plt.text(i, j, info, <span class="hljs-attribute">color</span>=<span class="hljs-string">&quot;white&quot;</span> <span class="hljs-keyword">if</span> <span class="hljs-built_in">info</span> &gt; thresh <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;black&quot;</span>)<br>    plt.savefig(<span class="hljs-string">&quot;confusion_matrix.jpg&quot;</span>)<br>    plt.show()<br><br><br><br><br><br>import matplotlib.pyplot as plt<br><br>def eval_single_sample(<span class="hljs-attribute">csv_file</span>=<span class="hljs-string">&#x27;test_data.csv&#x27;</span>, <span class="hljs-attribute">model_path</span>=<span class="hljs-string">&#x27;model/MLPFormer_betch_2_normal.pth&#x27;</span>):<br>    # 数据集和数据加载器<br>    val_dataset = EEGDataset_eval(<span class="hljs-attribute">csv_file</span>=csv_file, <span class="hljs-attribute">transform</span>=transform)<br><br>    val_data_loader = DataLoader(val_dataset, <span class="hljs-attribute">batch_size</span>=1, <span class="hljs-attribute">shuffle</span>=<span class="hljs-literal">False</span>)<br>    device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>    model = IntegratedNet().<span class="hljs-keyword">to</span>(device)<br>    model.load_state_dict(torch.load(model_path))<br><br>    labels = [<span class="hljs-string">&#x27;认知功能障碍&#x27;</span>,<span class="hljs-string">&#x27;轻度认知功能障碍&#x27;</span>,<span class="hljs-string">&#x27;认知功能正常&#x27;</span>]<br>    m = nn.Softmax(<span class="hljs-attribute">dim</span>=1)<br>    rcParams[<span class="hljs-string">&#x27;font.family&#x27;</span>] = <span class="hljs-string">&#x27;SimHei&#x27;</span><br><br>    # 初始化一个列表来保存每个预测的概率<br>    all_probs = []<br><br>    <span class="hljs-keyword">for</span> val_x <span class="hljs-keyword">in</span> val_data_loader:<br>        val_x = val_x.<span class="hljs-keyword">to</span>(device)<br>        val_x = val_x.unsqueeze(1)<br>        val_x = val_x.view(1, 1, 33, 1025)<br>        val_y_pred = model(val_x)<br>        pred_probs = m(val_y_pred).squeeze().detach().cpu().numpy()<br><br>        # 保存预测的概率<br>        all_probs.append(pred_probs)<br><br>    # 计算平均概率<br>    avg_probs = np.mean(all_probs, <span class="hljs-attribute">axis</span>=0)<br><br>    # 绘制平均预测概率的柱状图<br>    plt.figure(figsize=(10, 6))<br>    plt.bar(labels, avg_probs)<br>    plt.xlabel(<span class="hljs-string">&#x27;Classes&#x27;</span>)<br>    plt.ylabel(<span class="hljs-string">&#x27;Average Predicted Probability&#x27;</span>)<br>    plt.title(<span class="hljs-string">&#x27;Average Predicted Probabilities for Each Class&#x27;</span>)<br>    plt.show()<br><br>    pred_label = labels[np.argmax(avg_probs)]<br>    <span class="hljs-built_in">print</span>(f<span class="hljs-string">&quot;Most probable class: &#123;pred_label&#125; with average probability &#123;np.max(avg_probs)*100:.2f&#125;%&quot;</span>)<br><br><br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    val()<br>    # eval_single_sample()<br><br><br></code></pre></td></tr></table></figure><h2 id="第二版-自动化"><a href="#第二版-自动化" class="headerlink" title="第二版-自动化"></a>第二版-自动化</h2>]]></content>
    
    
    
    <tags>
      
      <tag>论文思路</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>选导师</title>
    <link href="/2024/05/09/tiankeng7/"/>
    <url>/2024/05/09/tiankeng7/</url>
    
    <content type="html"><![CDATA[<ol><li>四川大学，电子信息（085400） 考察科目：22，874（计算机科学专业基础综合组成是，计算机网络、数据结构、操作系统。）</li><li>西安交通</li><li>西南交大</li><li>重庆邮电</li><li></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>填坑</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>安排1</title>
    <link href="/2024/05/07/anpai/"/>
    <url>/2024/05/07/anpai/</url>
    
    <content type="html"><![CDATA[<h2 id="安排"><a href="#安排" class="headerlink" title="安排"></a>安排</h2><ol><li>数学（进步本本分析 + 刷题 ）（一般在19:00 - 22：00时间段内） （4小件 3本书 + 进步本复习），第一本一天5道题，复习5道题、第二本一天3页码，复习2页码。1</li><li>英语（进步本复习 + 单词记忆 + 刷题 ）（一般在19:00 - 22：00时间段内）（ 4小件 进步本2本 + 作文+翻译+记忆单词 ） 1.单词记忆， 2.作文 3.做题</li><li>论文（目前在阅读论文阶段 + 同步在博客上）（有缘就看，有缘就写字，最多一天100字）</li><li>学校课程（有课就去上，搞完课程 + 同步在博客上）（课程做业吗，同步博客。（全是大坑） ）</li></ol><p>注：复习了之后记得发散思维，专注和发散模式相互切换。</p><p>2024&#x2F;5&#x2F;28</p><ol><li>6 月 14 日 的强化学习</li><li>6 月 15 日 的英语六级</li><li>6 月 28 日 的专业数学</li></ol><p>注： 目的需要精确性，任务需要精确性。了解自己将要做什么后，就创造条件去实现这个目的，就这么简单。路是走出来的，不是想出来的。<br>我应该专注于完成任务，而不是忧虑于困难本身。</p>]]></content>
    
    
    
    <tags>
      
      <tag>计划</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>校园</title>
    <link href="/2024/05/05/tupian3/"/>
    <url>/2024/05/05/tupian3/</url>
    
    <content type="html"><![CDATA[<p><img src="/pic/2024_5_5_1.jpg" alt="玫瑰花"><br><img src="/pic/2024_5_5_2.jpg" alt="图书馆"><br><img src="/pic/2024_5_5_3.jpg" alt="四维大楼"><br><img src="/pic/2024_5_5_4.jpg" alt="图书馆2"><br><img src="/pic/2024_5_5_5.jpg" alt="四维大楼2"><br><img src="/pic/2024_5_5_6.jpg"></p>]]></content>
    
    
    
    <tags>
      
      <tag>图片</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔15</title>
    <link href="/2024/05/04/ganwu15/"/>
    <url>/2024/05/04/ganwu15/</url>
    
    <content type="html"><![CDATA[<h2 id="我的爱情观"><a href="#我的爱情观" class="headerlink" title="我的爱情观"></a>我的爱情观</h2><p>先保护自己不受伤害，才能更好的去爱，如果自己缺爱，那么自己去自己，否然就会让别人来毁灭我吧。保护自己最佳的方式，就是从不高估自己在别人心中的分量，及时止损，别希望、别期望、别盼望、别指望、怎么会有失望？<br>喜欢归喜欢，太卑微就没有必要了，自己的旅程。<br>生活，活着，如果另一半不能共同成长、共同升值，共同承受，而是让自己慢慢长成被生活欺负，那应该好好思考现在的自己了。思考这一段经历，毕竟我的心力有限，与其让你来毁灭我，不如自己毁灭自己。<br>知识和信息密度远大于你的人，愿意俯下身来主动和你交流，尊重你、鼓励你、引导你、这便是温柔。</p><p>如果是为了性来交往，把性当作目的，那么不能称之为人了，而是兽。每当有人问起，为什么我不恋爱的时候，我都以麻烦为理由搪塞过去。又有人开始问我到底喜欢过谁没有，我也轻描淡写地表示否定。无数的朋友告诉我，或许是你还没碰到过真正喜欢的人吧，我却没法开口告诉他们，其实我曾经碰到过，碰得太早，以至于我没来得及分清，也没来得及弄明白。</p><p>你们也许还没法体会到，但人生在世，婚姻其实非常非常重要。我希望大家将来都认真对待婚姻，不求达到钱杨的境界，但最起码也要学习沈从文，把道德和感情这两条底线牢牢地把握住。人一辈子七八十年。其实长的超出你们的预料，想在这么长的时间里不遇到任何变故是不可能的。一个讲道德、有感情的婚姻，就像一把下了的锚，有了它，多大的浪头来了你都不会倾覆。因为你心里知道自己还有想见到的人，有想尽的责任，这种想法的力量是和信仰相当的。”</p><h2 id="人与人"><a href="#人与人" class="headerlink" title="人与人"></a>人与人</h2><p>世界上充满着不同的人，悲伤的，自立的，自私的，慷慨的，无畏的，善念的，恶意的，勤奋的，懒散的，自律的，乐观的，坚持的，忍耐的，乏味、反覆、放任、风趣、风趣幽默、浮躁 、富创造力、富有朝气、富于冒险、才思敏捷、猜疑、沉静、沉著、诚实坦白、成熟、成熟稳重、迟钝、迟缓、冲动、处事洒脱、聪明伶俐、粗心、脆弱、懒惰、老练、老实、老实巴交、唠叨、乐观、乐善好施、雷历风行、冷淡 、冷漠 、礼貌、吝啬、鲁莽 、罗嗦、脾气暴躁、贫乏、平和、婆婆妈妈、普普通通、勤劳、轻浮、轻率、轻率不踏实、轻松、情绪多变、缺乏耐力、缺乏自信、散漫、善变、善交际、善解人意、善良、善于分析、善于体察别人、善组织、少言寡语、深沉、神经质、实事求是、适应能力差、适应能力强、率直、水性扬花、思想开放、随和、踏实、坦率、贪婪、贪小便宜、体贴、挑衅、挑剔、统治欲、妥协、拖延、严肃、言行不一、阳光、一本正经、 依赖、毅力、抑郁、易激动、易见异思迁、易怒、易轻率作决定、易随波逐流、易兴奋、疑神疑鬼、意志坚定、阴险狡诈、勇敢、勇敢正义、友爱、友善、犹豫不决、忧心忡忡、有趣、有韧性、有条理、优柔寡断、幽默、幼稚 、幼稚调皮、愉快、郁郁寡欢、圆滑老练、怨恨。<br>众生百相，经历的不代表世界，只能代表经历的，遇到各种各样的人，不能使用相同的方法来交流，要随机应变，不同的人遇到不同的事，处理方法都不一样但是解决问题就好了，</p><h2 id="安静的做事"><a href="#安静的做事" class="headerlink" title="安静的做事"></a>安静的做事</h2><p>这件事，那件事，许多件事困扰着我，做真正能让我感到进步的事情，安排事件什么时候去做也是一个需要锻炼的能力。做事是为了进步的，每天抽出专门的时间，把本子上面的题拿出来重新做。仅仅是睡觉前看一遍是不够的，因为看一遍以为会了，以为掌握了，实际上不一定。很可能是自欺欺人。事实上，我常常发现,重做的时候，还是有些会做错。所以，在重做的过程中，会对相关的知识点，解题方法进行重新的标记。也会对原有的知识型笔记，进行更多的标注。所以，这绝不是机械式的学习，而是理解式的学习。不断迭代，不断深入的学习。<br>对于自己不想做的事情，先为自己想做的事情和必做的事情让步。减少不必要的物质的欲望（减）。（乘）把已经被验证正确的事，乘以100次。除把目标除分成无数小段。（等）等待满足感。</p><p>利用时间的正确方式是，每一天都有具体目标，有一个Deadline，有个目标截止时间。我该如何来制定每天的具体目标。<br>清醒自己在干嘛是我的追求。每天都在忙，但是不知道在忙什么，还容易心累，所以我决定对这件事进行一定程度的思考。基于清醒的角度来讲这个问题，我是不清醒的，或许有个计划可以在一定程度上解决这个问题。没有目标的计划的人生就像是一艘航行在大海里的船，不知道自己要去哪因而也没用方向。</p><h2 id="你想活出怎样的人生。"><a href="#你想活出怎样的人生。" class="headerlink" title="你想活出怎样的人生。"></a>你想活出怎样的人生。</h2><p>步骤一： 基于现实，确定自己的目标，把目标分类。 分类示例： 个人管理，个人健康，个人技能，兴趣爱好，<br>步骤二： 回顾自己过去的表现，设定长期目标。 三~五年计划 → 年计划 → 月计划 → 周计划 → 日计划。（执行过程中是反过来的，日计划）<br>步骤三： 在执行日计划的过程中进行回顾，回顾，回顾。</p><p>第一步：基于现状分析要完成的事件，分析现状，</p><ol><li>考研，细分为，数学，英语，思政，专业课。</li><li>论文，细分为，看参考文献，跑实验，写论文</li><li>学校上课，细分为，深度学习，数字图像处理，强化学习，专业数学，专业综合实践1，2。占用大部分时间，在上课过程中经常摸鱼。</li></ol><p>分析： 对于考研第一要务，包含数学，英语，思政，专业课四项。其中数学的内容和专业数学内容重合。可以花费大部分时间来对其进行攻打，使用进步本策略（先复习进步本，后进行刷题）。英语还有6级的考试要通过，预先级提升到2（先看单词和做题技巧，后刷题）。<br>论文： 第一阶段是看材料，分析材料讲的什么，构建自己的对比实验，第二阶段是跑实验，分析实验结果。第三阶段是根据看的论文和实验结果来写论文。<br>学校课程： 学校课程的最终目标是通过考试，针对性的学习，深度学习，数字图像处理可以归在一类，强化学习一类。<br>任务记录</p><ol><li>数学（进步本本分析 + 刷题 ）（一般在19:00 - 22：00时间段内）</li><li>英语（进步本复习 + 单词记忆 + 刷题 ）（一般在19:00 - 22：00时间段内）</li><li>论文（阅读论文阶段 + 同步在博客上）（有缘就看，有缘就写字）</li><li>学校课程（有课就去上，搞完课程 + 同步在博客上）（课程做业同步博客。 ）</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>感悟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>高等数学 —— 一元函数的微分</title>
    <link href="/2024/05/04/gaodengshuxue2/"/>
    <url>/2024/05/04/gaodengshuxue2/</url>
    
    <content type="html"><![CDATA[<p>导数和微分的概念，导数的几何意义和物理意义，函数的可导性与连续性之间的关系。<br>平面曲线的切线和法线，导数和微分的四则运算，基本初等函数的导数，复合函数、反函数、隐函数以及参数方程所确定的函数的微分法，高阶段导数，一阶段微分形式的不变性，微分中值定理（罗尔中值定理，拉格朗日中值定理，泰勒定理，柯西中值定理），洛必达法则，函数单调性的判别，函数的极值，函数的凹凸性，拐点以及渐近线，函数图形的描绘，函数的最大小值。<br>弧微分，曲率的概念，曲率圆与曲率半径。</p><h2 id="概念介绍"><a href="#概念介绍" class="headerlink" title="概念介绍"></a>概念介绍</h2><ol><li>导数（Derivative）：导数描述了函数在某一点的变化率。对于函数 f(x)，其在点 x 处的导数可以用极限的概念来定义：<img src="/pic/gaodengshuxue_2_1.png"><br><img src="/pic/gaodengshuxue_2_2.png"><br><img src="/pic/gaodengshuxue_2_3.png" alt="基本导数公式"><br><img src="/pic/gaodengshuxue_2_4.png" alt="函数的求导运算法则"><br><a href=""></a></li><li>微分（Differential）：微分是导数的一个应用，它描述了函数在某一点附近的局部线性近似。如果 f(x) 在某点 x 处可导，则在该点附近，函数的微分可以表示为：df&#x3D; f&#96;(x)dx</li></ol><p><img src="/pic/gaodengshuxue_2_5.png" alt="古典数学算法"></p><p>导数的几何意义和物理意义<br>几何意义：在几何学中，导数表示函数图像在某一点的切线斜率。切线的斜率描述了曲线在该点附近的变化率，即在该点处函数的瞬时变化率。通过导数，我们可以了解函数在不同点处的曲率、凹凸性等几何特征。<br>物理意义：在物理学中，导数描述了物理量随时间的变化率。例如，如果一个物体的位置随时间变化，其速度可以表示为位置关于时间的导数，即速度是位置的一阶导数。同样，加速度则是速度关于时间的导数，即加速度描述了速度的变化率。因此，导数在描述运动、变化和变化率方面在物理学中起着关键作用。<br>函数的可导性与连续性之间的关系：一个函数在某一点可导，意味着它在该点附近有良好的局部线性近似，即它在该点连续。因此，如果一个函数在某点可导，则它在该点必然连续。但是，连续并不意味着可导。例如，绝对值函数，在x&#x3D;0处连续，但是在该点不可导。</p><p>导数与微分之间的关系：<br><a href="https://www.zhihu.com/question/53159621">参考博客</a><br>微分本质是一个微小的线性变化量，是用一个线性函数作为原函数变化的逼近（或者叫近似）。<br>导数:是指函数在某一点处变化的快慢,是一种变化率。<br>微分:是指函数在某一点处（趋近于无穷小）的变化量，是一种变化的量。<br>请区别下面不同的算法：古典数学的计算方法<br><img src="/pic/gaodengshuxue_2_6.png" alt="古典数学算法"><br><img src="/pic/gaodengshuxue_2_7.png" alt="极限算法"></p><ol start="3"><li><p>平面曲线的切线和法线。 平面的切线的斜率即f(x)在该点的导数，法线也就是f(x)导数的负分之一。法线和导数之间的关系互为相反数。</p></li><li><p>导数与微分的四则运算<br>导数的运算法则在前面，下面阐述了微分四则运算。<br><img src="/pic/gaodengshuxue_2_8.png" alt="微分运算法则—有理数运算法则"><br><img src="/pic/gaodengshuxue_2_9.png" alt="微分运算法则—复合函数运算法则"></p></li><li><p>参数方程所确定的函数的微分法：<a href="https://zhuanlan.zhihu.com/p/298373433">隐函数和参数方程所确定函数的导数</a></p></li><li><p>高阶导数：导数的导数称为高阶导数。求解答高阶导数的方法，1. 归纳法：常见函数的n阶导，找规律。 2. 莱布尼茨公式 3. 泰勒公式</p></li><li><p>微分形式的不变性：如果两个函数在某一点的微分形式相同，则它们在该点的函数值和导数值也相同。<a href="https://zhuanlan.zhihu.com/p/350936061">对一阶微分形式不变性的理解</a></p></li><li><p>微分中值定理：1.罗尔中值定理 2.拉格朗日中值定理 3.泰勒定理 4. 柯西中值定理。<br><img src="/pic/gaodengshuxue_2_10.png" alt="罗尔中值定理"> <img src="/pic/gaodengshuxue_2_11.png" alt="拉格朗日中值定理"> <img src="/pic/gaodengshuxue_2_12.png" alt="柯西中值定理"><br><a href="https://zhuanlan.zhihu.com/p/377120363">泰勒定理</a><br><img src="/pic/tailezhankai.png" alt="等价无穷小泰勒展开"><br><img src="/pic/tailezhankai2.png" alt="泰勒展开"><br><img src="/pic/tailezhankai3.png" alt="泰勒展开"></p></li><li><p>洛必达法则：用于解决不定型的极限 <a href="https://zhuanlan.zhihu.com/p/553569134">参考链接</a></p></li><li><p>函数的性质<br>函数单调性的判别：通过导数的正负性可以判断函数在区间上的单调性。<br>函数的极值：函数在局部最大值或最小值处称为极值，通过导数的零点或变号来判断。<br>函数的凹凸性：通过二阶导数的正负性来判断函数在某区间上的凹凸性。<br>拐点：函数图像在拐点处由凹转凸或由凸转凹。<br>渐近线：用来描述函数在无穷远处的趋势。<br>函数图形的描绘：通过函数的导数、极值、拐点、渐近线等特性来描绘函数图形。<br>函数的最大小值：通过导数或二阶导数的性质来判断函数的最大值和最小值。</p></li><li><p>弧微分和曲率<br>在一段弧上，一段弧长和它两端点的横坐标有关。当Δx极小时，弧可以看作是一条直线，此时Δx^2+Δy^2&#x3D;Δs^2，又Δy&#x3D;y‘*Δx，所以弧微分公式为<br><img src="/pic/gaodengshuxue_2_13.png" alt="弧微分公式"><br>因为y‘&#x3D;dy&#x2F;dx。所以对于参数方程，将dx移到根号内，再乘以dt&#x2F;dt，分母上的dt移到根号内可得到<br><img src="/pic/gaodengshuxue_2_14.png" alt="参数方程弧微分公式"><br>曲率描述弧的弯曲程度，如果弧角度变化地越快，则曲率越大<br>设一段弧，起点为M终点为M‘，M到M’的弧长为|ds|，两点的切线倾角变化为|dα|，则这一段弧的曲率K为<br><img src="/pic/gaodengshuxue_2_15.png" alt="曲率公式"><br>般求曲率都要通过参数方程，设<br><img src="/pic/gaodengshuxue_2_16.png" alt="参数方程曲率公式"></p></li></ol><p>曲率圆 ： 把一小段弧长当成一个圆的一部分，则可通过曲率求处圆的半径为r&#x3D;1&#x2F;K<br><a href="https://blog.csdn.net/qq_42578970/article/details/106967819">参考链接</a><br><a href="https://zhuanlan.zhihu.com/p/479710119">参考链接2</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>高等数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分类模型-MetaFormer Baselines for Vision</title>
    <link href="/2024/05/04/deeplearnpaper6/"/>
    <url>/2024/05/04/deeplearnpaper6/</url>
    
    <content type="html"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/577709208">参考博客-知乎</a><br><a href="https://arxiv.org/pdf/2210.13452">论文原文链接</a><br><a href="https://zhuanlan.zhihu.com/p/579175302">读论文博客</a><br><a href="https://github.com/sail-sg/metaformer">原文代码</a></p><h2 id="原文参考"><a href="#原文参考" class="headerlink" title="原文参考"></a>原文参考</h2><p>Nevertheless, some work <a href="https://arxiv.org/pdf/2105.01601">17</a>, <a href="https://arxiv.org/pdf/2105.03824">18</a>, <a href="https://arxiv.org/pdf/2108.13002">19</a>,<a href="https://arxiv.org/pdf/2106.04263">20</a>, <a href="https://arxiv.org/pdf/2107.00645">21</a> found that, by replacing the attention module in Transformers with simple operators like spatial MLP <a href="https://arxiv.org/pdf/2105.01601">17</a>,<a href="https://arxiv.org/pdf/2105.03404">22</a>, <a href="https://arxiv.org/pdf/2005.00743">23</a> or Fourier transform [18], the resultant models still produce encouraging performance.<br>最近，一些工作，17，18，19，20 发现，通过在Transformers中的自注意力为简单的operators 为MLP或者其他的 Fourier transform，模型仍然保持着良好的表现。</p><p>基于此这篇论文团队之前的工作在<a href="https://arxiv.org/pdf/2111.11418">24</a>这篇论文中他们提出了MetaFormer，为了更进一步的验证MetaFormer，Our goal is to push the limits of MetaFomer, based on which we may have a comprehensive picture of its capacity. 团队选取了最basic or common token mixers ，such as ，identity mapping or global random mixing， swparable convolution [6],[7] ，[8]  and vanilla self-attention [9]</p><p><img src="/pic/MetaFormer1.png" alt="模型结构图"><br><img src="/pic/MateFormer2.png" alt="模型实验图"><br><img src="/pic/MateFormer3.png" alt="模型实验图"></p><h2 id="挖坑"><a href="#挖坑" class="headerlink" title="挖坑"></a>挖坑</h2><p>MACs（Multiply-Accumulate Operations，乘加运算）是衡量神经网络计算复杂性的一个重要指标。它表示神经网络在进行一次前向传播（即推理）时所需的乘加运算次数。乘加运算是神经网络中最基本的操作，尤其在卷积层和全连接层中广泛使用。</p><h3 id="代码解析工程"><a href="#代码解析工程" class="headerlink" title="代码解析工程"></a>代码解析工程</h3><p>metaformer_baselines.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br><span class="line">675</span><br><span class="line">676</span><br><span class="line">677</span><br><span class="line">678</span><br><span class="line">679</span><br><span class="line">680</span><br><span class="line">681</span><br><span class="line">682</span><br><span class="line">683</span><br><span class="line">684</span><br><span class="line">685</span><br><span class="line">686</span><br><span class="line">687</span><br><span class="line">688</span><br><span class="line">689</span><br><span class="line">690</span><br><span class="line">691</span><br><span class="line">692</span><br><span class="line">693</span><br><span class="line">694</span><br><span class="line">695</span><br><span class="line">696</span><br><span class="line">697</span><br><span class="line">698</span><br><span class="line">699</span><br><span class="line">700</span><br><span class="line">701</span><br><span class="line">702</span><br><span class="line">703</span><br><span class="line">704</span><br><span class="line">705</span><br><span class="line">706</span><br><span class="line">707</span><br><span class="line">708</span><br><span class="line">709</span><br><span class="line">710</span><br><span class="line">711</span><br><span class="line">712</span><br><span class="line">713</span><br><span class="line">714</span><br><span class="line">715</span><br><span class="line">716</span><br><span class="line">717</span><br><span class="line">718</span><br><span class="line">719</span><br><span class="line">720</span><br><span class="line">721</span><br><span class="line">722</span><br><span class="line">723</span><br><span class="line">724</span><br><span class="line">725</span><br><span class="line">726</span><br><span class="line">727</span><br><span class="line">728</span><br><span class="line">729</span><br><span class="line">730</span><br><span class="line">731</span><br><span class="line">732</span><br><span class="line">733</span><br><span class="line">734</span><br><span class="line">735</span><br><span class="line">736</span><br><span class="line">737</span><br><span class="line">738</span><br><span class="line">739</span><br><span class="line">740</span><br><span class="line">741</span><br><span class="line">742</span><br><span class="line">743</span><br><span class="line">744</span><br><span class="line">745</span><br><span class="line">746</span><br><span class="line">747</span><br><span class="line">748</span><br><span class="line">749</span><br><span class="line">750</span><br><span class="line">751</span><br><span class="line">752</span><br><span class="line">753</span><br><span class="line">754</span><br><span class="line">755</span><br><span class="line">756</span><br><span class="line">757</span><br><span class="line">758</span><br><span class="line">759</span><br><span class="line">760</span><br><span class="line">761</span><br><span class="line">762</span><br><span class="line">763</span><br><span class="line">764</span><br><span class="line">765</span><br><span class="line">766</span><br><span class="line">767</span><br><span class="line">768</span><br><span class="line">769</span><br><span class="line">770</span><br><span class="line">771</span><br><span class="line">772</span><br><span class="line">773</span><br><span class="line">774</span><br><span class="line">775</span><br><span class="line">776</span><br><span class="line">777</span><br><span class="line">778</span><br><span class="line">779</span><br><span class="line">780</span><br><span class="line">781</span><br><span class="line">782</span><br><span class="line">783</span><br><span class="line">784</span><br><span class="line">785</span><br><span class="line">786</span><br><span class="line">787</span><br><span class="line">788</span><br><span class="line">789</span><br><span class="line">790</span><br><span class="line">791</span><br><span class="line">792</span><br><span class="line">793</span><br><span class="line">794</span><br><span class="line">795</span><br><span class="line">796</span><br><span class="line">797</span><br><span class="line">798</span><br><span class="line">799</span><br><span class="line">800</span><br><span class="line">801</span><br><span class="line">802</span><br><span class="line">803</span><br><span class="line">804</span><br><span class="line">805</span><br><span class="line">806</span><br><span class="line">807</span><br><span class="line">808</span><br><span class="line">809</span><br><span class="line">810</span><br><span class="line">811</span><br><span class="line">812</span><br><span class="line">813</span><br><span class="line">814</span><br><span class="line">815</span><br><span class="line">816</span><br><span class="line">817</span><br><span class="line">818</span><br><span class="line">819</span><br><span class="line">820</span><br><span class="line">821</span><br><span class="line">822</span><br><span class="line">823</span><br><span class="line">824</span><br><span class="line">825</span><br><span class="line">826</span><br><span class="line">827</span><br><span class="line">828</span><br><span class="line">829</span><br><span class="line">830</span><br><span class="line">831</span><br><span class="line">832</span><br><span class="line">833</span><br><span class="line">834</span><br><span class="line">835</span><br><span class="line">836</span><br><span class="line">837</span><br><span class="line">838</span><br><span class="line">839</span><br><span class="line">840</span><br><span class="line">841</span><br><span class="line">842</span><br><span class="line">843</span><br><span class="line">844</span><br><span class="line">845</span><br><span class="line">846</span><br><span class="line">847</span><br><span class="line">848</span><br><span class="line">849</span><br><span class="line">850</span><br><span class="line">851</span><br><span class="line">852</span><br><span class="line">853</span><br><span class="line">854</span><br><span class="line">855</span><br><span class="line">856</span><br><span class="line">857</span><br><span class="line">858</span><br><span class="line">859</span><br><span class="line">860</span><br><span class="line">861</span><br><span class="line">862</span><br><span class="line">863</span><br><span class="line">864</span><br><span class="line">865</span><br><span class="line">866</span><br><span class="line">867</span><br><span class="line">868</span><br><span class="line">869</span><br><span class="line">870</span><br><span class="line">871</span><br><span class="line">872</span><br><span class="line">873</span><br><span class="line">874</span><br><span class="line">875</span><br><span class="line">876</span><br><span class="line">877</span><br><span class="line">878</span><br><span class="line">879</span><br><span class="line">880</span><br><span class="line">881</span><br><span class="line">882</span><br><span class="line">883</span><br><span class="line">884</span><br><span class="line">885</span><br><span class="line">886</span><br><span class="line">887</span><br><span class="line">888</span><br><span class="line">889</span><br><span class="line">890</span><br><span class="line">891</span><br><span class="line">892</span><br><span class="line">893</span><br><span class="line">894</span><br><span class="line">895</span><br><span class="line">896</span><br><span class="line">897</span><br><span class="line">898</span><br><span class="line">899</span><br><span class="line">900</span><br><span class="line">901</span><br><span class="line">902</span><br><span class="line">903</span><br><span class="line">904</span><br><span class="line">905</span><br><span class="line">906</span><br><span class="line">907</span><br><span class="line">908</span><br><span class="line">909</span><br><span class="line">910</span><br><span class="line">911</span><br><span class="line">912</span><br><span class="line">913</span><br><span class="line">914</span><br><span class="line">915</span><br><span class="line">916</span><br><span class="line">917</span><br><span class="line">918</span><br><span class="line">919</span><br><span class="line">920</span><br><span class="line">921</span><br><span class="line">922</span><br><span class="line">923</span><br><span class="line">924</span><br><span class="line">925</span><br><span class="line">926</span><br><span class="line">927</span><br><span class="line">928</span><br><span class="line">929</span><br><span class="line">930</span><br><span class="line">931</span><br><span class="line">932</span><br><span class="line">933</span><br><span class="line">934</span><br><span class="line">935</span><br><span class="line">936</span><br><span class="line">937</span><br><span class="line">938</span><br><span class="line">939</span><br><span class="line">940</span><br><span class="line">941</span><br><span class="line">942</span><br><span class="line">943</span><br><span class="line">944</span><br><span class="line">945</span><br><span class="line">946</span><br><span class="line">947</span><br><span class="line">948</span><br><span class="line">949</span><br><span class="line">950</span><br><span class="line">951</span><br><span class="line">952</span><br><span class="line">953</span><br><span class="line">954</span><br><span class="line">955</span><br><span class="line">956</span><br><span class="line">957</span><br><span class="line">958</span><br><span class="line">959</span><br><span class="line">960</span><br><span class="line">961</span><br><span class="line">962</span><br><span class="line">963</span><br><span class="line">964</span><br><span class="line">965</span><br><span class="line">966</span><br><span class="line">967</span><br><span class="line">968</span><br><span class="line">969</span><br><span class="line">970</span><br><span class="line">971</span><br><span class="line">972</span><br><span class="line">973</span><br><span class="line">974</span><br><span class="line">975</span><br><span class="line">976</span><br><span class="line">977</span><br><span class="line">978</span><br><span class="line">979</span><br><span class="line">980</span><br><span class="line">981</span><br><span class="line">982</span><br><span class="line">983</span><br><span class="line">984</span><br><span class="line">985</span><br><span class="line">986</span><br><span class="line">987</span><br><span class="line">988</span><br><span class="line">989</span><br><span class="line">990</span><br><span class="line">991</span><br><span class="line">992</span><br><span class="line">993</span><br><span class="line">994</span><br><span class="line">995</span><br><span class="line">996</span><br><span class="line">997</span><br><span class="line">998</span><br><span class="line">999</span><br><span class="line">1000</span><br><span class="line">1001</span><br><span class="line">1002</span><br><span class="line">1003</span><br><span class="line">1004</span><br><span class="line">1005</span><br><span class="line">1006</span><br><span class="line">1007</span><br><span class="line">1008</span><br><span class="line">1009</span><br><span class="line">1010</span><br><span class="line">1011</span><br><span class="line">1012</span><br><span class="line">1013</span><br><span class="line">1014</span><br><span class="line">1015</span><br><span class="line">1016</span><br><span class="line">1017</span><br><span class="line">1018</span><br><span class="line">1019</span><br><span class="line">1020</span><br><span class="line">1021</span><br><span class="line">1022</span><br><span class="line">1023</span><br><span class="line">1024</span><br><span class="line">1025</span><br><span class="line">1026</span><br><span class="line">1027</span><br><span class="line">1028</span><br><span class="line">1029</span><br><span class="line">1030</span><br><span class="line">1031</span><br><span class="line">1032</span><br><span class="line">1033</span><br><span class="line">1034</span><br><span class="line">1035</span><br><span class="line">1036</span><br><span class="line">1037</span><br><span class="line">1038</span><br><span class="line">1039</span><br><span class="line">1040</span><br><span class="line">1041</span><br><span class="line">1042</span><br><span class="line">1043</span><br><span class="line">1044</span><br><span class="line">1045</span><br><span class="line">1046</span><br><span class="line">1047</span><br><span class="line">1048</span><br><span class="line">1049</span><br><span class="line">1050</span><br><span class="line">1051</span><br><span class="line">1052</span><br><span class="line">1053</span><br><span class="line">1054</span><br><span class="line">1055</span><br><span class="line">1056</span><br><span class="line">1057</span><br><span class="line">1058</span><br><span class="line">1059</span><br><span class="line">1060</span><br><span class="line">1061</span><br><span class="line">1062</span><br><span class="line">1063</span><br><span class="line">1064</span><br><span class="line">1065</span><br><span class="line">1066</span><br><span class="line">1067</span><br><span class="line">1068</span><br><span class="line">1069</span><br><span class="line">1070</span><br><span class="line">1071</span><br><span class="line">1072</span><br><span class="line">1073</span><br><span class="line">1074</span><br><span class="line">1075</span><br><span class="line">1076</span><br><span class="line">1077</span><br><span class="line">1078</span><br><span class="line">1079</span><br><span class="line">1080</span><br><span class="line">1081</span><br><span class="line">1082</span><br><span class="line">1083</span><br><span class="line">1084</span><br><span class="line">1085</span><br><span class="line">1086</span><br><span class="line">1087</span><br><span class="line">1088</span><br><span class="line">1089</span><br><span class="line">1090</span><br><span class="line">1091</span><br><span class="line">1092</span><br><span class="line">1093</span><br><span class="line">1094</span><br><span class="line">1095</span><br><span class="line">1096</span><br><span class="line">1097</span><br><span class="line">1098</span><br><span class="line">1099</span><br><span class="line">1100</span><br><span class="line">1101</span><br><span class="line">1102</span><br><span class="line">1103</span><br><span class="line">1104</span><br><span class="line">1105</span><br><span class="line">1106</span><br><span class="line">1107</span><br><span class="line">1108</span><br><span class="line">1109</span><br><span class="line">1110</span><br><span class="line">1111</span><br><span class="line">1112</span><br><span class="line">1113</span><br><span class="line">1114</span><br><span class="line">1115</span><br><span class="line">1116</span><br><span class="line">1117</span><br><span class="line">1118</span><br><span class="line">1119</span><br><span class="line">1120</span><br><span class="line">1121</span><br><span class="line">1122</span><br><span class="line">1123</span><br><span class="line">1124</span><br><span class="line">1125</span><br><span class="line">1126</span><br><span class="line">1127</span><br><span class="line">1128</span><br><span class="line">1129</span><br><span class="line">1130</span><br><span class="line">1131</span><br><span class="line">1132</span><br><span class="line">1133</span><br><span class="line">1134</span><br><span class="line">1135</span><br><span class="line">1136</span><br><span class="line">1137</span><br><span class="line">1138</span><br><span class="line">1139</span><br><span class="line">1140</span><br><span class="line">1141</span><br><span class="line">1142</span><br><span class="line">1143</span><br><span class="line">1144</span><br><span class="line">1145</span><br><span class="line">1146</span><br><span class="line">1147</span><br><span class="line">1148</span><br><span class="line">1149</span><br><span class="line">1150</span><br><span class="line">1151</span><br><span class="line">1152</span><br><span class="line">1153</span><br><span class="line">1154</span><br><span class="line">1155</span><br><span class="line">1156</span><br><span class="line">1157</span><br><span class="line">1158</span><br><span class="line">1159</span><br><span class="line">1160</span><br><span class="line">1161</span><br><span class="line">1162</span><br><span class="line">1163</span><br><span class="line">1164</span><br><span class="line">1165</span><br><span class="line">1166</span><br><span class="line">1167</span><br><span class="line">1168</span><br><span class="line">1169</span><br><span class="line">1170</span><br><span class="line">1171</span><br><span class="line">1172</span><br><span class="line">1173</span><br><span class="line">1174</span><br><span class="line">1175</span><br><span class="line">1176</span><br><span class="line">1177</span><br><span class="line">1178</span><br><span class="line">1179</span><br><span class="line">1180</span><br><span class="line">1181</span><br><span class="line">1182</span><br><span class="line">1183</span><br><span class="line">1184</span><br><span class="line">1185</span><br><span class="line">1186</span><br><span class="line">1187</span><br><span class="line">1188</span><br><span class="line">1189</span><br><span class="line">1190</span><br><span class="line">1191</span><br><span class="line">1192</span><br><span class="line">1193</span><br><span class="line">1194</span><br><span class="line">1195</span><br><span class="line">1196</span><br><span class="line">1197</span><br><span class="line">1198</span><br><span class="line">1199</span><br><span class="line">1200</span><br><span class="line">1201</span><br><span class="line">1202</span><br><span class="line">1203</span><br><span class="line">1204</span><br><span class="line">1205</span><br><span class="line">1206</span><br><span class="line">1207</span><br><span class="line">1208</span><br><span class="line">1209</span><br><span class="line">1210</span><br><span class="line">1211</span><br><span class="line">1212</span><br><span class="line">1213</span><br><span class="line">1214</span><br><span class="line">1215</span><br><span class="line">1216</span><br><span class="line">1217</span><br><span class="line">1218</span><br><span class="line">1219</span><br><span class="line">1220</span><br><span class="line">1221</span><br><span class="line">1222</span><br><span class="line">1223</span><br><span class="line">1224</span><br><span class="line">1225</span><br><span class="line">1226</span><br><span class="line">1227</span><br><span class="line">1228</span><br><span class="line">1229</span><br><span class="line">1230</span><br><span class="line">1231</span><br><span class="line">1232</span><br><span class="line">1233</span><br><span class="line">1234</span><br><span class="line">1235</span><br><span class="line">1236</span><br><span class="line">1237</span><br><span class="line">1238</span><br><span class="line">1239</span><br><span class="line">1240</span><br><span class="line">1241</span><br><span class="line">1242</span><br><span class="line">1243</span><br><span class="line">1244</span><br><span class="line">1245</span><br><span class="line">1246</span><br><span class="line">1247</span><br><span class="line">1248</span><br><span class="line">1249</span><br><span class="line">1250</span><br><span class="line">1251</span><br><span class="line">1252</span><br><span class="line">1253</span><br><span class="line">1254</span><br><span class="line">1255</span><br><span class="line">1256</span><br><span class="line">1257</span><br><span class="line">1258</span><br><span class="line">1259</span><br><span class="line">1260</span><br><span class="line">1261</span><br><span class="line">1262</span><br><span class="line">1263</span><br><span class="line">1264</span><br><span class="line">1265</span><br><span class="line">1266</span><br><span class="line">1267</span><br><span class="line">1268</span><br><span class="line">1269</span><br><span class="line">1270</span><br><span class="line">1271</span><br><span class="line">1272</span><br><span class="line">1273</span><br><span class="line">1274</span><br><span class="line">1275</span><br><span class="line">1276</span><br><span class="line">1277</span><br><span class="line">1278</span><br><span class="line">1279</span><br><span class="line">1280</span><br><span class="line">1281</span><br><span class="line">1282</span><br><span class="line">1283</span><br><span class="line">1284</span><br><span class="line">1285</span><br><span class="line">1286</span><br><span class="line">1287</span><br><span class="line">1288</span><br><span class="line">1289</span><br><span class="line">1290</span><br><span class="line">1291</span><br><span class="line">1292</span><br><span class="line">1293</span><br><span class="line">1294</span><br><span class="line">1295</span><br><span class="line">1296</span><br><span class="line">1297</span><br><span class="line">1298</span><br><span class="line">1299</span><br><span class="line">1300</span><br><span class="line">1301</span><br><span class="line">1302</span><br><span class="line">1303</span><br><span class="line">1304</span><br><span class="line">1305</span><br><span class="line">1306</span><br><span class="line">1307</span><br><span class="line">1308</span><br><span class="line">1309</span><br><span class="line">1310</span><br><span class="line">1311</span><br><span class="line">1312</span><br><span class="line">1313</span><br><span class="line">1314</span><br><span class="line">1315</span><br><span class="line">1316</span><br><span class="line">1317</span><br><span class="line">1318</span><br><span class="line">1319</span><br><span class="line">1320</span><br><span class="line">1321</span><br><span class="line">1322</span><br><span class="line">1323</span><br><span class="line">1324</span><br><span class="line">1325</span><br><span class="line">1326</span><br><span class="line">1327</span><br><span class="line">1328</span><br><span class="line">1329</span><br><span class="line">1330</span><br><span class="line">1331</span><br><span class="line">1332</span><br><span class="line">1333</span><br><span class="line">1334</span><br><span class="line">1335</span><br><span class="line">1336</span><br><span class="line">1337</span><br><span class="line">1338</span><br><span class="line">1339</span><br><span class="line">1340</span><br><span class="line">1341</span><br><span class="line">1342</span><br><span class="line">1343</span><br><span class="line">1344</span><br><span class="line">1345</span><br><span class="line">1346</span><br><span class="line">1347</span><br><span class="line">1348</span><br><span class="line">1349</span><br><span class="line">1350</span><br><span class="line">1351</span><br><span class="line">1352</span><br><span class="line">1353</span><br><span class="line">1354</span><br><span class="line">1355</span><br><span class="line">1356</span><br><span class="line">1357</span><br><span class="line">1358</span><br><span class="line">1359</span><br><span class="line">1360</span><br><span class="line">1361</span><br><span class="line">1362</span><br><span class="line">1363</span><br><span class="line">1364</span><br><span class="line">1365</span><br><span class="line">1366</span><br><span class="line">1367</span><br><span class="line">1368</span><br><span class="line">1369</span><br><span class="line">1370</span><br><span class="line">1371</span><br><span class="line">1372</span><br><span class="line">1373</span><br><span class="line">1374</span><br><span class="line">1375</span><br><span class="line">1376</span><br><span class="line">1377</span><br><span class="line">1378</span><br><span class="line">1379</span><br><span class="line">1380</span><br><span class="line">1381</span><br><span class="line">1382</span><br><span class="line">1383</span><br><span class="line">1384</span><br><span class="line">1385</span><br><span class="line">1386</span><br><span class="line">1387</span><br><span class="line">1388</span><br><span class="line">1389</span><br><span class="line">1390</span><br><span class="line">1391</span><br><span class="line">1392</span><br><span class="line">1393</span><br><span class="line">1394</span><br><span class="line">1395</span><br><span class="line">1396</span><br><span class="line">1397</span><br><span class="line">1398</span><br><span class="line">1399</span><br><span class="line">1400</span><br><span class="line">1401</span><br><span class="line">1402</span><br><span class="line">1403</span><br><span class="line">1404</span><br><span class="line">1405</span><br><span class="line">1406</span><br><span class="line">1407</span><br><span class="line">1408</span><br><span class="line">1409</span><br><span class="line">1410</span><br><span class="line">1411</span><br><span class="line">1412</span><br><span class="line">1413</span><br><span class="line">1414</span><br><span class="line">1415</span><br><span class="line">1416</span><br><span class="line">1417</span><br><span class="line">1418</span><br><span class="line">1419</span><br><span class="line">1420</span><br><span class="line">1421</span><br><span class="line">1422</span><br><span class="line">1423</span><br><span class="line">1424</span><br><span class="line">1425</span><br><span class="line">1426</span><br><span class="line">1427</span><br><span class="line">1428</span><br><span class="line">1429</span><br><span class="line">1430</span><br><span class="line">1431</span><br><span class="line">1432</span><br><span class="line">1433</span><br><span class="line">1434</span><br><span class="line">1435</span><br><span class="line">1436</span><br><span class="line">1437</span><br><span class="line">1438</span><br><span class="line">1439</span><br><span class="line">1440</span><br><span class="line">1441</span><br><span class="line">1442</span><br><span class="line">1443</span><br><span class="line">1444</span><br><span class="line">1445</span><br><span class="line">1446</span><br><span class="line">1447</span><br><span class="line">1448</span><br><span class="line">1449</span><br><span class="line">1450</span><br><span class="line">1451</span><br><span class="line">1452</span><br><span class="line">1453</span><br><span class="line">1454</span><br><span class="line">1455</span><br><span class="line">1456</span><br><span class="line">1457</span><br><span class="line">1458</span><br><span class="line">1459</span><br><span class="line">1460</span><br><span class="line">1461</span><br><span class="line">1462</span><br><span class="line">1463</span><br><span class="line">1464</span><br><span class="line">1465</span><br><span class="line">1466</span><br><span class="line">1467</span><br><span class="line">1468</span><br><span class="line">1469</span><br><span class="line">1470</span><br><span class="line">1471</span><br><span class="line">1472</span><br><span class="line">1473</span><br><span class="line">1474</span><br><span class="line">1475</span><br><span class="line">1476</span><br><span class="line">1477</span><br><span class="line">1478</span><br><span class="line">1479</span><br><span class="line">1480</span><br><span class="line">1481</span><br><span class="line">1482</span><br><span class="line">1483</span><br><span class="line">1484</span><br><span class="line">1485</span><br><span class="line">1486</span><br><span class="line">1487</span><br><span class="line">1488</span><br><span class="line">1489</span><br><span class="line">1490</span><br><span class="line">1491</span><br><span class="line">1492</span><br><span class="line">1493</span><br><span class="line">1494</span><br><span class="line">1495</span><br><span class="line">1496</span><br><span class="line">1497</span><br><span class="line">1498</span><br><span class="line">1499</span><br><span class="line">1500</span><br><span class="line">1501</span><br><span class="line">1502</span><br><span class="line">1503</span><br><span class="line">1504</span><br><span class="line">1505</span><br><span class="line">1506</span><br><span class="line">1507</span><br><span class="line">1508</span><br><span class="line">1509</span><br><span class="line">1510</span><br><span class="line">1511</span><br><span class="line">1512</span><br><span class="line">1513</span><br><span class="line">1514</span><br><span class="line">1515</span><br><span class="line">1516</span><br><span class="line">1517</span><br><span class="line">1518</span><br><span class="line">1519</span><br><span class="line">1520</span><br><span class="line">1521</span><br><span class="line">1522</span><br><span class="line">1523</span><br><span class="line">1524</span><br><span class="line">1525</span><br><span class="line">1526</span><br><span class="line">1527</span><br><span class="line">1528</span><br><span class="line">1529</span><br><span class="line">1530</span><br><span class="line">1531</span><br><span class="line">1532</span><br><span class="line">1533</span><br><span class="line">1534</span><br><span class="line">1535</span><br><span class="line">1536</span><br><span class="line">1537</span><br><span class="line">1538</span><br><span class="line">1539</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Copyright 2022 Garena Online Private Limited</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="hljs-comment"># you may not use this file except in compliance with the License.</span><br><span class="hljs-comment"># You may obtain a copy of the License at</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#     http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># Unless required by applicable law or agreed to in writing, software</span><br><span class="hljs-comment"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="hljs-comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="hljs-comment"># See the License for the specific language governing permissions and</span><br><span class="hljs-comment"># limitations under the License.</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">MetaFormer baselines including IdentityFormer, RandFormer, PoolFormerV2,</span><br><span class="hljs-string">ConvFormer and CAFormer.</span><br><span class="hljs-string">Some implementations are modified from timm (https://github.com/rwightman/pytorch-image-models).</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">from</span> functools <span class="hljs-keyword">import</span> partial<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">from</span> timm.models.layers <span class="hljs-keyword">import</span> trunc_normal_, DropPath<br><span class="hljs-keyword">from</span> timm.models.registry <span class="hljs-keyword">import</span> register_model<br><span class="hljs-keyword">from</span> timm.data <span class="hljs-keyword">import</span> IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD<br><span class="hljs-keyword">from</span> timm.models.layers.helpers <span class="hljs-keyword">import</span> to_2tuple<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_cfg</span>(<span class="hljs-params">url=<span class="hljs-string">&#x27;&#x27;</span>, **kwargs</span>):<br>    <span class="hljs-keyword">return</span> &#123;<br>        <span class="hljs-string">&#x27;url&#x27;</span>: url,<br>        <span class="hljs-string">&#x27;num_classes&#x27;</span>: <span class="hljs-number">1000</span>, <span class="hljs-string">&#x27;input_size&#x27;</span>: (<span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>), <span class="hljs-string">&#x27;pool_size&#x27;</span>: <span class="hljs-literal">None</span>,<br>        <span class="hljs-string">&#x27;crop_pct&#x27;</span>: <span class="hljs-number">1.0</span>, <span class="hljs-string">&#x27;interpolation&#x27;</span>: <span class="hljs-string">&#x27;bicubic&#x27;</span>,<br>        <span class="hljs-string">&#x27;mean&#x27;</span>: IMAGENET_DEFAULT_MEAN, <span class="hljs-string">&#x27;std&#x27;</span>: IMAGENET_DEFAULT_STD, <span class="hljs-string">&#x27;classifier&#x27;</span>: <span class="hljs-string">&#x27;head&#x27;</span>,<br>        **kwargs<br>    &#125;<br><br><br>default_cfgs = &#123;<br>    <span class="hljs-string">&#x27;identityformer_s12&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/identityformer/identityformer_s12.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;identityformer_s24&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/identityformer/identityformer_s24.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;identityformer_s36&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/identityformer/identityformer_s36.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;identityformer_m36&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/identityformer/identityformer_m36.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;identityformer_m48&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/identityformer/identityformer_m48.pth&#x27;</span>),<br><br><br>    <span class="hljs-string">&#x27;randformer_s12&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/randformer/randformer_s12.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;randformer_s24&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/randformer/randformer_s24.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;randformer_s36&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/randformer/randformer_s36.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;randformer_m36&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/randformer/randformer_m36.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;randformer_m48&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/randformer/randformer_m48.pth&#x27;</span>),<br><br>    <span class="hljs-string">&#x27;poolformerv2_s12&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/poolformerv2/poolformerv2_s12.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;poolformerv2_s24&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/poolformerv2/poolformerv2_s24.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;poolformerv2_s36&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/poolformerv2/poolformerv2_s36.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;poolformerv2_m36&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/poolformerv2/poolformerv2_m36.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;poolformerv2_m48&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/poolformerv2/poolformerv2_m48.pth&#x27;</span>),<br><br><br><br>    <span class="hljs-string">&#x27;convformer_s18&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/convformer/convformer_s18.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;convformer_s18_384&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/convformer/convformer_s18_384.pth&#x27;</span>,<br>        input_size=(<span class="hljs-number">3</span>, <span class="hljs-number">384</span>, <span class="hljs-number">384</span>)),<br>    <span class="hljs-string">&#x27;convformer_s18_in21ft1k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/convformer/convformer_s18_in21ft1k.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;convformer_s18_384_in21ft1k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/convformer/convformer_s18_384_in21ft1k.pth&#x27;</span>,<br>        input_size=(<span class="hljs-number">3</span>, <span class="hljs-number">384</span>, <span class="hljs-number">384</span>)),<br>    <span class="hljs-string">&#x27;convformer_s18_in21k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/convformer/convformer_s18_in21k.pth&#x27;</span>,<br>        num_classes=<span class="hljs-number">21841</span>),<br><br>    <span class="hljs-string">&#x27;convformer_s36&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/convformer/convformer_s36.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;convformer_s36_384&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/convformer/convformer_s36_384.pth&#x27;</span>,<br>        input_size=(<span class="hljs-number">3</span>, <span class="hljs-number">384</span>, <span class="hljs-number">384</span>)),<br>    <span class="hljs-string">&#x27;convformer_s36_in21ft1k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/convformer/convformer_s36_in21ft1k.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;convformer_s36_384_in21ft1k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/convformer/convformer_s36_384_in21ft1k.pth&#x27;</span>,<br>        input_size=(<span class="hljs-number">3</span>, <span class="hljs-number">384</span>, <span class="hljs-number">384</span>)),<br>    <span class="hljs-string">&#x27;convformer_s36_in21k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/convformer/convformer_s36_in21k.pth&#x27;</span>,<br>        num_classes=<span class="hljs-number">21841</span>),<br><br>    <span class="hljs-string">&#x27;convformer_m36&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/convformer/convformer_m36.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;convformer_m36_384&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/convformer/convformer_m36_384.pth&#x27;</span>,<br>        input_size=(<span class="hljs-number">3</span>, <span class="hljs-number">384</span>, <span class="hljs-number">384</span>)),<br>    <span class="hljs-string">&#x27;convformer_m36_in21ft1k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/convformer/convformer_m36_in21ft1k.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;convformer_m36_384_in21ft1k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/convformer/convformer_m36_384_in21ft1k.pth&#x27;</span>,<br>        input_size=(<span class="hljs-number">3</span>, <span class="hljs-number">384</span>, <span class="hljs-number">384</span>)),<br>    <span class="hljs-string">&#x27;convformer_m36_in21k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/convformer/convformer_m36_in21k.pth&#x27;</span>,<br>        num_classes=<span class="hljs-number">21841</span>),<br><br>    <span class="hljs-string">&#x27;convformer_b36&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/convformer/convformer_b36.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;convformer_b36_384&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/convformer/convformer_b36_384.pth&#x27;</span>,<br>        input_size=(<span class="hljs-number">3</span>, <span class="hljs-number">384</span>, <span class="hljs-number">384</span>)),<br>    <span class="hljs-string">&#x27;convformer_b36_in21ft1k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/convformer/convformer_b36_in21ft1k.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;convformer_b36_384_in21ft1k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/convformer/convformer_b36_384_in21ft1k.pth&#x27;</span>,<br>        input_size=(<span class="hljs-number">3</span>, <span class="hljs-number">384</span>, <span class="hljs-number">384</span>)),<br>    <span class="hljs-string">&#x27;convformer_b36_in21k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/convformer/convformer_b36_in21k.pth&#x27;</span>,<br>        num_classes=<span class="hljs-number">21841</span>),<br><br><br>    <span class="hljs-string">&#x27;caformer_s18&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/caformer/caformer_s18.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;caformer_s18_384&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/caformer/caformer_s18_384.pth&#x27;</span>,<br>        input_size=(<span class="hljs-number">3</span>, <span class="hljs-number">384</span>, <span class="hljs-number">384</span>)),<br>    <span class="hljs-string">&#x27;caformer_s18_in21ft1k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/caformer/caformer_s18_in21ft1k.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;caformer_s18_384_in21ft1k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/caformer/caformer_s18_384_in21ft1k.pth&#x27;</span>,<br>        input_size=(<span class="hljs-number">3</span>, <span class="hljs-number">384</span>, <span class="hljs-number">384</span>)),<br>    <span class="hljs-string">&#x27;caformer_s18_in21k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/caformer/caformer_s18_in21k.pth&#x27;</span>,<br>        num_classes=<span class="hljs-number">21841</span>),<br><br>    <span class="hljs-string">&#x27;caformer_s36&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/caformer/caformer_s36.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;caformer_s36_384&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/caformer/caformer_s36_384.pth&#x27;</span>,<br>        input_size=(<span class="hljs-number">3</span>, <span class="hljs-number">384</span>, <span class="hljs-number">384</span>)),<br>    <span class="hljs-string">&#x27;caformer_s36_in21ft1k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/caformer/caformer_s36_in21ft1k.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;caformer_s36_384_in21ft1k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/caformer/caformer_s36_384_in21ft1k.pth&#x27;</span>,<br>        input_size=(<span class="hljs-number">3</span>, <span class="hljs-number">384</span>, <span class="hljs-number">384</span>)),<br>    <span class="hljs-string">&#x27;caformer_s36_in21k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/caformer/caformer_s36_in21k.pth&#x27;</span>,<br>        num_classes=<span class="hljs-number">21841</span>),<br><br>    <span class="hljs-string">&#x27;caformer_m36&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/caformer/caformer_m36.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;caformer_m36_384&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/caformer/caformer_m36_384.pth&#x27;</span>,<br>        input_size=(<span class="hljs-number">3</span>, <span class="hljs-number">384</span>, <span class="hljs-number">384</span>)),<br>    <span class="hljs-string">&#x27;caformer_m36_in21ft1k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/caformer/caformer_m36_in21ft1k.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;caformer_m36_384_in21ft1k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/caformer/caformer_m36_384_in21ft1k.pth&#x27;</span>,<br>        input_size=(<span class="hljs-number">3</span>, <span class="hljs-number">384</span>, <span class="hljs-number">384</span>)),<br>    <span class="hljs-string">&#x27;caformer_m36_in21k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/caformer/caformer_m36_in21k.pth&#x27;</span>,<br>        num_classes=<span class="hljs-number">21841</span>),<br><br>    <span class="hljs-string">&#x27;caformer_b36&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/caformer/caformer_b36.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;caformer_b36_384&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/caformer/caformer_b36_384.pth&#x27;</span>,<br>        input_size=(<span class="hljs-number">3</span>, <span class="hljs-number">384</span>, <span class="hljs-number">384</span>)),<br>    <span class="hljs-string">&#x27;caformer_b36_in21ft1k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/caformer/caformer_b36_in21ft1k.pth&#x27;</span>),<br>    <span class="hljs-string">&#x27;caformer_b36_384_in21ft1k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/caformer/caformer_b36_384_in21ft1k.pth&#x27;</span>,<br>        input_size=(<span class="hljs-number">3</span>, <span class="hljs-number">384</span>, <span class="hljs-number">384</span>)),<br>    <span class="hljs-string">&#x27;caformer_b36_in21k&#x27;</span>: _cfg(<br>        url=<span class="hljs-string">&#x27;https://huggingface.co/sail/dl/resolve/main/caformer/caformer_b36_in21k.pth&#x27;</span>,<br>        num_classes=<span class="hljs-number">21841</span>),<br>&#125;<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Downsampling</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Downsampling implemented by a layer of convolution.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels, out_channels, </span><br><span class="hljs-params">        kernel_size, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>, </span><br><span class="hljs-params">        pre_norm=<span class="hljs-literal">None</span>, post_norm=<span class="hljs-literal">None</span>, pre_permute=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.pre_norm = pre_norm(in_channels) <span class="hljs-keyword">if</span> pre_norm <span class="hljs-keyword">else</span> nn.Identity()<br>        self.pre_permute = pre_permute<br>        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, <br>                              stride=stride, padding=padding)<br>        self.post_norm = post_norm(out_channels) <span class="hljs-keyword">if</span> post_norm <span class="hljs-keyword">else</span> nn.Identity()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.pre_norm(x)<br>        <span class="hljs-keyword">if</span> self.pre_permute:<br>            <span class="hljs-comment"># if take [B, H, W, C] as input, permute it to [B, C, H, W]</span><br>            x = x.permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>        x = self.conv(x)<br>        x = x.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>) <span class="hljs-comment"># [B, C, H, W] -&gt; [B, H, W, C]</span><br>        x = self.post_norm(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Scale</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Scale vector by element multiplications.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim, init_value=<span class="hljs-number">1.0</span>, trainable=<span class="hljs-literal">True</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.scale = nn.Parameter(init_value * torch.ones(dim), requires_grad=trainable)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> x * self.scale<br>        <br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SquaredReLU</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Squared ReLU: https://arxiv.org/abs/2109.08668</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, inplace=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.relu = nn.ReLU(inplace=inplace)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> torch.square(self.relu(x))<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">StarReLU</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    StarReLU: s * relu(x) ** 2 + b</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, scale_value=<span class="hljs-number">1.0</span>, bias_value=<span class="hljs-number">0.0</span>,</span><br><span class="hljs-params">        scale_learnable=<span class="hljs-literal">True</span>, bias_learnable=<span class="hljs-literal">True</span>, </span><br><span class="hljs-params">        mode=<span class="hljs-literal">None</span>, inplace=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.inplace = inplace<br>        self.relu = nn.ReLU(inplace=inplace)<br>        self.scale = nn.Parameter(scale_value * torch.ones(<span class="hljs-number">1</span>),<br>            requires_grad=scale_learnable)<br>        self.bias = nn.Parameter(bias_value * torch.ones(<span class="hljs-number">1</span>),<br>            requires_grad=bias_learnable)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> self.scale * self.relu(x)**<span class="hljs-number">2</span> + self.bias<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Attention</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Vanilla self-attention from Transformer: https://arxiv.org/abs/1706.03762.</span><br><span class="hljs-string">    Modified from timm.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim, head_dim=<span class="hljs-number">32</span>, num_heads=<span class="hljs-literal">None</span>, qkv_bias=<span class="hljs-literal">False</span>,</span><br><span class="hljs-params">        attn_drop=<span class="hljs-number">0.</span>, proj_drop=<span class="hljs-number">0.</span>, proj_bias=<span class="hljs-literal">False</span>, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br><br>        self.head_dim = head_dim<br>        self.scale = head_dim ** -<span class="hljs-number">0.5</span><br><br>        self.num_heads = num_heads <span class="hljs-keyword">if</span> num_heads <span class="hljs-keyword">else</span> dim // head_dim<br>        <span class="hljs-keyword">if</span> self.num_heads == <span class="hljs-number">0</span>:<br>            self.num_heads = <span class="hljs-number">1</span><br>        <br>        self.attention_dim = self.num_heads * self.head_dim<br><br>        self.qkv = nn.Linear(dim, self.attention_dim * <span class="hljs-number">3</span>, bias=qkv_bias)<br>        self.attn_drop = nn.Dropout(attn_drop)<br>        self.proj = nn.Linear(self.attention_dim, dim, bias=proj_bias)<br>        self.proj_drop = nn.Dropout(proj_drop)<br><br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        B, H, W, C = x.shape<br>        N = H * W<br>        qkv = self.qkv(x).reshape(B, N, <span class="hljs-number">3</span>, self.num_heads, self.head_dim).permute(<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">4</span>)<br>        q, k, v = qkv.unbind(<span class="hljs-number">0</span>)   <span class="hljs-comment"># make torchscript happy (cannot use tensor as tuple)</span><br><br>        attn = (q @ k.transpose(-<span class="hljs-number">2</span>, -<span class="hljs-number">1</span>)) * self.scale<br>        attn = attn.softmax(dim=-<span class="hljs-number">1</span>)<br>        attn = self.attn_drop(attn)<br><br>        x = (attn @ v).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>).reshape(B, H, W, self.attention_dim)<br>        x = self.proj(x)<br>        x = self.proj_drop(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">RandomMixing</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_tokens=<span class="hljs-number">196</span>, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.random_matrix = nn.parameter.Parameter(<br>            data=torch.softmax(torch.rand(num_tokens, num_tokens), dim=-<span class="hljs-number">1</span>), <br>            requires_grad=<span class="hljs-literal">False</span>)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        B, H, W, C = x.shape<br>        x = x.reshape(B, H*W, C)<br>        x = torch.einsum(<span class="hljs-string">&#x27;mn, bnc -&gt; bmc&#x27;</span>, self.random_matrix, x)<br>        x = x.reshape(B, H, W, C)<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LayerNormGeneral</span>(nn.Module):<br>    <span class="hljs-string">r&quot;&quot;&quot; General LayerNorm for different situations.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        affine_shape (int, list or tuple): The shape of affine weight and bias.</span><br><span class="hljs-string">            Usually the affine_shape=C, but in some implementation, like torch.nn.LayerNorm,</span><br><span class="hljs-string">            the affine_shape is the same as normalized_dim by default. </span><br><span class="hljs-string">            To adapt to different situations, we offer this argument here.</span><br><span class="hljs-string">        normalized_dim (tuple or list): Which dims to compute mean and variance. </span><br><span class="hljs-string">        scale (bool): Flag indicates whether to use scale or not.</span><br><span class="hljs-string">        bias (bool): Flag indicates whether to use scale or not.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        We give several examples to show how to specify the arguments.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        LayerNorm (https://arxiv.org/abs/1607.06450):</span><br><span class="hljs-string">            For input shape of (B, *, C) like (B, N, C) or (B, H, W, C),</span><br><span class="hljs-string">                affine_shape=C, normalized_dim=(-1, ), scale=True, bias=True;</span><br><span class="hljs-string">            For input shape of (B, C, H, W),</span><br><span class="hljs-string">                affine_shape=(C, 1, 1), normalized_dim=(1, ), scale=True, bias=True.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Modified LayerNorm (https://arxiv.org/abs/2111.11418)</span><br><span class="hljs-string">            that is idental to partial(torch.nn.GroupNorm, num_groups=1):</span><br><span class="hljs-string">            For input shape of (B, N, C),</span><br><span class="hljs-string">                affine_shape=C, normalized_dim=(1, 2), scale=True, bias=True;</span><br><span class="hljs-string">            For input shape of (B, H, W, C),</span><br><span class="hljs-string">                affine_shape=C, normalized_dim=(1, 2, 3), scale=True, bias=True;</span><br><span class="hljs-string">            For input shape of (B, C, H, W),</span><br><span class="hljs-string">                affine_shape=(C, 1, 1), normalized_dim=(1, 2, 3), scale=True, bias=True.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        For the several metaformer baslines,</span><br><span class="hljs-string">            IdentityFormer, RandFormer and PoolFormerV2 utilize Modified LayerNorm without bias (bias=False);</span><br><span class="hljs-string">            ConvFormer and CAFormer utilizes LayerNorm without bias (bias=False).</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, affine_shape=<span class="hljs-literal">None</span>, normalized_dim=(<span class="hljs-params">-<span class="hljs-number">1</span>, </span>), scale=<span class="hljs-literal">True</span>, </span><br><span class="hljs-params">        bias=<span class="hljs-literal">True</span>, eps=<span class="hljs-number">1e-5</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.normalized_dim = normalized_dim<br>        self.use_scale = scale<br>        self.use_bias = bias<br>        self.weight = nn.Parameter(torch.ones(affine_shape)) <span class="hljs-keyword">if</span> scale <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span><br>        self.bias = nn.Parameter(torch.zeros(affine_shape)) <span class="hljs-keyword">if</span> bias <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span><br>        self.eps = eps<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        c = x - x.mean(self.normalized_dim, keepdim=<span class="hljs-literal">True</span>)<br>        s = c.<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>).mean(self.normalized_dim, keepdim=<span class="hljs-literal">True</span>)<br>        x = c / torch.sqrt(s + self.eps)<br>        <span class="hljs-keyword">if</span> self.use_scale:<br>            x = x * self.weight<br>        <span class="hljs-keyword">if</span> self.use_bias:<br>            x = x + self.bias<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LayerNormWithoutBias</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Equal to partial(LayerNormGeneral, bias=False) but faster, </span><br><span class="hljs-string">    because it directly utilizes otpimized F.layer_norm</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, normalized_shape, eps=<span class="hljs-number">1e-5</span>, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.eps = eps<br>        self.bias = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(normalized_shape, <span class="hljs-built_in">int</span>):<br>            normalized_shape = (normalized_shape,)<br>        self.weight = nn.Parameter(torch.ones(normalized_shape))<br>        self.normalized_shape = normalized_shape<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> F.layer_norm(x, self.normalized_shape, weight=self.weight, bias=self.bias, eps=self.eps)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SepConv</span>(nn.Module):<br>    <span class="hljs-string">r&quot;&quot;&quot;</span><br><span class="hljs-string">    Inverted separable convolution from MobileNetV2: https://arxiv.org/abs/1801.04381.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim, expansion_ratio=<span class="hljs-number">2</span>,</span><br><span class="hljs-params">        act1_layer=StarReLU, act2_layer=nn.Identity, </span><br><span class="hljs-params">        bias=<span class="hljs-literal">False</span>, kernel_size=<span class="hljs-number">7</span>, padding=<span class="hljs-number">3</span>,</span><br><span class="hljs-params">        **kwargs, </span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        med_channels = <span class="hljs-built_in">int</span>(expansion_ratio * dim)<br>        self.pwconv1 = nn.Linear(dim, med_channels, bias=bias)<br>        self.act1 = act1_layer()<br>        self.dwconv = nn.Conv2d(<br>            med_channels, med_channels, kernel_size=kernel_size,<br>            padding=padding, groups=med_channels, bias=bias) <span class="hljs-comment"># depthwise conv</span><br>        self.act2 = act2_layer()<br>        self.pwconv2 = nn.Linear(med_channels, dim, bias=bias)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.pwconv1(x)<br>        x = self.act1(x)<br>        x = x.permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>        x = self.dwconv(x)<br>        x = x.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br>        x = self.act2(x)<br>        x = self.pwconv2(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Pooling</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Implementation of pooling for PoolFormer: https://arxiv.org/abs/2111.11418</span><br><span class="hljs-string">    Modfiled for [B, H, W, C] input</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, pool_size=<span class="hljs-number">3</span>, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.pool = nn.AvgPool2d(<br>            pool_size, stride=<span class="hljs-number">1</span>, padding=pool_size//<span class="hljs-number">2</span>, count_include_pad=<span class="hljs-literal">False</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        y = x.permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>        y = self.pool(y)<br>        y = y.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> y - x<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Mlp</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot; MLP as used in MetaFormer models, eg Transformer, MLP-Mixer, PoolFormer, MetaFormer baslines and related networks.</span><br><span class="hljs-string">    Mostly copied from timm.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim, mlp_ratio=<span class="hljs-number">4</span>, out_features=<span class="hljs-literal">None</span>, act_layer=StarReLU, drop=<span class="hljs-number">0.</span>, bias=<span class="hljs-literal">False</span>, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        in_features = dim<br>        out_features = out_features <span class="hljs-keyword">or</span> in_features<br>        hidden_features = <span class="hljs-built_in">int</span>(mlp_ratio * in_features)<br>        drop_probs = to_2tuple(drop)<br><br>        self.fc1 = nn.Linear(in_features, hidden_features, bias=bias)<br>        self.act = act_layer()<br>        self.drop1 = nn.Dropout(drop_probs[<span class="hljs-number">0</span>])<br>        self.fc2 = nn.Linear(hidden_features, out_features, bias=bias)<br>        self.drop2 = nn.Dropout(drop_probs[<span class="hljs-number">1</span>])<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.fc1(x)<br>        x = self.act(x)<br>        x = self.drop1(x)<br>        x = self.fc2(x)<br>        x = self.drop2(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MlpHead</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot; MLP classification head</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim, num_classes=<span class="hljs-number">1000</span>, mlp_ratio=<span class="hljs-number">4</span>, act_layer=SquaredReLU,</span><br><span class="hljs-params">        norm_layer=nn.LayerNorm, head_dropout=<span class="hljs-number">0.</span>, bias=<span class="hljs-literal">True</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        hidden_features = <span class="hljs-built_in">int</span>(mlp_ratio * dim)<br>        self.fc1 = nn.Linear(dim, hidden_features, bias=bias)<br>        self.act = act_layer()<br>        self.norm = norm_layer(hidden_features)<br>        self.fc2 = nn.Linear(hidden_features, num_classes, bias=bias)<br>        self.head_dropout = nn.Dropout(head_dropout)<br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.fc1(x)<br>        x = self.act(x)<br>        x = self.norm(x)<br>        x = self.head_dropout(x)<br>        x = self.fc2(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MetaFormerBlock</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Implementation of one MetaFormer block.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim,</span><br><span class="hljs-params">                 token_mixer=nn.Identity, mlp=Mlp,</span><br><span class="hljs-params">                 norm_layer=nn.LayerNorm,</span><br><span class="hljs-params">                 drop=<span class="hljs-number">0.</span>, drop_path=<span class="hljs-number">0.</span>,</span><br><span class="hljs-params">                 layer_scale_init_value=<span class="hljs-literal">None</span>, res_scale_init_value=<span class="hljs-literal">None</span></span><br><span class="hljs-params">                 </span>):<br><br>        <span class="hljs-built_in">super</span>().__init__()<br><br>        self.norm1 = norm_layer(dim)<br>        self.token_mixer = token_mixer(dim=dim, drop=drop)<br>        self.drop_path1 = DropPath(drop_path) <span class="hljs-keyword">if</span> drop_path &gt; <span class="hljs-number">0.</span> <span class="hljs-keyword">else</span> nn.Identity()<br>        self.layer_scale1 = Scale(dim=dim, init_value=layer_scale_init_value) \<br>            <span class="hljs-keyword">if</span> layer_scale_init_value <span class="hljs-keyword">else</span> nn.Identity()<br>        self.res_scale1 = Scale(dim=dim, init_value=res_scale_init_value) \<br>            <span class="hljs-keyword">if</span> res_scale_init_value <span class="hljs-keyword">else</span> nn.Identity()<br><br>        self.norm2 = norm_layer(dim)<br>        self.mlp = mlp(dim=dim, drop=drop)<br>        self.drop_path2 = DropPath(drop_path) <span class="hljs-keyword">if</span> drop_path &gt; <span class="hljs-number">0.</span> <span class="hljs-keyword">else</span> nn.Identity()<br>        self.layer_scale2 = Scale(dim=dim, init_value=layer_scale_init_value) \<br>            <span class="hljs-keyword">if</span> layer_scale_init_value <span class="hljs-keyword">else</span> nn.Identity()<br>        self.res_scale2 = Scale(dim=dim, init_value=res_scale_init_value) \<br>            <span class="hljs-keyword">if</span> res_scale_init_value <span class="hljs-keyword">else</span> nn.Identity()<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.res_scale1(x) + \<br>            self.layer_scale1(<br>                self.drop_path1(<br>                    self.token_mixer(self.norm1(x))<br>                )<br>            )<br>        x = self.res_scale2(x) + \<br>            self.layer_scale2(<br>                self.drop_path2(<br>                    self.mlp(self.norm2(x))<br>                )<br>            )<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-string">r&quot;&quot;&quot;</span><br><span class="hljs-string">downsampling (stem) for the first stage is a layer of conv with k7, s4 and p2</span><br><span class="hljs-string">downsamplings for the last 3 stages is a layer of conv with k3, s2 and p1</span><br><span class="hljs-string">DOWNSAMPLE_LAYERS_FOUR_STAGES format: [Downsampling, Downsampling, Downsampling, Downsampling]</span><br><span class="hljs-string">use `partial` to specify some arguments</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>DOWNSAMPLE_LAYERS_FOUR_STAGES = [partial(Downsampling,<br>            kernel_size=<span class="hljs-number">7</span>, stride=<span class="hljs-number">4</span>, padding=<span class="hljs-number">2</span>,<br>            post_norm=partial(LayerNormGeneral, bias=<span class="hljs-literal">False</span>, eps=<span class="hljs-number">1e-6</span>)<br>            )] + \<br>            [partial(Downsampling,<br>                kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>, <br>                pre_norm=partial(LayerNormGeneral, bias=<span class="hljs-literal">False</span>, eps=<span class="hljs-number">1e-6</span>), pre_permute=<span class="hljs-literal">True</span><br>            )]*<span class="hljs-number">3</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MetaFormer</span>(nn.Module):<br>    <span class="hljs-string">r&quot;&quot;&quot; MetaFormer</span><br><span class="hljs-string">        A PyTorch impl of : `MetaFormer Baselines for Vision`  -</span><br><span class="hljs-string">          https://arxiv.org/abs/2210.13452</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        in_chans (int): Number of input image channels. Default: 3.</span><br><span class="hljs-string">        num_classes (int): Number of classes for classification head. Default: 1000.</span><br><span class="hljs-string">        depths (list or tuple): Number of blocks at each stage. Default: [2, 2, 6, 2].</span><br><span class="hljs-string">        dims (int): Feature dimension at each stage. Default: [64, 128, 320, 512].</span><br><span class="hljs-string">        downsample_layers: (list or tuple): Downsampling layers before each stage.</span><br><span class="hljs-string">        token_mixers (list, tuple or token_fcn): Token mixer for each stage. Default: nn.Identity.</span><br><span class="hljs-string">        mlps (list, tuple or mlp_fcn): Mlp for each stage. Default: Mlp.</span><br><span class="hljs-string">        norm_layers (list, tuple or norm_fcn): Norm layers for each stage. Default: partial(LayerNormGeneral, eps=1e-6, bias=False).</span><br><span class="hljs-string">        drop_path_rate (float): Stochastic depth rate. Default: 0.</span><br><span class="hljs-string">        head_dropout (float): dropout for MLP classifier. Default: 0.</span><br><span class="hljs-string">        layer_scale_init_values (list, tuple, float or None): Init value for Layer Scale. Default: None.</span><br><span class="hljs-string">            None means not use the layer scale. Form: https://arxiv.org/abs/2103.17239.</span><br><span class="hljs-string">        res_scale_init_values (list, tuple, float or None): Init value for Layer Scale. Default: [None, None, 1.0, 1.0].</span><br><span class="hljs-string">            None means not use the layer scale. From: https://arxiv.org/abs/2110.09456.</span><br><span class="hljs-string">        output_norm: norm before classifier head. Default: partial(nn.LayerNorm, eps=1e-6).</span><br><span class="hljs-string">        head_fn: classification head. Default: nn.Linear.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_chans=<span class="hljs-number">3</span>, num_classes=<span class="hljs-number">1000</span>, </span><br><span class="hljs-params">                 depths=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>],</span><br><span class="hljs-params">                 dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],</span><br><span class="hljs-params">                 downsample_layers=DOWNSAMPLE_LAYERS_FOUR_STAGES,</span><br><span class="hljs-params">                 token_mixers=nn.Identity,</span><br><span class="hljs-params">                 mlps=Mlp,</span><br><span class="hljs-params">                 norm_layers=partial(<span class="hljs-params">LayerNormWithoutBias, eps=<span class="hljs-number">1e-6</span></span>), <span class="hljs-comment"># partial(LayerNormGeneral, eps=1e-6, bias=False),</span></span><br><span class="hljs-params">                 drop_path_rate=<span class="hljs-number">0.</span>,</span><br><span class="hljs-params">                 head_dropout=<span class="hljs-number">0.0</span>, </span><br><span class="hljs-params">                 layer_scale_init_values=<span class="hljs-literal">None</span>,</span><br><span class="hljs-params">                 res_scale_init_values=[<span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>],</span><br><span class="hljs-params">                 output_norm=partial(<span class="hljs-params">nn.LayerNorm, eps=<span class="hljs-number">1e-6</span></span>), </span><br><span class="hljs-params">                 head_fn=nn.Linear,</span><br><span class="hljs-params">                 **kwargs,</span><br><span class="hljs-params">                 </span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.num_classes = num_classes<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(depths, (<span class="hljs-built_in">list</span>, <span class="hljs-built_in">tuple</span>)):<br>            depths = [depths] <span class="hljs-comment"># it means the model has only one stage</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(dims, (<span class="hljs-built_in">list</span>, <span class="hljs-built_in">tuple</span>)):<br>            dims = [dims]<br><br>        num_stage = <span class="hljs-built_in">len</span>(depths)<br>        self.num_stage = num_stage<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(downsample_layers, (<span class="hljs-built_in">list</span>, <span class="hljs-built_in">tuple</span>)):<br>            downsample_layers = [downsample_layers] * num_stage<br>        down_dims = [in_chans] + dims<br>        self.downsample_layers = nn.ModuleList(<br>            [downsample_layers[i](down_dims[i], down_dims[i+<span class="hljs-number">1</span>]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_stage)]<br>        )<br>        <br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(token_mixers, (<span class="hljs-built_in">list</span>, <span class="hljs-built_in">tuple</span>)):<br>            token_mixers = [token_mixers] * num_stage<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(mlps, (<span class="hljs-built_in">list</span>, <span class="hljs-built_in">tuple</span>)):<br>            mlps = [mlps] * num_stage<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(norm_layers, (<span class="hljs-built_in">list</span>, <span class="hljs-built_in">tuple</span>)):<br>            norm_layers = [norm_layers] * num_stage<br>        <br>        dp_rates=[x.item() <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> torch.linspace(<span class="hljs-number">0</span>, drop_path_rate, <span class="hljs-built_in">sum</span>(depths))]<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(layer_scale_init_values, (<span class="hljs-built_in">list</span>, <span class="hljs-built_in">tuple</span>)):<br>            layer_scale_init_values = [layer_scale_init_values] * num_stage<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">isinstance</span>(res_scale_init_values, (<span class="hljs-built_in">list</span>, <span class="hljs-built_in">tuple</span>)):<br>            res_scale_init_values = [res_scale_init_values] * num_stage<br><br>        self.stages = nn.ModuleList() <span class="hljs-comment"># each stage consists of multiple metaformer blocks</span><br>        cur = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_stage):<br>            stage = nn.Sequential(<br>                *[MetaFormerBlock(dim=dims[i],<br>                token_mixer=token_mixers[i],<br>                mlp=mlps[i],<br>                norm_layer=norm_layers[i],<br>                drop_path=dp_rates[cur + j],<br>                layer_scale_init_value=layer_scale_init_values[i],<br>                res_scale_init_value=res_scale_init_values[i],<br>                ) <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(depths[i])]<br>            )<br>            self.stages.append(stage)<br>            cur += depths[i]<br><br>        self.norm = output_norm(dims[-<span class="hljs-number">1</span>])<br><br>        <span class="hljs-keyword">if</span> head_dropout &gt; <span class="hljs-number">0.0</span>:<br>            self.head = head_fn(dims[-<span class="hljs-number">1</span>], num_classes, head_dropout=head_dropout)<br>        <span class="hljs-keyword">else</span>:<br>            self.head = head_fn(dims[-<span class="hljs-number">1</span>], num_classes)<br><br>        self.apply(self._init_weights)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_weights</span>(<span class="hljs-params">self, m</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, (nn.Conv2d, nn.Linear)):<br>            trunc_normal_(m.weight, std=<span class="hljs-number">.02</span>)<br>            <span class="hljs-keyword">if</span> m.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                nn.init.constant_(m.bias, <span class="hljs-number">0</span>)<br><br><span class="hljs-meta">    @torch.jit.ignore</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">no_weight_decay</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;norm&#x27;</span>&#125;<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward_features</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.num_stage):<br>            x = self.downsample_layers[i](x)<br>            x = self.stages[i](x)<br>        <span class="hljs-keyword">return</span> self.norm(x.mean([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>])) <span class="hljs-comment"># (B, H, W, C) -&gt; (B, C)</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.forward_features(x)<br>        x = self.head(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">identityformer_s12</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=nn.Identity,<br>        norm_layers=partial(LayerNormGeneral, normalized_dim=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), eps=<span class="hljs-number">1e-6</span>, bias=<span class="hljs-literal">False</span>),<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;identityformer_s12&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">identityformer_s24</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">4</span>, <span class="hljs-number">4</span>, <span class="hljs-number">12</span>, <span class="hljs-number">4</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=nn.Identity,<br>        norm_layers=partial(LayerNormGeneral, normalized_dim=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), eps=<span class="hljs-number">1e-6</span>, bias=<span class="hljs-literal">False</span>),<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;identityformer_s24&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">identityformer_s36</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">6</span>, <span class="hljs-number">6</span>, <span class="hljs-number">18</span>, <span class="hljs-number">6</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=nn.Identity,<br>        norm_layers=partial(LayerNormGeneral, normalized_dim=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), eps=<span class="hljs-number">1e-6</span>, bias=<span class="hljs-literal">False</span>),<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;identityformer_s36&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">identityformer_m36</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">6</span>, <span class="hljs-number">6</span>, <span class="hljs-number">18</span>, <span class="hljs-number">6</span>],<br>        dims=[<span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">768</span>],<br>        token_mixers=nn.Identity,<br>        norm_layers=partial(LayerNormGeneral, normalized_dim=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), eps=<span class="hljs-number">1e-6</span>, bias=<span class="hljs-literal">False</span>),<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;identityformer_m36&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">identityformer_m48</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">8</span>, <span class="hljs-number">8</span>, <span class="hljs-number">24</span>, <span class="hljs-number">8</span>],<br>        dims=[<span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">768</span>],<br>        token_mixers=nn.Identity,<br>        norm_layers=partial(LayerNormGeneral, normalized_dim=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), eps=<span class="hljs-number">1e-6</span>, bias=<span class="hljs-literal">False</span>),<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;identityformer_m48&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">randformer_s12</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=[nn.Identity, nn.Identity, RandomMixing, partial(RandomMixing, num_tokens=<span class="hljs-number">49</span>)],<br>        norm_layers=partial(LayerNormGeneral, normalized_dim=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), eps=<span class="hljs-number">1e-6</span>, bias=<span class="hljs-literal">False</span>),<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;randformer_s12&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">randformer_s24</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">4</span>, <span class="hljs-number">4</span>, <span class="hljs-number">12</span>, <span class="hljs-number">4</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=[nn.Identity, nn.Identity, RandomMixing, partial(RandomMixing, num_tokens=<span class="hljs-number">49</span>)],<br>        norm_layers=partial(LayerNormGeneral, normalized_dim=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), eps=<span class="hljs-number">1e-6</span>, bias=<span class="hljs-literal">False</span>),<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;randformer_s24&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">randformer_s36</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">6</span>, <span class="hljs-number">6</span>, <span class="hljs-number">18</span>, <span class="hljs-number">6</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=[nn.Identity, nn.Identity, RandomMixing, partial(RandomMixing, num_tokens=<span class="hljs-number">49</span>)],<br>        norm_layers=partial(LayerNormGeneral, normalized_dim=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), eps=<span class="hljs-number">1e-6</span>, bias=<span class="hljs-literal">False</span>),<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;randformer_s36&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">randformer_m36</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">6</span>, <span class="hljs-number">6</span>, <span class="hljs-number">18</span>, <span class="hljs-number">6</span>],<br>        dims=[<span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">768</span>],<br>        token_mixers=[nn.Identity, nn.Identity, RandomMixing, partial(RandomMixing, num_tokens=<span class="hljs-number">49</span>)],<br>        norm_layers=partial(LayerNormGeneral, normalized_dim=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), eps=<span class="hljs-number">1e-6</span>, bias=<span class="hljs-literal">False</span>),<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;randformer_m36&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">randformer_m48</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">8</span>, <span class="hljs-number">8</span>, <span class="hljs-number">24</span>, <span class="hljs-number">8</span>],<br>        dims=[<span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">768</span>],<br>        token_mixers=[nn.Identity, nn.Identity, RandomMixing, partial(RandomMixing, num_tokens=<span class="hljs-number">49</span>)],<br>        norm_layers=partial(LayerNormGeneral, normalized_dim=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), eps=<span class="hljs-number">1e-6</span>, bias=<span class="hljs-literal">False</span>),<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;randformer_m48&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">poolformerv2_s12</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=Pooling,<br>        norm_layers=partial(LayerNormGeneral, normalized_dim=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), eps=<span class="hljs-number">1e-6</span>, bias=<span class="hljs-literal">False</span>),<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;poolformerv2_s12&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">poolformerv2_s24</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">4</span>, <span class="hljs-number">4</span>, <span class="hljs-number">12</span>, <span class="hljs-number">4</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=Pooling,<br>        norm_layers=partial(LayerNormGeneral, normalized_dim=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), eps=<span class="hljs-number">1e-6</span>, bias=<span class="hljs-literal">False</span>),<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;poolformerv2_s24&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">poolformerv2_s36</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">6</span>, <span class="hljs-number">6</span>, <span class="hljs-number">18</span>, <span class="hljs-number">6</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=Pooling,<br>        norm_layers=partial(LayerNormGeneral, normalized_dim=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), eps=<span class="hljs-number">1e-6</span>, bias=<span class="hljs-literal">False</span>),<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;poolformerv2_s36&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">poolformerv2_m36</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">6</span>, <span class="hljs-number">6</span>, <span class="hljs-number">18</span>, <span class="hljs-number">6</span>],<br>        dims=[<span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">768</span>],<br>        token_mixers=Pooling,<br>        norm_layers=partial(LayerNormGeneral, normalized_dim=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), eps=<span class="hljs-number">1e-6</span>, bias=<span class="hljs-literal">False</span>),<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;poolformerv2_m36&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">poolformerv2_m48</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">8</span>, <span class="hljs-number">8</span>, <span class="hljs-number">24</span>, <span class="hljs-number">8</span>],<br>        dims=[<span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">768</span>],<br>        token_mixers=Pooling,<br>        norm_layers=partial(LayerNormGeneral, normalized_dim=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), eps=<span class="hljs-number">1e-6</span>, bias=<span class="hljs-literal">False</span>),<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;poolformerv2_m48&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convformer_s18</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">9</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=SepConv,<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;convformer_s18&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convformer_s18_384</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">9</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=SepConv,<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;convformer_s18_384&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convformer_s18_in21ft1k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">9</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=SepConv,<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;convformer_s18_in21ft1k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convformer_s18_384_in21ft1k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">9</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=SepConv,<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;convformer_s18_384_in21ft1k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convformer_s18_in21k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">9</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=SepConv,<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;convformer_s18_in21k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convformer_s36</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=SepConv,<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;convformer_s36&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convformer_s36_384</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=SepConv,<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;convformer_s36_384&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convformer_s36_in21ft1k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=SepConv,<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;convformer_s36_in21ft1k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convformer_s36_384_in21ft1k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=SepConv,<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;convformer_s36_384_in21ft1k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convformer_s36_in21k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=SepConv,<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;convformer_s36_in21k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convformer_m36</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">576</span>],<br>        token_mixers=SepConv,<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;convformer_m36&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convformer_m36_384</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">576</span>],<br>        token_mixers=SepConv,<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;convformer_m36_384&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convformer_m36_in21ft1k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">576</span>],<br>        token_mixers=SepConv,<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;convformer_m36_in21ft1k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convformer_m36_384_in21ft1k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">576</span>],<br>        token_mixers=SepConv,<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;convformer_m36_384_in21ft1k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convformer_m36_in21k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">576</span>],<br>        token_mixers=SepConv,<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;convformer_m36_in21k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convformer_b36</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">512</span>, <span class="hljs-number">768</span>],<br>        token_mixers=SepConv,<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;convformer_b36&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convformer_b36_384</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">512</span>, <span class="hljs-number">768</span>],<br>        token_mixers=SepConv,<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;convformer_b36_384&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convformer_b36_in21ft1k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">512</span>, <span class="hljs-number">768</span>],<br>        token_mixers=SepConv,<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;convformer_b36_in21ft1k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convformer_b36_384_in21ft1k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">512</span>, <span class="hljs-number">768</span>],<br>        token_mixers=SepConv,<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;convformer_b36_384_in21ft1k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">convformer_b36_in21k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">512</span>, <span class="hljs-number">768</span>],<br>        token_mixers=SepConv,<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;convformer_b36_in21k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">caformer_s18</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">9</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=[SepConv, SepConv, Attention, Attention],<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;caformer_s18&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">caformer_s18_384</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">9</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=[SepConv, SepConv, Attention, Attention],<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;caformer_s18_384&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">caformer_s18_in21ft1k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">9</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=[SepConv, SepConv, Attention, Attention],<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;caformer_s18_in21ft1k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">caformer_s18_384_in21ft1k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">9</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=[SepConv, SepConv, Attention, Attention],<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;caformer_s18_384_in21ft1k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">caformer_s18_in21k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">9</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=[SepConv, SepConv, Attention, Attention],<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;caformer_s18_in21k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">caformer_s36</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=[SepConv, SepConv, Attention, Attention],<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;caformer_s36&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">caformer_s36_384</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=[SepConv, SepConv, Attention, Attention],<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;caformer_s36_384&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">caformer_s36_in21ft1k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=[SepConv, SepConv, Attention, Attention],<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;caformer_s36_in21ft1k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">caformer_s36_384_in21ft1k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=[SepConv, SepConv, Attention, Attention],<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;caformer_s36_384_in21ft1k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">caformer_s36_in21k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],<br>        token_mixers=[SepConv, SepConv, Attention, Attention],<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;caformer_s36_in21k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">caformer_m36</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">576</span>],<br>        token_mixers=[SepConv, SepConv, Attention, Attention],<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;caformer_m36&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">caformer_m36_384</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">576</span>],<br>        token_mixers=[SepConv, SepConv, Attention, Attention],<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;caformer_m36_384&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">caformer_m36_in21ft1k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">576</span>],<br>        token_mixers=[SepConv, SepConv, Attention, Attention],<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;caformer_m36_in21ft1k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">caformer_m36_384_in21ft1k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">576</span>],<br>        token_mixers=[SepConv, SepConv, Attention, Attention],<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;caformer_m36_384_in21ft1k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">caformer_m364_in21k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">576</span>],<br>        token_mixers=[SepConv, SepConv, Attention, Attention],<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;caformer_m364_in21k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">caformer_b36</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">512</span>, <span class="hljs-number">768</span>],<br>        token_mixers=[SepConv, SepConv, Attention, Attention],<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;caformer_b36&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">caformer_b36_384</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">512</span>, <span class="hljs-number">768</span>],<br>        token_mixers=[SepConv, SepConv, Attention, Attention],<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;caformer_b36_384&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">caformer_b36_in21ft1k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">512</span>, <span class="hljs-number">768</span>],<br>        token_mixers=[SepConv, SepConv, Attention, Attention],<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;caformer_b36_in21ft1k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">caformer_b36_384_in21ft1k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">512</span>, <span class="hljs-number">768</span>],<br>        token_mixers=[SepConv, SepConv, Attention, Attention],<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;caformer_b36_384_in21ft1k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-meta">@register_model</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">caformer_b36_in21k</span>(<span class="hljs-params">pretrained=<span class="hljs-literal">False</span>, **kwargs</span>):<br>    model = MetaFormer(<br>        depths=[<span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">18</span>, <span class="hljs-number">3</span>],<br>        dims=[<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">512</span>, <span class="hljs-number">768</span>],<br>        token_mixers=[SepConv, SepConv, Attention, Attention],<br>        head_fn=MlpHead,<br>        **kwargs)<br>    model.default_cfg = default_cfgs[<span class="hljs-string">&#x27;caformer_b36_in21k&#x27;</span>]<br>    <span class="hljs-keyword">if</span> pretrained:<br>        state_dict = torch.hub.load_state_dict_from_url(<br>            url= model.default_cfg[<span class="hljs-string">&#x27;url&#x27;</span>], map_location=<span class="hljs-string">&quot;cpu&quot;</span>, check_hash=<span class="hljs-literal">True</span>)<br>        model.load_state_dict(state_dict)<br>    <span class="hljs-keyword">return</span> model<br><br></code></pre></td></tr></table></figure><p>训练代码</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><code class="hljs css">import os<br>import numpy as np<br>import torch<br>import torch<span class="hljs-selector-class">.nn</span> as nn<br>import torch<span class="hljs-selector-class">.optim</span> as optim<br><span class="hljs-selector-tag">from</span> torch<span class="hljs-selector-class">.utils</span><span class="hljs-selector-class">.data</span> import DataLoader<br><span class="hljs-selector-tag">from</span> torchvision import transforms<br><span class="hljs-selector-tag">from</span> tqdm import tqdm<br><span class="hljs-selector-tag">from</span> dataset import EEGDataset, EEGDataset_Batch_normal<br><span class="hljs-selector-tag">from</span> net import IntegratedNet<br><span class="hljs-selector-tag">from</span> sklearn<span class="hljs-selector-class">.metrics</span> import classification_report<br><span class="hljs-selector-tag">from</span> matplotlib import pyplot as plt<br><br># 定义归一化操作<br>def normalize(data):<br>    mean = np.<span class="hljs-built_in">mean</span>(data)<br>    std = np.<span class="hljs-built_in">std</span>(data)<br>    return (data - mean) / std<br><br>transform = transforms.<span class="hljs-built_in">Compose</span>([<br>    transforms.<span class="hljs-built_in">Lambda</span>(normalize),  # 使用Lambda函数应用自定义归一化操作<br>    transforms.<span class="hljs-built_in">ToTensor</span>()<br>])<br><br>def <span class="hljs-built_in">train_identityformer_model</span>(model, model_name, num_epochs=<span class="hljs-number">100</span>, num_classes=<span class="hljs-number">3</span>, batch_size=<span class="hljs-number">16</span>, learning_rate=<span class="hljs-number">0.0001</span>, w_wight=<span class="hljs-number">2560</span>, chennal=<span class="hljs-number">32</span>):<br>    # Checking CUDA availability<br>    if torch.cuda.<span class="hljs-built_in">is_available</span>():<br>        device = torch.<span class="hljs-built_in">device</span>(<span class="hljs-string">&quot;cuda&quot;</span>)<br>    else:<br>        device = torch.<span class="hljs-built_in">device</span>(<span class="hljs-string">&quot;cpu&quot;</span>)<br>    m = nn.<span class="hljs-built_in">Softmax</span>(dim=<span class="hljs-number">1</span>)  # 只对样本的维度做softmax<br>    # Creating datasets and data loaders<br>    train_dataset = <span class="hljs-built_in">EEGDataset</span>(csv_file=<span class="hljs-string">&#x27;train_data.csv&#x27;</span>, transform=transform)<br>    test_dataset = <span class="hljs-built_in">EEGDataset</span>(csv_file=<span class="hljs-string">&#x27;test_data.csv&#x27;</span>, transform=transform)<br><br>    train_loader = <span class="hljs-built_in">DataLoader</span>(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)<br>    test_loader = <span class="hljs-built_in">DataLoader</span>(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)<br><br>    model.<span class="hljs-built_in">to</span>(device)<br>    loss_fn = nn.<span class="hljs-built_in">CrossEntropyLoss</span>()<br>    optimizer = optim.<span class="hljs-built_in">RMSprop</span>(model.<span class="hljs-built_in">parameters</span>(), lr=learning_rate)<br><br>    save_dir = os.path.<span class="hljs-built_in">join</span>(<span class="hljs-string">&#x27;model&#x27;</span>, model_name)<br>    os.<span class="hljs-built_in">makedirs</span>(save_dir, exist_ok=True)<br><br>    best_val_acc = <span class="hljs-number">0</span><br>    best_model_path = os.path.<span class="hljs-built_in">join</span>(save_dir, <span class="hljs-string">&quot;&#123;&#125;_best_model.pth&quot;</span>.<span class="hljs-built_in">format</span>(model_name))<br><br>    # 训练<br>    train_loss_arr = []<br>    train_acc_arr = []<br>    val_loss_arr = []<br>    val_acc_arr = []<br><br>    for epoch in <span class="hljs-built_in">range</span>(num_epochs):<br>        train_loss_total = <span class="hljs-number">0</span>  # 所有batch的loss累加值<br>        train_acc_total = <span class="hljs-number">0</span>   # 所有batch的acc累加值`<br>        val_loss_total = <span class="hljs-number">0</span><br>        val_acc_total = <span class="hljs-number">0</span><br><br>        model.<span class="hljs-built_in">train</span>()    # 标志模型的模式是什么，因为dropout只在训练时启用<br>        for i, (train_x, train_y) in <span class="hljs-built_in">enumerate</span>(<span class="hljs-built_in">tqdm</span>(train_loader, desc=f<span class="hljs-string">&quot;Epoch &#123;epoch+1&#125;/&#123;num_epochs&#125;&quot;</span>)):<br>            train_x = train_x.<span class="hljs-built_in">to</span>(device)<br>            train_y = train_y.<span class="hljs-built_in">to</span>(device)<br>            train_x = train_x.<span class="hljs-built_in">unsqueeze</span>(<span class="hljs-number">1</span>)<br>            train_x = train_x.<span class="hljs-built_in">view</span>(batch_size, <span class="hljs-number">1</span>, chennal, w_wight)<br>            # 前向传播<br>            train_y_pred = <span class="hljs-built_in">model</span>(train_x)<br>            train_loss = <span class="hljs-built_in">loss_fn</span>(train_y_pred, train_y)<br><br>            # 通过模型每个样本得到<span class="hljs-number">3</span>个实数值（train_y_pred）,通过softmax将实数值转换成概率值，通过max取概率最大的下标，最后用下标和标签做比较<br>            train_acc = (<span class="hljs-built_in">m</span>(train_y_pred).<span class="hljs-built_in">max</span>(dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>] == train_y).<span class="hljs-built_in">sum</span>()/train_y.shape[<span class="hljs-number">0</span>]<br>            train_loss_total += train_loss.data.<span class="hljs-built_in">item</span>()<br>            train_acc_total += train_acc.data.<span class="hljs-built_in">item</span>()<br>            # 反向传播<br>            train_loss.<span class="hljs-built_in">backward</span>()<br>            # 梯度下降<br>            optimizer.<span class="hljs-built_in">step</span>()<br>            optimizer.<span class="hljs-built_in">zero_grad</span>()<br><br>            # <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;epoch:&#123;&#125; train_loss:&#123;&#125; train_acc:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(epoch, train_loss.data.<span class="hljs-built_in">item</span>(), train_acc.data.<span class="hljs-built_in">item</span>()))<br><br>        train_loss_arr.<span class="hljs-built_in">append</span>(train_loss_total / <span class="hljs-built_in">len</span>(train_loader))  # 平均值<br>        train_acc_arr.<span class="hljs-built_in">append</span>(train_acc_total / <span class="hljs-built_in">len</span>(train_loader))<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;epoch:&#123;&#125; train_loss:&#123;&#125; train_acc:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(epoch, train_loss_arr[-<span class="hljs-number">1</span>], train_acc_arr[-<span class="hljs-number">1</span>]))<br>        # 测试集<br>        model.<span class="hljs-built_in">eval</span>()<br>        for j, (val_x, val_y) in <span class="hljs-built_in">enumerate</span>(test_loader):<br>            val_x = val_x.<span class="hljs-built_in">to</span>(device)<br>            val_y = val_y.<span class="hljs-built_in">to</span>(device)<br>            val_x = val_x.<span class="hljs-built_in">unsqueeze</span>(<span class="hljs-number">1</span>)<br>            val_x = val_x.<span class="hljs-built_in">view</span>(batch_size, <span class="hljs-number">1</span>, chennal, w_wight)<br>            # 前向传播<br>            val_y_pred = <span class="hljs-built_in">model</span>(val_x)<br>            val_loss = <span class="hljs-built_in">loss_fn</span>(val_y_pred, val_y)<br>            val_acc = (<span class="hljs-built_in">m</span>(val_y_pred).<span class="hljs-built_in">max</span>(dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>] == val_y).<span class="hljs-built_in">sum</span>()/val_y.shape[<span class="hljs-number">0</span>]<br>            val_loss_total += val_loss.data.<span class="hljs-built_in">item</span>()<br>            val_acc_total += val_acc.data.<span class="hljs-built_in">item</span>()<br><br>        val_loss_arr.<span class="hljs-built_in">append</span>(val_loss_total / <span class="hljs-built_in">len</span>(test_loader)) # 平均值<br>        val_acc_arr.<span class="hljs-built_in">append</span>(val_acc_total / <span class="hljs-built_in">len</span>(test_loader))<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;epoch:&#123;&#125; val_loss:&#123;&#125; val_acc:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(epoch, val_loss_arr[-<span class="hljs-number">1</span>], val_acc_arr[-<span class="hljs-number">1</span>]))<br><br>        # 保存最佳模型<br>        if val_acc_arr[-<span class="hljs-number">1</span>] &gt; best_val_acc:<br>            best_val_acc = val_acc_arr[-<span class="hljs-number">1</span>]<br>            torch.<span class="hljs-built_in">save</span>(model.<span class="hljs-built_in">state_dict</span>(), best_model_path)<br><br>        # 保存训练和验证过程中的loss和acc<br>    np.<span class="hljs-built_in">save</span>(os.path.<span class="hljs-built_in">join</span>(save_dir, f<span class="hljs-string">&quot;&#123;model_name&#125;_train_loss.npy&quot;</span>), np.<span class="hljs-built_in">array</span>(train_loss_arr))<br>    np.<span class="hljs-built_in">save</span>(os.path.<span class="hljs-built_in">join</span>(save_dir, f<span class="hljs-string">&quot;&#123;model_name&#125;_train_acc.npy&quot;</span>), np.<span class="hljs-built_in">array</span>(train_acc_arr))<br>    np.<span class="hljs-built_in">save</span>(os.path.<span class="hljs-built_in">join</span>(save_dir, f<span class="hljs-string">&quot;&#123;model_name&#125;_val_loss.npy&quot;</span>), np.<span class="hljs-built_in">array</span>(val_loss_arr))<br>    np.<span class="hljs-built_in">save</span>(os.path.<span class="hljs-built_in">join</span>(save_dir, f<span class="hljs-string">&quot;&#123;model_name&#125;_val_acc.npy&quot;</span>), np.<span class="hljs-built_in">array</span>(val_acc_arr))<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;保存模型成功!&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Training completed!&#x27;</span>)<br><br></code></pre></td></tr></table></figure><h3 id="运行代码"><a href="#运行代码" class="headerlink" title="运行代码"></a>运行代码</h3><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><code class="hljs scss"><br>import os<br>import numpy as np<br>import torch<br>import torch<span class="hljs-selector-class">.nn</span> as nn<br>import torch<span class="hljs-selector-class">.optim</span> as optim<br>from torch<span class="hljs-selector-class">.utils</span><span class="hljs-selector-class">.data</span> import DataLoader<br>from torchvision import transforms<br>from tqdm import tqdm<br>from dataset import EEGDataset, transform1<br>from net import IntegratedNet<br>from sklearn<span class="hljs-selector-class">.metrics</span> import classification_report<br>from matplotlib import pyplot as plt<br><br><br><br>def <span class="hljs-built_in">train_identityformer_model</span>(model, model_name, num_epochs=<span class="hljs-number">100</span>, num_classes=<span class="hljs-number">3</span>, batch_size=<span class="hljs-number">4</span>, learning_rate=<span class="hljs-number">0.00001</span>, w_wight=<span class="hljs-number">2560</span>, chennal=<span class="hljs-number">32</span>):<br>    # Checking CUDA availability<br>    if torch.cuda.<span class="hljs-built_in">is_available</span>():<br>        device = torch.<span class="hljs-built_in">device</span>(<span class="hljs-string">&quot;cuda&quot;</span>)<br>    else:<br>        device = torch.<span class="hljs-built_in">device</span>(<span class="hljs-string">&quot;cpu&quot;</span>)<br>    m = nn.<span class="hljs-built_in">Softmax</span>(dim=<span class="hljs-number">1</span>)  # 只对样本的维度做softmax<br>    # Creating datasets and data loaders<br>    train_dataset = <span class="hljs-built_in">EEGDataset</span>(csv_file=<span class="hljs-string">&#x27;train_data.csv&#x27;</span>, transform=transform1)<br>    test_dataset = <span class="hljs-built_in">EEGDataset</span>(csv_file=<span class="hljs-string">&#x27;test_data.csv&#x27;</span>, transform=transform1)<br><br>    train_loader = <span class="hljs-built_in">DataLoader</span>(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)<br>    test_loader = <span class="hljs-built_in">DataLoader</span>(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)<br><br>    model.<span class="hljs-built_in">to</span>(device)<br>    loss_fn = nn.<span class="hljs-built_in">CrossEntropyLoss</span>()<br>    optimizer = optim.<span class="hljs-built_in">RMSprop</span>(model.<span class="hljs-built_in">parameters</span>(), lr=learning_rate)<br><br>    save_dir = os.path.<span class="hljs-built_in">join</span>(<span class="hljs-string">&#x27;model&#x27;</span>, model_name)<br>    os.<span class="hljs-built_in">makedirs</span>(save_dir, exist_ok=True)<br><br>    best_val_acc = <span class="hljs-number">0</span><br>    best_model_path = os.path.<span class="hljs-built_in">join</span>(save_dir, <span class="hljs-string">&quot;&#123;&#125;_best_model.pth&quot;</span>.<span class="hljs-built_in">format</span>(model_name))<br><br>    # 训练<br>    train_loss_arr = []<br>    train_acc_arr = []<br>    val_loss_arr = []<br>    val_acc_arr = []<br><br>    for epoch in <span class="hljs-built_in">range</span>(num_epochs):<br>        train_loss_total = <span class="hljs-number">0</span>  # 所有batch的loss累加值<br>        train_acc_total = <span class="hljs-number">0</span>   # 所有batch的acc累加值`<br>        val_loss_total = <span class="hljs-number">0</span><br>        val_acc_total = <span class="hljs-number">0</span><br><br>        model.<span class="hljs-built_in">train</span>()    # 标志模型的模式是什么，因为dropout只在训练时启用<br>        for i, (train_x, train_y) in <span class="hljs-built_in">enumerate</span>(<span class="hljs-built_in">tqdm</span>(train_loader, desc=f<span class="hljs-string">&quot;Epoch &#123;epoch+1&#125;/&#123;num_epochs&#125;&quot;</span>)):<br>            train_x = train_x.<span class="hljs-built_in">to</span>(device)<br>            # <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;train_x&#x27;</span>,train_x.shape)<br>            train_y = train_y.<span class="hljs-built_in">to</span>(device)<br>            train_x = train_x.<span class="hljs-built_in">unsqueeze</span>(<span class="hljs-number">1</span>)<br>            train_x = train_x.<span class="hljs-built_in">view</span>(batch_size, <span class="hljs-number">5</span>, chennal, w_wight)<br>            # 前向传播<br>            train_y_pred = <span class="hljs-built_in">model</span>(train_x)<br>            train_loss = <span class="hljs-built_in">loss_fn</span>(train_y_pred, train_y)<br><br>            # 通过模型每个样本得到<span class="hljs-number">4</span>个实数值（train_y_pred）,通过softmax将实数值转换成概率值，通过max取概率最大的下标，最后用下标和标签做比较<br>            train_acc = (<span class="hljs-built_in">m</span>(train_y_pred).<span class="hljs-built_in">max</span>(dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>] == train_y).<span class="hljs-built_in">sum</span>()/train_y.shape[<span class="hljs-number">0</span>]<br>            train_loss_total += train_loss.data.<span class="hljs-built_in">item</span>()<br>            train_acc_total += train_acc.data.<span class="hljs-built_in">item</span>()<br>            # 反向传播<br>            train_loss.<span class="hljs-built_in">backward</span>()<br>            # 梯度下降<br>            optimizer.<span class="hljs-built_in">step</span>()<br>            optimizer.<span class="hljs-built_in">zero_grad</span>()<br><br>            # <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;epoch:&#123;&#125; train_loss:&#123;&#125; train_acc:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(epoch, train_loss.data.<span class="hljs-built_in">item</span>(), train_acc.data.<span class="hljs-built_in">item</span>()))<br><br>        train_loss_arr.<span class="hljs-built_in">append</span>(train_loss_total / <span class="hljs-built_in">len</span>(train_loader))  # 平均值<br>        train_acc_arr.<span class="hljs-built_in">append</span>(train_acc_total / <span class="hljs-built_in">len</span>(train_loader))<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;epoch:&#123;&#125; train_loss:&#123;&#125; train_acc:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(epoch, train_loss_arr[-<span class="hljs-number">1</span>], train_acc_arr[-<span class="hljs-number">1</span>]))<br>        # 测试集<br>        model.<span class="hljs-built_in">eval</span>()<br>        for j, (val_x, val_y) in <span class="hljs-built_in">enumerate</span>(test_loader):<br>            val_x = val_x.<span class="hljs-built_in">to</span>(device)<br>            val_y = val_y.<span class="hljs-built_in">to</span>(device)<br>            val_x = val_x.<span class="hljs-built_in">unsqueeze</span>(<span class="hljs-number">1</span>)<br>            val_x = val_x.<span class="hljs-built_in">view</span>(batch_size, <span class="hljs-number">5</span>, chennal, w_wight)<br>            # 前向传播<br>            val_y_pred = <span class="hljs-built_in">model</span>(val_x)<br>            val_loss = <span class="hljs-built_in">loss_fn</span>(val_y_pred, val_y)<br>            val_acc = (<span class="hljs-built_in">m</span>(val_y_pred).<span class="hljs-built_in">max</span>(dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>] == val_y).<span class="hljs-built_in">sum</span>()/val_y.shape[<span class="hljs-number">0</span>]<br>            val_loss_total += val_loss.data.<span class="hljs-built_in">item</span>()<br>            val_acc_total += val_acc.data.<span class="hljs-built_in">item</span>()<br><br>        val_loss_arr.<span class="hljs-built_in">append</span>(val_loss_total / <span class="hljs-built_in">len</span>(test_loader)) # 平均值<br>        val_acc_arr.<span class="hljs-built_in">append</span>(val_acc_total / <span class="hljs-built_in">len</span>(test_loader))<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;epoch:&#123;&#125; val_loss:&#123;&#125; val_acc:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(epoch, val_loss_arr[-<span class="hljs-number">1</span>], val_acc_arr[-<span class="hljs-number">1</span>]))<br><br>        # 保存最佳模型<br>        if val_acc_arr[-<span class="hljs-number">1</span>] &gt; best_val_acc:<br>            best_val_acc = val_acc_arr[-<span class="hljs-number">1</span>]<br>            torch.<span class="hljs-built_in">save</span>(model.<span class="hljs-built_in">state_dict</span>(), best_model_path)<br><br>        # 保存训练和验证过程中的loss和acc<br>    np.<span class="hljs-built_in">save</span>(os.path.<span class="hljs-built_in">join</span>(save_dir, f<span class="hljs-string">&quot;&#123;model_name&#125;_train_loss.npy&quot;</span>), np.<span class="hljs-built_in">array</span>(train_loss_arr))<br>    np.<span class="hljs-built_in">save</span>(os.path.<span class="hljs-built_in">join</span>(save_dir, f<span class="hljs-string">&quot;&#123;model_name&#125;_train_acc.npy&quot;</span>), np.<span class="hljs-built_in">array</span>(train_acc_arr))<br>    np.<span class="hljs-built_in">save</span>(os.path.<span class="hljs-built_in">join</span>(save_dir, f<span class="hljs-string">&quot;&#123;model_name&#125;_val_loss.npy&quot;</span>), np.<span class="hljs-built_in">array</span>(val_loss_arr))<br>    np.<span class="hljs-built_in">save</span>(os.path.<span class="hljs-built_in">join</span>(save_dir, f<span class="hljs-string">&quot;&#123;model_name&#125;_val_acc.npy&quot;</span>), np.<span class="hljs-built_in">array</span>(val_acc_arr))<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;保存模型成功!&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Training completed!&#x27;</span>)<br><br># 创建模型并训练<br>model = <span class="hljs-built_in">IntegratedNet</span>(input_size=<span class="hljs-number">5</span>,in_feature=<span class="hljs-number">29</span>)  # 确保模型的输出层适用于三分类问题<br><span class="hljs-built_in">train_identityformer_model</span>(model, model_name=<span class="hljs-string">&#x27;MLPFormer_betch_16_fft_opendata&#x27;</span>,chennal=<span class="hljs-number">19</span>,w_wight=<span class="hljs-number">453</span>)<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔14</title>
    <link href="/2024/05/01/ganwu14/"/>
    <url>/2024/05/01/ganwu14/</url>
    
    <content type="html"><![CDATA[<h2 id="内心的想法"><a href="#内心的想法" class="headerlink" title="内心的想法"></a>内心的想法</h2><p>清空掉头脑中的思想，没有欲望，感受着时间的流动，像是生命在流动。没有感情的波动，一切都刚刚好。发自内心中的喜悦，获得了片刻的自由。<br>人啊人啊，什么禁锢了我，心中的牢笼束缚了自己内心的想法。欲望来源于什么，物质禁锢了身体，外在便不再自由。<br>我该怎么突破这内心和外在的牢笼，去感受那片刻、短暂的喜悦。<br>心啊心啊，为何要自我束缚，物啊物啊，将我带入了沉沦。<br>外在的法则和心中的法则并不相通，我连接了内心和外在。<br>时间啊，你在不断的消逝，也在不断的增加。<br>新生和死亡，未来和过去，或许只有现在最重要。<br>牢笼将我们禁锢，死亡为我指引方向，感受提出了方法。<br>去感受悲伤，感受快乐，感受情绪，感受内心。去感受风，感受雨，感受这个世界。<br>累了就休息，困了就睡觉。生活就是如此简单。<br>活出自己想要的人生，只有自己才知道自己的价值。</p>]]></content>
    
    
    
    <tags>
      
      <tag>感悟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>填坑——强化学习——使用智能体来玩游戏</title>
    <link href="/2024/04/30/tiankeng6/"/>
    <url>/2024/04/30/tiankeng6/</url>
    
    <content type="html"><![CDATA[<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://github.com/markub3327/flappy-bird-gymnasium">flappy-bird-gymnasium环境</a><br><a href="https://gymnasium.farama.org/">Gymnasim官网</a><br><a href="https://github.com/luozhiyun993/FlappyBird-PPO-pytorch">github上的代码</a><br><a href="https://hrl.boyuai.com/chapter/">动手强化学习</a><br><a href="https://github.com/jalaxy33/learn-lr">动手强化学习代码</a><br><a href="https://github.com/alexzhuustc/gym-flappybird">tensorflow实现的强化学习</a><br><a href="https://github.com/alexzhuustc/gym-flappybird">tensorflow+gym实现的flyappybird</a><br><a href="https://stackoverflow.com/questions/69442971/error-in-importing-environment-openai-gym">问答网站</a></p><h2 id="开篇"><a href="#开篇" class="headerlink" title="开篇"></a>开篇</h2><p>（广义的讲）强化学习是机器通过与环境交互来实现目标的一种计算方法。机器和环境的一轮交互是指，机器在环境的一个状态下做一个动作决策，把这个动作作用到环境当中，这个环境发生相应的改变并且将相应的奖励反馈和下一轮状态传回机器。这种交互是迭代进行的，机器的目标是最大化在多轮交互过程中获得的累积奖励的期望。强化学习用智能体（agent）这个概念来表示做决策的机器。相比于有监督学习中的“模型”，强化学习中的“智能体”强调机器不但可以感知周围的环境信息，还可以通过做决策来直接改变这个环境，而不只是给出一些预测信号。<br>在每一轮交互中，智能体感知到环境目前所处的状态，经过自身的计算给出本轮的动作，将其作用到环境中；环境得到智能体的动作后，产生相应的即时奖励信号并发生相应的状态转移。智能体则在下一轮交互中感知到新的环境状态，依次类推。<br>在这个过程中，智能体有3种控制要素、即感知、决策和奖励<br>感知：智能体在某种程度上感知环境的状态，从而知道自己所处的现状。<br>决策： 智能体根据感知的现状计算出达到目标需要采取的动作的过程叫做决策。比如，针对当前棋盘决定下一颗落子的位置。<br>奖励： 环境根据状态和智能体采取的动作，产生一个标量信号作为奖励反馈。这个标量信号衡量智能体的好坏。（类似于在深度学习中的损失函数，）<br>强化学习中模型和环境交互，对于模型的目的来讲，就是从环境中取得最大的奖励值，主要在于策略的更新方法。<br>参数更新方法：价值更新、梯度更新。输出的值，连续的值，离散的值。</p><p>强化学习的构成元素：</p><ol><li>智能体（Agent）： 人工智能操作的游戏角色，它就是这个游戏的主要玩家。</li><li>环境（Environment） ： 提供游玩的条件，agent做出的任何选择都会得到游戏环境的反馈。</li><li>状态（State）： 游戏汉奸内所有元素所处的状态，基于环境来进行反馈。</li><li>行动（action）: agent做出的行为来随着状态变化而变化。</li><li>奖励（Reward）： agent的目标在于获取更高的奖励，根据环境的反馈，如果反馈是负向的也可以被描述为惩罚。</li><li>目标（Goal）： 在合理设置奖励后，目标应该被表示为最大化奖励之和。<br>整个强化学习的过程，是为了学到好的策略（Policy）,本质上就是学习在某个状态下应该采取什么样的行动。</li></ol><p>目前已经有的算法; </p><h2 id="游戏选择-FlappyBird"><a href="#游戏选择-FlappyBird" class="headerlink" title="游戏选择 FlappyBird"></a>游戏选择 FlappyBird</h2><p>flappy bird》是一款由来自越南的独立游戏开发者Dong Nguyen所开发的作品，游戏于2013年5月24日上线，并在2014年2月突然暴红。2014年2月，《Flappy Bird》被开发者本人从苹果及谷歌应用商店（Google Play）撤下。2014年8月份正式回归App Store，正式加入Flappy迷们期待已久的多人对战模式。游戏中玩家必须控制一只小鸟，跨越由各种不同长度水管所组成的障碍。</p><h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><ol><li>使用miniconda 配置环境，命令<code>conda create -n rl_python python=3.10</code>，配置环境，如果配置错误使用<code>conda remove rl_python --all </code>来删除环境，使用<code>conda activate rl_python</code>来启动环境。</li><li>配置游戏环境，使用<code>pip install flappy-bird-gymnasium</code>安装游戏</li><li>安装tersorflow深度学习框架<a href="https://tensorflow.google.cn/install/gpu?hl=zh-cn">官网连接</a></li><li>安装pytorch-GPU环境 <a href="https://pytorch.org/get-started/previous-versions/">官网链接</a> 通过 nvcc –version 来查看CUDA版本。安装10.2版本的pytorch<code>pip install torch==1.12.1+cu102 torchvision==0.13.1+cu102 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu102</code> python 的3.10不兼容，换11.8的pytorch版本<code>pip install torch==2.2.1 torchvision==0.17.1 torchaudio==2.2.1 --index-url https://download.pytorch.org/whl/cu118</code></li></ol><h2 id="ppo算法"><a href="#ppo算法" class="headerlink" title="ppo算法"></a>ppo算法</h2><p>PPO（Proximal Policy Optimization）近端策略优化算法，是一种基于策略（policy-based）的强化学习算法，是一种off-policy算法。由OpenAI于2017年提出，主要用于解决强化学习中的策略优化问题。它是Trust Region Policy Optimization（TRPO）的简化版本，旨在保持TRPO的优点，同时降低其计算复杂性。<br>核心原理：PPO的核心在于限制策略更新的步长，确保新策略不会偏离旧策略太远。这通过引入一个剪辑的目标函数来实现，该函数可以最小化策略更新过程中的风险。PPO算法通过这种方式平衡了探索与利用，提高了算法的稳定性和效率。PPO算法的核心在于更新策略梯度，主流方法有两种，分别是KL散度做penalty，另一种是Clip剪裁，它们的主要作用都是限制策略梯度更新的幅度，从而推导出不同的神经网络参数更新方式</p><h2 id="代码解析工程"><a href="#代码解析工程" class="headerlink" title="代码解析工程"></a>代码解析工程</h2><p>下面这份代码实现了使用ppo算法训练模型来玩Flappy Bird游戏。<br>get_args()函数用于解析命令行参数，包括学习率、折扣因子、迭代次数等。<br>PolicyNet类定义了策略网络，用于输出动作的概率分布。<br>ValueNet类定义了值函数网络，用于评估状态的价值。<br>compute_advantage()函数计算优势值，用于策略更新。<br>train()函数是训练的主要逻辑，包括初始化网络和优化器，采样游戏轨迹，计算优势值，更新策略网络和值函数网络等过程。<br>在训练过程中，使用TensorBoard记录训练过程中的奖励和其他指标。<br>在每轮训练结束后，保存表现最好的模型。<br>if <strong>name</strong> &#x3D;&#x3D; “<strong>main</strong>“:部分用于执行整个训练过程。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">import</span> argparse <span class="hljs-comment"># 用于解析命令行参数，方便地从命令行中读取参数值</span><br><span class="hljs-keyword">import</span> os <br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span>   BatchSampler, SubsetRandomSampler <span class="hljs-comment"># BatchSampler 用于批次采样，subsetRandomSampler用于随机采样子集</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn <br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter <span class="hljs-comment"># 提供了与TensorBoard集成的功能，用于可视化训练过程和结果。</span><br><br><span class="hljs-keyword">from</span> src.flappy_bird <span class="hljs-keyword">import</span> FlappyBird <br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_args</span>():<br>    <span class="hljs-comment"># 该函数用于解析命令行参数，包括学习率、折扣因子、迭代次数</span><br>    parser = argparse.ArgumentParser(<br>        <span class="hljs-string">&quot;&quot;&quot;Implementation of PPO to play Flappy Bird&quot;&quot;&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--lr&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">1e-5</span>) <span class="hljs-comment"># 学习率</span><br>    parser.add_argument(<span class="hljs-string">&quot;--gamma&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">0.99</span>) <span class="hljs-comment"># 折扣因子</span><br>    parser.add_argument(<span class="hljs-string">&quot;--num_iters&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">20000</span>) <span class="hljs-comment"># 迭代次数</span><br>    parser.add_argument(<span class="hljs-string">&quot;--log_path&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&quot;tensorboard_ppo&quot;</span>) <span class="hljs-comment"># 保存日志</span><br>    parser.add_argument(<span class="hljs-string">&quot;--saved_path&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&quot;trained_models&quot;</span>) <span class="hljs-comment"># 模型保存路径</span><br>    parser.add_argument(<span class="hljs-string">&quot;--lmbda&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">0.95</span>) <span class="hljs-comment"># lmbda 参数</span><br>    parser.add_argument(<span class="hljs-string">&quot;--epochs&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">10</span>) <span class="hljs-comment"># 训练轮数</span><br>    parser.add_argument(<span class="hljs-string">&quot;--eps&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">0.2</span>) <span class="hljs-comment"># eps ppo算法中的参数，默认值为0.2</span><br>    parser.add_argument(<span class="hljs-string">&quot;--batch_size&quot;</span>,<span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">2048</span> ) <span class="hljs-comment"># 批处理大小，默认值为2048</span><br>    parser.add_argument(<span class="hljs-string">&quot;--mini_batch_size&quot;</span>,<span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">64</span> ) <span class="hljs-comment"># 小批量大小</span><br><br>    args = parser.parse_args()<br>    <span class="hljs-keyword">return</span> args<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PolicyNet</span>(nn.Module):<br>    <span class="hljs-comment"># 定义策略网络，用于输出动作的概率分布，表演者。</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(PolicyNet, self).__init__()<br>        self.conv1 = nn.Sequential(nn.Conv2d(<span class="hljs-number">4</span>, <span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">8</span>, stride=<span class="hljs-number">4</span>), nn.ReLU())<br>        self.conv2 = nn.Sequential(nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">4</span>, stride=<span class="hljs-number">2</span>), nn.ReLU())<br>        self.conv3 = nn.Sequential(nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>), nn.ReLU())<br>        self.flat = nn.Flatten()<br>        self.fc1 = nn.Sequential(nn.Linear(<span class="hljs-number">7</span> * <span class="hljs-number">7</span> * <span class="hljs-number">64</span>, <span class="hljs-number">512</span>), nn.Tanh())<br>        self.drop = nn.Dropout(<span class="hljs-number">0.5</span>)<br>        self.fc3 = nn.Sequential(nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">2</span>))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        <span class="hljs-comment"># 前向传播</span><br>        output = self.conv1(<span class="hljs-built_in">input</span>)<br>        output = self.conv2(output)<br>        output = self.conv3(output)<br>        output = self.flat(output)<br>        output = self.drop(output)<br>        output = self.fc1(output)<br>        <span class="hljs-keyword">return</span> nn.functional.softmax(self.fc3(output), dim=<span class="hljs-number">1</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ValueNet</span>(nn.Module):<br>    <span class="hljs-comment"># 定义值函数网络，用于评估状态的价值，评论家</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(ValueNet, self).__init__()<br>        self.net = nn.Sequential(<br>            nn.Conv2d(<span class="hljs-number">4</span>, <span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">8</span>, stride=<span class="hljs-number">4</span>), nn.ReLU(),<br>            nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">4</span>, stride=<span class="hljs-number">2</span>), nn.ReLU(),<br>            nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>), nn.ReLU(),<br>            nn.Flatten(),<br>            nn.Linear(<span class="hljs-number">7</span> * <span class="hljs-number">7</span> * <span class="hljs-number">64</span>, <span class="hljs-number">512</span>), nn.Tanh(),<br>            nn.Dropout(<span class="hljs-number">0.5</span>),<br>            nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">1</span>),<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        <span class="hljs-keyword">return</span> self.net(<span class="hljs-built_in">input</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_advantage</span>(<span class="hljs-params">gamma, lmbda, td_delta</span>):<br>    <span class="hljs-comment"># 函数计算优势值，用于策略更新</span><br>    td_delta = td_delta.detach().numpy()<br>    advantage_list = []<br>    advantage = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">for</span> delta <span class="hljs-keyword">in</span> td_delta[::-<span class="hljs-number">1</span>]:<br>        advantage = gamma * lmbda * advantage + delta<br>        advantage_list.append(advantage)<br>    advantage_list.reverse()<br>    <span class="hljs-keyword">return</span> torch.tensor(advantage_list, dtype=torch.<span class="hljs-built_in">float</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">opt</span>):<br>    <span class="hljs-comment"># 训练的主要逻辑，包括初始化网络和优化器，采样游戏轨迹，计算优势值，更新策略网络和值函数网络等过程。</span><br>    <span class="hljs-keyword">if</span> torch.cuda.is_available(): <span class="hljs-comment"># 检查CUDA是否可以使用，</span><br>        torch.cuda.manual_seed(<span class="hljs-number">1993</span>) <span class="hljs-comment"># 设计随机种子，确保实验的可用性。</span><br>    <span class="hljs-keyword">else</span>:<br>        torch.manual_seed(<span class="hljs-number">123</span>)<br><br>    actor = PolicyNet().cuda() <span class="hljs-comment"># 初始化策略函数，演员</span><br>    critic = ValueNet().cuda() <span class="hljs-comment"># 初始化值函数，评论家</span><br><br>    actor_optimizer = torch.optim.Adam(actor.parameters(), lr=opt.lr) <span class="hljs-comment"># 定义策略函数网络的优化器器</span><br>    critic_optimizer = torch.optim.Adam(critic.parameters(), lr=opt.lr) <span class="hljs-comment"># 定义值函数网络的优化器</span><br><br><br>    writer = SummaryWriter(opt.log_path) <span class="hljs-comment"># 创建一个TensorBoard的SummaryWriter对象，用于记录训练过程中的指标</span><br>    game_state = FlappyBird(<span class="hljs-string">&quot;ppo&quot;</span>) <span class="hljs-comment"># </span><br>    state, reward, terminal = game_state.step(<span class="hljs-number">0</span>)<br>    max_reward = <span class="hljs-number">0</span><br>    <span class="hljs-built_in">iter</span> = <span class="hljs-number">0</span><br>    replay_memory = [] <span class="hljs-comment"># 初始化回放内存，用于存储游戏轨迹</span><br>    evaluate_num = <span class="hljs-number">0</span>  <span class="hljs-comment"># Record the number of evaluations</span><br>    evaluate_rewards = [] <span class="hljs-comment"># 初始化评估次数和评估列表，</span><br>    <span class="hljs-keyword">while</span> <span class="hljs-built_in">iter</span> &lt; opt.num_iters:<br>        terminal = <span class="hljs-literal">False</span><br>        episode_return = <span class="hljs-number">0.0</span><br><br>        <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> terminal:<br>            prediction = actor(state)<br>            <span class="hljs-built_in">print</span>(prediction)<br>            action_dist = torch.distributions.Categorical(prediction)<br>            action_sample = action_dist.sample()<br>            action = action_sample.item()<br>            next_state, reward, terminal = game_state.step(action) <span class="hljs-comment"># 执行游戏环境的一步，获取下一个状态、奖励和终止状态。</span><br>            replay_memory.append([state, action, reward, next_state, terminal])<br>            state = next_state<br>            episode_return += reward<br><br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(replay_memory) &gt; opt.batch_size:<br>                state_batch, action_batch, reward_batch, next_state_batch, terminal_batch = <span class="hljs-built_in">zip</span>(*replay_memory)<br>                states = torch.cat(state_batch, dim=<span class="hljs-number">0</span>).cuda()<br>                actions = torch.tensor(action_batch).view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>).cuda()<br>                rewards = torch.tensor(reward_batch).view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>).cuda()<br>                dones = torch.tensor(terminal_batch).view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>).<span class="hljs-built_in">int</span>().cuda()<br>                next_states = torch.cat(next_state_batch, dim=<span class="hljs-number">0</span>).cuda()<br><br>                <span class="hljs-keyword">with</span> torch.no_grad():<br>                    td_target = rewards + opt.gamma * critic(next_states) * (<span class="hljs-number">1</span> - dones)<br>                    td_delta = td_target - critic(states)<br>                    advantage = compute_advantage(opt.gamma, opt.lmbda, td_delta.cpu()).cuda()<br>                    old_log_probs = torch.log(actor(states).gather(<span class="hljs-number">1</span>, actions)).detach()<br><br>                <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(opt.epochs):<br>                    <span class="hljs-keyword">for</span> index <span class="hljs-keyword">in</span> BatchSampler(SubsetRandomSampler(<span class="hljs-built_in">range</span>(opt.batch_size)), opt.mini_batch_size, <span class="hljs-literal">False</span>):<br>                        log_probs = torch.log(actor(states[index]).gather(<span class="hljs-number">1</span>, actions[index]))<br>                        ratio = torch.exp(log_probs - old_log_probs[index])<br>                        surr1 = ratio * advantage[index]<br>                        surr2 = torch.clamp(ratio, <span class="hljs-number">1</span> - opt.eps, <span class="hljs-number">1</span> + opt.eps) * advantage[index]  <span class="hljs-comment"># 截断</span><br>                        actor_loss = torch.mean(-torch.<span class="hljs-built_in">min</span>(surr1, surr2))<br>                        critic_loss = torch.mean(<br>                            nn.functional.mse_loss(critic(states[index]), td_target[index].detach()))<br>                        actor_optimizer.zero_grad()<br>                        critic_optimizer.zero_grad()<br>                        actor_loss.backward()<br>                        critic_loss.backward()<br>                        actor_optimizer.step()<br>                        critic_optimizer.step()<br>                replay_memory = []<br><br>        <span class="hljs-keyword">if</span> episode_return &gt; max_reward:<br>            max_reward = episode_return<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot; max_reward Iteration: &#123;&#125;/&#123;&#125;, Reward: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">iter</span> + <span class="hljs-number">1</span>, opt.num_iters, episode_return))<br><br>        <span class="hljs-built_in">iter</span> += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">iter</span>+<span class="hljs-number">1</span>) % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>            evaluate_num += <span class="hljs-number">1</span><br>            evaluate_rewards.append(episode_return)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;evaluate_num:&#123;&#125; \t episode_return:&#123;&#125; \t&quot;</span>.<span class="hljs-built_in">format</span>(evaluate_num, episode_return))<br>            writer.add_scalar(<span class="hljs-string">&#x27;step_rewards&#x27;</span>, evaluate_rewards[-<span class="hljs-number">1</span>], global_step= <span class="hljs-built_in">iter</span>)<br>        <span class="hljs-keyword">if</span> (<span class="hljs-built_in">iter</span>+<span class="hljs-number">1</span>) % <span class="hljs-number">1000</span> == <span class="hljs-number">0</span>:<br>            actor_dict = &#123;<span class="hljs-string">&quot;net&quot;</span>: actor.state_dict(), <span class="hljs-string">&quot;optimizer&quot;</span>: actor_optimizer.state_dict()&#125;<br>            critic_dict = &#123;<span class="hljs-string">&quot;net&quot;</span>: critic.state_dict(), <span class="hljs-string">&quot;optimizer&quot;</span>: critic_optimizer.state_dict()&#125;<br>            torch.save(actor_dict, <span class="hljs-string">&quot;&#123;&#125;/flappy_bird_actor_good&quot;</span>.<span class="hljs-built_in">format</span>(opt.saved_path))<br>            torch.save(critic_dict, <span class="hljs-string">&quot;&#123;&#125;/flappy_bird_critic_good&quot;</span>.<span class="hljs-built_in">format</span>(opt.saved_path))<br><br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    opt = get_args()<br>    train(opt)<br><br><br></code></pre></td></tr></table></figure><p>问题是上面代码使用了自定义的Flappy Bird来实现游戏环境，没有使用flappy-bird-gymnasium环境来创建游戏环境，具有一定的参考意义。注： 代码暂时不能移植到Flappy Bird，上我需要解析上面的代码的逻辑。</p><h3 id="移植工程。"><a href="#移植工程。" class="headerlink" title="移植工程。"></a>移植工程。</h3><h4 id="第一步，明白怎么调用flappy-Bird环境"><a href="#第一步，明白怎么调用flappy-Bird环境" class="headerlink" title="第一步，明白怎么调用flappy_Bird环境"></a>第一步，明白怎么调用flappy_Bird环境</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> flappy_bird_gymnasium<br><span class="hljs-keyword">import</span> gymnasium <span class="hljs-keyword">as</span> gym<br>env = gym.make(<span class="hljs-string">&quot;FlappyBird-v0&quot;</span>, render_mode=<span class="hljs-string">&quot;human&quot;</span>, use_lidar=<span class="hljs-literal">True</span>)<br><br>obs, _ = env.reset() <span class="hljs-comment">#  reset() 用于重置环境并返回初始观测值</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>):<br>    <span class="hljs-comment"># Next action:</span><br>    <span class="hljs-comment"># (feed the observation to your agent here)</span><br>    action = env.action_space.sample() <br>    <span class="hljs-built_in">print</span>(action)<br>    <span class="hljs-comment"># Processing:</span><br>    obs, reward, terminated, _, info = env.step(action)<br>    <span class="hljs-comment"># obs: 这是一个变量，用于存储执行动作后的观测值（observation）。在强化学习中，代理根据观测值来决定下一步的动作。</span><br>    <span class="hljs-comment"># reward: 这是一个变量，用于存储执行动作后获得的奖励值（reward）。奖励值表示环境对代理执行动作的评价，可以是正数、负数或零。</span><br>    <span class="hljs-comment"># terminated: 这是一个布尔变量，用于表示游戏是否结束（terminated）。如果游戏结束，则该变量为 True；否则为 False。</span><br>    <span class="hljs-comment"># _: 下划线是一个通用的占位符，通常用于表示我们不关心的变量。在这里，它被用作占位符，因为 env.step(action) 返回的是一个元组，我们只关心其中的前三个元素（obs、reward 和 terminated），而不关心其他的返回值。</span><br>    <span class="hljs-comment"># info: 这是一个字典，用于存储额外的环境信息（info）。这些信息可能包括调试信息、性能指标等，可以帮助我们更好地理解环境的运行情况。</span><br>    <span class="hljs-built_in">print</span>(env.step(action))<br>    <span class="hljs-comment"># Checking if the player is still alive</span><br>    <span class="hljs-keyword">if</span> terminated:<br>        <span class="hljs-keyword">break</span><br><br>env.close()<br></code></pre></td></tr></table></figure><p>在github上，作者表明 在论文中有更详细的参考：<a href="https://www.mdpi.com/1424-8220/24/6/1905">论文链接</a></p><ol><li>状态空间：<br>在”FlappyBird-v0”环境中，提供了代表游戏屏幕的观测数据，这些数据为游戏状态提供了简单的数值信息。</li></ol><p>FlappyBird-v0<br>存在两种观测选项：</p><p>选项一<br>激光雷达传感器的180个读数（论文：使用变压器模型和激光雷达传感器进行运动识别玩Flappy Bird）<br>选项二<br>最后一个管道的水平位置<br>最后一个顶部管道的垂直位置<br>最后一个底部管道的垂直位置<br>下一个管道的水平位置<br>下一个顶部管道的垂直位置<br>下一个底部管道的垂直位置<br>下下一个管道的水平位置<br>下下一个顶部管道的垂直位置<br>下下一个底部管道的垂直位置<br>玩家的垂直位置<br>玩家的垂直速度<br>玩家的旋转</p><ol start="2"><li><p>动作空间：<br>0 - 什么都不做<br>1 - 拍打翅膀</p></li><li><p>奖励：<br>+0.1 - 每帧保持存活状态<br>+1.0 - 成功通过一根管道<br>-1.0 - 死亡<br>−0.5 - 触摸屏幕顶部</p></li></ol><h2 id="第二步，使用一个简单的游戏来实践dqn"><a href="#第二步，使用一个简单的游戏来实践dqn" class="headerlink" title="第二步，使用一个简单的游戏来实践dqn"></a>第二步，使用一个简单的游戏来实践dqn</h2><p>上代码：实践了打砖块的游戏，游戏输入为（4，80，80）图片架构，</p><p>rl_utils代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> collections<br><span class="hljs-keyword">import</span> random<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ReplayBuffer</span>: <span class="hljs-comment"># 记忆池子</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, capacity</span>):<br>        self.buffer = collections.deque(maxlen=capacity) <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">self, state, action, reward, next_state, done</span>): <br>        self.buffer.append((state, action, reward, next_state, done)) <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">sample</span>(<span class="hljs-params">self, batch_size</span>): <br>        transitions = random.sample(self.buffer, batch_size)<br>        state, action, reward, next_state, done = <span class="hljs-built_in">zip</span>(*transitions)<br>        <span class="hljs-keyword">return</span> np.array(state), action, reward, np.array(next_state), done <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">size</span>(<span class="hljs-params">self</span>): <br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.buffer)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">moving_average</span>(<span class="hljs-params">a, window_size</span>):<br>    cumulative_sum = np.cumsum(np.insert(a, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>)) <br>    middle = (cumulative_sum[window_size:] - cumulative_sum[:-window_size]) / window_size<br>    r = np.arange(<span class="hljs-number">1</span>, window_size-<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>    begin = np.cumsum(a[:window_size-<span class="hljs-number">1</span>])[::<span class="hljs-number">2</span>] / r<br>    end = (np.cumsum(a[:-window_size:-<span class="hljs-number">1</span>])[::<span class="hljs-number">2</span>] / r)[::-<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">return</span> np.concatenate((begin, middle, end))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_on_policy_agent</span>(<span class="hljs-params">env, agent, num_episodes</span>):<br>    return_list = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        <span class="hljs-keyword">with</span> tqdm(total=<span class="hljs-built_in">int</span>(num_episodes/<span class="hljs-number">10</span>), desc=<span class="hljs-string">&#x27;Iteration %d&#x27;</span> % i) <span class="hljs-keyword">as</span> pbar:<br>            <span class="hljs-keyword">for</span> i_episode <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(num_episodes/<span class="hljs-number">10</span>)):<br>                episode_return = <span class="hljs-number">0</span><br>                transition_dict = &#123;<span class="hljs-string">&#x27;states&#x27;</span>: [], <span class="hljs-string">&#x27;actions&#x27;</span>: [], <span class="hljs-string">&#x27;next_states&#x27;</span>: [], <span class="hljs-string">&#x27;rewards&#x27;</span>: [], <span class="hljs-string">&#x27;dones&#x27;</span>: []&#125;<br>                state = env.reset()<br>                done = <span class="hljs-literal">False</span><br>                <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> done:<br>                    action = agent.take_action(state)<br>                    next_state, reward, done, _ = env.step(action)<br>                    transition_dict[<span class="hljs-string">&#x27;states&#x27;</span>].append(state)<br>                    transition_dict[<span class="hljs-string">&#x27;actions&#x27;</span>].append(action)<br>                    transition_dict[<span class="hljs-string">&#x27;next_states&#x27;</span>].append(next_state)<br>                    transition_dict[<span class="hljs-string">&#x27;rewards&#x27;</span>].append(reward)<br>                    transition_dict[<span class="hljs-string">&#x27;dones&#x27;</span>].append(done)<br>                    state = next_state<br>                    episode_return += reward<br>                return_list.append(episode_return)<br>                agent.update(transition_dict)<br>                <span class="hljs-keyword">if</span> (i_episode+<span class="hljs-number">1</span>) % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>                    pbar.set_postfix(&#123;<span class="hljs-string">&#x27;episode&#x27;</span>: <span class="hljs-string">&#x27;%d&#x27;</span> % (num_episodes/<span class="hljs-number">10</span> * i + i_episode+<span class="hljs-number">1</span>), <span class="hljs-string">&#x27;return&#x27;</span>: <span class="hljs-string">&#x27;%.3f&#x27;</span> % np.mean(return_list[-<span class="hljs-number">10</span>:])&#125;)<br>                pbar.update(<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> return_list<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_off_policy_agent</span>(<span class="hljs-params">env, agent, num_episodes, replay_buffer, minimal_size, batch_size</span>):<br>    return_list = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        <span class="hljs-keyword">with</span> tqdm(total=<span class="hljs-built_in">int</span>(num_episodes/<span class="hljs-number">10</span>), desc=<span class="hljs-string">&#x27;Iteration %d&#x27;</span> % i) <span class="hljs-keyword">as</span> pbar:<br>            <span class="hljs-keyword">for</span> i_episode <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(num_episodes/<span class="hljs-number">10</span>)):<br>                episode_return = <span class="hljs-number">0</span><br>                state = env.reset()<br>                done = <span class="hljs-literal">False</span><br>                <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> done:<br>                    action = agent.take_action(state)<br>                    next_state, reward, done, _ = env.step(action)<br>                    replay_buffer.add(state, action, reward, next_state, done)<br>                    state = next_state<br>                    episode_return += reward<br>                    <span class="hljs-keyword">if</span> replay_buffer.size() &gt; minimal_size:<br>                        b_s, b_a, b_r, b_ns, b_d = replay_buffer.sample(batch_size)<br>                        transition_dict = &#123;<span class="hljs-string">&#x27;states&#x27;</span>: b_s, <span class="hljs-string">&#x27;actions&#x27;</span>: b_a, <span class="hljs-string">&#x27;next_states&#x27;</span>: b_ns, <span class="hljs-string">&#x27;rewards&#x27;</span>: b_r, <span class="hljs-string">&#x27;dones&#x27;</span>: b_d&#125;<br>                        agent.update(transition_dict)<br>                return_list.append(episode_return)<br>                <span class="hljs-keyword">if</span> (i_episode+<span class="hljs-number">1</span>) % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>                    pbar.set_postfix(&#123;<span class="hljs-string">&#x27;episode&#x27;</span>: <span class="hljs-string">&#x27;%d&#x27;</span> % (num_episodes/<span class="hljs-number">10</span> * i + i_episode+<span class="hljs-number">1</span>), <span class="hljs-string">&#x27;return&#x27;</span>: <span class="hljs-string">&#x27;%.3f&#x27;</span> % np.mean(return_list[-<span class="hljs-number">10</span>:])&#125;)<br>                pbar.update(<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> return_list<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_advantage</span>(<span class="hljs-params">gamma, lmbda, td_delta</span>):<br>    td_delta = td_delta.detach().numpy()<br>    advantage_list = []<br>    advantage = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">for</span> delta <span class="hljs-keyword">in</span> td_delta[::-<span class="hljs-number">1</span>]:<br>        advantage = gamma * lmbda * advantage + delta<br>        advantage_list.append(advantage)<br>    advantage_list.reverse()<br>    <span class="hljs-keyword">return</span> torch.tensor(advantage_list, dtype=torch.<span class="hljs-built_in">float</span>)<br>                <br><br></code></pre></td></tr></table></figure><p>dqn_breakout 文件包括dqn网络的构建，模型的训练<a href="https://gymnasium.farama.org/environments/atari/breakout/">介绍的链接</a>，</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> gymnasium <span class="hljs-keyword">as</span> gym<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> collections<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> rl_utils<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ReplayBuffer</span>:<br>    <span class="hljs-string">&#x27;&#x27;&#x27; 经验回放池 &#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, capacity</span>):<br>        self.buffer = collections.deque(maxlen=capacity)  <span class="hljs-comment"># 队列,先进先出</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">self, state, action, reward, next_state, done</span>):  <span class="hljs-comment"># 将数据加入buffer</span><br>        self.buffer.append((state, action, reward, next_state, done))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">sample</span>(<span class="hljs-params">self, batch_size</span>):  <span class="hljs-comment"># 从buffer中采样数据,数量为batch_size</span><br>        transitions = random.sample(self.buffer, batch_size)<br>        state, action, reward, next_state, done = <span class="hljs-built_in">zip</span>(*transitions)<br>        <span class="hljs-keyword">return</span> np.array(state), action, reward, np.array(next_state), done<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">size</span>(<span class="hljs-params">self</span>):  <span class="hljs-comment"># 目前buffer中数据的数量</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.buffer)<br>    <br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Qnet</span>(torch.nn.Module):<br>    <span class="hljs-string">&#x27;&#x27;&#x27; 加入卷积层的Q网络 &#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, action_dim, in_channels=<span class="hljs-number">4</span></span>):<br>        <span class="hljs-built_in">super</span>(Qnet, self).__init__()<br>        self.conv1 = torch.nn.Conv2d(in_channels, <span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">8</span>, stride=<span class="hljs-number">4</span>) <span class="hljs-comment"># 卷积层，输入</span><br>        self.conv2 = torch.nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">4</span>, stride=<span class="hljs-number">2</span>)<br>        self.conv3 = torch.nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>)<br>        self.fc4 = torch.nn.Linear(<span class="hljs-number">7</span> * <span class="hljs-number">7</span> * <span class="hljs-number">64</span>, <span class="hljs-number">512</span>)<br>        self.head = torch.nn.Linear(<span class="hljs-number">512</span>, action_dim)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = x / <span class="hljs-number">255</span><br>        x = F.relu(self.conv1(x))<br>        x = F.relu(self.conv2(x))<br>        x = F.relu(self.conv3(x))<br>        x = F.relu(self.fc4(x.reshape(x.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)))<br>        <span class="hljs-keyword">return</span> self.head(x)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DQN</span>:<br>    <span class="hljs-string">&#x27;&#x27;&#x27; DQN算法 &#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, action_dim, learning_rate, gamma,</span><br><span class="hljs-params">                 epsilon, target_update, device</span>):<br>        self.action_dim = action_dim<br>        self.q_net = Qnet(in_channels=<span class="hljs-number">4</span>, action_dim=action_dim).to(device)  <span class="hljs-comment"># Q网络</span><br>        <span class="hljs-comment"># 目标网络</span><br>        self.target_q_net = Qnet(self.action_dim).to(device)<br>        <span class="hljs-comment"># 使用Adam优化器</span><br>        self.optimizer = torch.optim.Adam(self.q_net.parameters(),<br>                                          lr=learning_rate)<br>        self.gamma = gamma  <span class="hljs-comment"># 折扣因子</span><br>        self.epsilon = epsilon  <span class="hljs-comment"># epsilon-贪婪策略</span><br>        self.target_update = target_update  <span class="hljs-comment"># 目标网络更新频率</span><br>        self.count = <span class="hljs-number">0</span>  <span class="hljs-comment"># 计数器,记录更新次数</span><br>        self.device = device<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">save</span>(<span class="hljs-params">self, model_file=<span class="hljs-string">&quot;mymodel&quot;</span></span>):<br>        torch.save(self.q_net, model_file)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">take_action</span>(<span class="hljs-params">self, state</span>):  <span class="hljs-comment"># epsilon-贪婪策略采取动作</span><br>        <span class="hljs-keyword">if</span> np.random.random() &lt; self.epsilon:<br>            action = np.random.randint(self.action_dim)<br>        <span class="hljs-keyword">else</span>:<br>            state = torch.tensor([state], dtype=torch.<span class="hljs-built_in">float</span>).to(self.device)<br>            action = self.q_net(state).argmax().item()<br>        <span class="hljs-keyword">return</span> action<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, transition_dict</span>):<br>        states = torch.tensor(transition_dict[<span class="hljs-string">&#x27;states&#x27;</span>],<br>                              dtype=torch.<span class="hljs-built_in">float</span>).to(self.device)<br>        actions = torch.tensor(transition_dict[<span class="hljs-string">&#x27;actions&#x27;</span>]).view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>).to(<br>            self.device)<br>        rewards = torch.tensor(transition_dict[<span class="hljs-string">&#x27;rewards&#x27;</span>],<br>                               dtype=torch.<span class="hljs-built_in">float</span>).view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>).to(self.device)<br>        next_states = torch.tensor(transition_dict[<span class="hljs-string">&#x27;next_states&#x27;</span>],<br>                                   dtype=torch.<span class="hljs-built_in">float</span>).to(self.device)<br>        dones = torch.tensor(transition_dict[<span class="hljs-string">&#x27;dones&#x27;</span>],<br>                             dtype=torch.<span class="hljs-built_in">float</span>).view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>).to(self.device)<br><br>        q_values = self.q_net(states).gather(<span class="hljs-number">1</span>, actions)  <span class="hljs-comment"># Q值</span><br>        <span class="hljs-comment"># 下个状态的最大Q值</span><br>        max_next_q_values = self.target_q_net(next_states).<span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>].view(<br>            -<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>        q_targets = rewards + self.gamma * max_next_q_values * (<span class="hljs-number">1</span> - dones<br>                                                                )  <span class="hljs-comment"># TD误差目标</span><br>        dqn_loss = torch.mean(F.mse_loss(q_values, q_targets))  <span class="hljs-comment"># 均方误差损失函数</span><br>        self.optimizer.zero_grad()  <span class="hljs-comment"># PyTorch中默认梯度会累积,这里需要显式将梯度置为0</span><br>        dqn_loss.backward()  <span class="hljs-comment"># 反向传播更新参数</span><br>        self.optimizer.step()<br><br>        <span class="hljs-keyword">if</span> self.count % self.target_update == <span class="hljs-number">0</span>:<br>            self.target_q_net.load_state_dict(<br>                self.q_net.state_dict())  <span class="hljs-comment"># 更新目标网络</span><br>        self.count += <span class="hljs-number">1</span><br><br>lr = <span class="hljs-number">2e-3</span><br>num_episodes = <span class="hljs-number">500</span><br>hidden_dim = <span class="hljs-number">128</span><br>gamma = <span class="hljs-number">0.98</span><br>epsilon = <span class="hljs-number">0.01</span><br>target_update = <span class="hljs-number">10</span><br>buffer_size = <span class="hljs-number">100000</span><br>minimal_size = <span class="hljs-number">500</span><br>batch_size = <span class="hljs-number">64</span><br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>) <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)<br><br>env_name = <span class="hljs-string">&#x27;BreakoutNoFrameskip-v4&#x27;</span> <span class="hljs-comment"># 雅达利的弹球游戏</span><br>env = gym.make(env_name)<br>env = gym.wrappers.AtariPreprocessing(env)<br>env = gym.wrappers.FrameStack(env, num_stack=<span class="hljs-number">4</span>)<br>random.seed(<span class="hljs-number">0</span>)<br>np.random.seed(<span class="hljs-number">0</span>)<br>torch.manual_seed(<span class="hljs-number">0</span>)<br>replay_buffer = ReplayBuffer(buffer_size)<br>state_dim = env.observation_space.shape[<span class="hljs-number">0</span>]<br>action_dim = env.action_space.n<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;state shape:&#x27;</span>, env.observation_space.shape)<br>agent = DQN(action_dim, lr, gamma, epsilon,target_update, device)<br><br>return_list = []<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>    <span class="hljs-keyword">with</span> tqdm(total=<span class="hljs-built_in">int</span>(num_episodes / <span class="hljs-number">10</span>), desc=<span class="hljs-string">&#x27;Iteration %d&#x27;</span> % i) <span class="hljs-keyword">as</span> pbar:<br>        <span class="hljs-keyword">for</span> i_episode <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(num_episodes / <span class="hljs-number">10</span>)):<br>            episode_return = <span class="hljs-number">0</span><br>            state, _ = env.reset()<br>            done = <span class="hljs-literal">False</span><br>            <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> done:<br>                action = agent.take_action(state)<br>                next_state, reward, terminate, truncated, _ = env.step(action)<br>                done = terminate <span class="hljs-keyword">or</span> truncated<br>                replay_buffer.add(state, action, reward, next_state, done)<br>                state = next_state<br>                episode_return += reward<br>                <span class="hljs-comment"># 当buffer数据的数量超过一定值后,才进行Q网络训练</span><br>                <span class="hljs-keyword">if</span> replay_buffer.size() &gt; minimal_size:<br>                    b_s, b_a, b_r, b_ns, b_d = replay_buffer.sample(batch_size)<br>                    transition_dict = &#123;<br>                        <span class="hljs-string">&#x27;states&#x27;</span>: b_s,<br>                        <span class="hljs-string">&#x27;actions&#x27;</span>: b_a,<br>                        <span class="hljs-string">&#x27;next_states&#x27;</span>: b_ns,<br>                        <span class="hljs-string">&#x27;rewards&#x27;</span>: b_r,<br>                        <span class="hljs-string">&#x27;dones&#x27;</span>: b_d<br>                    &#125;<br>                    agent.update(transition_dict)<br>            return_list.append(episode_return)<br>            <span class="hljs-keyword">if</span> (i_episode + <span class="hljs-number">1</span>) % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>                pbar.set_postfix(&#123;<br>                    <span class="hljs-string">&#x27;episode&#x27;</span>:<br>                    <span class="hljs-string">&#x27;%d&#x27;</span> % (num_episodes / <span class="hljs-number">10</span> * i + i_episode + <span class="hljs-number">1</span>),<br>                    <span class="hljs-string">&#x27;return&#x27;</span>:<br>                    <span class="hljs-string">&#x27;%.3f&#x27;</span> % np.mean(return_list[-<span class="hljs-number">10</span>:])<br>                &#125;)<br>            pbar.update(<span class="hljs-number">1</span>)<br><br>agent.save()<br>episodes_list = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(return_list)))<br>plt.plot(episodes_list, return_list)<br>plt.xlabel(<span class="hljs-string">&#x27;Episodes&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;Returns&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;DQN on &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(env_name))<br>plt.show()<br><br>mv_return = rl_utils.moving_average(return_list, <span class="hljs-number">9</span>)<br>plt.plot(episodes_list, mv_return)<br>plt.xlabel(<span class="hljs-string">&#x27;Episodes&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;Returns&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;DQN on &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(env_name))<br>plt.show()<br><br></code></pre></td></tr></table></figure><h2 id="第三步解析上面实现的弹球游戏"><a href="#第三步解析上面实现的弹球游戏" class="headerlink" title="第三步解析上面实现的弹球游戏"></a>第三步解析上面实现的弹球游戏</h2><p>打砖块的游戏的输入为(4, 84, 84)，动作有4个有四个动作( 0 , 1 , 2 , 3 )，奖励为分数。对于Flappy Bird for Gymnasium环境中游戏action 为（180，）The LIDAR sensor 180 readings， action space 为 0 do nothing， 1 为 flap 奖励为0.1 - every frame it stays alive，1.0 - successfully passing a pipe，1.0 - dying， 0.5 - touch the top of the screen 输入有点少。</p><h2 id="第四步，使用DQN网络"><a href="#第四步，使用DQN网络" class="headerlink" title="第四步，使用DQN网络"></a>第四步，使用DQN网络</h2><p>笔记： 函数的方法（DQN）和基于策略的方法（REINFORCE），其中基于值函数的方法只学习一个价值函数，而基于策略的方法只学习一个策略函数。那么，一个很自然的问题是，有没有什么方法既学习价值函数，又学习策略函数呢？答案就是 Actor-Critic。在 REINFORCE 算法中，目标函数的梯度中有一项轨迹回报，用于指导策略的更新。Actor 的更新采用策略梯度的原则，之前路走偏了使用了价值策略来更新参数，不容易收敛。</p><p>model</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ACnet</span>(torch.nn.Module):<br>    <span class="hljs-string">&#x27;&#x27;&#x27; 加入卷积层的Q网络 &#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, action_dim, in_channels=<span class="hljs-number">4</span></span>):<br>        <span class="hljs-built_in">super</span>(ACnet, self).__init__()<br>        self.conv1 = torch.nn.Conv2d(in_channels, <span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">8</span>, stride=<span class="hljs-number">4</span>)<br>        self.conv2 = torch.nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">4</span>, stride=<span class="hljs-number">2</span>)<br>        self.conv3 = torch.nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>)<br>        self.flatten = torch.nn.Flatten()<br>        self.fc4 = torch.nn.Linear(<span class="hljs-number">7</span> * <span class="hljs-number">7</span> * <span class="hljs-number">64</span>, <span class="hljs-number">512</span>)<br>        <span class="hljs-comment">#Actor                </span><br>        self.actor_fc = torch.nn.Linear(<span class="hljs-number">512</span>, action_dim)<br>        <span class="hljs-comment">#Critic</span><br>        self.policy_fc = torch.nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">1</span>)<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">policy</span>(<span class="hljs-params">self, obs</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            obs: A float32 tensor array of shape [B, C, H, W]</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            policy_logits: B * ACT_DIM</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        obs = obs / <span class="hljs-number">255.0</span><br>        conv1 = F.relu(self.conv1(obs))<br>        conv2 = F.relu(self.conv2(conv1))<br>        conv3 = F.relu(self.conv3(conv2))<br>        flatten = self.flatten(conv3)<br>        fc_output = F.relu(self.fc(flatten))<br>        policy_logits = self.policy_fc(fc_output)<br><br>        <span class="hljs-keyword">return</span> policy_logits<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">value</span>(<span class="hljs-params">self, obs</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            obs: A float32 tensor of shape [B, C, H, W]</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            values: B</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        obs = obs / <span class="hljs-number">255.0</span><br>        conv1 = F.relu(self.conv1(obs))<br>        conv2 = F.relu(self.conv2(conv1))<br>        conv3 = F.relu(self.conv3(conv2))<br>        flatten = self.flatten(conv3)<br>        fc_output = F.relu(self.fc(flatten))<br>        values = self.value_fc(fc_output)<br>        values = torch.squeeze(values, axis=<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> values<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">policy_and_value</span>(<span class="hljs-params">self, obs</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            obs: A tensor array of shape [B, C, H, W]</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            policy_logits: B * ACT_DIM</span><br><span class="hljs-string">            values: B</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        obs = obs / <span class="hljs-number">255.0</span><br>        conv1 = F.relu(self.conv1(obs))<br>        conv2 = F.relu(self.conv2(conv1))<br>        conv3 = F.relu(self.conv3(conv2))<br>        flatten = self.flatten(conv3)<br>        fc_output = F.relu(self.fc(flatten))<br><br>        policy_logits = self.policy_fc(fc_output)<br><br>        values = self.value_fc(fc_output)<br>        values = torch.squeeze(values, axis=<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> policy_logits, values<br>    <br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PolicyNet</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, state_dim, hidden_dim, action_dim</span>):<br>        <span class="hljs-built_in">super</span>(PolicyNet, self).__init__()<br>        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)<br>        self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim)<br>        self.fc3 = torch.nn.Linear(hidden_dim, hidden_dim)<br>        self.fc4 = torch.nn.Linear(hidden_dim, action_dim)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = F.relu(self.fc1(x))<br>        x = F.relu(self.fc2(x))<br>        x = F.relu(self.fc3(x))<br>        <span class="hljs-keyword">return</span> F.softmax(self.fc4(x), dim=<span class="hljs-number">1</span>)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ValueNet</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, state_dim, hidden_dim</span>):<br>        <span class="hljs-built_in">super</span>(ValueNet, self).__init__()<br>        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)<br>        self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim)<br>        self.fc3 = torch.nn.Linear(hidden_dim, hidden_dim)<br>        self.fc4 = torch.nn.Linear(hidden_dim, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = F.relu(self.fc1(x))<br>        x = F.relu(self.fc2(x))<br>        x = F.relu(self.fc3(x))<br>        <span class="hljs-keyword">return</span> self.fc4(x)<br><br><br></code></pre></td></tr></table></figure><p>agent</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> PolicyNet, ValueNet<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ActorCritic</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, state_dim, hidden_dim, action_dim, actor_lr, critic_lr,</span><br><span class="hljs-params">                 gamma, device</span>):<br>        <span class="hljs-comment"># 策略网络</span><br>        self.actor = PolicyNet(state_dim, hidden_dim, action_dim).to(device)<br>        self.critic = ValueNet(state_dim, hidden_dim).to(device)  <span class="hljs-comment"># 价值网络</span><br>        <br>                <span class="hljs-comment"># 策略网络优化器</span><br>        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(),<br>                                                lr=actor_lr)<br>        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(),<br>                                                 lr=critic_lr)  <span class="hljs-comment"># 价值网络优化器</span><br>        <span class="hljs-comment">#学习率衰减</span><br>        <span class="hljs-comment"># self.actor_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(self.actor_optimizer, gamma=0.99)</span><br>        <span class="hljs-comment"># self.critic_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(self.critic_optimizer, gamma=0.99)</span><br>        self.actor_lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.actor_optimizer, T_max=<span class="hljs-number">50</span>, eta_min=<span class="hljs-number">1e-6</span>)<br>        self.critic_lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.critic_optimizer, T_max=<span class="hljs-number">50</span>, eta_min=<span class="hljs-number">1e-6</span>)<br>        self.gamma = gamma<br>        self.device = device<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">take_action</span>(<span class="hljs-params">self, state</span>):<br>        state = torch.tensor([state], dtype=torch.<span class="hljs-built_in">float</span>).to(self.device)<br>        probs = self.actor(state)<br>        action_dist = torch.distributions.Categorical(probs)<br>        action = action_dist.sample()<br>        <span class="hljs-keyword">return</span> action.item()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, transition_dict</span>):<br>        states = torch.tensor(transition_dict[<span class="hljs-string">&#x27;states&#x27;</span>],<br>                              dtype=torch.<span class="hljs-built_in">float</span>).to(self.device)<br>        actions = torch.tensor(transition_dict[<span class="hljs-string">&#x27;actions&#x27;</span>]).view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>).to(<br>            self.device)<br>        rewards = torch.tensor(transition_dict[<span class="hljs-string">&#x27;rewards&#x27;</span>],<br>                               dtype=torch.<span class="hljs-built_in">float</span>).view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>).to(self.device)<br>        next_states = torch.tensor(transition_dict[<span class="hljs-string">&#x27;next_states&#x27;</span>],<br>                                   dtype=torch.<span class="hljs-built_in">float</span>).to(self.device)<br>        dones = torch.tensor(transition_dict[<span class="hljs-string">&#x27;dones&#x27;</span>],<br>                             dtype=torch.<span class="hljs-built_in">float</span>).view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>).to(self.device)<br><br>        <span class="hljs-comment"># 时序差分目标</span><br>        td_target = rewards + self.gamma * self.critic(next_states) * (<span class="hljs-number">1</span> -<br>                                                                       dones)<br>        td_delta = td_target - self.critic(states)  <span class="hljs-comment"># 时序差分误差</span><br>        log_probs = torch.log(self.actor(states).gather(<span class="hljs-number">1</span>, actions))<br>        actor_loss = torch.mean(-log_probs * td_delta.detach())<br>        <span class="hljs-comment"># 均方误差损失函数</span><br>        critic_loss = torch.mean(<br>            F.mse_loss(self.critic(states), td_target.detach()))<br>        self.actor_optimizer.zero_grad()<br>        self.critic_optimizer.zero_grad()<br>        actor_loss.backward()  <span class="hljs-comment"># 计算策略网络的梯度</span><br>        critic_loss.backward()  <span class="hljs-comment"># 计算价值网络的梯度</span><br>        self.actor_optimizer.step()  <span class="hljs-comment"># 更新策略网络的参数</span><br>        self.critic_optimizer.step()  <span class="hljs-comment"># 更新价值网络的参数</span><br>        self.actor_lr_scheduler.step()<br>        self.critic_lr_scheduler.step()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">save</span>(<span class="hljs-params">self, path=<span class="hljs-string">&#x27;mymodel&#x27;</span>, epoch=<span class="hljs-number">0</span></span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;保存模型&#x27;&#x27;&#x27;</span><br>        checkpoint = &#123;<span class="hljs-string">&quot;actor&quot;</span>: self.actor.state_dict(),<br>                      <span class="hljs-string">&quot;critic&quot;</span>: self.critic.state_dict(),<br>                      <span class="hljs-string">&quot;actor_opt&quot;</span>: self.actor_optimizer.state_dict(),<br>                      <span class="hljs-string">&quot;critic_opt&quot;</span>: self.critic_optimizer.state_dict(),<br>                      <span class="hljs-string">&quot;epoch&quot;</span>: epoch&#125;        <br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(path):<br>            os.makedirs(path, <span class="hljs-literal">True</span>)<br>        path = os.path.join(path, <span class="hljs-string">f&#x27;checkpoint_<span class="hljs-subst">&#123;epoch&#125;</span>.ckpt&#x27;</span>)<br>        torch.save(checkpoint, path)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">load</span>(<span class="hljs-params">self, path=<span class="hljs-string">&#x27;mymodel&#x27;</span></span>):<br>        checkpoint = torch.load(path)<br>        self.actor.load_state_dict(checkpoint[<span class="hljs-string">&#x27;actor&#x27;</span>])<br>        self.critic.load_state_dict(checkpoint[<span class="hljs-string">&#x27;critic&#x27;</span>])<br>        self.actor_optimizer.load_state_dict(checkpoint[<span class="hljs-string">&#x27;actor_opt&#x27;</span>])<br>        self.critic_optimizer.load_state_dict(checkpoint[<span class="hljs-string">&#x27;critic_opt&#x27;</span>])<br>        <span class="hljs-keyword">return</span> checkpoint[<span class="hljs-string">&#x27;epoch&#x27;</span>]<br><br></code></pre></td></tr></table></figure><p>rl_utils 文件，用于测试代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> collections<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> tensorboardX <span class="hljs-keyword">import</span> SummaryWriter<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ReplayBuffer</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, capacity</span>):<br>        self.buffer = collections.deque(maxlen=capacity) <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">self, state, action, reward, next_state, done</span>): <br>        self.buffer.append((state, action, reward, next_state, done)) <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">sample</span>(<span class="hljs-params">self, batch_size</span>): <br>        transitions = random.sample(self.buffer, batch_size)<br>        state, action, reward, next_state, done = <span class="hljs-built_in">zip</span>(*transitions)<br>        <span class="hljs-keyword">return</span> np.array(state), action, reward, np.array(next_state), done <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">size</span>(<span class="hljs-params">self</span>): <br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.buffer)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">moving_average</span>(<span class="hljs-params">a, window_size</span>):<br>    cumulative_sum = np.cumsum(np.insert(a, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>)) <br>    middle = (cumulative_sum[window_size:] - cumulative_sum[:-window_size]) / window_size<br>    r = np.arange(<span class="hljs-number">1</span>, window_size-<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>    begin = np.cumsum(a[:window_size-<span class="hljs-number">1</span>])[::<span class="hljs-number">2</span>] / r<br>    end = (np.cumsum(a[:-window_size:-<span class="hljs-number">1</span>])[::<span class="hljs-number">2</span>] / r)[::-<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">return</span> np.concatenate((begin, middle, end))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_on_policy_agent</span>(<span class="hljs-params">env, agent, num_episodes</span>):<br>    current_time = time.strftime(<span class="hljs-string">&quot;logs/%Y-%m-%dT%H_%M&quot;</span>, time.localtime())<br>    writer = SummaryWriter(log_dir=current_time)<br>    return_list = []<br>    global_step = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        <span class="hljs-keyword">with</span> tqdm(total=<span class="hljs-built_in">int</span>(num_episodes/<span class="hljs-number">10</span>), desc=<span class="hljs-string">&#x27;Iteration %d&#x27;</span> % i) <span class="hljs-keyword">as</span> pbar:<br>            <span class="hljs-keyword">for</span> i_episode <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(num_episodes/<span class="hljs-number">10</span>)):<br>                episode_return = <span class="hljs-number">0</span><br>                transition_dict = &#123;<span class="hljs-string">&#x27;states&#x27;</span>: [], <span class="hljs-string">&#x27;actions&#x27;</span>: [], <span class="hljs-string">&#x27;next_states&#x27;</span>: [], <span class="hljs-string">&#x27;rewards&#x27;</span>: [], <span class="hljs-string">&#x27;dones&#x27;</span>: []&#125;<br>                state,_ = env.reset()<br>                <span class="hljs-comment"># print(state)</span><br>                done = <span class="hljs-literal">False</span><br>                <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> done:<br>                    action = agent.take_action(state)<br>                    <span class="hljs-comment"># print(action)</span><br>                    next_state, reward, terminated,truncated, _ = env.step(action)<br>                    done = terminated <span class="hljs-keyword">or</span> truncated<br>                    transition_dict[<span class="hljs-string">&#x27;states&#x27;</span>].append(state)<br>                    transition_dict[<span class="hljs-string">&#x27;actions&#x27;</span>].append(action)<br>                    transition_dict[<span class="hljs-string">&#x27;next_states&#x27;</span>].append(next_state)<br>                    transition_dict[<span class="hljs-string">&#x27;rewards&#x27;</span>].append(reward)<br>                    transition_dict[<span class="hljs-string">&#x27;dones&#x27;</span>].append(done)<br>                    state = next_state<br>                    episode_return += reward<br>                <br>                return_list.append(episode_return)<br>                writer.add_scalar(<span class="hljs-string">&#x27;reward&#x27;</span>, episode_return, global_step)<br>                writer.add_scalar(<span class="hljs-string">&#x27;actor LR&#x27;</span>, agent.actor_lr_scheduler.get_last_lr(),global_step)<br>                writer.add_scalar(<span class="hljs-string">&#x27;critic LR&#x27;</span>, agent.critic_lr_scheduler.get_last_lr(),global_step)<br>                global_step += <span class="hljs-number">1</span><br>                agent.update(transition_dict)<br>                <span class="hljs-keyword">if</span> (i_episode+<span class="hljs-number">1</span>) % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>                    pbar.set_postfix(&#123;<span class="hljs-string">&#x27;episode&#x27;</span>: <span class="hljs-string">&#x27;%d&#x27;</span> % (num_episodes/<span class="hljs-number">10</span> * i + i_episode+<span class="hljs-number">1</span>), <span class="hljs-string">&#x27;return&#x27;</span>: <span class="hljs-string">&#x27;%.3f&#x27;</span> % np.mean(return_list[-<span class="hljs-number">10</span>:])&#125;)<br>                pbar.update(<span class="hljs-number">1</span>)<br>        agent.save(path=<span class="hljs-string">&#x27;mymodel&#x27;</span>, epoch=i)<br><br>    <span class="hljs-keyword">return</span> return_list<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_off_policy_agent</span>(<span class="hljs-params">env, agent, num_episodes, replay_buffer, minimal_size, batch_size</span>):<br>    return_list = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        <span class="hljs-keyword">with</span> tqdm(total=<span class="hljs-built_in">int</span>(num_episodes/<span class="hljs-number">10</span>), desc=<span class="hljs-string">&#x27;Iteration %d&#x27;</span> % i) <span class="hljs-keyword">as</span> pbar:<br>            <span class="hljs-keyword">for</span> i_episode <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(num_episodes/<span class="hljs-number">10</span>)):<br>                episode_return = <span class="hljs-number">0</span><br>                state = env.reset()<br>                done = <span class="hljs-literal">False</span><br>                <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> done:<br>                    action = agent.take_action(state)<br>                    next_state, reward, done, _ = env.step(action)<br>                    replay_buffer.add(state, action, reward, next_state, done)<br>                    state = next_state<br>                    episode_return += reward<br>                    <span class="hljs-keyword">if</span> replay_buffer.size() &gt; minimal_size:<br>                        b_s, b_a, b_r, b_ns, b_d = replay_buffer.sample(batch_size)<br>                        transition_dict = &#123;<span class="hljs-string">&#x27;states&#x27;</span>: b_s, <span class="hljs-string">&#x27;actions&#x27;</span>: b_a, <span class="hljs-string">&#x27;next_states&#x27;</span>: b_ns, <span class="hljs-string">&#x27;rewards&#x27;</span>: b_r, <span class="hljs-string">&#x27;dones&#x27;</span>: b_d&#125;<br>                        agent.update(transition_dict)<br>                return_list.append(episode_return)<br>                <span class="hljs-keyword">if</span> (i_episode+<span class="hljs-number">1</span>) % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>                    pbar.set_postfix(&#123;<span class="hljs-string">&#x27;episode&#x27;</span>: <span class="hljs-string">&#x27;%d&#x27;</span> % (num_episodes/<span class="hljs-number">10</span> * i + i_episode+<span class="hljs-number">1</span>), <span class="hljs-string">&#x27;return&#x27;</span>: <span class="hljs-string">&#x27;%.3f&#x27;</span> % np.mean(return_list[-<span class="hljs-number">10</span>:])&#125;)<br>                pbar.update(<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> return_list<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_advantage</span>(<span class="hljs-params">gamma, lmbda, td_delta</span>):<br>    td_delta = td_delta.detach().numpy()<br>    advantage_list = []<br>    advantage = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">for</span> delta <span class="hljs-keyword">in</span> td_delta[::-<span class="hljs-number">1</span>]:<br>        advantage = gamma * lmbda * advantage + delta<br>        advantage_list.append(advantage)<br>    advantage_list.reverse()<br>    <span class="hljs-keyword">return</span> torch.tensor(advantage_list, dtype=torch.<span class="hljs-built_in">float</span>)<br>                <br></code></pre></td></tr></table></figure><p>训练代码，使用Ac—Critic算法来进行梯度更新</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">import</span> flappy_bird_gymnasium<br><span class="hljs-keyword">import</span> gymnasium <span class="hljs-keyword">as</span> gym<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> rl_utils<br><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> ACnet<br><span class="hljs-keyword">from</span> agent <span class="hljs-keyword">import</span> ActorCritic<br><br><br><br>actor_lr = <span class="hljs-number">1e-3</span><br>critic_lr = <span class="hljs-number">1e-2</span><br>num_episodes = <span class="hljs-number">4000</span><br>hidden_dim = <span class="hljs-number">256</span><br>gamma = <span class="hljs-number">0.96</span><br>device = torch.device(&quot;cuda&quot;) <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> torch.device(<br>    &quot;cpu&quot;)<br><br>env_name = <span class="hljs-string">&#x27;FlappyBird-v0&#x27;</span><br>env = gym.make(env_name)<br>torch.manual_seed(<span class="hljs-number">0</span>)<br>state_dim = env.observation_space.shape[<span class="hljs-number">0</span>]<br>action_dim = env.action_space.n<br>agent = ActorCritic(state_dim, hidden_dim, action_dim, actor_lr, critic_lr,<br>                    gamma, device)<br><br>#恢复训练<br># agent.<span class="hljs-keyword">load</span>(<span class="hljs-string">&#x27;mymodel/checkpoint_9&#x27;</span>)<br><br>return_list = rl_utils.train_on_policy_agent(env, agent, num_episodes)<br><br>agent.save()<br><br><br>episodes_list = list(range(len(return_list)))<br>plt.plot(episodes_list, return_list)<br>plt.xlabel(<span class="hljs-string">&#x27;Episodes&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;Returns&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;Actor-Critic on &#123;&#125;&#x27;</span>.format(env_name))<br>plt.<span class="hljs-keyword">show</span>()<br><br>mv_return = rl_utils.moving_average(return_list, <span class="hljs-number">9</span>)<br>plt.plot(episodes_list, mv_return)<br>plt.xlabel(<span class="hljs-string">&#x27;Episodes&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;Returns&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;Actor-Critic on &#123;&#125;&#x27;</span>.format(env_name))<br>plt.<span class="hljs-keyword">show</span>()<br><br></code></pre></td></tr></table></figure><p>结果不怎么样，一直维持到0.8 左右。agent一直没有行动。某种程度上是数据输入太少了，论文中的结果怎么好我看不懂，真的服了。更换算法，</p><h2 id="第五步ppo算法"><a href="#第五步ppo算法" class="headerlink" title="第五步ppo算法."></a>第五步ppo算法.</h2><p>代码 详细代码我放在了github上<a href="https://github.com/changjingzhi/FlappyBird-with-ppo">github链接</a><br>配置文件，rl_utils</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">from</span> abc <span class="hljs-keyword">import</span> ABC, abstractmethod<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> collections<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> gymnasium <span class="hljs-keyword">as</span> gym<br><span class="hljs-keyword">import</span> flappy_bird_gymnasium<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BasePolicy</span>(<span class="hljs-title class_ inherited__">ABC</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    策略类的抽象基类</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">assert</span> <span class="hljs-literal">True</span><br><br><span class="hljs-meta">    @abstractmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">take_action</span>(<span class="hljs-params">self, state:np.ndarray</span>) -&gt; <span class="hljs-built_in">int</span>:<br>        <span class="hljs-keyword">raise</span> NotImplementedError<br><br><span class="hljs-meta">    @abstractmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, transition_dict:<span class="hljs-built_in">dict</span></span>):<br>        <span class="hljs-keyword">raise</span> NotImplementedError<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ReplayBuffer</span>:<br>    <span class="hljs-string">&#x27;&#x27;&#x27; 经验回放池 &#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, capacity:<span class="hljs-built_in">int</span></span>):<br>        self.buffer = collections.deque(maxlen=capacity)    <span class="hljs-comment"># 队列,先进先出</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">self, state:np.ndarray, action:<span class="hljs-built_in">int</span>, reward:<span class="hljs-built_in">float</span>, next_state:np.ndarray, done:<span class="hljs-built_in">bool</span></span>):     <span class="hljs-comment"># 将数据加入buffer</span><br>        self.buffer.append((state, action, reward, next_state, done)) <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">sample</span>(<span class="hljs-params">self, batch_size:<span class="hljs-built_in">int</span></span>):   <span class="hljs-comment"># 从buffer中采样数据,数量为batch_size</span><br>        transitions = random.sample(self.buffer, batch_size)<br>        state, action, reward, next_state, done = <span class="hljs-built_in">zip</span>(*transitions)<br>        <span class="hljs-keyword">return</span> np.array(state), action, reward, np.array(next_state), done <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">size</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">int</span>:  <span class="hljs-comment"># 目前buffer中数据的数量</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.buffer)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">moving_average</span>(<span class="hljs-params">a:<span class="hljs-built_in">list</span>, window_size:<span class="hljs-built_in">int</span></span>) -&gt; np.ndarray:<br>    cumulative_sum = np.cumsum(np.insert(a, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>)) <br>    middle = (cumulative_sum[window_size:] - cumulative_sum[:-window_size]) / window_size<br>    r = np.arange(<span class="hljs-number">1</span>, window_size-<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>    begin = np.cumsum(a[:window_size-<span class="hljs-number">1</span>])[::<span class="hljs-number">2</span>] / r<br>    end = (np.cumsum(a[:-window_size:-<span class="hljs-number">1</span>])[::<span class="hljs-number">2</span>] / r)[::-<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">return</span> np.concatenate((begin, middle, end))<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_on_policy_agent</span>(<span class="hljs-params">env:gym.Env, agent:BasePolicy, num_episodes:<span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">list</span>:<br>    return_list = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        <span class="hljs-keyword">with</span> tqdm(total=<span class="hljs-built_in">int</span>(num_episodes/<span class="hljs-number">10</span>), desc=<span class="hljs-string">&#x27;Iteration %d&#x27;</span> % i) <span class="hljs-keyword">as</span> pbar:<br>            <span class="hljs-keyword">for</span> i_episode <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(num_episodes/<span class="hljs-number">10</span>)):<br>                episode_return = <span class="hljs-number">0</span><br>                transition_dict = &#123;<span class="hljs-string">&#x27;states&#x27;</span>: [], <span class="hljs-string">&#x27;actions&#x27;</span>: [], <span class="hljs-string">&#x27;next_states&#x27;</span>: [], <span class="hljs-string">&#x27;rewards&#x27;</span>: [], <span class="hljs-string">&#x27;dones&#x27;</span>: []&#125;<br>                state,_ = env.reset()<br>                done = <span class="hljs-literal">False</span><br>                <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> done:<br>                    action = agent.take_action(state)<br>                    next_state, reward, done, _,info = env.step(action)<br>                    transition_dict[<span class="hljs-string">&#x27;states&#x27;</span>].append(state)<br>                    transition_dict[<span class="hljs-string">&#x27;actions&#x27;</span>].append(action)<br>                    transition_dict[<span class="hljs-string">&#x27;next_states&#x27;</span>].append(next_state)<br>                    transition_dict[<span class="hljs-string">&#x27;rewards&#x27;</span>].append(reward)<br>                    transition_dict[<span class="hljs-string">&#x27;dones&#x27;</span>].append(done)<br>                    state = next_state<br>                    episode_return += reward<br>                return_list.append(episode_return)<br>                agent.update(transition_dict)<br>                <span class="hljs-keyword">if</span> (i_episode+<span class="hljs-number">1</span>) % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>                    pbar.set_postfix(&#123;<br>                            <span class="hljs-string">&#x27;episode&#x27;</span>: <span class="hljs-string">&#x27;%d&#x27;</span> % (num_episodes/<span class="hljs-number">10</span> * i + i_episode+<span class="hljs-number">1</span>), <br>                            <span class="hljs-string">&#x27;return&#x27;</span>: <span class="hljs-string">&#x27;%.3f&#x27;</span> % np.mean(return_list[-<span class="hljs-number">10</span>:])<br>                        &#125;)<br>                pbar.update(<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> return_list<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_off_policy_agent</span>(<span class="hljs-params"></span><br><span class="hljs-params">        env:gym.Env, agent:BasePolicy, num_episodes:<span class="hljs-built_in">int</span>, </span><br><span class="hljs-params">        replay_buffer:ReplayBuffer, minimal_size:<span class="hljs-built_in">int</span>, batch_size:<span class="hljs-built_in">int</span></span><br><span class="hljs-params">    </span>) -&gt; <span class="hljs-built_in">list</span>:<br>    return_list = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>        <span class="hljs-keyword">with</span> tqdm(total=<span class="hljs-built_in">int</span>(num_episodes/<span class="hljs-number">10</span>), desc=<span class="hljs-string">&#x27;Iteration %d&#x27;</span> % i) <span class="hljs-keyword">as</span> pbar:<br>            <span class="hljs-keyword">for</span> i_episode <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">int</span>(num_episodes/<span class="hljs-number">10</span>)):<br>                episode_return = <span class="hljs-number">0</span><br>                state = env.reset()<br>                done = <span class="hljs-literal">False</span><br>                <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> done:<br>                    action = agent.take_action(state)<br>                    next_state, reward, done, _ = env.step(action)<br>                    replay_buffer.add(state, action, reward, next_state, done)<br>                    state = next_state<br>                    episode_return += reward<br>                    <span class="hljs-keyword">if</span> replay_buffer.size() &gt; minimal_size:<br>                        b_s, b_a, b_r, b_ns, b_d = replay_buffer.sample(batch_size)<br>                        transition_dict = &#123;<span class="hljs-string">&#x27;states&#x27;</span>: b_s, <span class="hljs-string">&#x27;actions&#x27;</span>: b_a, <span class="hljs-string">&#x27;next_states&#x27;</span>: b_ns, <span class="hljs-string">&#x27;rewards&#x27;</span>: b_r, <span class="hljs-string">&#x27;dones&#x27;</span>: b_d&#125;<br>                        agent.update(transition_dict)<br>                return_list.append(episode_return)<br>                <span class="hljs-keyword">if</span> (i_episode+<span class="hljs-number">1</span>) % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>                    pbar.set_postfix(&#123;<br>                            <span class="hljs-string">&#x27;episode&#x27;</span>: <span class="hljs-string">&#x27;%d&#x27;</span> % (num_episodes/<span class="hljs-number">10</span> * i + i_episode+<span class="hljs-number">1</span>), <br>                            <span class="hljs-string">&#x27;return&#x27;</span>: <span class="hljs-string">&#x27;%.3f&#x27;</span> % np.mean(return_list[-<span class="hljs-number">10</span>:])<br>                        &#125;)<br>                pbar.update(<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> return_list<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_advantage</span>(<span class="hljs-params">gamma:<span class="hljs-built_in">float</span>, lmbda:<span class="hljs-built_in">float</span>, td_delta:torch.Tensor</span>) -&gt; torch.Tensor:<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    广义优势估计 (Generalized Advantage Estimation, GAE)，</span><br><span class="hljs-string">    解释：https://hrl.boyuai.com/chapter/2/trpo%E7%AE%97%E6%B3%95#116-%E5%B9%BF%E4%B9%89%E4%BC%98%E5%8A%BF%E4%BC%B0%E8%AE%A1</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    td_delta = td_delta.detach().numpy()<br>    advantage_list = []<br>    advantage = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">for</span> delta <span class="hljs-keyword">in</span> td_delta[::-<span class="hljs-number">1</span>]:<br>        advantage = gamma * lmbda * advantage + delta<br>        advantage_list.append(advantage)<br>    advantage_list.reverse()<br>    <span class="hljs-keyword">return</span> torch.tensor(advantage_list, dtype=torch.<span class="hljs-built_in">float</span>)<br>                <br><br></code></pre></td></tr></table></figure><p>训练代码,ppo</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> gymnasium <span class="hljs-keyword">as</span> gym<br><span class="hljs-keyword">import</span> flappy_bird_gymnasium<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> rl_utils<br><span class="hljs-keyword">import</span> os<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PolicyNet</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, state_dim, hidden_dim, action_dim</span>):<br>        <span class="hljs-built_in">super</span>(PolicyNet, self).__init__()<br>        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)<br>        self.fc2 = torch.nn.Linear(hidden_dim, action_dim)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = F.relu(self.fc1(x))<br>        <span class="hljs-keyword">return</span> F.softmax(self.fc2(x), dim=<span class="hljs-number">1</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ValueNet</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, state_dim, hidden_dim</span>):<br>        <span class="hljs-built_in">super</span>(ValueNet, self).__init__()<br>        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)<br>        self.fc2 = torch.nn.Linear(hidden_dim, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = F.relu(self.fc1(x))<br>        <span class="hljs-keyword">return</span> self.fc2(x)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PPO</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, state_dim, hidden_dim, action_dim, actor_lr, critic_lr,</span><br><span class="hljs-params">                 lmbda, epochs, eps, gamma, device</span>):<br>        self.actor = PolicyNet(state_dim, hidden_dim, action_dim).to(device)<br>        self.critic = ValueNet(state_dim, hidden_dim).to(device)<br>        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(),<br>                                                lr=actor_lr)<br>        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(),<br>                                                 lr=critic_lr)<br>        self.gamma = gamma<br>        self.lmbda = lmbda<br>        self.epochs = epochs<br>        self.eps = eps<br>        self.device = device<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">take_action</span>(<span class="hljs-params">self, state</span>):<br>        state = torch.tensor([state], dtype=torch.<span class="hljs-built_in">float</span>).to(self.device)<br>        probs = self.actor(state)<br>        action_dist = torch.distributions.Categorical(probs)<br>        action = action_dist.sample()<br>        <span class="hljs-keyword">return</span> action.item()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, transition_dict</span>):<br>        states = torch.tensor(transition_dict[<span class="hljs-string">&#x27;states&#x27;</span>],<br>                              dtype=torch.<span class="hljs-built_in">float</span>).to(self.device)<br>        actions = torch.tensor(transition_dict[<span class="hljs-string">&#x27;actions&#x27;</span>]).view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>).to(<br>            self.device)<br>        rewards = torch.tensor(transition_dict[<span class="hljs-string">&#x27;rewards&#x27;</span>],<br>                               dtype=torch.<span class="hljs-built_in">float</span>).view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>).to(self.device)<br>        next_states = torch.tensor(transition_dict[<span class="hljs-string">&#x27;next_states&#x27;</span>],<br>                                   dtype=torch.<span class="hljs-built_in">float</span>).to(self.device)<br>        dones = torch.tensor(transition_dict[<span class="hljs-string">&#x27;dones&#x27;</span>],<br>                             dtype=torch.<span class="hljs-built_in">float</span>).view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>).to(self.device)<br>        td_target = rewards + self.gamma * self.critic(next_states) * (<span class="hljs-number">1</span> -<br>                                                                       dones)<br>        td_delta = td_target - self.critic(states)<br>        advantage = rl_utils.compute_advantage(self.gamma, self.lmbda,<br>                                               td_delta.cpu()).to(self.device)<br>        old_log_probs = torch.log(self.actor(states).gather(<span class="hljs-number">1</span>,<br>                                                            actions)).detach()<br><br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.epochs):<br>            log_probs = torch.log(self.actor(states).gather(<span class="hljs-number">1</span>, actions))<br>            ratio = torch.exp(log_probs - old_log_probs)<br>            surr1 = ratio * advantage<br>            surr2 = torch.clamp(ratio, <span class="hljs-number">1</span> - self.eps,<br>                                <span class="hljs-number">1</span> + self.eps) * advantage<br>            actor_loss = torch.mean(-torch.<span class="hljs-built_in">min</span>(surr1, surr2))<br>            critic_loss = torch.mean(<br>                F.mse_loss(self.critic(states), td_target.detach()))<br>            self.actor_optimizer.zero_grad()<br>            self.critic_optimizer.zero_grad()<br>            actor_loss.backward()<br>            critic_loss.backward()<br>            self.actor_optimizer.step()<br>            self.critic_optimizer.step()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">save_model</span>(<span class="hljs-params">self, model_save_path</span>):<br>        os.makedirs(os.path.dirname(model_save_path), exist_ok=<span class="hljs-literal">True</span>)<br>        torch.save(&#123;<br>            <span class="hljs-string">&#x27;actor&#x27;</span>: self.actor.state_dict(),<br>            <span class="hljs-string">&#x27;critic&#x27;</span>: self.critic.state_dict(),<br>            <span class="hljs-string">&#x27;actor_optimizer&#x27;</span>: self.actor_optimizer.state_dict(),<br>            <span class="hljs-string">&#x27;critic_optimizer&#x27;</span>: self.critic_optimizer.state_dict()<br>        &#125;, model_save_path)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">load_model</span>(<span class="hljs-params">self, model_save_path</span>):<br>        <span class="hljs-keyword">if</span> os.path.exists(model_save_path):<br>            checkpoint = torch.load(model_save_path)<br>            self.actor.load_state_dict(checkpoint[<span class="hljs-string">&#x27;actor&#x27;</span>])<br>            self.critic.load_state_dict(checkpoint[<span class="hljs-string">&#x27;critic&#x27;</span>])<br>            self.actor_optimizer.load_state_dict(checkpoint[<span class="hljs-string">&#x27;actor_optimizer&#x27;</span>])<br>            self.critic_optimizer.load_state_dict(checkpoint[<span class="hljs-string">&#x27;critic_optimizer&#x27;</span>])<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;模型成功加载！&quot;</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;模型路径不存在，将从头开始训练。&quot;</span>)<br><br><span class="hljs-comment"># 定义超参数和环境</span><br>actor_lr = <span class="hljs-number">1e-6</span><br>critic_lr = <span class="hljs-number">1e-5</span><br>num_episodes = <span class="hljs-number">10000</span><br>hidden_dim = <span class="hljs-number">64</span><br>gamma = <span class="hljs-number">0.99</span><br>lmbda = <span class="hljs-number">0.95</span><br>epochs = <span class="hljs-number">10</span><br>eps = <span class="hljs-number">0.2</span><br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>) <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)<br>env_name = <span class="hljs-string">&#x27;FlappyBird-v0&#x27;</span><br><br><span class="hljs-comment"># 创建环境和代理</span><br>env = gym.make(env_name)<br>state_dim = env.observation_space.shape[<span class="hljs-number">0</span>]<br>action_dim = env.action_space.n<br><br><span class="hljs-comment"># 创建PPO代理</span><br>agent = PPO(state_dim, hidden_dim, action_dim, actor_lr, critic_lr, lmbda,<br>            epochs, eps, gamma, device)<br><br><span class="hljs-comment"># 定义模型保存路径</span><br>model_save_path = <span class="hljs-string">&quot;model/ppo_model.pth&quot;</span><br><br><span class="hljs-comment"># 加载模型或训练新模型</span><br>agent.load_model(model_save_path)<br><br><span class="hljs-comment"># 训练或测试代理</span><br>return_list = rl_utils.train_on_policy_agent(env, agent, num_episodes)<br><br>agent.save_model(model_save_path)<br><br><span class="hljs-comment"># 绘制训练曲线</span><br>episodes_list = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(return_list)))<br>plt.plot(episodes_list, return_list)<br>plt.xlabel(<span class="hljs-string">&#x27;num_episodes&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;reward&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;PPO on &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(env_name))<br>plt.show()<br></code></pre></td></tr></table></figure><p>测试代码，test</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> gymnasium <span class="hljs-keyword">as</span> gym<br><span class="hljs-keyword">import</span> flappy_bird_gymnasium<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> time <span class="hljs-keyword">import</span> sleep<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-comment"># 定义游戏环境和设备</span><br>env = gym.make(<span class="hljs-string">&quot;FlappyBird-v0&quot;</span>, render_mode=<span class="hljs-string">&quot;human&quot;</span>)<br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br><br><span class="hljs-comment"># 定义模型路径</span><br>model_path = <span class="hljs-string">&quot;ppo_model.pth&quot;</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PolicyNet</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, state_dim, hidden_dim, action_dim</span>):<br>        <span class="hljs-built_in">super</span>(PolicyNet, self).__init__()<br>        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)<br>        self.fc2 = torch.nn.Linear(hidden_dim, action_dim)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = F.relu(self.fc1(x))<br>        <span class="hljs-keyword">return</span> F.softmax(self.fc2(x), dim=<span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># 定义 PPO 代理类</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PPOAgent</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, state_dim, hidden_dim, action_dim, model_path</span>):<br>        self.model = PolicyNet(state_dim, hidden_dim, action_dim).to(device)<br>        self.model.load_state_dict(torch.load(model_path)[<span class="hljs-string">&#x27;actor&#x27;</span>])  <span class="hljs-comment"># 加载模型的 &#x27;actor&#x27; 部分</span><br>        self.model.<span class="hljs-built_in">eval</span>()  <span class="hljs-comment"># 设置模型为评估模式</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">take_action</span>(<span class="hljs-params">self, state</span>):<br>        state_tensor = torch.tensor([state], dtype=torch.<span class="hljs-built_in">float</span>).to(device)<br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            action = self.model(state_tensor).argmax().item()<br>        <span class="hljs-keyword">return</span> action<br><br><span class="hljs-comment"># 创建 PPO 代理</span><br>state_dim = env.observation_space.shape[<span class="hljs-number">0</span>]<br>action_dim = env.action_space.n<br>hidden_dim = <span class="hljs-number">64</span><br>agent = PPOAgent(state_dim, hidden_dim, action_dim, model_path)<br><br><span class="hljs-comment"># 运行游戏并观察动画</span><br>state, _ = env.reset()<br>done = <span class="hljs-literal">False</span><br>total_reward = <span class="hljs-number">0</span><br><br><span class="hljs-keyword">try</span>:<br>    <span class="hljs-keyword">while</span> <span class="hljs-keyword">not</span> done:<br>        <span class="hljs-comment"># 使用代理选择动作</span><br>        action = agent.take_action(state)<br><br>        <span class="hljs-comment"># 执行动作并观察游戏动画</span><br>        next_state, reward, terminate, truncated, _ = env.step(action)<br>        done = terminate <span class="hljs-keyword">or</span> truncated<br>        total_reward += reward<br>        env.render()<br><br>        state = next_state<br><br><span class="hljs-keyword">finally</span>:<br>    <span class="hljs-comment"># 输出游戏得分</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;游戏结束，得分：<span class="hljs-subst">&#123;total_reward&#125;</span>&quot;</span>)<br>    <span class="hljs-comment"># 手动关闭游戏画面</span><br>    <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;按任意键关闭游戏画面...&quot;</span>)<br>    env.close()  <span class="hljs-comment"># 关闭游戏环境</span><br><br></code></pre></td></tr></table></figure><h2 id="补充知识"><a href="#补充知识" class="headerlink" title="补充知识"></a>补充知识</h2><p>价值方法： Sarsa、Qlearning、DQN<br>策略方法： Reinfore、Actor-Critic、A2C、TRPO、PPO、DDPC</p><p>on-policy（在策略） 的算法： Sarsa、Reinforce、Actor-Critic、A2C、TRPO、PPO<br>非on-policy算法：Qlearning，DQN，Double DQN<br>两者区别在于： on-policy是在线训练的，采样做预测做动作的思路。非on-policy离线训练。对于on-policy算法，采样先预测然后计算概率来采取动作。（on-policy是激进的，非on-policy是保守的。）</p><h2 id="挖坑"><a href="#挖坑" class="headerlink" title="挖坑"></a>挖坑</h2><h3 id="怎么使用tensorboar来进行可视化过程。"><a href="#怎么使用tensorboar来进行可视化过程。" class="headerlink" title="怎么使用tensorboar来进行可视化过程。"></a>怎么使用tensorboar来进行可视化过程。</h3><p>TensorBoard是一个可视化工具，它可以用来展示网络图、张量的指标变化、张量的分布情况等。特别是在训练网络的时候，我们可以设置不同的参数（比如：权重W、偏置B、卷积层数、全连接层数等），使用TensorBoader可以很直观的帮我们进行参数的选择。它通过运行一个本地服务器，来监听6006端口。在浏览器发出请求时，分析训练时记录的数据，绘制训练过程中的图像。</p>]]></content>
    
    
    
    <tags>
      
      <tag>填坑</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>经典网络结构-shuffleNet</title>
    <link href="/2024/04/30/deeplearnpaper5/"/>
    <url>/2024/04/30/deeplearnpaper5/</url>
    
    <content type="html"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/32304419">ShuffleNet论文参考</a><br><a href="https://arxiv.org/pdf/1707.01083">ShuffleNet的论文原文</a></p><h2 id="实践使用shuffleNet来实现垃圾的40分类"><a href="#实践使用shuffleNet来实现垃圾的40分类" class="headerlink" title="实践使用shuffleNet来实现垃圾的40分类"></a>实践使用shuffleNet来实现垃圾的40分类</h2><h3 id="划分固定数据集"><a href="#划分固定数据集" class="headerlink" title="划分固定数据集"></a>划分固定数据集</h3><p>在这里划分固定数据集，生成两个csv表，一个是训练集，一个是验证集</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs lua">import <span class="hljs-built_in">os</span><br>import csv<br>import numpy as np<br>train_path = <span class="hljs-string">&quot;train_data.csv&quot;</span><br>val_path = <span class="hljs-string">&quot;val_data.csv&quot;</span><br><br>train_percent = <span class="hljs-number">0.9</span><br><br>def create_data_txt(<span class="hljs-built_in">path</span>):<br>    f_train = <span class="hljs-built_in">open</span>(train_path,<span class="hljs-string">&quot;w&quot;</span>,newline=<span class="hljs-string">&quot;&quot;</span>)<br>    f_val = <span class="hljs-built_in">open</span>(val_path,<span class="hljs-string">&quot;w&quot;</span>,newline=<span class="hljs-string">&quot;&quot;</span>)<br>    train_writer = csv.writer(f_train)<br>    val_writer = csv.writer(f_val)<br><br>    <span class="hljs-keyword">for</span> cls,dirname <span class="hljs-keyword">in</span> enumerate(<span class="hljs-built_in">os</span>.listdir(<span class="hljs-built_in">path</span>)):<br>        flist = <span class="hljs-built_in">os</span>.listdir(<span class="hljs-built_in">os</span>.<span class="hljs-built_in">path</span>.join(<span class="hljs-built_in">path</span>,dirname))<br>        np.<span class="hljs-built_in">random</span>.shuffle(flist)<br>        fnum = <span class="hljs-built_in">len</span>(flist)<br>        <span class="hljs-keyword">for</span> i,filename <span class="hljs-keyword">in</span> enumerate(flist):<br>            <span class="hljs-keyword">if</span> i &lt; fnum*train_percent:<br>                train_writer.writerow([<span class="hljs-built_in">os</span>.<span class="hljs-built_in">path</span>.join(<span class="hljs-built_in">path</span>,dirname,filename),str(cls)])<br>            <span class="hljs-keyword">else</span>:<br>                val_writer.writerow([<span class="hljs-built_in">os</span>.<span class="hljs-built_in">path</span>.join(<span class="hljs-built_in">path</span>, dirname, filename), str(cls)])<br><br>    f_train.<span class="hljs-built_in">close</span>()<br>    f_val.<span class="hljs-built_in">close</span>()<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    create_data_txt(<span class="hljs-string">&quot;data_garbage&quot;</span>)<br></code></pre></td></tr></table></figure><h3 id="dataset-设置。"><a href="#dataset-设置。" class="headerlink" title="dataset 设置。"></a>dataset 设置。</h3><p>在这里设置数据预处理的操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms,utils<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset,DataLoader<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>train_tf = transforms.Compose([<br>    <span class="hljs-comment"># transforms.RandomResizedCrop(size=(224,224), scale=(0.9,1.1)),</span><br>    transforms.Resize(<span class="hljs-number">224</span>),<br>    transforms.CenterCrop((<span class="hljs-number">224</span>,<span class="hljs-number">224</span>)),<br>    transforms.RandomRotation(<span class="hljs-number">10</span>),<br>    transforms.ColorJitter(brightness=(<span class="hljs-number">0.9</span>,<span class="hljs-number">1.1</span>),contrast=(<span class="hljs-number">0.9</span>,<span class="hljs-number">1.1</span>)),<br>    <span class="hljs-comment"># transforms.Resize((50,50)),</span><br>    transforms.ToTensor(),<br>])<br><br>val_tf = transforms.Compose([<br>    transforms.Resize(<span class="hljs-number">224</span>),<br>    transforms.CenterCrop((<span class="hljs-number">224</span>, <span class="hljs-number">224</span>)),<br>    <span class="hljs-comment"># transforms.Grayscale(1),</span><br>    transforms.ToTensor(),<br>])<br><br><span class="hljs-comment">#自定义数据集</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Animals_dataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,istrain=<span class="hljs-literal">True</span></span>):<br>        <span class="hljs-keyword">if</span> istrain:<br>            f = <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;train_data.csv&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>)<br>        <span class="hljs-keyword">else</span>:<br>            f = <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;val_data.csv&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>)<br>        self.dataset = f.readlines()<br>        f.close()<br>        self.istrain = istrain<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.dataset)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>        data = self.dataset[index]<br>        img_path = data.split(<span class="hljs-string">&quot;,&quot;</span>)[<span class="hljs-number">0</span>]<br>        cls = <span class="hljs-built_in">int</span>(data.split(<span class="hljs-string">&quot;,&quot;</span>)[<span class="hljs-number">1</span>])<br><br>        img_data = Image.<span class="hljs-built_in">open</span>(img_path).convert(<span class="hljs-string">&quot;RGB&quot;</span>)<br>        <span class="hljs-keyword">if</span> self.istrain:<br>            dst = train_tf(img_data)<br>        <span class="hljs-keyword">else</span>:<br>            dst =val_tf(img_data)<br><br>        <span class="hljs-keyword">return</span> dst,torch.tensor(cls)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">visulization</span>():<br>    train_dataset = Animals_dataset(<span class="hljs-literal">True</span>)<br>    train_dataloader = DataLoader(train_dataset, batch_size=<span class="hljs-number">16</span>, shuffle=<span class="hljs-literal">True</span>)<br><br>    examples = <span class="hljs-built_in">enumerate</span>(train_dataloader)<br>    batch_index,(data, lable) = <span class="hljs-built_in">next</span>(examples)<br>    <span class="hljs-built_in">print</span>(data.shape)<br><br>    grid = utils.make_grid(data)<br>    plt.imshow(grid.numpy().transpose(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>))<br>    plt.show()<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    visulization()<br></code></pre></td></tr></table></figure><h3 id="训练代码"><a href="#训练代码" class="headerlink" title="训练代码"></a>训练代码</h3><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> optim,nn<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> dataset <span class="hljs-keyword">import</span> *<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> models<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt<br><br>m = nn.Softmax(dim=<span class="hljs-number">1</span>)<br>def train(<span class="hljs-keyword">method</span>=&quot;normal&quot;,ckpt_path=&quot;&quot;):<br>    # 数据集和数据加载器<br>    train_dataset = Animals_dataset(<span class="hljs-keyword">True</span>)<br>    train_dataloader = DataLoader(train_dataset, batch_size=<span class="hljs-number">32</span>, shuffle=<span class="hljs-keyword">True</span>)<br>    val_dataset = Animals_dataset(<span class="hljs-keyword">False</span>)<br>    val_dataloader = DataLoader(val_dataset, batch_size=<span class="hljs-number">32</span>, shuffle=<span class="hljs-keyword">False</span>)<br><br>    #模型<br>    device = torch.device(&quot;cuda&quot; <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> &quot;cpu&quot;)#系统自己决定有啥训练<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">method</span>==&quot;normal&quot;:<br>       # 创建ShuffleNet模型<br>        model = models.shufflenet_v2_x1_0(pretrained=<span class="hljs-keyword">True</span>)  # 使用预训练的ShuffleNetV2模型<br><br>        # 修改最后的全连接层以适应您的数据集<br>        num_ftrs = model.fc.in_features<br>        model.fc = nn.Linear(num_ftrs,<span class="hljs-number">40</span>)  # 将全连接层输出维度修改为您数据集的类别数<br>        model.<span class="hljs-keyword">to</span>(device)<br>    print(&quot;train on &quot;,device)<br>    #损失函数（二分类交叉熵）<br>    loss_fn = nn.CrossEntropyLoss()<br><br>    #优化器<br>    optimizer = optim.RMSprop(model.parameters(),lr=<span class="hljs-number">0.0001</span>)<br><br>    #断点恢复<br>    start_epoch = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">if</span> ckpt_path != &quot;&quot;:<br>        <span class="hljs-keyword">checkpoint</span> = torch.<span class="hljs-keyword">load</span>(ckpt_path)<br>        model.load_state_dict(<span class="hljs-keyword">checkpoint</span>[&quot;net&quot;])<br>        optimizer.load_state_dict(<span class="hljs-keyword">checkpoint</span>[&quot;optimizer&quot;])<br>        start_epoch = <span class="hljs-keyword">checkpoint</span>[&quot;epoch&quot;] + <span class="hljs-number">1</span><br><br>    #训练<br>    train_loss_arr = []<br>    train_acc_arr = []<br>    val_loss_arr = []<br>    val_acc_arr = []<br><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">30</span>):<br>        train_loss_total = <span class="hljs-number">0</span><br>        train_acc_total = <span class="hljs-number">0</span><br>        val_loss_total = <span class="hljs-number">0</span><br>        val_acc_total = <span class="hljs-number">0</span><br>        model.train()<br>        <span class="hljs-keyword">for</span> i,(train_x,train_y) <span class="hljs-keyword">in</span> enumerate(train_dataloader):<br>            train_x = train_x.<span class="hljs-keyword">to</span>(device)<br>            train_y = train_y.<span class="hljs-keyword">to</span>(device)<br><br>            train_y_pred = model(train_x)<br>            train_loss = loss_fn(train_y_pred.squeeze(),train_y)<br>            train_acc = (m(train_y_pred).max(dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>] == train_y).sum()/train_y.shape[<span class="hljs-number">0</span>]<br>            train_loss_total += train_loss.data.item()<br>            train_acc_total += train_acc.data.item()<br><br>            train_loss.backward()<br>            optimizer.step()<br>            optimizer.zero_grad()<br><br>            print(&quot;epoch:&#123;&#125; train_loss: &#123;&#125; train_acc: &#123;&#125;&quot;.format(epoch,train_loss.data.item(),train_acc.data.item()))<br>        <br>        train_loss_arr.append(train_loss_total / len(train_dataloader))<br>        train_acc_arr.append(train_acc_total / len(train_dataloader))<br><br>        model.eval()<br><br>        <span class="hljs-keyword">for</span> j, (val_x,val_y) <span class="hljs-keyword">in</span> enumerate(val_dataloader):<br>            val_x = val_x.<span class="hljs-keyword">to</span>(device)<br>            val_y = val_y.<span class="hljs-keyword">to</span>(device)<br><br>            val_y_pred = model(val_x)<br>            val_loss = loss_fn(val_y_pred.squeeze(),val_y)<br>            val_acc = (m(val_y_pred).max(dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>]==val_y).sum()/val_y.shape[<span class="hljs-number">0</span>]<br>            val_loss_total += val_loss.data.item()<br>            val_acc_total += val_acc.data.item()<br><br>        val_loss_arr.append(val_loss_total / len(val_dataloader))  # 平均值<br>        val_acc_arr.append(val_acc_total / len(val_dataloader))<br>        print(&quot;epoch:&#123;&#125; val_loss:&#123;&#125; val_acc:&#123;&#125;&quot;.format(epoch, val_loss_arr[<span class="hljs-number">-1</span>], val_acc_arr[<span class="hljs-number">-1</span>]))<br><br>    plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)   # 画布一分为二,<span class="hljs-number">1</span>行<span class="hljs-number">2</span>列，用第一个<br>    plt.title(&quot;loss&quot;)<br>    plt.plot(train_loss_arr, &quot;r&quot;, label=&quot;train&quot;)<br>    plt.plot(val_loss_arr, &quot;b&quot;, label=&quot;val&quot;)<br>    plt.legend()<br><br>    plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)  # 画布一分为二,<span class="hljs-number">1</span>行<span class="hljs-number">2</span>列，用第一个<br>    plt.title(&quot;acc&quot;)<br>    plt.plot(train_acc_arr, &quot;r&quot;, label=&quot;train&quot;)<br>    plt.plot(val_acc_arr, &quot;b&quot;, label=&quot;val&quot;)<br>    plt.legend()<br>    plt.savefig(&quot;loss_acc-1.png&quot;)<br><br>    plt.<span class="hljs-keyword">show</span>()<br><br>    # 保存模型<br>    # <span class="hljs-number">1.</span>torch.save()<br>    # <span class="hljs-number">2.</span>文件的后缀名：.pt、.pth、.pkl<br>    torch.save(model.state_dict(), r&quot;shuffeNet.pth&quot;)<br>    print(&quot;保存模型成功!&quot;)<br><br><br><br><span class="hljs-keyword">if</span> __name__ == &quot;__main__&quot;:<br>    train()<br><br><br>    train()<br><br><br></code></pre></td></tr></table></figure><h2 id="挖坑"><a href="#挖坑" class="headerlink" title="挖坑"></a>挖坑</h2><h3 id="什么是断点训练"><a href="#什么是断点训练" class="headerlink" title="什么是断点训练"></a>什么是断点训练</h3>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文思路——论文阅读文献</title>
    <link href="/2024/04/30/paper-idear3/"/>
    <url>/2024/04/30/paper-idear3/</url>
    
    <content type="html"><![CDATA[<p>阅读工具<a href="https://kimi.moonshot.cn/">Kimi</a></p><h2 id="论文阅读记录"><a href="#论文阅读记录" class="headerlink" title="论文阅读记录"></a>论文阅读记录</h2><ol><li><p><a href="https://ieeexplore.ieee.org/abstract/document/10179900">DICE-Net</a> 发表在IEEE Access 2022-2023年实时影响因子为3.9，中科院分区3区到4区。论文为OA论文，开源。<br>启发是对数据预处理的方法（比如RBP，SCC），一种未验证的双输入数据模型结构（注：我看来就是数据的通道加一）。这篇论文在公开 <a href="https://www.mdpi.com/2306-5729/8/6/95">数据集</a>  做的分类为CN&#x2F;AD,FTD&#x2F;CN,这么划分，是因为他要做对比实验，横向对比。实验结果是CN&#x2F;AD 的ACC为83.28%，SENS 79.81% ，SPEC 为87.94%, PREC为88.94%，F1为84.12% 。在FTD&#x2F;CN上ACC为74.96%，SENS 60.62% ，SPEC 为78.63%, PREC为64.01%，F1为62.27%<br><img src="/pic/lwsl2.png" alt="论文结果"></p></li><li><p><a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2023.1272834/full">静息状态下脑电信号多特征融合学习预测阿尔茨海默病</a> 2023年<br>这篇论文在AD&#x2F;FDT&#x2F;CN 三分类上达到了80.23%的准确率。论文中提到了（DICE-net），还提到了一篇论文使用Transformer-based methodlogy<a href="https://www.sciencedirect.com/science/article/abs/pii/S0378437122004642">链接</a>     在公开数据集SEED上进行情绪检测在三类问题上实现了83.03的准确率。<br>在2020年，一篇论文<a href="https://ieeexplore.ieee.org/document/9162148"></a>中使用了 Fast Fourier Transform （FFT）来进行数据预处理，然后经过处理的数据给入CNN网络，实现了79%的结果。<br><img src="/pic/lwsl3.png" alt="论文结果"><br>看着看着感觉这篇论文有点细节问题没有处理好。（注： 这篇论文有点小毛病,明明做的FDT的分类，为什么有MCI的标记呀）</p></li><li><p><a href="https://www.mdpi.com/2306-5729/8/6/95">A Dataset of Scalp EEG Recordings of Alzheimer’s Disease, Frontotemporal Dementia and Healthy Subjects from Routine EEG</a>提供了19通道的 (Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, and O2) 的脑电记录数据，有36个AD患者，23个FDT（前额叶痴呆），29个CN对照。数据包含了未经过伪迹处理的和已经经过伪迹处理的信号,同时论文中也使用了一定的方法来对数据进行处理。<br><img src="/pic/lwsl.png" alt="论文结果"><br>数据集获取链接<a href="https://openneuro.org/datasets/ds004504/versions/1.0.7">链接</a></p></li><li><p><a href="https://iopscience.iop.org/article/10.1088/1741-2552/ac05d8">Deep learning of resting-state electroencephalogram signals for three-class classification of Alzheimer’s disease, mild cognitive impairment and healthy ageing</a>2021年，使用AlexNet来作分类。进一步数据处理的方法为CWT，使用Adam，作为思路。</p></li></ol><h2 id="挖坑"><a href="#挖坑" class="headerlink" title="挖坑"></a>挖坑</h2><h3 id="公开数据集介绍"><a href="#公开数据集介绍" class="headerlink" title="公开数据集介绍"></a>公开数据集介绍</h3><p>This article provides a detailed description of a resting-state EEG dataset of individuals with Alzheimer’s disease and frontotemporal dementia, and healthy controls. The dataset was collected using a clinical EEG system with 19 scalp electrodes while participants were in a resting state with their eyes closed. The data collection process included rigorous quality control measures to ensure data accuracy and consistency. The dataset contains recordings of 36 Alzheimer’s patients, 23 frontotemporal dementia patients, and 29 healthy age-matched subjects.<br>提供了19通道的 (Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, and O2) 的脑电记录数据，有36个AD患者，23个FDT（前额叶痴呆），29个CN对照。数据包含了未经过伪迹处理的和已经经过伪迹处理的信号（伪迹处理的信号过程请参考论文）</p><h3 id="论文结构"><a href="#论文结构" class="headerlink" title="论文结构"></a>论文结构</h3><p>鉴于论文大修，所以我打算重新构建一下思路。</p><ol><li><p>标题</p></li><li><p>摘要</p></li><li><p>关键词</p></li><li><p>介绍</p></li><li><p>数据和方法</p></li><li><p>结果</p></li><li><p>讨论</p></li><li><p>参考文献</p></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>论文思路</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线性代数 —— 行列式</title>
    <link href="/2024/04/29/xianxindaishu/"/>
    <url>/2024/04/29/xianxindaishu/</url>
    
    <content type="html"><![CDATA[<p>神经元的工程实现使用了矩阵来作为工程学上的实现。线性代数研究向量空间和线性映射的理论。</p><h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><ol><li>行列式 ，行列式的概念和基本性质 行列式按行（列）展开定理 。</li><li>矩阵 ， 矩阵的概念， 矩阵的线性运算， 矩阵的乘法， 方阵的幂， 方阵乘积的行列式， 矩阵的转置，逆矩阵的概念和性质， 矩阵可逆的充分必要条件， 伴随矩阵，矩阵的初等变换，初等矩阵，矩阵的秩，矩阵的等价 分块矩阵及其运算。 </li><li>向量 ，向量的概念， 向量的线性组合和线性表示， 向量组的线性相关与线性无关， 向量组的极， 大线性无关组， 等价向量组， 向量组的秩， 向量组的秩与矩阵的秩之间的关系， 向量的内积 ，线性无关向量组的的正交规范化方法 。</li><li>线性方程组 ，线性方程组的克拉默（Cramer）法则， 齐次线性方程组有非零解的充分必要条件， 非齐次线性方程组有解的充分必要条件， 线性方程组解的性质和解的结构， 齐次线性方程组的基础解系和通解， 非齐次线性方程组的通解 。</li><li>矩阵的特征值和特征向量， 矩阵的特征值和特征向量的概念、性质， 相似矩阵的概念及性质， 矩阵可相似对角化的充分必要条件及相似对角矩阵， 实对称矩阵的特征值、特征向量及其相似对角矩阵 。</li><li>二次型 ，二次型及其矩阵表示，合同变换与合同矩阵，二次型的秩，惯性定理，二次型的标准形和规范形， 用正交变换和配方法化二次型为标准形，二次型及其矩阵的正定性。</li></ol><h2 id="行列式"><a href="#行列式" class="headerlink" title="行列式"></a>行列式</h2><p>包含十一个公式，行列式的计算公式。<br><img src="/pic/xxds-hls1.jpg" alt="行列式公式"></p><h3 id="公式三的例子"><a href="#公式三的例子" class="headerlink" title="公式三的例子"></a>公式三的例子</h3><table><thead><tr><th align="left"></th></tr></thead><tbody><tr><td align="left"><img src="/pic/xxds-hls2.jpg" alt="有规律的情况下，顺着规律相加减，会更简单"></td></tr><tr><td align="left"><img src="/pic/xxds-hls3.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-hls4.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-hls5.jpg"></td></tr></tbody></table><h3 id="公式四"><a href="#公式四" class="headerlink" title="公式四"></a>公式四</h3><table><thead><tr><th align="left"></th></tr></thead><tbody><tr><td align="left"><img src="/pic/xxds-hls6.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-hls7.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-hls8.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-hls9.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-hls10.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-hls11.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-hls12.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-hls13.jpg"></td></tr></tbody></table><h3 id="公式五"><a href="#公式五" class="headerlink" title="公式五"></a>公式五</h3><table><thead><tr><th align="left"></th></tr></thead><tbody><tr><td align="left"><img src="/pic/xxds-hls14.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-hls15.jpg"></td></tr></tbody></table><h3 id="公式六"><a href="#公式六" class="headerlink" title="公式六"></a>公式六</h3><table><thead><tr><th align="left"></th></tr></thead><tbody><tr><td align="left"><img src="/pic/xxds-hls16.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-hls17.jpg"></td></tr></tbody></table><h3 id="公式七"><a href="#公式七" class="headerlink" title="公式七"></a>公式七</h3><table><thead><tr><th align="left"></th></tr></thead><tbody><tr><td align="left"><img src="/pic/xxds-hls18.jpg"></td></tr></tbody></table><h3 id="公式八"><a href="#公式八" class="headerlink" title="公式八"></a>公式八</h3><table><thead><tr><th align="left"></th></tr></thead><tbody><tr><td align="left"><img src="/pic/xxds-hls19.jpg"></td></tr></tbody></table><h3 id="公式九"><a href="#公式九" class="headerlink" title="公式九"></a>公式九</h3><table><thead><tr><th align="left"></th></tr></thead><tbody><tr><td align="left"><img src="/pic/xxds-hls20.jpg"></td></tr></tbody></table><h3 id="公式十：范德蒙德行列式"><a href="#公式十：范德蒙德行列式" class="headerlink" title="公式十：范德蒙德行列式"></a>公式十：范德蒙德行列式</h3><table><thead><tr><th align="left"></th></tr></thead><tbody><tr><td align="left"><img src="/pic/xxds-hls21.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-hls22.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-hls23.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-hls24.jpg"></td></tr></tbody></table><h3 id="拉普拉斯行列式"><a href="#拉普拉斯行列式" class="headerlink" title="拉普拉斯行列式"></a>拉普拉斯行列式</h3><table><thead><tr><th align="left"></th></tr></thead><tbody><tr><td align="left"><img src="/pic/xxds-hls25.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-hls26.jpg"></td></tr></tbody></table><h3 id="代数余子式"><a href="#代数余子式" class="headerlink" title="代数余子式"></a>代数余子式</h3><table><thead><tr><th align="left"></th></tr></thead><tbody><tr><td align="left"><img src="/pic/xxds-hls27.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-hls28.jpg"></td></tr><tr><td align="left"><img src="/pic/xxds-hls29.jpg"></td></tr></tbody></table>]]></content>
    
    
    
    <tags>
      
      <tag>线性代数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>有意思的句子</title>
    <link href="/2024/04/29/juzhi4/"/>
    <url>/2024/04/29/juzhi4/</url>
    
    <content type="html"><![CDATA[<h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>腰有十文，必振衣作响；</p><p>每遇美人，必急色登床；</p><p>相逢故交，必装逼摆阔；</p><p>每与人言，必谈及贵戚；</p><p>施人小惠，必广布于众；</p><p>与人言谈，必刁言逞才；</p><p>当人前称兄道弟，背人后揭人隐私；</p><p>借钱时觍颜如乞，拖款时蛮横如王。</p><p>—— 改述自林语堂</p><h2 id="-1"><a href="#-1" class="headerlink" title=""></a></h2><p>小有姿色，则矫揉造作；</p><p>每逢故友，必揭人情史；</p><p>屡踩前任，且喋喋不休；</p><p>偶购名牌，必通告全网；</p><p>严人宽己，常自怜自艾；</p><p>妒人姻缘，必暗中破坏；</p><p>用你时姐妹情深，不用你音讯全无；</p><p>当人前惺惺作态，背人后口吐芬芳。</p>]]></content>
    
    
    
    <tags>
      
      <tag>句子</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>高等数学-函数、极限、连续</title>
    <link href="/2024/04/29/gaodengshuxue1/"/>
    <url>/2024/04/29/gaodengshuxue1/</url>
    
    <content type="html"><![CDATA[<p><a href="https://zhuanlan.zhihu.com/p/105704401">我在知乎学数学</a><br><a href="https://www.zhihu.com/question/336322284/answer/918067537">什么是微积分</a></p><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>最近需要解析梯度下降算法，对于矩阵搞不清楚怎么进行多矩阵的梯度下降，算起来是补充基础了。</p><p><img src="/pic/gaodengshuxue1.jpg" alt="数学的图"></p><h2 id="高等数学研究了什么问题？"><a href="#高等数学研究了什么问题？" class="headerlink" title="高等数学研究了什么问题？"></a>高等数学研究了什么问题？</h2><p>高等数学是由微积分学，较深入的代数学、几何学以及它们之间的交叉内容所形成的一门基础学科。主要内容包括：数列、极限、微积分、空间解析几何与线性代数、级数、常微分方程。初等数学研究的是常量与匀变量，高等数学研究的是非匀变量。</p><ol><li><p>函数、极限、连续。<br>函数的概念是什么？函数的有界性、单调性、周期性和奇偶性是什么？复合函数、反函数、分段函数和隐函数。基本初等函数的性质。函数关系的建立。<br>数列极限与函数极限的定义及其性质，函数的左极限与右极限，无穷小量和无穷大量的概念及其关系，无穷小量的性质及无穷小量的比较。极限的存在准则：单调有界性准则和夹逼准则，两个重要极限。<br>函数连续的概念，函数间断点的类型，初等函数的连续性，闭区间上连续函数的性质。</p></li><li><p>一元函数的微分的问题。什么是微分？导数、微分。<br>导数和微分的概念，导数的几何意义和物理意义，函数的可导性与连续性之间的关系。<br>平面曲线的切线和法线，导数和微分的四则运算，基本初等函数的导数，复合函数、反函数、隐函数以及参数方程所确定的函数的微分法，高阶段导数，一阶段微分形式的不变性，微分中值定理（罗尔中值定理，拉格朗日中值定理，泰勒定理，柯西中值定理），洛必达法则，函数单调性的判别，函数的极值，函数的凹凸性，拐点以及渐近线，函数图形的描绘，函数的最大小值。<br>弧微分，曲率的概念，曲率圆与曲率半径。</p></li><li><p>一元函数积分学。<br>原函数和不定积分的概念，不定积分的基本性质，基本积分公式，定积分的概念和基本性质，定积分中值定理，积分上限的函数及其导数，牛顿-莱布尼茨（Newton-Leibniz）公式，不定积分和定积分的换元积分法与分部积分法。<br>有理函数、三角函数的有理式和简单无理函数的积分，反常（广义）积分，定积分的应用（平面图形的面积，平面曲线的弧长，旋转体的体积及侧面积，平行截面积为已知的立体体积、功、引力、压力、质心、形心等）及函数平均值。</p></li><li><p>多元函数微分学。<br>多元函数的概念，二元函数的几何意义，二元函数的极限与连续的概念，有界闭区间上二元连续函数的性质，多元函数的偏导数和全微分，多元复合函数、隐函数的求导法，二阶偏导数，多元函数的极值和条件极值、最大值和最小值，二重积分的概念、基本性子和计算。</p></li><li><p>常微分方程。<br>常微分方程的基本概念，变量可分离的微分方程，齐次微分方程，一阶线性微分方程 ，可降阶的高阶微分方程，线性微分方程解的性质及解的结构定理，二阶常系数齐次线性微分方程， 高于二阶的某些常系数齐次线性微分方程，简单的二阶常系数非齐次线性微分方程 ，微分方程的简单应用</p></li></ol><h2 id="填坑"><a href="#填坑" class="headerlink" title="填坑"></a>填坑</h2><h3 id="函数的概念"><a href="#函数的概念" class="headerlink" title="函数的概念"></a>函数的概念</h3><p>在数学中，函数是一种对应关系，它将一个集合中的每个元素（称为自变量）映射到另一个集合中的唯一元素（称为因变量）。函数通常用一个符号表示，例如 f(x)，表示自变量为 x 时对应的因变量值。<br>函数的概念包括以下几个要点：</p><p>定义域（Domain）： 函数的定义域是指所有可能作为自变量的值的集合。函数在定义域内有定义。<br>值域（Range）： 函数的值域是指所有可能作为因变量的值的集合。对于实函数（实数到实数的映射），值域是函数的所有可能取值的集合。<br>图像（Graph）： 函数的图像是在坐标系中表示函数的一种方式，横轴表示自变量，纵轴表示因变量。函数的图像可以帮助我们直观地理解函数的性质。<br>对应关系（Correspondence）： 函数是一种对应关系，它确保了每个自变量都有唯一的因变量与之对应。<br>函数的表示方式： 函数可以通过公式、图表、数据表等方式来表示。常见的函数包括多项式函数、指数函数、对数函数、三角函数等。</p><p>注： 补充概念，数学中的“元”指未知数，常见的一元一次，二元一次。数学中的“项”代表由数与未知数还有运算符号组成的基本算术单元。“次”就是方程中未知数的乘方数。<br><img src="/pic/gaodengshuxue2.png" alt="一元二次方程组"></p><h3 id="函数的性质。"><a href="#函数的性质。" class="headerlink" title="函数的性质。"></a>函数的性质。</h3><p>函数的有界性、单调性、周期性和奇偶性是什么？</p><p>有界性（Boundedness）：一个函数在某个区间内是有界的，意味着存在一个常数M，使得函数的取值始终在一个特定的范围内，即|f(x)| ≤ M，对于所有的x在给定的区间内成立。如果一个函数既有上界又有下界，则称该函数在该区间内是有界的。<br>函数的有界性判断方法？</p><p>单调性（Monotonicity）：一个函数在某个区间内是单调的，意味着函数的值随着自变量的增加而增加或者随着自变量的减少而减少。如果函数在区间上满足f(x1) ≤ f(x2)对于任意x1 &lt; x2或者f(x1) ≥ f(x2)对于任意x1 &lt; x2，则称函数在该区间内是单调递增或单调递减的。<br>函数单调性判断方法？</p><ol><li>定义法</li><li>导数法</li></ol><p>周期性（Periodicity）：一个函数在某个区间内是周期的，意味着存在一个正数T，使得对于所有的x在该区间内，有f(x+T) &#x3D; f(x)。即函数在一个周期内重复。</p><p>奇偶性（Odd and Even）：一个函数的奇偶性指的是函数的对称性。如果对于所有的x在定义域内，有f(-x) &#x3D; -f(x)，则称函数是奇函数。如果对于所有的x在定义域内，有f(-x) &#x3D; f(x)，则称函数是偶函数。</p><h3 id="复合函数"><a href="#复合函数" class="headerlink" title="复合函数"></a>复合函数</h3><p>设函数y&#x3D;f(u)的定义域为Du，函数u&#x3D;g(x)的定义域为Dg，值域Rg。若Du和Rg的交集不为空集，则称函数y&#x3D;f[g(x) ]为函数y&#x3D;f(u)与函数u&#x3D;g(x )的复合函数，它的定义域为{x|x属于Dg，g(x)属于Du}。<br>例如：如果有函数f(x) &#x3D; x^2 和g(x) &#x3D; 2x +1,那么他们的复合函数f(g(x))就是先计算g(x)，得到2x+1，然后将2x+1作为f(x)的输入，最终得到f(g(x)) &#x3D; (2x+1)^2<br>复合函数的性质：</p><ol><li>结合律：即(f。g)。h&#x3D;f。(g。h)，其中。表示复合。</li><li>交换律：一般情况下，复合函数不满足交换律，即一般情况下f。g&#x3D;&#x2F;&#x3D;g。f</li><li>单位元：对于每个函数f(x)，都存在一个单位元函数e(x) &#x3D; x ，使得f。e &#x3D; f和e。f &#x3D; f</li></ol><h3 id="反函数"><a href="#反函数" class="headerlink" title="反函数"></a>反函数</h3><p>反函数是指一个函数的逆运算，如果函数f将集合A中的元素映射到集合B中的元素，那么f的反函数f^-1将集合B中的元素映射回集合A中的元素，使得f^-1(f(x))&#x3D;x对于所有x成立。<br>例如：如果有函数f(x) &#x3D; 2x ,它将实数集合中的每一个数映射到其自身的两倍，那么它的反函数就是f^-1(x) &#x3D; x&#x2F;2，将任意实数x映射回其的一半。反函数在数学中可以用来解决函数的逆运算问题。</p><h3 id="分段函数"><a href="#分段函数" class="headerlink" title="分段函数"></a>分段函数</h3><p>分段函数是指由多个部分组成的函数，每个部分在定义域的不同区间内具有不同的表达式。例如，绝对值函数就是一个常见的分段函数，它在正数区间和负数区间的表达式是不同的。分段函数用两个或两个以上的 式子表示，分段函数不是一个函数，判断分段函数的值域、运算、性质时，都需要在相应的定义域范围内进行。<br><a href="https://zhuanlan.zhihu.com/p/662140765">参考博客</a></p><h3 id="隐函数"><a href="#隐函数" class="headerlink" title="隐函数"></a>隐函数</h3><p>隐函数是由隐式方程所隐含定义的函数。设F（x,y）是某个定义域上的函数。如果存在定义域上的子集D，使得对每个x属于D，存在相应的y满足F(x,y)&#x3D;0，则称方程确定了一个隐函数。记为y&#x3D;y(x)。 [2]显函数是用y&#x3D;f(x)来表示的函数，显函数是相对于隐函数来说的。<br>如果在方程F(x,y)&#x3D;0中，当x取某区间内的任一值时，相应地总有满足此方程唯一的y值存在，那么方程F(x,y)&#x3D;0在该区间内确定了一个一元隐函数。类似若有一个三元方程F(x,y,z)&#x3D;0所确定的二元函数z&#x3D;f(x,)存在，则有可能确定一个二元隐函数。<br>例如，圆的方程 x^2 + y^2 &#x3D; r^2 中就包含了一个隐函数关系。<br><a href="https://www.zhihu.com/people/wo-zai-kan-19">参考博客</a></p><h3 id="基本初等函数的性质"><a href="#基本初等函数的性质" class="headerlink" title="基本初等函数的性质"></a>基本初等函数的性质</h3><p>基本初等函数包括常数函数、幂函数、指数函数、对数函数、三角函数和反三角函数等。它们具有一些常见的性质，如奇偶性、周期性、单调性等。例如，正弦函数是一个奇函数，具有周期性和单调性。（反三，对，幂，指，三）<br><img src="/pic/jbcdhs1.png" alt="常数函数"><br><img src="/pic/jbcdhs2.png" alt="幂函数"><br><img src="/pic/jbcdhs3.png" alt="指数函数"><br><img src="/pic/jbcdhs4.png" alt="对数函数"><br><img src="/pic/jbcdhs5.png" alt="三角函数-正弦函数"><br><img src="/pic/jbcdhs6.png" alt="三角函数-余弦函数"><br><img src="/pic/jbcdhs7.png" alt="三角函数-正切函数"><br><img src="/pic/jbcdhs8.png" alt="三角函数-余切函数"><br><img src="/pic/jbcdhs9.png" alt="反三角函数-反正弦函数"><br><img src="/pic/jbcdhs10.png" alt="反三角函数-反余弦函数"><br><img src="/pic/jbcdhs11.png" alt="反三角函数-反正切函数"><br><img src="/pic/jbcdhs12.png" alt="反三角函数-反余切函数"><br><a href="https://blog.csdn.net/chaotiantian/article/details/115029466">参考博客</a><br>注:初等函数是指可以由有限次常数函数、幂函数、指数函数、对数函数、三角函数和反三角函数通过有限次四则运算和复合运算（即函数的和、差、积、商以及函数的复合）构成的函数。</p><p><img src="/pic/sjhsgs1.png" alt="两角和公式"><br><img src="/pic/sjhsgs2.png" alt="倍角公式"><br><img src="/pic/sjhsgs3.png" alt="三倍角公式"><br><img src="/pic/sjhsgs4.png" alt="半角公式"><br><img src="/pic/sjhsgs5.png" alt="和差化积"><br><img src="/pic/sjhsgs6.png" alt="积化和差"><br><img src="/pic/sjhsgs7.png" alt="诱导公式"><br><img src="/pic/sjhsgs8.png" alt="万能公式"></p><h3 id="函数关系的建立："><a href="#函数关系的建立：" class="headerlink" title="函数关系的建立："></a>函数关系的建立：</h3><p>建立函数关系通常涉及到确定函数的表达式或规律，以描述输入和输出之间的关系。这可以通过观察规律、实验数据或者解决实际问题来完成。例如，建立两个变量之间的线性关系可以通过观察数据点来确定斜率和截距，从而建立线性函数的关系。、</p><h2 id="极限"><a href="#极限" class="headerlink" title="极限"></a>极限</h2><p>数列极限与函数极限的定义及其性质，函数的左极限与右极限，无穷小量和无穷大量的概念及其关系，无穷小量的性质及无穷小量的比较。极限的存在准则：单调有界性准则和夹逼准则，两个重要极限。</p><h3 id="数列极限与函数极限的定义及其性质："><a href="#数列极限与函数极限的定义及其性质：" class="headerlink" title="数列极限与函数极限的定义及其性质："></a>数列极限与函数极限的定义及其性质：</h3><p>数列极限的定义： 对于数列{an}，如果对于任何给定的正数E，存在正整数N，使得当n&gt;N时，有|an-A| &lt; E ,称数列{an}收敛于A，记住lim n 趋近于无穷an &#x3D; A<br>函数极限的定义： 设函数f(x)在点x0的某个去心领域内有定义，如果对于任意给定的正数E，存在正数&amp;，使得当0 &lt; |x - x0| &lt; &amp; 时，有|f(x) - A | &lt; E,则称函数f(x)在点x0处的极限为A，记住lim x——&gt;f(x) &#x3D; A<br>性质：数列和函数极限都具有唯一性、局部有界性、四则运算性质。<br><a href="https://zhuanlan.zhihu.com/p/350844135"></a></p><p>计算函数极限的方法有，带入计算，等价无穷小（泰勒展开的一阶展开。），泰勒展开，洛必达（只能乘除不能加减。）<br><img src="/pic/tailezhankai.png" alt="等价无穷小泰勒展开"><br><img src="/pic/tailezhankai2.png" alt="泰勒展开"><br><img src="/pic/tailezhankai3.png" alt="泰勒展开"></p><h3 id="背景补充"><a href="#背景补充" class="headerlink" title="背景补充"></a>背景补充</h3><p>微积分：分为微积与微分。 微积： 由无数个无穷小的面积组成的面积S，对应一元函数微分学。微分学的基本概念是导数，导数代表斜率，斜率刚好就是这条直线和夹角的正切值，就是说直线和x轴的夹角越大，就倾斜越大。但是对于曲线来讲，曲线跟直线不同，完全可以在不同的地方的倾斜程度是不一样的，所以，我们不能说一条曲线的倾斜程度（”斜率”）而只能说曲线在某个点的倾斜程度。故此，需要引入一个概念，切线观地看，就是刚好在这点“碰到”曲线的直线。因为切线是直线，所以切线有斜率，于是我们就可以用切线的斜率代表曲线在这点的倾斜程度。利用无穷小定义了一点上的切线，我们就可以理所当然地用过这点切线的斜率来表示曲线在这点的倾斜度了。</p>]]></content>
    
    
    
    <tags>
      
      <tag>高等数学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文思路——数据预处理</title>
    <link href="/2024/04/28/paper-idear2/"/>
    <url>/2024/04/28/paper-idear2/</url>
    
    <content type="html"><![CDATA[<h2 id="目前的数据预处理有"><a href="#目前的数据预处理有" class="headerlink" title="目前的数据预处理有"></a>目前的数据预处理有</h2><p>This may be time-domain features(时域特征)<a href="dx.doi.org/10.3390/diagnostics11081437">45——2021年</a></p><ol><li>absolute band power(绝对功率谱)</li><li>Discrete Wavelet Transform (离散小波变换)<a href="https://ieeexplore.ieee.org/document/9857825">37-2022-IEEE</a></li><li>permutation entropy (排列熵) or spectral entropy (熵谱)[21-2021-Complexity of EEG dynamics for early diagnosis of Alzheimer’s disease using permutation entropy neuromarker,’’ C]</li><li>coherence anaylysis features (相干性分析) such as spectrall coherece(光谱相干性)</li><li>RBP (注：按照下面的频率划分，the shape of data is [T , B ,C]&#x3D;[T, 5, C]，Delta: 0.5 – 4 Hz Theta: 4 – 8 Hz Alpha: 8 – 13 Hz Beta: 13-25 Hz Gamma: 25-45 Hz,或许这个数据预处理的方法会生效 )</li><li>spectral coherence connectivity (光谱相干性，光谱相干性建立在PSD，PSD是功率谱密度)</li><li>FFT (Fast Fourier Transform) 快速傅里叶变换</li></ol><h2 id="数据预处理组合思路"><a href="#数据预处理组合思路" class="headerlink" title="数据预处理组合思路"></a>数据预处理组合思路</h2><ol><li>Morlet Wavelet Transform ——&gt; RBP</li><li>Welch PSD ——&gt; SSC</li></ol><h2 id="需要注意的前提知识。"><a href="#需要注意的前提知识。" class="headerlink" title="需要注意的前提知识。"></a>需要注意的前提知识。</h2><ol><li>AD patients may exhaibit changes in the EEG signal, such as reduced(减少) alpha power (Alpha: 8 – 13 Hz ) and increased (增加) theta power (: 4 – 8 Hz).<a href="https://www.sciencedirect.com/science/article/abs/pii/S1388245721005976">39-2021-Clinical Neurophysiology-3区 </a><br>It can be visually observed that AD group has lower delta connectivity than CN group in multiple brain locations.This finding is supported by the literature  [53-2016]<a href="https://www.sciencedirect.com/science/article/pii/S1388245715009839()">https://www.sciencedirect.com/science/article/pii/S1388245715009839()</a></li><li>Train, validation and test sets are created.</li><li>The time frequency transforms and the feature extraction steps were implemented in Python 3.10 using the MNE library.</li><li>GFlops (计算量)</li><li>hyperparameters (超参数)</li></ol><h2 id="挖坑"><a href="#挖坑" class="headerlink" title="挖坑"></a>挖坑</h2><h3 id="怎么计算模型的计算量。"><a href="#怎么计算模型的计算量。" class="headerlink" title="怎么计算模型的计算量。"></a>怎么计算模型的计算量。</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 创建模型实例</span><br>model = IntegratedNet(<span class="hljs-attribute">input_size</span>=1, <span class="hljs-attribute">in_feature</span>=320)<br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>model = model.<span class="hljs-keyword">to</span>(device)<br><br><span class="hljs-comment"># 随机输入数据</span><br>x = torch.randn(1, 1, 11, 5120).<span class="hljs-keyword">to</span>(device)<br><br><span class="hljs-keyword">from</span> thop import<span class="hljs-built_in"> profile</span><br><span class="hljs-built_in"></span>flops, params = profile(model, inputs=(x,))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Total FLOPs:&#x27;</span>, flops)<br><br><br></code></pre></td></tr></table></figure><h2 id="看论文的心态"><a href="#看论文的心态" class="headerlink" title="看论文的心态"></a>看论文的心态</h2><p>Because it is an English paper, there is a kind of resistance. Take your time.<br>由于是英文论文，有种抗拒的心态。慢慢看吧。</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><ol><li><p>FFT快速傅里叶变换<a href="https://zhuanlan.zhihu.com/p/347091298">参考博客</a></p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">import os<br>import numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-built_in">from</span> tqdm import tqdm<br><br><span class="hljs-comment"># 定义输入和输出文件夹路径</span><br>input_folder = <span class="hljs-string">&#x27;data_cut_npy/AD&#x27;</span>  <span class="hljs-comment"># 输入文件夹路径，包含要进行 FFT 变换的 .npy 文件</span><br>output_folder = <span class="hljs-string">&#x27;data_FFT_npy/AD&#x27;</span>  <span class="hljs-comment"># 输出文件夹路径，用于保存变换后的数据</span><br><br><span class="hljs-comment"># 确保输出文件夹存在</span><br>os.makedirs(output_folder, exist_ok=True)<br><br><span class="hljs-comment"># 获取输入文件夹中的所有 .npy 文件</span><br>file_list = os.listdir(input_folder)<br>npy_files = [<span class="hljs-built_in">file</span> <span class="hljs-keyword">for</span> <span class="hljs-built_in">file</span> <span class="hljs-keyword">in</span> file_list <span class="hljs-keyword">if</span> <span class="hljs-built_in">file</span>.endswith(<span class="hljs-string">&#x27;.npy&#x27;</span>)]<br><br><span class="hljs-comment"># 遍历每个 .npy 文件进行 FFT 变换并保存</span><br><span class="hljs-keyword">for</span> file_name <span class="hljs-keyword">in</span> tqdm(npy_files, desc=<span class="hljs-string">&#x27;Processing&#x27;</span>, unit=<span class="hljs-string">&#x27;file&#x27;</span>):<br>    <span class="hljs-comment"># 读取 .npy 文件</span><br>    file_path = os.path.join(input_folder, file_name)<br>    data = np.<span class="hljs-built_in">load</span>(file_path)<br><br>    <span class="hljs-comment"># 对数据中的每一行进行 FFT 变换</span><br>    fft_data = np.apply_along_axis(np.fft.fft, axis=<span class="hljs-number">0</span>, arr=data)<br><br>    <span class="hljs-comment"># 获取 FFT 结果的幅值</span><br>    fft_magnitude = np.<span class="hljs-built_in">abs</span>(fft_data)<br><br>    <span class="hljs-comment"># 构造输出文件路径</span><br>    output_file_name = file_name.<span class="hljs-built_in">replace</span>(<span class="hljs-string">&#x27;.npy&#x27;</span>, <span class="hljs-string">&#x27;_fft.npy&#x27;</span>)<br>    output_file_path = os.path.join(output_folder, output_file_name)<br><br>    <span class="hljs-comment"># 保存 FFT 结果</span><br>    np.save(output_file_path, fft_magnitude)<br><br></code></pre></td></tr></table></figure></li><li><p>RBP 按频率划分[T, C, B]</p></li></ol><h2 id="什么是时域和频域"><a href="#什么是时域和频域" class="headerlink" title="什么是时域和频域"></a>什么是时域和频域</h2><p><a href="https://zhuanlan.zhihu.com/p/401681076">参考资料</a><br>原始的EEG数据是由很多个样本点数所构成的一个有限的离散的时间序列数据。至于样本点数的多少，则由采样率所决定，比如采样率为1000Hz，那么每秒就有1000个数据样本点。其中，每个样本点数据代表的是脑电波幅的大小，物理学上称为电压值，单位为伏特（V），由于脑电信号通常较弱，所以更常使用的单位为微伏（uV）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> mne<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">process_and_save_set_files</span>(<span class="hljs-params">input_folder, output_folder</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">process_data</span>(<span class="hljs-params">raw</span>):<br>        <span class="hljs-comment"># 获取信号数据</span><br>        data = raw.get_data() <span class="hljs-comment"># shape: (n_channels, n_samples)</span><br><br>        <span class="hljs-comment"># 定义频率范围</span><br>        freq_ranges = &#123;<br>            <span class="hljs-string">&#x27;Delta&#x27;</span>: (<span class="hljs-number">0.5</span>, <span class="hljs-number">4</span>),<br>            <span class="hljs-string">&#x27;Theta&#x27;</span>: (<span class="hljs-number">4</span>, <span class="hljs-number">8</span>),<br>            <span class="hljs-string">&#x27;Alpha&#x27;</span>: (<span class="hljs-number">8</span>, <span class="hljs-number">13</span>),<br>            <span class="hljs-string">&#x27;Beta&#x27;</span>: (<span class="hljs-number">13</span>, <span class="hljs-number">25</span>),<br>            <span class="hljs-string">&#x27;Gamma&#x27;</span>: (<span class="hljs-number">25</span>, <span class="hljs-number">45</span>)<br>        &#125;<br><br>        <span class="hljs-comment"># 初始化频带划分后的数据</span><br>        data_bands = []<br><br>        <span class="hljs-comment"># 对每个频带进行处理</span><br>        <span class="hljs-keyword">for</span> _, (fmin, fmax) <span class="hljs-keyword">in</span> freq_ranges.items():<br>            <span class="hljs-comment"># 使用 mne.filter 函数进行滤波</span><br>            filtered_data = mne.<span class="hljs-built_in">filter</span>.filter_data(data, raw.info[<span class="hljs-string">&#x27;sfreq&#x27;</span>], fmin, fmax)<br><br>            <span class="hljs-comment"># 将滤波后的数据存储到列表中</span><br>            data_bands.append(filtered_data)<br><br>        <span class="hljs-comment"># 将列表转换为numpy数组</span><br>        data_bands = np.array(data_bands)<br><br>        <span class="hljs-keyword">return</span> data_bands<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">find_set_files</span>(<span class="hljs-params">root_folder</span>):<br>        set_files = []<br>        <span class="hljs-keyword">for</span> root, dirs, files <span class="hljs-keyword">in</span> os.walk(root_folder):<br>            <span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> files:<br>                <span class="hljs-keyword">if</span> file.endswith(<span class="hljs-string">&#x27;.set&#x27;</span>):<br>                    set_files.append(os.path.join(root, file))<br>        <span class="hljs-keyword">return</span> set_files<br><br>    <span class="hljs-comment"># 找到所有的 .set 文件</span><br>    set_files = find_set_files(input_folder)<br><br>    <span class="hljs-keyword">for</span> file_path <span class="hljs-keyword">in</span> tqdm(set_files, desc=<span class="hljs-string">&#x27;Processing files&#x27;</span>):<br>        <span class="hljs-comment"># 读取 .set 文件</span><br>        raw = mne.io.read_raw_eeglab(file_path, preload=<span class="hljs-literal">True</span>)<br><br>        <span class="hljs-comment"># 处理数据</span><br>        processed_data = process_data(raw)<br><br>        <span class="hljs-comment"># 构造新的文件路径</span><br>        npy_file_name = os.path.basename(file_path).replace(<span class="hljs-string">&#x27;.set&#x27;</span>, <span class="hljs-string">&#x27;.npy&#x27;</span>)<br>        npy_file_path = os.path.join(output_folder, npy_file_name)<br><br>        <span class="hljs-comment"># 保存为 .npy 文件</span><br>        np.save(npy_file_path, processed_data)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-comment"># 指定您的 AD 文件夹路径和保存 .npy 文件的新文件夹路径</span><br>    ad_folder = <span class="hljs-string">r&#x27;C:/Users/Administrator/Desktop/RBP/data/FDT&#x27;</span><br>    output_folder = <span class="hljs-string">r&#x27;C:/Users/Administrator/Desktop/RBP/data_npy/FDT&#x27;</span><br><br>    <span class="hljs-comment"># 处理并保存数据</span><br>    process_and_save_set_files(ad_folder, output_folder)<br><br></code></pre></td></tr></table></figure><h2 id="赫兹-HZ-的定义是什么？"><a href="#赫兹-HZ-的定义是什么？" class="headerlink" title="赫兹(HZ)的定义是什么？"></a>赫兹(HZ)的定义是什么？</h2><p>Hz 是频率的单位。频率是指电脉冲，交流电波形，电磁波，声波和机械的振动周期循环时，1秒钟重复的次数。1Hz代表每秒钟周期震动1次，60Hz代表每秒周期震动60次。<br>对于声音，人类的听觉范围为20Hz～20000Hz，低于这个范围叫做次声波，高于这个范围的叫做超声波。<br>0. 提取set文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> shutil<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">find_set_files</span>(<span class="hljs-params">root_folder</span>):<br>    set_files = []<br>    <span class="hljs-keyword">for</span> root, dirs, files <span class="hljs-keyword">in</span> os.walk(root_folder):<br>        <span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> files:<br>            <span class="hljs-keyword">if</span> file.endswith(<span class="hljs-string">&#x27;.set&#x27;</span>):<br>                set_files.append(os.path.join(root, file))<br>    <span class="hljs-keyword">return</span> set_files<br><br><span class="hljs-comment"># 输入文件夹列表</span><br>input_folders = [<span class="hljs-string">&#x27;AD&#x27;</span>,<span class="hljs-string">&#x27;CN&#x27;</span>,<span class="hljs-string">&#x27;FDT&#x27;</span>]<br><br><span class="hljs-comment"># 目标文件夹列表</span><br>target_folders = [<span class="hljs-string">&#x27;data_processing/AD&#x27;</span>,<span class="hljs-string">&#x27;data_processing/CN&#x27;</span>,<span class="hljs-string">&#x27;data_processing/FDT&#x27;</span>]<br><br><span class="hljs-comment"># 确保输入和目标文件夹数量匹配</span><br><span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(input_folders) == <span class="hljs-built_in">len</span>(target_folders), <span class="hljs-string">&quot;输入文件夹和目标文件夹数量不匹配&quot;</span><br><br><span class="hljs-comment"># 遍历输入文件夹列表</span><br><span class="hljs-keyword">for</span> input_folder, target_folder <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(input_folders, target_folders):<br>    <span class="hljs-comment"># 找到所有的 .set 文件</span><br>    set_files = find_set_files(input_folder)<br>    <br>    <span class="hljs-comment"># 确保目标文件夹存在</span><br>    os.makedirs(target_folder, exist_ok=<span class="hljs-literal">True</span>)<br>    <br>    <span class="hljs-comment"># 打印所有找到的 .set 文件路径</span><br>    <span class="hljs-keyword">for</span> file_path <span class="hljs-keyword">in</span> set_files:<br>        <span class="hljs-built_in">print</span>(file_path)<br>        <br>        <span class="hljs-comment"># 将找到的 .set 文件复制到目标文件夹中</span><br>        shutil.copy(file_path, target_folder)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;复制 <span class="hljs-subst">&#123;file_path&#125;</span> 到 <span class="hljs-subst">&#123;target_folder&#125;</span>&quot;</span>)<br><br><br></code></pre></td></tr></table></figure><p>AD交集</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 原始通道列表</span><br>original_channels = [<span class="hljs-string">&#x27;PO3&#x27;</span>, <span class="hljs-string">&#x27;PO7&#x27;</span>, <span class="hljs-string">&#x27;P3&#x27;</span>, <span class="hljs-string">&#x27;P7&#x27;</span>, <span class="hljs-string">&#x27;CP1&#x27;</span>, <span class="hljs-string">&#x27;CP5&#x27;</span>, <span class="hljs-string">&#x27;Cz&#x27;</span>, <span class="hljs-string">&#x27;C3&#x27;</span>, <span class="hljs-string">&#x27;T7&#x27;</span>, <span class="hljs-string">&#x27;FC5&#x27;</span>, <span class="hljs-string">&#x27;FC1&#x27;</span>, <span class="hljs-string">&#x27;F7&#x27;</span>, <span class="hljs-string">&#x27;F3&#x27;</span>, <span class="hljs-string">&#x27;Fz&#x27;</span>, <span class="hljs-string">&#x27;AF3&#x27;</span>, <span class="hljs-string">&#x27;FP1&#x27;</span>, <span class="hljs-string">&#x27;FP2&#x27;</span>, <span class="hljs-string">&#x27;AF4&#x27;</span>, <span class="hljs-string">&#x27;F4&#x27;</span>, <span class="hljs-string">&#x27;F8&#x27;</span>, <span class="hljs-string">&#x27;FC2&#x27;</span>, <span class="hljs-string">&#x27;FC6&#x27;</span>, <span class="hljs-string">&#x27;C4&#x27;</span>, <span class="hljs-string">&#x27;T8&#x27;</span>, <span class="hljs-string">&#x27;CP6&#x27;</span>, <span class="hljs-string">&#x27;CP2&#x27;</span>, <span class="hljs-string">&#x27;P8&#x27;</span>, <span class="hljs-string">&#x27;P4&#x27;</span>, <span class="hljs-string">&#x27;Pz&#x27;</span>, <span class="hljs-string">&#x27;PO8&#x27;</span>, <span class="hljs-string">&#x27;PO4&#x27;</span>, <span class="hljs-string">&#x27;OZ&#x27;</span>, <span class="hljs-string">&#x27;Status&#x27;</span>]<br><br><span class="hljs-comment"># 所需通道列表</span><br>channels = [<span class="hljs-string">&#x27;Fp1&#x27;</span>, <span class="hljs-string">&#x27;Fp2&#x27;</span>, <span class="hljs-string">&#x27;F7&#x27;</span>, <span class="hljs-string">&#x27;F3&#x27;</span>, <span class="hljs-string">&#x27;Fz&#x27;</span>, <span class="hljs-string">&#x27;F4&#x27;</span>, <span class="hljs-string">&#x27;F8&#x27;</span>, <span class="hljs-string">&#x27;T3&#x27;</span>, <span class="hljs-string">&#x27;C3&#x27;</span>, <span class="hljs-string">&#x27;Cz&#x27;</span>, <span class="hljs-string">&#x27;C4&#x27;</span>, <span class="hljs-string">&#x27;T4&#x27;</span>, <span class="hljs-string">&#x27;T5&#x27;</span>, <span class="hljs-string">&#x27;P3&#x27;</span>, <span class="hljs-string">&#x27;Pz&#x27;</span>, <span class="hljs-string">&#x27;P4&#x27;</span>, <span class="hljs-string">&#x27;T6&#x27;</span>, <span class="hljs-string">&#x27;O1&#x27;</span>, <span class="hljs-string">&#x27;O2&#x27;</span>]<br><br>channels2 = [<span class="hljs-string">&#x27;Fp1&#x27;</span>, <span class="hljs-string">&#x27;Fp2&#x27;</span>, <span class="hljs-string">&#x27;F11&#x27;</span>, <span class="hljs-string">&#x27;F7&#x27;</span>, <span class="hljs-string">&#x27;F3&#x27;</span>, <span class="hljs-string">&#x27;Fz&#x27;</span>, <span class="hljs-string">&#x27;F4&#x27;</span>, <span class="hljs-string">&#x27;F8&#x27;</span>, <span class="hljs-string">&#x27;F12&#x27;</span>, <span class="hljs-string">&#x27;FT11&#x27;</span>, <span class="hljs-string">&#x27;FC3&#x27;</span>, <span class="hljs-string">&#x27;FCz&#x27;</span>, <span class="hljs-string">&#x27;FC4&#x27;</span>, <span class="hljs-string">&#x27;FT12&#x27;</span>, <span class="hljs-string">&#x27;T7&#x27;</span>, <span class="hljs-string">&#x27;C3&#x27;</span>, <span class="hljs-string">&#x27;Cz&#x27;</span>, <span class="hljs-string">&#x27;C4&#x27;</span>, <span class="hljs-string">&#x27;T8&#x27;</span>, <span class="hljs-string">&#x27;CP3&#x27;</span>, <span class="hljs-string">&#x27;CPz&#x27;</span>, <span class="hljs-string">&#x27;CP4&#x27;</span>, <span class="hljs-string">&#x27;P7&#x27;</span>, <span class="hljs-string">&#x27;P3&#x27;</span>, <span class="hljs-string">&#x27;Pz&#x27;</span>, <span class="hljs-string">&#x27;P4&#x27;</span>, <span class="hljs-string">&#x27;P8&#x27;</span>, <span class="hljs-string">&#x27;O1&#x27;</span>, <span class="hljs-string">&#x27;Oz&#x27;</span>, <span class="hljs-string">&#x27;O2&#x27;</span>, <span class="hljs-string">&#x27;Status&#x27;</span>]<br><span class="hljs-comment"># 找出交集</span><br>intersection = list(<span class="hljs-built_in">set</span>(original_channels) &amp; <span class="hljs-built_in">set</span>(channels) &amp; <span class="hljs-built_in">set</span>(channels2))<br><br><span class="hljs-comment"># 打印交集通道</span><br><span class="hljs-built_in">print</span>(f<span class="hljs-string">&quot;交集通道: &#123;intersection&#125;&quot;</span>)<br><span class="hljs-built_in">print</span>(f<span class="hljs-string">&quot;交集通道数量: &#123;len(intersection)&#125;&quot;</span>)<br><br></code></pre></td></tr></table></figure><p>检查通道</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> mne<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">check_electrode_order</span>(<span class="hljs-params">folder_path, expected_orders</span>):<br>    <span class="hljs-comment"># 获取文件夹中的所有EDF文件</span><br>    edf_files = [file <span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> os.listdir(folder_path) <span class="hljs-keyword">if</span> file.endswith(<span class="hljs-string">&#x27;.edf&#x27;</span>)]<br>    <br>    <span class="hljs-comment"># 初始化匹配计数</span><br>    match_counts = &#123;<span class="hljs-built_in">tuple</span>(order): <span class="hljs-number">0</span> <span class="hljs-keyword">for</span> order <span class="hljs-keyword">in</span> expected_orders&#125;<br>    <br>    <span class="hljs-comment"># 循环检查每个EDF文件的电极顺序</span><br>    <span class="hljs-keyword">for</span> edf_file <span class="hljs-keyword">in</span> edf_files:<br>        edf_file_path = os.path.join(folder_path, edf_file)<br><br>        <span class="hljs-comment"># 读取EDF文件</span><br>        raw = mne.io.read_raw_edf(edf_file_path, preload=<span class="hljs-literal">True</span>)<br><br>        <span class="hljs-comment"># 获取当前EDF文件的电极顺序</span><br>        current_order = raw.ch_names<br><br>        <span class="hljs-comment"># 检查电极顺序是否符合任何一个预期顺序</span><br>        matched = <span class="hljs-literal">False</span><br>        <span class="hljs-keyword">for</span> order <span class="hljs-keyword">in</span> expected_orders:<br>            <span class="hljs-keyword">if</span> current_order == order:<br>                match_counts[<span class="hljs-built_in">tuple</span>(order)] += <span class="hljs-number">1</span><br>                matched = <span class="hljs-literal">True</span><br>                <span class="hljs-keyword">break</span><br><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> matched:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;edf_file&#125;</span>: Electrode order is incorrect. Current order: <span class="hljs-subst">&#123;current_order&#125;</span>&quot;</span>)<br>    <br>    <span class="hljs-keyword">for</span> order, count <span class="hljs-keyword">in</span> match_counts.items():<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Order <span class="hljs-subst">&#123;<span class="hljs-built_in">list</span>(order)&#125;</span> matches <span class="hljs-subst">&#123;count&#125;</span> files.channal is <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(<span class="hljs-built_in">list</span>(order))&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># 替换为实际的文件夹路径和期望的电极顺序</span><br>folder_path = <span class="hljs-string">&quot;data/NC&quot;</span><br>expected_orders = [<br>    [<span class="hljs-string">&#x27;Fp1&#x27;</span>, <span class="hljs-string">&#x27;Fp2&#x27;</span>, <span class="hljs-string">&#x27;F7&#x27;</span>, <span class="hljs-string">&#x27;F3&#x27;</span>, <span class="hljs-string">&#x27;Fz&#x27;</span>, <span class="hljs-string">&#x27;F4&#x27;</span>, <span class="hljs-string">&#x27;F8&#x27;</span>, <span class="hljs-string">&#x27;T3&#x27;</span>, <span class="hljs-string">&#x27;C3&#x27;</span>, <span class="hljs-string">&#x27;Cz&#x27;</span>, <span class="hljs-string">&#x27;C4&#x27;</span>, <span class="hljs-string">&#x27;T4&#x27;</span>, <span class="hljs-string">&#x27;T5&#x27;</span>, <span class="hljs-string">&#x27;P3&#x27;</span>, <span class="hljs-string">&#x27;Pz&#x27;</span>, <span class="hljs-string">&#x27;P4&#x27;</span>, <span class="hljs-string">&#x27;T6&#x27;</span>, <span class="hljs-string">&#x27;O1&#x27;</span>, <span class="hljs-string">&#x27;O2&#x27;</span>, <span class="hljs-string">&#x27;Status&#x27;</span>],<br>    [<span class="hljs-string">&#x27;Fp1&#x27;</span>, <span class="hljs-string">&#x27;Fp2&#x27;</span>, <span class="hljs-string">&#x27;F3&#x27;</span>, <span class="hljs-string">&#x27;F4&#x27;</span>, <span class="hljs-string">&#x27;C3&#x27;</span>, <span class="hljs-string">&#x27;C4&#x27;</span>, <span class="hljs-string">&#x27;P3&#x27;</span>, <span class="hljs-string">&#x27;P4&#x27;</span>, <span class="hljs-string">&#x27;F7&#x27;</span>, <span class="hljs-string">&#x27;F8&#x27;</span>, <span class="hljs-string">&#x27;T7&#x27;</span>, <span class="hljs-string">&#x27;T8&#x27;</span>, <span class="hljs-string">&#x27;P7&#x27;</span>, <span class="hljs-string">&#x27;P8&#x27;</span>, <span class="hljs-string">&#x27;Fz&#x27;</span>, <span class="hljs-string">&#x27;Cz&#x27;</span>, <span class="hljs-string">&#x27;Pz&#x27;</span>, <span class="hljs-string">&#x27;FC1&#x27;</span>, <span class="hljs-string">&#x27;FC2&#x27;</span>, <span class="hljs-string">&#x27;CP1&#x27;</span>, <span class="hljs-string">&#x27;CP2&#x27;</span>, <span class="hljs-string">&#x27;FC5&#x27;</span>, <span class="hljs-string">&#x27;FC6&#x27;</span>, <span class="hljs-string">&#x27;CP5&#x27;</span>, <span class="hljs-string">&#x27;CP6&#x27;</span>, <span class="hljs-string">&#x27;AF3&#x27;</span>, <span class="hljs-string">&#x27;AF4&#x27;</span>, <span class="hljs-string">&#x27;PO3&#x27;</span>, <span class="hljs-string">&#x27;PO4&#x27;</span>, <span class="hljs-string">&#x27;PO7&#x27;</span>, <span class="hljs-string">&#x27;PO8&#x27;</span>, <span class="hljs-string">&#x27;Oz&#x27;</span>, <span class="hljs-string">&#x27;Status&#x27;</span>],<br>    [<span class="hljs-string">&#x27;Fp1&#x27;</span>, <span class="hljs-string">&#x27;Fp2&#x27;</span>, <span class="hljs-string">&#x27;F11&#x27;</span>, <span class="hljs-string">&#x27;F7&#x27;</span>, <span class="hljs-string">&#x27;F3&#x27;</span>, <span class="hljs-string">&#x27;Fz&#x27;</span>, <span class="hljs-string">&#x27;F4&#x27;</span>, <span class="hljs-string">&#x27;F8&#x27;</span>, <span class="hljs-string">&#x27;F12&#x27;</span>, <span class="hljs-string">&#x27;FT11&#x27;</span>, <span class="hljs-string">&#x27;FC3&#x27;</span>, <span class="hljs-string">&#x27;FCz&#x27;</span>, <span class="hljs-string">&#x27;FC4&#x27;</span>, <span class="hljs-string">&#x27;FT12&#x27;</span>, <span class="hljs-string">&#x27;T7&#x27;</span>, <span class="hljs-string">&#x27;C3&#x27;</span>, <span class="hljs-string">&#x27;Cz&#x27;</span>, <span class="hljs-string">&#x27;C4&#x27;</span>, <span class="hljs-string">&#x27;T8&#x27;</span>, <span class="hljs-string">&#x27;CP3&#x27;</span>, <span class="hljs-string">&#x27;CPz&#x27;</span>, <span class="hljs-string">&#x27;CP4&#x27;</span>, <span class="hljs-string">&#x27;P7&#x27;</span>, <span class="hljs-string">&#x27;P3&#x27;</span>, <span class="hljs-string">&#x27;Pz&#x27;</span>, <span class="hljs-string">&#x27;P4&#x27;</span>, <span class="hljs-string">&#x27;P8&#x27;</span>, <span class="hljs-string">&#x27;O1&#x27;</span>, <span class="hljs-string">&#x27;Oz&#x27;</span>, <span class="hljs-string">&#x27;O2&#x27;</span>, <span class="hljs-string">&#x27;Status&#x27;</span>],<br>    [<span class="hljs-string">&#x27;Fp1&#x27;</span>, <span class="hljs-string">&#x27;Fp2&#x27;</span>, <span class="hljs-string">&#x27;F11&#x27;</span>, <span class="hljs-string">&#x27;F7&#x27;</span>, <span class="hljs-string">&#x27;F3&#x27;</span>, <span class="hljs-string">&#x27;Fz&#x27;</span>, <span class="hljs-string">&#x27;F4&#x27;</span>, <span class="hljs-string">&#x27;F8&#x27;</span>, <span class="hljs-string">&#x27;F12&#x27;</span>, <span class="hljs-string">&#x27;FT11&#x27;</span>, <span class="hljs-string">&#x27;FC3&#x27;</span>, <span class="hljs-string">&#x27;FCz&#x27;</span>, <span class="hljs-string">&#x27;FC4&#x27;</span>, <span class="hljs-string">&#x27;FT12&#x27;</span>, <span class="hljs-string">&#x27;T7&#x27;</span>, <span class="hljs-string">&#x27;C3&#x27;</span>, <span class="hljs-string">&#x27;Cz&#x27;</span>, <span class="hljs-string">&#x27;C4&#x27;</span>, <span class="hljs-string">&#x27;T8&#x27;</span>, <span class="hljs-string">&#x27;CP3&#x27;</span>, <span class="hljs-string">&#x27;CPz&#x27;</span>, <span class="hljs-string">&#x27;CP4&#x27;</span>, <span class="hljs-string">&#x27;M1&#x27;</span>, <span class="hljs-string">&#x27;M2&#x27;</span>, <span class="hljs-string">&#x27;P7&#x27;</span>, <span class="hljs-string">&#x27;P3&#x27;</span>, <span class="hljs-string">&#x27;Pz&#x27;</span>, <span class="hljs-string">&#x27;P4&#x27;</span>, <span class="hljs-string">&#x27;P8&#x27;</span>, <span class="hljs-string">&#x27;O1&#x27;</span>, <span class="hljs-string">&#x27;Oz&#x27;</span>, <span class="hljs-string">&#x27;O2&#x27;</span>, <span class="hljs-string">&#x27;Trigger&#x27;</span>, <span class="hljs-string">&#x27;Status&#x27;</span>],<br>    [<span class="hljs-string">&#x27;Fp1&#x27;</span>, <span class="hljs-string">&#x27;Fp2&#x27;</span>, <span class="hljs-string">&#x27;F3&#x27;</span>, <span class="hljs-string">&#x27;F4&#x27;</span>, <span class="hljs-string">&#x27;C3&#x27;</span>, <span class="hljs-string">&#x27;C4&#x27;</span>, <span class="hljs-string">&#x27;P3&#x27;</span>, <span class="hljs-string">&#x27;P4&#x27;</span>, <span class="hljs-string">&#x27;F7&#x27;</span>, <span class="hljs-string">&#x27;F8&#x27;</span>, <span class="hljs-string">&#x27;T7&#x27;</span>, <span class="hljs-string">&#x27;T8&#x27;</span>, <span class="hljs-string">&#x27;P7&#x27;</span>, <span class="hljs-string">&#x27;P8&#x27;</span>, <span class="hljs-string">&#x27;Fz&#x27;</span>, <span class="hljs-string">&#x27;Cz&#x27;</span>, <span class="hljs-string">&#x27;Pz&#x27;</span>, <span class="hljs-string">&#x27;Oz&#x27;</span>, <span class="hljs-string">&#x27;FC1&#x27;</span>, <span class="hljs-string">&#x27;FC2&#x27;</span>, <span class="hljs-string">&#x27;CP1&#x27;</span>, <span class="hljs-string">&#x27;CP2&#x27;</span>, <span class="hljs-string">&#x27;FC5&#x27;</span>, <span class="hljs-string">&#x27;FC6&#x27;</span>, <span class="hljs-string">&#x27;CP5&#x27;</span>, <span class="hljs-string">&#x27;CP6&#x27;</span>, <span class="hljs-string">&#x27;ECG&#x27;</span>, <span class="hljs-string">&#x27;AF3&#x27;</span>, <span class="hljs-string">&#x27;AF4&#x27;</span>, <span class="hljs-string">&#x27;PO3&#x27;</span>, <span class="hljs-string">&#x27;PO4&#x27;</span>, <span class="hljs-string">&#x27;PO7&#x27;</span>, <span class="hljs-string">&#x27;PO8&#x27;</span>, <span class="hljs-string">&#x27;Status&#x27;</span>],<br>    [<span class="hljs-string">&#x27;Fp1&#x27;</span>, <span class="hljs-string">&#x27;Fp2&#x27;</span>, <span class="hljs-string">&#x27;Fz&#x27;</span>, <span class="hljs-string">&#x27;F3&#x27;</span>, <span class="hljs-string">&#x27;F4&#x27;</span>, <span class="hljs-string">&#x27;F7&#x27;</span>, <span class="hljs-string">&#x27;F8&#x27;</span>, <span class="hljs-string">&#x27;FCz&#x27;</span>, <span class="hljs-string">&#x27;FC3&#x27;</span>, <span class="hljs-string">&#x27;FC4&#x27;</span>, <span class="hljs-string">&#x27;FT7&#x27;</span>, <span class="hljs-string">&#x27;FT8&#x27;</span>, <span class="hljs-string">&#x27;Cz&#x27;</span>, <span class="hljs-string">&#x27;C3&#x27;</span>, <span class="hljs-string">&#x27;C4&#x27;</span>, <span class="hljs-string">&#x27;T3&#x27;</span>, <span class="hljs-string">&#x27;T4&#x27;</span>, <span class="hljs-string">&#x27;CPz&#x27;</span>, <span class="hljs-string">&#x27;CP3&#x27;</span>, <span class="hljs-string">&#x27;CP4&#x27;</span>, <span class="hljs-string">&#x27;TP7&#x27;</span>, <span class="hljs-string">&#x27;TP8&#x27;</span>, <span class="hljs-string">&#x27;Pz&#x27;</span>, <span class="hljs-string">&#x27;P3&#x27;</span>, <span class="hljs-string">&#x27;P4&#x27;</span>, <span class="hljs-string">&#x27;T5&#x27;</span>, <span class="hljs-string">&#x27;T6&#x27;</span>, <span class="hljs-string">&#x27;Oz&#x27;</span>, <span class="hljs-string">&#x27;O1&#x27;</span>, <span class="hljs-string">&#x27;O2&#x27;</span>, <span class="hljs-string">&#x27;HEOL&#x27;</span>, <span class="hljs-string">&#x27;HEOR&#x27;</span>, <span class="hljs-string">&#x27;Status&#x27;</span>],<br>    [<span class="hljs-string">&#x27;PO3&#x27;</span>, <span class="hljs-string">&#x27;PO7&#x27;</span>, <span class="hljs-string">&#x27;P3&#x27;</span>, <span class="hljs-string">&#x27;P7&#x27;</span>, <span class="hljs-string">&#x27;CP1&#x27;</span>, <span class="hljs-string">&#x27;CP5&#x27;</span>, <span class="hljs-string">&#x27;Cz&#x27;</span>, <span class="hljs-string">&#x27;C3&#x27;</span>, <span class="hljs-string">&#x27;T7&#x27;</span>, <span class="hljs-string">&#x27;FC5&#x27;</span>, <span class="hljs-string">&#x27;FC1&#x27;</span>, <span class="hljs-string">&#x27;F7&#x27;</span>, <span class="hljs-string">&#x27;F3&#x27;</span>, <span class="hljs-string">&#x27;Fz&#x27;</span>, <span class="hljs-string">&#x27;AF3&#x27;</span>, <span class="hljs-string">&#x27;FP1&#x27;</span>, <span class="hljs-string">&#x27;FP2&#x27;</span>, <span class="hljs-string">&#x27;AF4&#x27;</span>, <span class="hljs-string">&#x27;F4&#x27;</span>, <span class="hljs-string">&#x27;F8&#x27;</span>, <span class="hljs-string">&#x27;FC2&#x27;</span>, <span class="hljs-string">&#x27;FC6&#x27;</span>, <span class="hljs-string">&#x27;C4&#x27;</span>, <span class="hljs-string">&#x27;T8&#x27;</span>, <span class="hljs-string">&#x27;CP6&#x27;</span>, <span class="hljs-string">&#x27;CP2&#x27;</span>, <span class="hljs-string">&#x27;P8&#x27;</span>, <span class="hljs-string">&#x27;P4&#x27;</span>, <span class="hljs-string">&#x27;Pz&#x27;</span>, <span class="hljs-string">&#x27;PO8&#x27;</span>, <span class="hljs-string">&#x27;PO4&#x27;</span>, <span class="hljs-string">&#x27;OZ&#x27;</span>, <span class="hljs-string">&#x27;Status&#x27;</span>],<br>    [<span class="hljs-string">&#x27;Fp1&#x27;</span>, <span class="hljs-string">&#x27;Fp2&#x27;</span>, <span class="hljs-string">&#x27;AF3&#x27;</span>, <span class="hljs-string">&#x27;AF4&#x27;</span>, <span class="hljs-string">&#x27;F7&#x27;</span>, <span class="hljs-string">&#x27;F3&#x27;</span>, <span class="hljs-string">&#x27;Fz&#x27;</span>, <span class="hljs-string">&#x27;F4&#x27;</span>, <span class="hljs-string">&#x27;F8&#x27;</span>, <span class="hljs-string">&#x27;FC5&#x27;</span>, <span class="hljs-string">&#x27;FC1&#x27;</span>, <span class="hljs-string">&#x27;FC2&#x27;</span>, <span class="hljs-string">&#x27;FC6&#x27;</span>, <span class="hljs-string">&#x27;T7&#x27;</span>, <span class="hljs-string">&#x27;C3&#x27;</span>, <span class="hljs-string">&#x27;Cz&#x27;</span>, <span class="hljs-string">&#x27;C4&#x27;</span>, <span class="hljs-string">&#x27;T8&#x27;</span>, <span class="hljs-string">&#x27;CP5&#x27;</span>, <span class="hljs-string">&#x27;CP1&#x27;</span>, <span class="hljs-string">&#x27;CP2&#x27;</span>, <span class="hljs-string">&#x27;CP6&#x27;</span>, <span class="hljs-string">&#x27;P7&#x27;</span>, <span class="hljs-string">&#x27;P3&#x27;</span>, <span class="hljs-string">&#x27;Pz&#x27;</span>, <span class="hljs-string">&#x27;P4&#x27;</span>, <span class="hljs-string">&#x27;P8&#x27;</span>, <span class="hljs-string">&#x27;PO7&#x27;</span>, <span class="hljs-string">&#x27;PO3&#x27;</span>, <span class="hljs-string">&#x27;PO4&#x27;</span>, <span class="hljs-string">&#x27;PO8&#x27;</span>, <span class="hljs-string">&#x27;OZ&#x27;</span>, <span class="hljs-string">&#x27;AFZ&#x27;</span>, <span class="hljs-string">&#x27;Status&#x27;</span>]<br>]<br><br><span class="hljs-comment"># 执行检查</span><br>check_electrode_order(folder_path, expected_orders)<br><br></code></pre></td></tr></table></figure><p>数据预处理- 留一法验证</p><ol><li><p>随机划分数据集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> shutil<br><span class="hljs-keyword">import</span> random<br><br><span class="hljs-comment"># 指定包含数据文件的文件夹列表</span><br>data_folders = [<br>    <span class="hljs-string">&quot;guding_channl/AD&quot;</span>,<br>    <span class="hljs-string">&quot;guding_channl/CN&quot;</span>,<br>    <span class="hljs-string">&quot;guding_channl/MCI&quot;</span><br>]<br><br><span class="hljs-comment"># 对应的保存训练集和测试集的文件夹路径</span><br>train_folders = [<br>    <span class="hljs-string">&quot;data/train/AD&quot;</span>,<br>    <span class="hljs-string">&quot;data/train/CN&quot;</span>,<br>    <span class="hljs-string">&quot;data/train/MCI&quot;</span><br>]<br><br>test_folders = [<br>    <span class="hljs-string">&quot;data/test/AD&quot;</span>,<br>    <span class="hljs-string">&quot;data/test/CN&quot;</span>,<br>    <span class="hljs-string">&quot;data/test/MCI&quot;</span><br>]<br><br><span class="hljs-comment"># 确保输入和目标文件夹数量匹配</span><br><span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(data_folders) == <span class="hljs-built_in">len</span>(train_folders) == <span class="hljs-built_in">len</span>(test_folders), <span class="hljs-string">&quot;输入文件夹和目标文件夹数量不匹配&quot;</span><br><br><span class="hljs-comment"># 遍历每个数据文件夹</span><br><span class="hljs-keyword">for</span> data_folder, train_folder, test_folder <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(data_folders, train_folders, test_folders):<br>    <span class="hljs-comment"># 创建保存训练集和测试集的文件夹</span><br>    os.makedirs(train_folder, exist_ok=<span class="hljs-literal">True</span>)<br>    os.makedirs(test_folder, exist_ok=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-comment"># 获取数据文件夹中的所有文件</span><br>    data_files = os.listdir(data_folder)<br><br>    <span class="hljs-comment"># 遍历数据文件夹中的文件</span><br>    <span class="hljs-keyword">for</span> file_name <span class="hljs-keyword">in</span> data_files:<br>        source_file = os.path.join(data_folder, file_name)<br>        <span class="hljs-keyword">try</span>:<br>            <span class="hljs-comment"># 以8:2的比例将文件分配到训练集或测试集</span><br>            <span class="hljs-keyword">if</span> random.random() &lt; <span class="hljs-number">0.9</span>:<br>                shutil.copy(source_file, train_folder)<br>            <span class="hljs-keyword">else</span>:<br>                shutil.copy(source_file, test_folder)<br>        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;无法复制文件 <span class="hljs-subst">&#123;file_name&#125;</span>: <span class="hljs-subst">&#123;e&#125;</span>&quot;</span>)<br><br>    <span class="hljs-comment"># 打印训练集和测试集的文件数量</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;data_folder&#125;</span> -&gt; 训练集大小:&quot;</span>, <span class="hljs-built_in">len</span>(os.listdir(train_folder)))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;data_folder&#125;</span> -&gt; 测试集大小:&quot;</span>, <span class="hljs-built_in">len</span>(os.listdir(test_folder)))<br><br><br></code></pre></td></tr></table></figure></li><li><p>选取固定通道数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> mne<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># 定义所需通道的列表</span><br>channels = [<span class="hljs-string">&#x27;C3&#x27;</span>, <span class="hljs-string">&#x27;Fz&#x27;</span>, <span class="hljs-string">&#x27;F8&#x27;</span>, <span class="hljs-string">&#x27;F4&#x27;</span>, <span class="hljs-string">&#x27;C4&#x27;</span>, <span class="hljs-string">&#x27;F3&#x27;</span>, <span class="hljs-string">&#x27;Pz&#x27;</span>, <span class="hljs-string">&#x27;P4&#x27;</span>, <span class="hljs-string">&#x27;Cz&#x27;</span>, <span class="hljs-string">&#x27;P3&#x27;</span>, <span class="hljs-string">&#x27;F7&#x27;</span>]<br><span class="hljs-comment"># 输入和输出文件夹路径列表</span><br>input_folders = [<span class="hljs-string">&#x27;data/AD&#x27;</span>, <span class="hljs-string">&#x27;data/MCI&#x27;</span>, <span class="hljs-string">&#x27;data/NC&#x27;</span>, <span class="hljs-string">&#x27;公开数据集/AD&#x27;</span>, <span class="hljs-string">&#x27;公开数据集/CN&#x27;</span>]<br>output_folders = [<span class="hljs-string">&#x27;guding_channl/AD&#x27;</span>, <span class="hljs-string">&#x27;guding_channl/MCI&#x27;</span>, <span class="hljs-string">&#x27;guding_channl/CN&#x27;</span>, <span class="hljs-string">&#x27;guding_channl/AD&#x27;</span>, <span class="hljs-string">&#x27;guding_channl/CN&#x27;</span>]<br><br><span class="hljs-comment"># 定义函数来处理EDF文件</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">process_edf_file</span>(<span class="hljs-params">file_path, output_folder</span>):<br>    <span class="hljs-comment"># 读取EDF文件</span><br>    raw = mne.io.read_raw_edf(file_path, preload=<span class="hljs-literal">True</span>)<br>    <br>    <span class="hljs-comment"># 检查通道数量</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">all</span>(ch <span class="hljs-keyword">in</span> raw.ch_names <span class="hljs-keyword">for</span> ch <span class="hljs-keyword">in</span> channels):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;文件 <span class="hljs-subst">&#123;file_path&#125;</span> 不包含所有所需通道，跳过处理。&quot;</span>)<br>        <span class="hljs-keyword">return</span><br>    <br>    <span class="hljs-comment"># 删除不需要的通道，只保留指定的通道</span><br>    raw.pick_channels(channels)<br>    <br>    <span class="hljs-comment"># 按照指定顺序重新排列通道</span><br>    raw.reorder_channels(channels)<br>    <br>    <span class="hljs-comment"># 获取处理后的EEG数据</span><br>    eeg_data = raw.get_data()<br>    <br>    <span class="hljs-comment"># 获取文件名（不包含扩展名）</span><br>    file_name = os.path.splitext(os.path.basename(file_path))[<span class="hljs-number">0</span>]<br>    <br>    <span class="hljs-comment"># 构建保存路径</span><br>    save_path = os.path.join(output_folder, <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;file_name&#125;</span>_processed.npy&#x27;</span>)<br>    <br>    <span class="hljs-comment"># 保存处理后的EEG数据为npy文件</span><br>    np.save(save_path, eeg_data)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;处理并保存文件: <span class="hljs-subst">&#123;save_path&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># 定义函数来处理SET文件</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">process_set_file</span>(<span class="hljs-params">file_path, output_folder</span>):<br>    <span class="hljs-comment"># 读取SET文件</span><br>    raw = mne.io.read_raw_eeglab(file_path, preload=<span class="hljs-literal">True</span>)<br>    <br>    <span class="hljs-comment"># 检查通道数量</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">all</span>(ch <span class="hljs-keyword">in</span> raw.ch_names <span class="hljs-keyword">for</span> ch <span class="hljs-keyword">in</span> channels):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;文件 <span class="hljs-subst">&#123;file_path&#125;</span> 不包含所有所需通道，跳过处理。&quot;</span>)<br>        <span class="hljs-keyword">return</span><br>    <br>    <span class="hljs-comment"># 删除不需要的通道，只保留指定的通道</span><br>    raw.pick_channels(channels)<br>    <br>    <span class="hljs-comment"># 按照指定顺序重新排列通道</span><br>    raw.reorder_channels(channels)<br>    <br>    <span class="hljs-comment"># 获取处理后的EEG数据</span><br>    eeg_data = raw.get_data()<br>    <br>    <span class="hljs-comment"># 获取文件名（不包含扩展名）</span><br>    file_name = os.path.splitext(os.path.basename(file_path))[<span class="hljs-number">0</span>]<br>    <br>    <span class="hljs-comment"># 构建保存路径</span><br>    save_path = os.path.join(output_folder, <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;file_name&#125;</span>_processed.npy&#x27;</span>)<br>    <br>    <span class="hljs-comment"># 保存处理后的EEG数据为npy文件</span><br>    np.save(save_path, eeg_data)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;处理并保存文件: <span class="hljs-subst">&#123;save_path&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># 定义函数来处理文件，根据文件后缀选择处理方法</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">process_file</span>(<span class="hljs-params">file_path, output_folder</span>):<br>    file_extension = os.path.splitext(file_path)[<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">if</span> file_extension == <span class="hljs-string">&#x27;.edf&#x27;</span>:<br>        process_edf_file(file_path, output_folder)<br>    <span class="hljs-keyword">elif</span> file_extension == <span class="hljs-string">&#x27;.set&#x27;</span>:<br>        process_set_file(file_path, output_folder)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;文件 <span class="hljs-subst">&#123;file_path&#125;</span> 格式不支持，跳过处理。&quot;</span>)<br><br><br><span class="hljs-comment"># 确保文件夹数量相同</span><br><span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(input_folders) == <span class="hljs-built_in">len</span>(output_folders), <span class="hljs-string">&quot;输入和输出文件夹数量不匹配&quot;</span><br><br><span class="hljs-comment"># 创建新文件夹</span><br><span class="hljs-keyword">for</span> output_folder <span class="hljs-keyword">in</span> output_folders:<br>    os.makedirs(output_folder, exist_ok=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 遍历每个输入文件夹</span><br><span class="hljs-keyword">for</span> input_folder, output_folder <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(input_folders, output_folders):<br>    <span class="hljs-keyword">for</span> file_name <span class="hljs-keyword">in</span> os.listdir(input_folder):<br>        file_path = os.path.join(input_folder, file_name)<br>        <span class="hljs-comment"># 根据文件后缀选择处理方法</span><br>        process_file(file_path, output_folder)<br><br></code></pre></td></tr></table></figure></li><li><p>剪切数据集代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-comment"># 指定包含原始npy文件的文件夹路径列表</span><br>input_folders = [<span class="hljs-string">&#x27;data/test/AD&#x27;</span>, <span class="hljs-string">&#x27;data/test/CN&#x27;</span>,<span class="hljs-string">&#x27;data/test/MCI&#x27;</span>,<span class="hljs-string">&#x27;data/train/AD&#x27;</span>, <span class="hljs-string">&#x27;data/train/CN&#x27;</span>,<span class="hljs-string">&#x27;data/train/MCI&#x27;</span>]  <span class="hljs-comment"># 输入文件夹列表</span><br>output_folders = [<span class="hljs-string">&#x27;data_npy_cut/test/AD&#x27;</span>, <span class="hljs-string">&#x27;data_npy_cut/test/CN&#x27;</span>,<span class="hljs-string">&#x27;data_npy_cut/test/MCI&#x27;</span>,<span class="hljs-string">&#x27;data_npy_cut/train/AD&#x27;</span>, <span class="hljs-string">&#x27;data_npy_cut/train/CN&#x27;</span>,<span class="hljs-string">&#x27;data_npy_cut/train/MCI&#x27;</span>]  <span class="hljs-comment"># 对应的输出文件夹列表</span><br><br><span class="hljs-comment"># 确定剪切后的数据长度</span><br>cut_length = <span class="hljs-number">2048</span><br><br><span class="hljs-comment"># 确保输出文件夹存在</span><br><span class="hljs-keyword">for</span> output_folder <span class="hljs-keyword">in</span> output_folders:<br>    os.makedirs(output_folder, exist_ok=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 遍历文件夹列表</span><br><span class="hljs-keyword">for</span> input_folder, output_folder <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(input_folders, output_folders):<br>    <span class="hljs-keyword">for</span> file_name <span class="hljs-keyword">in</span> os.listdir(input_folder):<br>        <span class="hljs-keyword">if</span> file_name.endswith(<span class="hljs-string">&#x27;.npy&#x27;</span>):<br>            <span class="hljs-comment"># 加载原始npy文件</span><br>            data = np.load(os.path.join(input_folder, file_name))<br>            <br>            <span class="hljs-comment"># 确定剪切的段数</span><br>            num_cuts = data.shape[<span class="hljs-number">1</span>] // cut_length<br><br>            <span class="hljs-comment"># 使用tqdm显示进度条</span><br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(num_cuts), desc=<span class="hljs-string">f&#x27;Processing <span class="hljs-subst">&#123;file_name&#125;</span> in <span class="hljs-subst">&#123;input_folder&#125;</span>&#x27;</span>, unit=<span class="hljs-string">&#x27;cut&#x27;</span>):<br>                cut_data = data[:, i * cut_length : (i + <span class="hljs-number">1</span>) * cut_length]<br>                np.save(os.path.join(output_folder, <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;file_name[:-<span class="hljs-number">4</span>]&#125;</span>_cut_<span class="hljs-subst">&#123;i&#125;</span>.npy&#x27;</span>), cut_data)<br><br></code></pre></td></tr></table></figure></li><li><p>固定训练数据集</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> csv<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>train_path = &quot;train_data.csv&quot;<br>val_path = &quot;test_data.csv&quot;<br><br>def create_data_text(<span class="hljs-type">path</span>):<br>    &quot;&quot;&quot;建立数据data列表,划分数据集&quot;&quot;&quot;<br>    f_train = <span class="hljs-keyword">open</span>(train_path, &quot;w&quot;, newline=<span class="hljs-string">&#x27;&#x27;</span>) <br>    f_val = <span class="hljs-keyword">open</span>(val_path, &quot;w&quot;, newline=<span class="hljs-string">&#x27;&#x27;</span>)<br>    <br>    train_writer = csv.writer(f_train)<br>    val_writer = csv.writer(f_val)<br>    <br>    # 遍历 <span class="hljs-string">&#x27;train&#x27;</span> 文件夹<br>    train_dir = os.path.<span class="hljs-keyword">join</span>(<span class="hljs-type">path</span>, <span class="hljs-string">&#x27;train&#x27;</span>)<br>    <span class="hljs-keyword">for</span> cls, dirname <span class="hljs-keyword">in</span> enumerate(os.listdir(train_dir)):<br>        class_path = os.path.<span class="hljs-keyword">join</span>(train_dir, dirname)<br>        <span class="hljs-keyword">if</span> os.path.isdir(class_path):<br>            flist = os.listdir(class_path)<br>            np.random.shuffle(flist)<br>            fnum = len(flist)<br>            <span class="hljs-keyword">for</span> i, filename <span class="hljs-keyword">in</span> enumerate(flist):<br>                train_writer.writerow([os.path.<span class="hljs-keyword">join</span>(class_path, filename), str(cls)])<br>    <br>    # 遍历 <span class="hljs-string">&#x27;test&#x27;</span> 文件夹<br>    test_dir = os.path.<span class="hljs-keyword">join</span>(<span class="hljs-type">path</span>, <span class="hljs-string">&#x27;test&#x27;</span>)<br>    <span class="hljs-keyword">for</span> cls, dirname <span class="hljs-keyword">in</span> enumerate(os.listdir(test_dir)):<br>        class_path = os.path.<span class="hljs-keyword">join</span>(test_dir, dirname)<br>        <span class="hljs-keyword">if</span> os.path.isdir(class_path):<br>            flist = os.listdir(class_path)<br>            np.random.shuffle(flist)<br>            fnum = len(flist)<br>            <span class="hljs-keyword">for</span> i, filename <span class="hljs-keyword">in</span> enumerate(flist):<br>                val_writer.writerow([os.path.<span class="hljs-keyword">join</span>(class_path, filename), str(cls)])<br><br>    f_train.<span class="hljs-keyword">close</span>()<br>    f_val.<span class="hljs-keyword">close</span>()<br><br><span class="hljs-keyword">if</span> __name__ == &quot;__main__&quot;:<br>    create_data_text(&quot;data_npy_cut&quot;)<br><br><br></code></pre></td></tr></table></figure></li><li><p>十折交叉验证</p></li></ol><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><code class="hljs scss">import os<br>import math<br>import shutil<br><br>def <span class="hljs-built_in">split_data_into_folds</span>(data_folders, output_folders):<br>    for data_folder, output_folder in <span class="hljs-built_in">zip</span>(data_folders, output_folders):<br>        os.<span class="hljs-built_in">makedirs</span>(output_folder, exist_ok=True)<br><br>        # 获取数据集文件夹中的所有文件名<br>        all_files = os.<span class="hljs-built_in">listdir</span>(data_folder)<br><br>        # 每个折中的文件数<br>        files_per_fold = <span class="hljs-built_in">len</span>(all_files) // <span class="hljs-number">10</span><br><br>        # 按照每个折的文件数划分文件列表<br>        fold_files = [all_files[i:i+files_per_fold] for i in <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(all_files), files_per_fold)]<br><br>        # 保存到对应的折文件夹中<br>        for i, files_in_fold in <span class="hljs-built_in">enumerate</span>(fold_files):<br>            fold_path = os.path.<span class="hljs-built_in">join</span>(output_folder, f<span class="hljs-string">&#x27;fold_&#123;i+1&#125;&#x27;</span>)<br>            os.<span class="hljs-built_in">makedirs</span>(fold_path, exist_ok=True)<br>            for file_name in files_in_fold:<br>                shutil.<span class="hljs-built_in">copy</span>(os.path.<span class="hljs-built_in">join</span>(data_folder, file_name), fold_path)<br><br>        # 检测是否存在fold_11文件夹<br>        fold11_path = os.path.<span class="hljs-built_in">join</span>(output_folder, <span class="hljs-string">&#x27;fold_11&#x27;</span>)<br>        if os.path.<span class="hljs-built_in">exists</span>(fold11_path) and os.path.<span class="hljs-built_in">isdir</span>(fold11_path):<br>            # 将fold_11中的内容移动到fold_10中<br>            fold10_path = os.path.<span class="hljs-built_in">join</span>(output_folder, <span class="hljs-string">&#x27;fold_10&#x27;</span>)<br>            for file_name in os.<span class="hljs-built_in">listdir</span>(fold11_path):<br>                shutil.<span class="hljs-built_in">move</span>(os.path.<span class="hljs-built_in">join</span>(fold11_path, file_name), fold10_path)<br>            <br>            # 删除fold_11文件夹<br>            os.<span class="hljs-built_in">rmdir</span>(fold11_path)<br><br># 数据集文件夹路径列表<br>data_folders = [<span class="hljs-string">&#x27;guding_channl/AD&#x27;</span>, <span class="hljs-string">&#x27;guding_channl/MCI&#x27;</span>, <span class="hljs-string">&#x27;guding_channl/CN&#x27;</span>]<br><br># 输出文件夹路径列表<br>output_folders = [<span class="hljs-string">&#x27;output_folder/AD&#x27;</span>, <span class="hljs-string">&#x27;output_folder/MCI&#x27;</span>, <span class="hljs-string">&#x27;output_folder/CN&#x27;</span>]<br><br><span class="hljs-built_in">split_data_into_folds</span>(data_folders, output_folders)<br><br>def <span class="hljs-built_in">create_train_test_sets</span>(input_folder, output_folder, test_folders):<br>    for test_folder in test_folders:<br>        os.<span class="hljs-built_in">makedirs</span>(os.path.<span class="hljs-built_in">join</span>(output_folder, test_folder, <span class="hljs-string">&#x27;test&#x27;</span>, os.path.<span class="hljs-built_in">basename</span>(input_folder)), exist_ok=True)<br>        os.<span class="hljs-built_in">makedirs</span>(os.path.<span class="hljs-built_in">join</span>(output_folder, test_folder, <span class="hljs-string">&#x27;train&#x27;</span>, os.path.<span class="hljs-built_in">basename</span>(input_folder)), exist_ok=True)<br><br>        train_folders = [folder for folder in os.<span class="hljs-built_in">listdir</span>(input_folder) if folder != test_folder]<br><br>        for file_name in os.<span class="hljs-built_in">listdir</span>(os.path.<span class="hljs-built_in">join</span>(input_folder, test_folder)):<br>            shutil.<span class="hljs-built_in">copy</span>(os.path.<span class="hljs-built_in">join</span>(input_folder, test_folder, file_name), os.path.<span class="hljs-built_in">join</span>(output_folder, test_folder, <span class="hljs-string">&#x27;test&#x27;</span>, os.path.<span class="hljs-built_in">basename</span>(input_folder)))<br><br>        for train_folder in train_folders:<br>            for file_name in os.<span class="hljs-built_in">listdir</span>(os.path.<span class="hljs-built_in">join</span>(input_folder, train_folder)):<br>                shutil.<span class="hljs-built_in">copy</span>(os.path.<span class="hljs-built_in">join</span>(input_folder, train_folder, file_name), os.path.<span class="hljs-built_in">join</span>(output_folder, test_folder, <span class="hljs-string">&#x27;train&#x27;</span>, os.path.<span class="hljs-built_in">basename</span>(input_folder)))<br><br># 输入文件夹路径列表，包含三个文件夹 AD、MCI、CN<br>input_folders = [<span class="hljs-string">&#x27;output_folder/AD&#x27;</span>, <span class="hljs-string">&#x27;output_folder/MCI&#x27;</span>, <span class="hljs-string">&#x27;output_folder/CN&#x27;</span>]<br><br># 输出文件夹路径<br>output_folder = <span class="hljs-string">&#x27;output_folder_fixed&#x27;</span><br><br># 测试文件夹名称列表，代表每个input_folders中文件的参照测试文件夹<br>test_folders = [<span class="hljs-string">&#x27;fold_1&#x27;</span>, <span class="hljs-string">&#x27;fold_2&#x27;</span>, <span class="hljs-string">&#x27;fold_3&#x27;</span>, <span class="hljs-string">&#x27;fold_4&#x27;</span>, <span class="hljs-string">&#x27;fold_5&#x27;</span>, <span class="hljs-string">&#x27;fold_6&#x27;</span>, <span class="hljs-string">&#x27;fold_7&#x27;</span>, <span class="hljs-string">&#x27;fold_8&#x27;</span>, <span class="hljs-string">&#x27;fold_9&#x27;</span>, <span class="hljs-string">&#x27;fold_10&#x27;</span>]<br><br># 对每个输入文件夹调用函数<br>for input_folder in input_folders:<br>    <span class="hljs-built_in">create_train_test_sets</span>(input_folder, output_folder, test_folders)<br><br></code></pre></td></tr></table></figure><h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><p>mne库的文档链接<a href="https://mne.tools/dev/api/python_reference.html">链接</a><br>pywt库的<br>3. 连续小波变换 + RBP + 绘制图像的代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> scipy.signal <span class="hljs-keyword">import</span> welch<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_psd</span>(<span class="hljs-params">signal, fs, nperseg</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    使用Welch方法计算功率谱密度（PSD）。</span><br><span class="hljs-string"></span><br><span class="hljs-string">    参数:</span><br><span class="hljs-string">    - signal: 输入信号（二维数组：通道数 x 样本数）。</span><br><span class="hljs-string">    - fs: 采样频率（Hz）。</span><br><span class="hljs-string">    - nperseg: 每段的长度（样本数）。</span><br><span class="hljs-string"></span><br><span class="hljs-string">    返回:</span><br><span class="hljs-string">    - f: 频率数组。</span><br><span class="hljs-string">    - psd: 功率谱密度（PSD），形状为（通道数 x 频率数）。</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    psd_list = []<br>    <span class="hljs-keyword">for</span> ch_signal <span class="hljs-keyword">in</span> signal:<br>        f, psd_ch = welch(ch_signal, fs, nperseg=nperseg)<br>        psd_list.append(psd_ch)<br>    <span class="hljs-keyword">return</span> f, np.array(psd_list)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_rbp</span>(<span class="hljs-params">f, psd, freq_bands</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    计算相对波动指数（RBP）。</span><br><span class="hljs-string"></span><br><span class="hljs-string">    参数:</span><br><span class="hljs-string">    - f: 频率数组。</span><br><span class="hljs-string">    - psd: 功率谱密度（PSD），形状为（通道数 x 频率数）。</span><br><span class="hljs-string">    - freq_bands: 频段列表，每个频段是一个元组（开始频率，结束频率）。</span><br><span class="hljs-string"></span><br><span class="hljs-string">    返回:</span><br><span class="hljs-string">    - rbp: 相对波动指数（RBP），形状为（通道数 x 频段数）。</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    total_psd = np.<span class="hljs-built_in">sum</span>(psd, axis=<span class="hljs-number">1</span>, keepdims=<span class="hljs-literal">True</span>)<br>    rbp = []<br>    <span class="hljs-keyword">for</span> (f_start, f_end) <span class="hljs-keyword">in</span> freq_bands:<br>        band_power = np.<span class="hljs-built_in">sum</span>(psd[:, (f &gt;= f_start) &amp; (f &lt;= f_end)], axis=<span class="hljs-number">1</span>, keepdims=<span class="hljs-literal">True</span>)<br>        rbp.append(band_power / total_psd)<br>    <span class="hljs-keyword">return</span> np.hstack(rbp)<br><br><span class="hljs-comment"># 示例频段（可以根据实际需求调整）</span><br>freq_bands = [(<span class="hljs-number">0.5</span>, <span class="hljs-number">4</span>), (<span class="hljs-number">4</span>, <span class="hljs-number">8</span>), (<span class="hljs-number">8</span>, <span class="hljs-number">12</span>), (<span class="hljs-number">12</span>, <span class="hljs-number">30</span>), (<span class="hljs-number">30</span>, <span class="hljs-number">50</span>)]<br><br><span class="hljs-comment"># 处理一个文件夹中的所有 .npy 文件</span><br>input_folder = <span class="hljs-string">&#x27;data_npy_cut/test/AD/&#x27;</span>  <span class="hljs-comment"># 输入文件夹路径</span><br>output_folder = <span class="hljs-string">&#x27;PSD-RBP/test/AD&#x27;</span>  <span class="hljs-comment"># 输出文件夹路径</span><br><br><span class="hljs-comment"># 创建输出文件夹（如果不存在）</span><br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(output_folder):<br>    os.makedirs(output_folder)<br><br><span class="hljs-comment"># 处理文件夹中的所有 .npy 文件</span><br><span class="hljs-keyword">for</span> filename <span class="hljs-keyword">in</span> os.listdir(input_folder):<br>    <span class="hljs-keyword">if</span> filename.endswith(<span class="hljs-string">&#x27;.npy&#x27;</span>):<br>        input_file_path = os.path.join(input_folder, filename)<br>        output_file_path = os.path.join(output_folder, filename.split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;_rbp.npy&#x27;</span>)<br>        <br>        <span class="hljs-comment"># 加载输入数据</span><br>        signal = np.load(input_file_path)<br><br>        <span class="hljs-comment"># 检查输入信号的大小是否为 [19, 2500]</span><br>        <span class="hljs-keyword">assert</span> signal.shape == (<span class="hljs-number">19</span>, <span class="hljs-number">2500</span>), <span class="hljs-string">f&quot;Expected input signal shape to be (19, 2500), but got <span class="hljs-subst">&#123;signal.shape&#125;</span>&quot;</span><br><br>        <span class="hljs-comment"># 设置采样频率和每段的长度</span><br>        fs = <span class="hljs-number">500</span>  <span class="hljs-comment"># 采样频率（Hz）</span><br>        nperseg = <span class="hljs-number">128</span>  <span class="hljs-comment"># 每段的长度（样本数）</span><br><br>        <span class="hljs-comment"># 计算PSD</span><br>        f, psd = calculate_psd(signal, fs, nperseg)<br><br>        <span class="hljs-comment"># 计算RBP</span><br>        rbp = calculate_rbp(f, psd, freq_bands)<br><br>        <span class="hljs-comment"># 将RBP保存到新的 .npy 文件</span><br>        np.save(output_file_path, rbp)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Saved <span class="hljs-subst">&#123;output_file_path&#125;</span>&#x27;</span>)<br><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># 加载 .npy 文件</span><br>npy_file_path = <span class="hljs-string">&#x27;output.npy&#x27;</span>  <span class="hljs-comment"># 替换为实际的 .npy 文件路径</span><br>rbp_data = np.load(npy_file_path)<br><span class="hljs-built_in">print</span>(rbp_data.shape)<br><span class="hljs-comment"># 检查数据形状</span><br><span class="hljs-keyword">assert</span> rbp_data.shape == (<span class="hljs-number">19</span>, <span class="hljs-number">5</span>), <span class="hljs-string">f&quot;Expected RBP data shape to be (19, 5), but got <span class="hljs-subst">&#123;rbp_data.shape&#125;</span>&quot;</span><br><br><span class="hljs-comment"># 绘制 RBP 数据</span><br>channels = [<span class="hljs-string">&#x27;Fp1&#x27;</span>, <span class="hljs-string">&#x27;Fp2&#x27;</span>, <span class="hljs-string">&#x27;F7&#x27;</span>, <span class="hljs-string">&#x27;F3&#x27;</span>, <span class="hljs-string">&#x27;Fz&#x27;</span>, <span class="hljs-string">&#x27;F4&#x27;</span>, <span class="hljs-string">&#x27;F8&#x27;</span>, <span class="hljs-string">&#x27;T3&#x27;</span>, <span class="hljs-string">&#x27;C3&#x27;</span>, <span class="hljs-string">&#x27;Cz&#x27;</span>, <span class="hljs-string">&#x27;C4&#x27;</span>, <span class="hljs-string">&#x27;T4&#x27;</span>, <span class="hljs-string">&#x27;T5&#x27;</span>, <span class="hljs-string">&#x27;P3&#x27;</span>, <span class="hljs-string">&#x27;Pz&#x27;</span>, <span class="hljs-string">&#x27;P4&#x27;</span>, <span class="hljs-string">&#x27;T6&#x27;</span>, <span class="hljs-string">&#x27;O1&#x27;</span>, <span class="hljs-string">&#x27;O2&#x27;</span>]  <span class="hljs-comment"># 替换为实际的通道名称</span><br>freq_bands = [<span class="hljs-string">&#x27;0.5-4 Hz&#x27;</span>, <span class="hljs-string">&#x27;4-8 Hz&#x27;</span>, <span class="hljs-string">&#x27;8-12 Hz&#x27;</span>, <span class="hljs-string">&#x27;12-30 Hz&#x27;</span>, <span class="hljs-string">&#x27;30-50 Hz&#x27;</span>]  <span class="hljs-comment"># 替换为实际的频段名称</span><br><br>fig, ax = plt.subplots(figsize=(<span class="hljs-number">12</span>, <span class="hljs-number">8</span>))<br>cax = ax.matshow(rbp_data, cmap=<span class="hljs-string">&#x27;viridis&#x27;</span>)<br><br><span class="hljs-comment"># 设置颜色条</span><br>fig.colorbar(cax)<br><br><span class="hljs-comment"># 设置通道名称</span><br>ax.set_xticks(np.arange(<span class="hljs-built_in">len</span>(freq_bands)))<br>ax.set_xticklabels(freq_bands, rotation=<span class="hljs-number">45</span>, ha=<span class="hljs-string">&#x27;left&#x27;</span>)<br>ax.set_yticks(np.arange(<span class="hljs-built_in">len</span>(channels)))<br>ax.set_yticklabels(channels)<br><br><span class="hljs-comment"># 设置标签</span><br>plt.xlabel(<span class="hljs-string">&#x27;Frequency Bands&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;Channels&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;Relative Band Power (RBP) Heatmap&#x27;</span>)<br><br><span class="hljs-comment"># 显示图像</span><br>plt.tight_layout()  <span class="hljs-comment"># 调整布局以防止标签重叠</span><br>plt.show()<br><br></code></pre></td></tr></table></figure><ol start="4"><li><p>CWT + RBP</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pywt<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-comment"># 采样频率</span><br>fs = <span class="hljs-number">500</span><br><br><span class="hljs-comment"># 输入和输出文件夹路径列表</span><br>input_folders = [<span class="hljs-string">&#x27;data_npy_cut/train/AD/&#x27;</span>, <span class="hljs-string">&#x27;data_npy_cut/train/CN/&#x27;</span>,<span class="hljs-string">&#x27;data_npy_cut/train/FDT/&#x27;</span>]<br>output_folders = [<span class="hljs-string">&#x27;CWT-RBP/train/AD&#x27;</span>, <span class="hljs-string">&#x27;CWT-RBP/train/CN&#x27;</span>,<span class="hljs-string">&#x27;CWT-RBP/train/FDT&#x27;</span>]<br><br><br><span class="hljs-comment"># 确保文件夹数量相同</span><br><span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(input_folders) == <span class="hljs-built_in">len</span>(output_folders), <span class="hljs-string">&quot;输入和输出文件夹数量不匹配&quot;</span><br><br><span class="hljs-comment"># 创建新文件夹</span><br><span class="hljs-keyword">for</span> output_folder <span class="hljs-keyword">in</span> output_folders:<br>    os.makedirs(output_folder, exist_ok=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 小波函数</span><br>wavelet = <span class="hljs-string">&#x27;morl&#x27;</span><br><br><span class="hljs-comment"># 定义 CWT 的频率范围</span><br>freq_ranges = [(<span class="hljs-number">0.5</span>, <span class="hljs-number">4</span>), (<span class="hljs-number">4</span>, <span class="hljs-number">8</span>), (<span class="hljs-number">8</span>, <span class="hljs-number">13</span>), (<span class="hljs-number">13</span>, <span class="hljs-number">25</span>), (<span class="hljs-number">25</span>, <span class="hljs-number">45</span>)]<br>scales = np.arange(<span class="hljs-number">1</span>, <span class="hljs-number">128</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_rbp</span>(<span class="hljs-params">cwt_coeffs, freq_band, scales, fs</span>):<br>    min_scale = np.<span class="hljs-built_in">min</span>(np.where((fs / (scales * <span class="hljs-number">2</span>)) &lt;= freq_band[<span class="hljs-number">1</span>]))<br>    max_scale = np.<span class="hljs-built_in">max</span>(np.where((fs / (scales * <span class="hljs-number">2</span>)) &gt;= freq_band[<span class="hljs-number">0</span>]))<br>    band_power = np.<span class="hljs-built_in">sum</span>(np.<span class="hljs-built_in">abs</span>(cwt_coeffs[min_scale:max_scale + <span class="hljs-number">1</span>, :])**<span class="hljs-number">2</span>, axis=<span class="hljs-number">0</span>)<br>    total_power = np.<span class="hljs-built_in">sum</span>(np.<span class="hljs-built_in">abs</span>(cwt_coeffs)**<span class="hljs-number">2</span>, axis=<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">return</span> band_power / total_power<br><br><span class="hljs-comment"># 遍历输入文件夹</span><br><span class="hljs-keyword">for</span> input_folder, output_folder <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(input_folders, output_folders):<br>    <span class="hljs-keyword">for</span> file_name <span class="hljs-keyword">in</span> tqdm(os.listdir(input_folder)):<br>        <span class="hljs-keyword">if</span> file_name.endswith(<span class="hljs-string">&#x27;.npy&#x27;</span>):<br>            <span class="hljs-comment"># 读取 .npy 文件</span><br>            data = np.load(os.path.join(input_folder, file_name))<br>            <br>            <span class="hljs-comment"># 提取不同频段的数据</span><br>            data_freq_bands = []<br>            <span class="hljs-keyword">for</span> ch_data <span class="hljs-keyword">in</span> data:<br>                ch_data_freq_band = []<br>                <span class="hljs-comment"># 计算 CWT 系数</span><br>                cwt_coeffs, _ = pywt.cwt(ch_data, scales, wavelet, sampling_period=<span class="hljs-number">1</span>/fs)<br>                <span class="hljs-keyword">for</span> fmin, fmax <span class="hljs-keyword">in</span> freq_ranges:<br>                    <span class="hljs-comment"># 计算频段的相对功率谱密度 (RBP)</span><br>                    rbp = calculate_rbp(cwt_coeffs, (fmin, fmax), scales, fs)<br>                    ch_data_freq_band.append(rbp)<br>                data_freq_bands.append(ch_data_freq_band)<br>            <br>            <span class="hljs-comment"># 重塑数据形状为 [5, 19, 2500]</span><br>            data_freq_bands = np.array(data_freq_bands)<br>            data_freq_bands = np.transpose(data_freq_bands, (<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>))  <span class="hljs-comment"># [5, 19, 2500]</span><br>            <br>            <span class="hljs-comment"># 修改文件名，添加处理方法标记</span><br>            output_file_name = os.path.splitext(file_name)[<span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;_cwt_rbp.npy&#x27;</span><br>            output_file_path = os.path.join(output_folder, output_file_name)<br>            <br>            <span class="hljs-comment"># 保存处理后的数据</span><br>            np.save(output_file_path, data_freq_bands)<br><br></code></pre></td></tr></table></figure></li><li><p>FTBT + BRP<br>FTBT</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> scipy.fftpack <span class="hljs-keyword">import</span> fft, ifft<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-comment"># 采样频率</span><br>fs = <span class="hljs-number">500</span><br><br><span class="hljs-comment"># 输入和输出文件夹路径列表</span><br>input_folders = [<span class="hljs-string">&#x27;data_npy_cut/train/AD/&#x27;</span>, <span class="hljs-string">&#x27;data_npy_cut/train/CN/&#x27;</span>,<span class="hljs-string">&#x27;data_npy_cut/train/FDT/&#x27;</span>]<br>output_folders = [<span class="hljs-string">&#x27;FBFT/train/AD&#x27;</span>, <span class="hljs-string">&#x27;FBFT/train/CN&#x27;</span>,<span class="hljs-string">&#x27;FBFT/train/FDT&#x27;</span>]<br><br><span class="hljs-comment"># 确保文件夹数量相同</span><br><span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(input_folders) == <span class="hljs-built_in">len</span>(output_folders), <span class="hljs-string">&quot;输入和输出文件夹数量不匹配&quot;</span><br><br><span class="hljs-comment"># 创建新文件夹</span><br><span class="hljs-keyword">for</span> output_folder <span class="hljs-keyword">in</span> output_folders:<br>    os.makedirs(output_folder, exist_ok=<span class="hljs-literal">True</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">fbft</span>(<span class="hljs-params">signal</span>):<br>    N = <span class="hljs-built_in">len</span>(signal)<br>    forward_fft = fft(signal)<br>    backward_fft = fft(ifft(forward_fft))<br>    fbft_result = forward_fft + backward_fft<br>    <span class="hljs-keyword">return</span> fbft_result<br><br><span class="hljs-comment"># 遍历输入文件夹</span><br><span class="hljs-keyword">for</span> input_folder, output_folder <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(input_folders, output_folders):<br>    <span class="hljs-keyword">for</span> file_name <span class="hljs-keyword">in</span> tqdm(os.listdir(input_folder)):<br>        <span class="hljs-keyword">if</span> file_name.endswith(<span class="hljs-string">&#x27;.npy&#x27;</span>):<br>            <span class="hljs-comment"># 读取 .npy 文件</span><br>            data = np.load(os.path.join(input_folder, file_name))<br>            <br>            <span class="hljs-comment"># 对每个通道的数据进行 FBFT 操作</span><br>            fbft_data = []<br>            <span class="hljs-keyword">for</span> ch_data <span class="hljs-keyword">in</span> data:<br>                fbft_ch_data = fbft(ch_data)<br>                fbft_data.append(fbft_ch_data)<br>            <br>            <span class="hljs-comment"># 将结果转换为 numpy 数组</span><br>            fbft_data = np.array(fbft_data)<br>            <br>            <span class="hljs-comment"># 修改文件名，添加处理方法标记</span><br>            output_file_name = os.path.splitext(file_name)[<span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;_fbft.npy&#x27;</span><br>            output_file_path = os.path.join(output_folder, output_file_name)<br>            <br>            <span class="hljs-comment"># 保存处理后的数据</span><br>            np.save(output_file_path, fbft_data)<br><br><br></code></pre></td></tr></table></figure></li></ol><p>使用matlab代码对数据进行CWT变换</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-comment">% 设置数据文件夹和图像保存的根目录</span><br>dataDir = <span class="hljs-string">&#x27;E:\数据处理\data_npy_cut\test\FDT&#x27;</span>; <span class="hljs-comment">% 数据文件夹路径</span><br>outputDir = <span class="hljs-string">&#x27;E:\数据处理\处理后\test\2&#x27;</span>; <span class="hljs-comment">% 输出文件夹路径</span><br><br><span class="hljs-comment">% 添加 npy-matlab 工具包路径</span><br>addpath(<span class="hljs-string">&#x27;E:\数据处理\npy-matlab-master\npy-matlab&#x27;</span>); <span class="hljs-comment">% 替换为 npy-matlab 工具包的实际路径</span><br><br><span class="hljs-comment">% 获取文件夹中所有 npy 文件</span><br>files = dir(fullfile(dataDir, <span class="hljs-string">&#x27;*.npy&#x27;</span>));<br><span class="hljs-comment">% 设置采样率</span><br>fs = <span class="hljs-number">500</span>;<br><br><span class="hljs-comment">% 定义要处理的通道</span><br>channelsToProcess = [<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">16</span>,<span class="hljs-number">19</span>];<br><br><span class="hljs-comment">% 处理每个文件</span><br><span class="hljs-keyword">for</span> k = <span class="hljs-number">1</span>:<span class="hljs-built_in">length</span>(files)<br>    <span class="hljs-comment">% 读取数据</span><br>    filename = files(k).name;<br>    filepath = fullfile(dataDir, filename);<br>    data = readNPY(filepath);<br>    <br>    <span class="hljs-comment">% 创建输出文件夹</span><br>    [~, name, ~] = fileparts(filename);<br>    saveFolder = fullfile(outputDir, name);<br>    <span class="hljs-keyword">if</span> ~exist(saveFolder, <span class="hljs-string">&#x27;dir&#x27;</span>)<br>        mkdir(saveFolder);<br>    <span class="hljs-keyword">end</span><br>    <br>    <span class="hljs-comment">% 对选定通道执行 CWT 并保存图像</span><br>    <span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = channelsToProcess <span class="hljs-comment">% 只处理指定通道</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">i</span> &lt;= <span class="hljs-built_in">size</span>(data, <span class="hljs-number">1</span>) <span class="hljs-comment">% 确保通道索引有效</span><br>            [cfs, frequencies] = cwt(data(<span class="hljs-built_in">i</span>, :), fs);<br>            <span class="hljs-built_in">figure</span>;<br>            imagesc(<span class="hljs-number">1</span>:<span class="hljs-built_in">size</span>(data, <span class="hljs-number">2</span>), frequencies, <span class="hljs-built_in">abs</span>(cfs)); <span class="hljs-comment">% 绘制小波系数的幅度</span><br>            axis xy;<br>            xlabel(<span class="hljs-string">&#x27;Time (samples)&#x27;</span>);<br>            ylabel(<span class="hljs-string">&#x27;Frequency (Hz)&#x27;</span>);<br>            title([<span class="hljs-string">&#x27;CWT Magnitude of Channel &#x27;</span>, num2str(<span class="hljs-built_in">i</span>)]);<br>            <br>            <span class="hljs-comment">% 保存图像</span><br>            saveFileName = fullfile(saveFolder, sprintf(<span class="hljs-string">&#x27;Channel_%d.png&#x27;</span>, <span class="hljs-built_in">i</span>));<br>            saveas(gcf, saveFileName);<br>            close(gcf); <span class="hljs-comment">% 关闭图像窗口以节省资源</span><br>        <span class="hljs-keyword">end</span><br>    <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><p>图片转换为npy数据格式，二值化输入</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-comment"># 输入的文件夹列表和保存位置列表</span><br>folder_list = [<span class="hljs-string">&#x27;data/train/AD&#x27;</span>, <span class="hljs-string">&#x27;data/train/CN&#x27;</span>, <span class="hljs-string">&#x27;data/train/FDT&#x27;</span>,<span class="hljs-string">&#x27;data/test/AD&#x27;</span>,<span class="hljs-string">&#x27;data/test/CN&#x27;</span>,<span class="hljs-string">&#x27;data/test/FDT&#x27;</span>]<br>save_location_list = [<span class="hljs-string">&#x27;data-npy/train/AD&#x27;</span>, <span class="hljs-string">&#x27;data-npy/train/CN&#x27;</span>, <span class="hljs-string">&#x27;data-npy/train/FDT&#x27;</span>,<span class="hljs-string">&#x27;data-npy/test/AD&#x27;</span>,<span class="hljs-string">&#x27;data-npy/test/CN&#x27;</span>,<span class="hljs-string">&#x27;data-npy/test/FDT&#x27;</span>]<br><br><span class="hljs-comment"># 遍历文件夹列表</span><br><span class="hljs-keyword">for</span> folder, save_location <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(folder_list, save_location_list):<br>    <span class="hljs-comment"># 遍历第二层文件夹</span><br>    <span class="hljs-keyword">for</span> sub_folder <span class="hljs-keyword">in</span> os.listdir(folder):<br>        sub_folder_path = os.path.join(folder, sub_folder)<br>        <span class="hljs-comment"># 读取第二层文件夹中所有图片</span><br>        image_files = [f <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> os.listdir(sub_folder_path) <span class="hljs-keyword">if</span> os.path.isfile(os.path.join(sub_folder_path, f))]<br>        images_data = []<br>        <span class="hljs-comment"># 使用tqdm添加进度条</span><br>        <span class="hljs-keyword">for</span> image_file <span class="hljs-keyword">in</span> tqdm(image_files, desc=<span class="hljs-string">f&quot;Processing <span class="hljs-subst">&#123;sub_folder&#125;</span>&quot;</span>):<br>            image_path = os.path.join(sub_folder_path, image_file)<br>            <span class="hljs-keyword">with</span> Image.<span class="hljs-built_in">open</span>(image_path).convert(<span class="hljs-string">&#x27;L&#x27;</span>) <span class="hljs-keyword">as</span> img:<br>                img_data = np.array(img)<br>                images_data.append(img_data)<br><br>        <span class="hljs-comment"># 创建保存.npy文件的文件夹</span><br>        os.makedirs(save_location, exist_ok=<span class="hljs-literal">True</span>)<br>        <span class="hljs-comment"># 保存为.npy文件，文件名为对应的保存位置</span><br>        output_path = os.path.join(save_location, <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;sub_folder&#125;</span>.npy&#x27;</span>)<br>        np.save(output_path, images_data)<br><br></code></pre></td></tr></table></figure><h2 id="任务寻找预处理代码"><a href="#任务寻找预处理代码" class="headerlink" title="任务寻找预处理代码"></a>任务寻找预处理代码</h2><p>在paperwithcode上。</p><ol><li><p>DWT 算法对将时间域上的数据转换为频率能量上的数据，找到这样的代码。<br>连续的小波变换 ：CWT<br>离散的小波变换 ：DWT<br>小波变换的基本知识：<br>不同的小波基函数，是由同一个基本小波函数经缩放和平移生成的。<br>小波变换是将原始图像与小波基函数以及尺度函数进行内积运算, 所以一个尺度函数和一个小波基函数就可以确定一个小波变换。</p></li><li><p>PSD<br><a href="https://blog.csdn.net/frostime/article/details/106967703">参考链接</a><br><a href="https://iq.opengenus.org/eeg-signal-analysis-with-python/">mne怎么使用</a><br><a href="https://mne.tools/stable/generated/mne.time_frequency.psd_array_welch.html">mne函数psd——array-welch介绍</a><br><a href="https://mne.tools/stable/auto_examples/decoding/ssd_spatial_filters.html#sphx-glr-auto-examples-decoding-ssd-spatial-filters-py">mne函数psd-array-welch使用例子</a><br>提取通道位置， TP9，AF7，AF8，TP10<br>[‘Fp1’, ‘Fp2’, ‘F7’, ‘F3’, ‘Fz’, ‘F4’, ‘F8’, ‘T3’, ‘C3’, ‘Cz’, ‘C4’, ‘T4’, ‘T5’, ‘P3’, ‘Pz’, ‘P4’, ‘T6’, ‘O1’, ‘O2’]</p></li></ol><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment">## https://blog.csdn.net/SashiMoore/article/details/128599822 --&gt;</span><br>import numpy as np<br><span class="hljs-keyword">from</span> matplotlib import pyplot as plt<br> <br><span class="hljs-keyword">from</span> mne import create_info, Epochs<br><span class="hljs-keyword">from</span> mne.baseline import rescale<br><span class="hljs-keyword">from</span> mne.io import RawArray<br><span class="hljs-keyword">from</span> mne.time_frequency import (tfr_multitaper, tfr_stockwell, tfr_morlet,<br>                                tfr_array_morlet, AverageTFR)<br><span class="hljs-keyword">from</span> mne.viz import centers_to_edges<br> <br><span class="hljs-string">&#x27;&#x27;</span><span class="hljs-string">&#x27;</span><br><span class="hljs-string">Time-frequency on simulated data</span><br><span class="hljs-string">(Multitaper vs. Morlet vs. Stockwell vs. Hilbert)</span><br><span class="hljs-string">&#x27;</span><span class="hljs-string">&#x27;&#x27;</span><br> <br><span class="hljs-string">&#x27;&#x27;</span><span class="hljs-string">&#x27;</span><br><span class="hljs-string">使用已知的频谱时间结构来模拟数据</span><br><span class="hljs-string">&#x27;</span><span class="hljs-string">&#x27;&#x27;</span><br><span class="hljs-comment"># 设定采样频率</span><br>sfreq = 1000.0<br><span class="hljs-comment"># 设定频道名称</span><br>ch_names = [<span class="hljs-string">&#x27;SIM0001&#x27;</span>, <span class="hljs-string">&#x27;SIM0002&#x27;</span>]<br><span class="hljs-comment"># 设定频道类型</span><br>ch_types = [<span class="hljs-string">&#x27;grad&#x27;</span>, <span class="hljs-string">&#x27;grad&#x27;</span>]<br><span class="hljs-comment"># 根据以上信息创建info</span><br><span class="hljs-built_in">info</span> = create_info(<span class="hljs-attribute">ch_names</span>=ch_names, <span class="hljs-attribute">sfreq</span>=sfreq, <span class="hljs-attribute">ch_types</span>=ch_types)<br> <br>n_times = 1024  # 时间采样点数量，构造epoch的时间长度多于1秒1000<br>n_epochs = 40   # 构建epoch数量<br>seed = 42       # 设定种子<br>rng = np.random.RandomState(seed)   # 根据种子生成随机数组，元素值在0-1之间<br><span class="hljs-comment"># 产生2行n_times*n_epochs+200列的标准正态分布随机数，长度为第二个参数所示</span><br>data = rng.randn(len(ch_names), n_times * n_epochs + 200)<br> <br><span class="hljs-comment"># 添加一个50赫兹的正弦脉冲噪声和斜坡</span><br><span class="hljs-comment"># 返回0-1023的浮点数，除采样频率来表示时间采样点在以秒为单位的时间轴中的位置</span><br>t = np.arange(n_times, <span class="hljs-attribute">dtype</span>=np.float64) / sfreq<br><span class="hljs-comment"># sin为数组中的每一个元素取正弦，t的系数为100pi，表示波的频率为100pi/2pi等于50hz</span><br>signal = np.sin(np.pi * 2. * 50. * t)<br><span class="hljs-comment"># 将信号中指定位置的t赋值为0，表示这些区域没有噪声,即只保留0.45s-0.55s的噪声信号</span><br>signal[np.logical_or(t &lt; 0.45, t &gt; 0.55)] = 0.  # Hard windowing<br><span class="hljs-built_in">print</span>(signal.shape)<br>on_time = np.logical_and(t &gt;= 0.45, t &lt;= 0.55)  # 设定取t范围<br><span class="hljs-built_in">print</span>(on_time)<br><span class="hljs-comment"># hanning生成长度为True数量的余弦窗口（即位于0.45s-0.55s的时间采样点个数），并乘在原数据区域上</span><br>signal[on_time] *= np.hanning(on_time.sum())  # Ramping<br><span class="hljs-comment"># 在data每一个频道的第一百个采样点到倒数第一百个采样点上加入噪声（持续1*20s）</span><br><span class="hljs-built_in">print</span>(data.shape)<br>data[:, 100:-100] += np.tile(signal, n_epochs)  # <span class="hljs-built_in">add</span> signal<br> <span class="hljs-built_in"></span><br><span class="hljs-built_in">raw </span>= RawArray(data, info)  # 建立raw结构<br>events = np.zeros((n_epochs, 3), <span class="hljs-attribute">dtype</span>=int)     # 建立一个shape为(20, 3)的0数组<br>events[:, 0] = np.arange(n_epochs) * n_times    # 将第二个维度的第一个数值赋值为epoch所在的时间采样点位置<br>epochs = Epochs(raw, events, dict(<span class="hljs-attribute">sin50hz</span>=0), <span class="hljs-attribute">tmin</span>=0, <span class="hljs-attribute">tmax</span>=n_times / sfreq,<br>                <span class="hljs-attribute">reject</span>=dict(grad=4000), <span class="hljs-attribute">baseline</span>=None)  # 建立epochs，将50hz波作为事件0输入<br> <br>epochs.average().plot()<br> <br><span class="hljs-string">&#x27;&#x27;</span><span class="hljs-string">&#x27;</span><br><span class="hljs-string">计算时频表示</span><br><span class="hljs-string">&#x27;</span><span class="hljs-string">&#x27;&#x27;</span><br><span class="hljs-comment"># 多窗口变换</span><br><span class="hljs-comment"># 生成感兴趣的频率数组</span><br>freqs = np.arange(5., 100., 3.)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;freqs shape is &#x27;</span>, freqs.shape)<br>vmin, vmax = -3., 3.  # Define our color limits.<br><span class="hljs-comment"># 生成组合图，维度为(1, 3)，详解可见之前博客或网上资料</span><br>fig, axs = plt.subplots(1, 3, figsize=(15, 5), <span class="hljs-attribute">sharey</span>=<span class="hljs-literal">True</span>)<br><span class="hljs-keyword">for</span> n_cycles, time_bandwidth, ax, title <span class="hljs-keyword">in</span> zip(<br>        [freqs / 2, freqs, freqs / 2],  # 周期数 时间窗口长度 <span class="hljs-attribute">T</span>=n_cycle/freqs，T过大时间精度不够，过小频率精度不够<br>        [2.0, 4.0, 8.0],  # 时间带宽积，越大计算次数越多，时间分辨率升高，频率分辨率降低，符合不确定性方程<br>        axs,<br>        [<span class="hljs-string">&#x27;Sim: Least smoothing, most variance&#x27;</span>,<br>         <span class="hljs-string">&#x27;Sim: Less frequency smoothing,\nmore time smoothing&#x27;</span>,<br>         <span class="hljs-string">&#x27;Sim: Less time smoothing,\nmore frequency smoothing&#x27;</span>]):<br>    power = tfr_multitaper(epochs, <span class="hljs-attribute">freqs</span>=freqs, <span class="hljs-attribute">n_cycles</span>=n_cycles,<br>                           <span class="hljs-attribute">time_bandwidth</span>=time_bandwidth, <span class="hljs-attribute">return_itc</span>=<span class="hljs-literal">False</span>)<br>    ax.set_title(title)<br>    # Plot results. Baseline correct based on first 100 ms.<br>    power.plot([0], baseline=(0., 0.1), <span class="hljs-attribute">mode</span>=<span class="hljs-string">&#x27;mean&#x27;</span>, <span class="hljs-attribute">vmin</span>=vmin, <span class="hljs-attribute">vmax</span>=vmax,<br>               <span class="hljs-attribute">axes</span>=ax, <span class="hljs-attribute">show</span>=<span class="hljs-literal">False</span>, <span class="hljs-attribute">colorbar</span>=<span class="hljs-literal">False</span>)<br>plt.tight_layout()<br>plt.show()<br> <br><span class="hljs-string">&#x27;&#x27;</span><span class="hljs-string">&#x27;</span><br><span class="hljs-string">Stockwell (S) transform</span><br><span class="hljs-string">&#x27;</span><span class="hljs-string">&#x27;&#x27;</span><br>fig, axs = plt.subplots(1, 3, figsize=(15, 5), <span class="hljs-attribute">sharey</span>=<span class="hljs-literal">True</span>)<br>fmin, fmax = freqs[[0, -1]]<br><span class="hljs-keyword">for</span> width, ax <span class="hljs-keyword">in</span> zip((0.2, 0.7, 3.0), axs):<br>    power = tfr_stockwell(epochs, <span class="hljs-attribute">fmin</span>=fmin, <span class="hljs-attribute">fmax</span>=fmax, <span class="hljs-attribute">width</span>=width)<br>    power.plot([0], baseline=(0., 0.1), <span class="hljs-attribute">mode</span>=<span class="hljs-string">&#x27;mean&#x27;</span>, <span class="hljs-attribute">axes</span>=ax, <span class="hljs-attribute">show</span>=<span class="hljs-literal">False</span>,<br>               <span class="hljs-attribute">colorbar</span>=<span class="hljs-literal">False</span>)<br>    ax.set_title(<span class="hljs-string">&#x27;Sim: Using S transform, width = &#123;:0.1f&#125;&#x27;</span>.format(width))<br>plt.tight_layout()<br>plt.show()<br> <br><span class="hljs-comment"># 小波变换</span><br>fig, axs = plt.subplots(1, 3, figsize=(15, 5), <span class="hljs-attribute">sharey</span>=<span class="hljs-literal">True</span>)<br>all_n_cycles = [1, 3, freqs / 2.]<br><span class="hljs-keyword">for</span> n_cycles, ax <span class="hljs-keyword">in</span> zip(all_n_cycles, axs):<br>    power = tfr_morlet(epochs, <span class="hljs-attribute">freqs</span>=freqs,<br>                       <span class="hljs-attribute">n_cycles</span>=n_cycles, <span class="hljs-attribute">return_itc</span>=<span class="hljs-literal">False</span>)<br>    power.plot([0], baseline=(0., 0.1), <span class="hljs-attribute">mode</span>=<span class="hljs-string">&#x27;mean&#x27;</span>, <span class="hljs-attribute">vmin</span>=vmin, <span class="hljs-attribute">vmax</span>=vmax,<br>               <span class="hljs-attribute">axes</span>=ax, <span class="hljs-attribute">show</span>=<span class="hljs-literal">False</span>, <span class="hljs-attribute">colorbar</span>=<span class="hljs-literal">False</span>)<br>    # 若n_cycle不为int，则赋值为字符串<br>    n_cycles = <span class="hljs-string">&#x27;scaled by freqs&#x27;</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> isinstance(n_cycles, int) <span class="hljs-keyword">else</span> n_cycles<br>    ax.set_title(f<span class="hljs-string">&#x27;Sim: Using Morlet wavelet, n_cycles = &#123;n_cycles&#125;&#x27;</span>)<br>plt.tight_layout()<br>plt.show()<br> <br><span class="hljs-comment"># Narrow-bandpass Filter and Hilbert Transform</span><br>fig, axs = plt.subplots(1, 3, figsize=(15, 5), <span class="hljs-attribute">sharey</span>=<span class="hljs-literal">True</span>)<br>bandwidths = [1., 2., 4.]   # 带通宽度<br><span class="hljs-keyword">for</span> bandwidth, ax <span class="hljs-keyword">in</span> zip(bandwidths, axs):<br>    data = np.zeros((len(ch_names), freqs.size, epochs.times.size),<br>                    <span class="hljs-attribute">dtype</span>=complex)<br>    <span class="hljs-keyword">for</span> idx, freq <span class="hljs-keyword">in</span> enumerate(freqs):<br>        # 过滤原始数据并重新epoch以避免过滤器的时间过长<br>        # 重新构造低频率和短周期的epoch数据<br>        raw_filter = raw.copy()<br>        # 注意:过滤器的带宽从默认值改变<br>        # 夸大差异。使用默认的转换带宽，<br>        # 这些都非常相似，因为过滤器几乎是一样的。<br>        # 在实践中，使用默认值通常是明智的选择。<br>        # 滤波器设置<br>        raw_filter.filter(<br>            <span class="hljs-attribute">l_freq</span>=freq - bandwidth / 2, <span class="hljs-attribute">h_freq</span>=freq + bandwidth / 2,<br>            # 对于大带宽和低频率计算没有负值<br>            # 过渡带宽度设定<br>            <span class="hljs-attribute">l_trans_bandwidth</span>=min([4 * bandwidth, freq - bandwidth]),<br>            <span class="hljs-attribute">h_trans_bandwidth</span>=4 * bandwidth)<br>        # 该函数计算通道子集的分析信号或包络<br>        raw_filter.apply_hilbert()<br>        epochs_hilb = Epochs(raw_filter, events, <span class="hljs-attribute">tmin</span>=0, <span class="hljs-attribute">tmax</span>=n_times / sfreq,<br>                             baseline=(0, 0.1))<br>        tfr_data = epochs_hilb.get_data()<br>        tfr_data = tfr_data * tfr_data.conj()  # compute power conj获取共轭复数<br>        tfr_data = np.mean(tfr_data, <span class="hljs-attribute">axis</span>=0)  # average over epochs<br>        data[:, idx] = tfr_data<br>    power = AverageTFR(info, data, epochs.times, freqs, <span class="hljs-attribute">nave</span>=n_epochs)<br>    power.plot([0], baseline=(0., 0.1), <span class="hljs-attribute">mode</span>=<span class="hljs-string">&#x27;mean&#x27;</span>, <span class="hljs-attribute">vmin</span>=-0.1, <span class="hljs-attribute">vmax</span>=0.1,<br>               <span class="hljs-attribute">axes</span>=ax, <span class="hljs-attribute">show</span>=<span class="hljs-literal">False</span>, <span class="hljs-attribute">colorbar</span>=<span class="hljs-literal">False</span>)<br>    n_cycles = <span class="hljs-string">&#x27;scaled by freqs&#x27;</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> isinstance(n_cycles, int) <span class="hljs-keyword">else</span> n_cycles<br>    ax.set_title(<span class="hljs-string">&#x27;Sim: Using narrow bandpass filter Hilbert,\n&#x27;</span><br>                 f<span class="hljs-string">&#x27;bandwidth = &#123;bandwidth&#125;, &#x27;</span><br>                 f<span class="hljs-string">&#x27;transition bandwidth = &#123;4 * bandwidth&#125;&#x27;</span>)<br>plt.tight_layout()<br>plt.show()<br> <br><span class="hljs-comment"># Calculating a TFR without averaging over epochs</span><br>n_cycles = freqs / 2.<br>power = tfr_morlet(epochs, <span class="hljs-attribute">freqs</span>=freqs,<br>                   <span class="hljs-attribute">n_cycles</span>=n_cycles, <span class="hljs-attribute">return_itc</span>=<span class="hljs-literal">False</span>, <span class="hljs-attribute">average</span>=<span class="hljs-literal">False</span>)<br><span class="hljs-built_in">print</span>(type(power))<br>avgpower = power.average()<br>avgpower.plot([0], baseline=(0., 0.1), <span class="hljs-attribute">mode</span>=<span class="hljs-string">&#x27;mean&#x27;</span>, <span class="hljs-attribute">vmin</span>=vmin, <span class="hljs-attribute">vmax</span>=vmax,<br>              <span class="hljs-attribute">title</span>=<span class="hljs-string">&#x27;Using Morlet wavelets and EpochsTFR&#x27;</span>, <span class="hljs-attribute">show</span>=<span class="hljs-literal">False</span>)<br>plt.show()<br><br></code></pre></td></tr></table></figure><p>划分数据集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> csv<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>train_path = <span class="hljs-string">&quot;train_data.csv&quot;</span><br>val_path = <span class="hljs-string">&quot;test_data.csv&quot;</span><br><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_data_text</span>(<span class="hljs-params">path,train_percent = <span class="hljs-number">0.9</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;建立数据data列表,划分数据集&quot;&quot;&quot;</span><br>    f_train = <span class="hljs-built_in">open</span>(train_path,<span class="hljs-string">&quot;w&quot;</span>,newline=<span class="hljs-string">&#x27;&#x27;</span>) <span class="hljs-comment">#</span><br>    <span class="hljs-comment">#并将文件对象赋给了变量 f_train。open(train_path, &quot;w&quot;, newline=&#x27;&#x27;)</span><br>    <span class="hljs-comment">#  的意思是以写入模式打开名为 train_path 的文件，</span><br>    <span class="hljs-comment"># 并且在写入文本时不插入额外的换行符（newline=&#x27;&#x27;）。open是python的内置函数</span><br>    f_val = <span class="hljs-built_in">open</span>(val_path,<span class="hljs-string">&quot;w&quot;</span>,newline=<span class="hljs-string">&#x27;&#x27;</span>)<br>    train_writer = csv.writer(f_train)<br>    <span class="hljs-comment"># 创建了一个 CSV writer 对象 train_writer，</span><br>    <span class="hljs-comment"># 用于向文件对象 f_train 中写入 CSV 格式的数据。csv.writer() 接受一个文件对象作为参数，</span><br>    <span class="hljs-comment"># 并返回一个 CSV writer 对象，可以使用该对象的方法将数据写入文件。</span><br>    val_writer = csv.writer(f_val)<br>    <span class="hljs-comment"># enumerate() 是 Python 内置函数，</span><br>    <span class="hljs-comment"># 用于将一个可迭代对象（如列表、元组、字符串等）</span><br>    <span class="hljs-comment"># 组合为一个索引序列，同时列出数据和数据下标。</span><br>    <span class="hljs-comment"># 函数返回一个枚举对象，其中每个元素是一个包含索引和对应元素的元组。</span><br>    <span class="hljs-keyword">for</span> cls,dirname <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(os.listdir(path)):<br>        flist = os.listdir(os.path.join(path,dirname))<br>        <span class="hljs-comment"># os.path.join(path, dirname) 是一个函数，用于将多个路径组合成一个完整的路径。</span><br>        <span class="hljs-comment"># 它会根据当前操作系统的规则使用正确的路径分隔符来连接路径。</span><br>        np.random.shuffle(flist)<br>        <span class="hljs-comment"># np.random.shuffle(flist) 是 NumPy 库中的一个函数，用于随机打乱列表 flist 中的元素顺序。</span><br>        <span class="hljs-comment"># 这个函数会改变原始列表的顺序，使得列表中的元素随机排列。</span><br>        fnum = <span class="hljs-built_in">len</span>(flist)<br>        <span class="hljs-comment"># len函数返回</span><br>        <span class="hljs-keyword">for</span> i,filename <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(flist):<br>            <span class="hljs-comment"># 使用了 enumerate() 函数来遍历列表 flist 中的元素，同时获取元素的索引和值。具体来说，</span><br>            <span class="hljs-comment"># enumerate(flist) 返回一个枚举对象，其中每个元素是一个元组，包含元素在列表中的索引和元素的值。</span><br>            <span class="hljs-keyword">if</span> i &lt; fnum * train_percent:<br>                train_writer.writerow([os.path.join(path,dirname,filename),<span class="hljs-built_in">str</span>(cls)])<br>            <span class="hljs-comment"># 是将一个包含两个元素的列表写入CSV文件的操作。这个列表包含两个元素：</span><br>            <span class="hljs-comment"># os.path.join(path,dirname,filename) 返回一个完整的文件路径，其中 path 是主目录路径，dirname 是子目录路径，filename 是文件名。这个路径表示要写入CSV文件的文件的完整路径。</span><br>            <span class="hljs-comment"># str(cls) 将整数 cls 转换为字符串，cls 表示类别编号。</span><br>            <span class="hljs-keyword">else</span>:<br>                val_writer.writerow([os.path.join(path,dirname,filename),<span class="hljs-built_in">str</span>(cls)])<br>    f_train.close()<br>    <span class="hljs-comment"># f_train.close() 是关闭文件 f_train 的方法。在使用完文件后，</span><br>    <span class="hljs-comment"># 应该调用这个方法来关闭文件，以释放资源并确保文件被正确关闭。</span><br>    f_val.close()<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    create_data_text(<span class="hljs-string">&quot;FFT_data&quot;</span>)<br>    <br></code></pre></td></tr></table></figure><h2 id="填坑"><a href="#填坑" class="headerlink" title="填坑"></a>填坑</h2><p>train-loss 和test-loss之间的关系<br>变化趋势分析：train loss 不断下降，test loss不断下降，说明网络仍在学习;（最好的）train loss 不断下降，test loss趋于不变，说明网络过拟合；train loss 趋于不变，test loss不断下降，说明数据集100%有问题;（检查dataset）train loss 趋于不变，test loss趋于不变，说明学习遇到瓶颈，需要减小学习率或批量数目;（减少学习率）train loss 不断上升，test loss不断上升，说明网络结构设计不当，训练超参数设置不当，数据集经过清洗等问题；（最不好的情况）train_loss 不断下降， test_loss 不断上升，和第2种情况类似说明网络过拟合了。</p><ol><li><p>调高batch——size有提高点的趋势 32好于 0.0005的参数。</p></li><li><p>动态调整学习率<br>使用 StepLR、ExponentialLR 或 ReduceLROnPlateau</p></li></ol><p>StepLR</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><br><span class="hljs-comment"># 定义优化器</span><br>optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)<br><br><span class="hljs-comment"># 定义学习率调度器，每隔 step_size 个 epoch，将学习率乘以 gamma</span><br>scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=<span class="hljs-number">10</span>, gamma=<span class="hljs-number">0.1</span>)<br><br><span class="hljs-comment"># 训练循环</span><br>num_epochs = <span class="hljs-number">50</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    <span class="hljs-comment"># 训练步骤</span><br>    train(...)<br>    <br>    <span class="hljs-comment"># 更新学习率</span><br>    scheduler.step()<br>    <br>    <span class="hljs-comment"># 打印当前学习率</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Epoch <span class="hljs-subst">&#123;epoch+<span class="hljs-number">1</span>&#125;</span>/<span class="hljs-subst">&#123;num_epochs&#125;</span>, Learning Rate: <span class="hljs-subst">&#123;scheduler.get_last_lr()&#125;</span>&quot;</span>)<br><br><br></code></pre></td></tr></table></figure><p>ExponentialLR 以指数方式衰减学习率。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 定义优化器</span><br>optimizer = optim.RMSprop(model.parameters(), <span class="hljs-attribute">lr</span>=learning_rate)<br><br><span class="hljs-comment"># 定义学习率调度器</span><span class="hljs-built_in"></span><br><span class="hljs-built_in">scheduler </span>= optim.lr_scheduler.ExponentialLR(optimizer, <span class="hljs-attribute">gamma</span>=0.9)<br></code></pre></td></tr></table></figure><p>ReduceLROnPlateau 在监测指标停滞时降低学习率，适用于验证损失等指标。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 定义优化器</span><br>optimizer = optim.RMSprop(model.parameters(), <span class="hljs-attribute">lr</span>=learning_rate)<br><br><span class="hljs-comment"># 定义学习率调度器</span><span class="hljs-built_in"></span><br><span class="hljs-built_in">scheduler </span>= optim.lr_scheduler.ReduceLROnPlateau(optimizer, <span class="hljs-attribute">mode</span>=<span class="hljs-string">&#x27;min&#x27;</span>, <span class="hljs-attribute">factor</span>=0.1, <span class="hljs-attribute">patience</span>=10, <span class="hljs-attribute">verbose</span>=<span class="hljs-literal">True</span>)<br><br><br></code></pre></td></tr></table></figure><ol start="3"><li>替换模型的输出层</li></ol><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs"><br></code></pre></td></tr></table></figure><table><thead><tr><th align="left"></th><th align="left"></th></tr></thead><tbody><tr><td align="left">batch-size</td><td align="left">learning</td></tr><tr><td align="left">16</td><td align="left">0.00005</td></tr><tr><td align="left">8</td><td align="left">0.00005</td></tr><tr><td align="left">32</td><td align="left">0.001</td></tr></tbody></table><table><thead><tr><th align="left"></th><th align="left"></th><th align="left"></th></tr></thead><tbody><tr><td align="left">time</td><td align="left">wight_size</td><td align="left">in_feature</td></tr><tr><td align="left">3</td><td align="left">1536</td><td align="left">96</td></tr><tr><td align="left">4</td><td align="left">2048</td><td align="left">128</td></tr><tr><td align="left">5</td><td align="left">2560</td><td align="left">160</td></tr><tr><td align="left">6</td><td align="left">3072</td><td align="left">192</td></tr><tr><td align="left">7</td><td align="left">3584</td><td align="left">224</td></tr><tr><td align="left">8</td><td align="left">4096</td><td align="left">256</td></tr><tr><td align="left">9</td><td align="left">4608</td><td align="left">288</td></tr><tr><td align="left">10</td><td align="left">5120</td><td align="left">320</td></tr><tr><td align="left">11</td><td align="left">5632</td><td align="left">352</td></tr><tr><td align="left">12</td><td align="left">6144</td><td align="left">384</td></tr><tr><td align="left">13</td><td align="left">6656</td><td align="left">416</td></tr></tbody></table><h3 id="密码"><a href="#密码" class="headerlink" title="密码"></a>密码</h3><p>Qwer123@<br>Qwer123.<br>train-loss 和test-loss之间的关系<br>变化趋势分析：train loss 不断下降，test loss不断下降，说明网络仍在学习;</p><p>（最好的）train loss 不断下降，test loss趋于不变，说明网络过拟合；</p><p>train loss 趋于不变，test loss不断下降，说明数据集100%有问题;</p><p>（检查dataset）train loss 趋于不变，test loss趋于不变，说明学习遇到瓶颈，需要减小学习率或批量数目;</p><p>（减少学习率）train loss 不断上升，test loss不断上升，说明网络结构设计不当，训练超参数设置不当，数据集经过清洗等问题；（最不好的情况）train_loss 不断下降， test_loss 不断上升，和第2种情况类似说明网络过拟合了。</p>]]></content>
    
    
    
    <tags>
      
      <tag>论文思路</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>兰亭集序</title>
    <link href="/2024/04/28/juzhi3/"/>
    <url>/2024/04/28/juzhi3/</url>
    
    <content type="html"><![CDATA[<center><font size = 6> 兰亭集序 / 兰亭序<font><center><center >魏晋：王羲之<center><font size = 5>永和九年，岁在癸丑，暮春之初，会于会稽山阴之兰亭，修禊事也。群贤毕至，少长咸集。此地有崇山峻岭，茂林修竹；又有清流激湍，映带左右，引以为流觞曲水，列坐其次。虽无丝竹管弦之盛，一觞一咏，亦足以畅叙幽情。<p>是日也，天朗气清，惠风和畅，仰观宇宙之大，俯察品类之盛，所以游目骋怀，足以极视听之娱，信可乐也。</p><p>夫人之相与，俯仰一世，或取诸怀抱，悟言一室之内；或因寄所托，放浪形骸之外。虽趣舍万殊，静躁不同，当其欣于所遇，暂得于己，快然自足，不知老之将至。及其所之既倦，情随事迁，感慨系之矣。向之所欣，俯仰之间，已为陈迹，犹不能不以之兴怀。况修短随化，终期于尽。古人云：“死生亦大矣。”岂不痛哉！(不知老之将至 一作：曾不知老之将至)</p><p>每览昔人兴感之由，若合一契，未尝不临文嗟悼，不能喻之于怀。固知一死生为虚诞，齐彭殇为妄作。后之视今，亦犹今之视昔。悲夫！故列叙时人，录其所述，虽世殊事异，所以兴怀，其致一也。后之览者，亦将有感于斯文。</p><font><div style="text-align: left;"><font size = 3>译文：永和九年，时在癸丑之年，三月上旬，我们会集在会稽郡山阴城的兰亭，为了做禊礼这件事。诸多贤士能人都汇聚到这里，年长、年少者都聚集在这里。兰亭这个地方有高峻的山峰，茂盛高密的树林和竹丛；又有清澈激荡的水流，在亭子的左右辉映环绕，我们把水引来作为飘传酒杯的环形渠水，排列坐在曲水旁边，虽然没有管弦齐奏的盛况，但喝着酒作着诗，也足够来畅快表达幽深内藏的感情了。<p>这一天，天气晴朗，和风习习，抬头纵观广阔的天空，俯看观察大地上繁多的万物，用来舒展眼力，开阔胸怀，足够来极尽视听的欢娱，实在很快乐。</p><p>人与人相互交往，很快便度过一生。有的人在室内畅谈自己的胸怀抱负；就着自己所爱好的事物，寄托自己的情怀，不受约束，放纵无羁的生活。虽然各有各的爱好，安静与躁动各不相同，但当他们对所接触的事物感到高兴时，一时感到自得，感到高兴和满足，竟然不知道衰老将要到来。等到对于自己所喜爱的事物感到厌倦，心情随着当前的境况而变化，感慨随之产生了。过去所喜欢的东西，转瞬间，已经成为旧迹，尚且不能不因为它引发心中的感触，况且寿命长短，听凭造化，最后归结于消灭。古人说：“死生毕竟是件大事啊。”怎么能不让人悲痛呢？</p><p>每当我看到前人兴怀感慨的原因，与我所感叹的好像符契一样相合，没有不面对着他们的文章而嗟叹感伤的，在心里又不能清楚地说明。本来知道把生死等同的说法是不真实的，把长寿和短命等同起来的说法是妄造的。后人看待今人，也就像今人看待前人。可悲呀！所以一个一个记下当时与会的人，录下他们所作的诗篇。纵使时代变了，事情不同了，但触发人们情怀的原因，他们的思想情趣是一样的。后世的读者，也将对这次集会的诗文有所感慨。</p></div size = 3><font><div style="text-align: left;"><font size = 3></div size = 3><font>]]></content>
    
    
    
    <tags>
      
      <tag>句子</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔13</title>
    <link href="/2024/04/28/ganwu13/"/>
    <url>/2024/04/28/ganwu13/</url>
    
    <content type="html"><![CDATA[<h2 id="实事求是"><a href="#实事求是" class="headerlink" title="实事求是"></a>实事求是</h2><p>重新写一下实事求是，做事最重要的是什么？清醒，明白自己在干嘛，明白自己做事是为了进步的，没有进步这件事就不需要去做。以进步为导向，以完成这个目标为目的，不畏惧目标的远大，以实事求是的态度，对一个不懂的东西，要去研究它，了解它，等研究透了，知其然，知其所以然。等了解这项工作后才能评价它，在这之后能不能做我能清楚的明白，在没有做之前不需要情绪上的波动，不需要什么自卑，崇拜。<br>实事求是的条件是分析现实的条件，分析条件的组成，但这只是一个思路，具体到做又有实践中需要注意的，但是知和行是一体两面的（感觉对这个理论还是很混沌，没有很好的阐述出来）。实践是检验真理的唯一标准，明白这句话需要这句清晰的知道实践，真理，标准的范畴。<br>今天看到一篇博客，觉得是实事求举得例子是举得很好的，这里放个链接(<a href="https://www.zhihu.com/question/365148040/answer/968807103">https://www.zhihu.com/question/365148040/answer/968807103</a>)</p><p>对于我来讲以现实为角度，如同子曰：为政以德譬，如北辰居其所而众星共之。当人把北极星的位置确定后，执持这位置相应就可以定出其他星星位置；当人从现实出发分析把握了现实关系的逻辑结构后，还不能把握大道吗？一切都从也只能从现实出发，现实在什么阶段，什么位次，是必须首要分析的问题。<br>哲学家们只是用不用的方式解释世界,问题在于改变世界</p><h2 id="精神的独立"><a href="#精神的独立" class="headerlink" title="精神的独立"></a>精神的独立</h2><p>人不仅要在物质上独立，更要在精神上独立。畏难情绪，不验证的验证，对于不验证验证了什么？验证了自己能不能做这件事，验证了自己不能做这件事。这样的精神气质就不对了，很难提升境界了。人云亦云，亦步亦趋，这样的精神是不行的，精神上畏难，即使再努力也是没有用的。不要认为任何人是不可超越的，始终相信不断的积累是可以达到他们的境界的。无论是智力不如别人，还是学的不够扎实。精神上站起来，认识到自己，实践是认识的来源，认识是改变的第一步，是成长的第一步。</p><h2 id="教育的作用"><a href="#教育的作用" class="headerlink" title="教育的作用"></a>教育的作用</h2><p>教育，读书，明理，解决问题。中国的大学教育被大众大众赋予了太多的神话，认为读了大学什么问题就解决了，上了大学一切就都解决了。我想这样的想法或多或少是不恰当的，把自己的未来放置于虚幻的未来，不立足于当下，立足于现实，想来是不恰当的。我认为教育的作用是去启发自我的本性，培养自我的能力，让自己能够去迎接挑战，而不是去等，去守株待兔，等待那虚幻的未来。知识付出一点时间和精力就能够获取，但是对于心理和人格的成长教育是欠缺的，这欠缺的反而需要学生自己去寻找，自己去开启心智的成长。<br>谈精神之独立，鲁迅是谈的好的，为此我在这挖一个坑（读鲁迅的杂文集）</p><h2 id="对死亡抱有希望真的会有解脱吗？"><a href="#对死亡抱有希望真的会有解脱吗？" class="headerlink" title="对死亡抱有希望真的会有解脱吗？"></a>对死亡抱有希望真的会有解脱吗？</h2><p>时常的，在我闲下来的时候，从高处往下看，总会幻想跳下去后，一切问题就都解决了。将解决问题的最终方式诉诸于死亡是我最后解决问题的办法，因为生命最终都会消逝，或早或晚没有什么不好，有的只有快慢。人的这一生，如昙花一现。如草木春绿秋枯，如曦月东升西落。死亡好像没有什么不好，但是我认为没有考虑到的是，人出生下来就应该背负一定的责任，对自己负责，对家人负责。自己亲手了结自己的生命是对自己不负责的表现，对家人不负责的表现。烦恼总是有的，但是为什么不换个想法，这件事最好会达到什么程度，做不好我会遭受什么，大部分时候我感到困惑，感到不解的来源是我的情绪，然而情绪在这种时候是最没有用处的东西，被情绪所裹挟是没有任何益处的，控制自己的情绪又是困难的，诉诸于死亡是无法之法。或许可以在感受情绪的同时，去想想最坏的结果，最坏的结果会导致我死亡，会影响我的生活，亦或者会失去什么，预演之后我能接受最坏的结果，再回来看最坏的结果也不过如此，更重要的是最坏的结果还没有发生，还有去改变的机会，这时就付诸一切的努力去改变。接受最坏的结果，尽力改变我接受的最坏的结果，即使最后失败了，我也欣然接受，而不是陷入不证之证，把希望诉诸于死亡。</p><h2 id="做事闲谈"><a href="#做事闲谈" class="headerlink" title="做事闲谈"></a>做事闲谈</h2><p>最开始开始写随笔是4月5日，现在已经积累了13篇随笔了，回头看看好像也没有什么难的，好像慢慢的就有了，我完成网站的构建，一开始我对于建网站只是有一个很模糊的想法，只是想了一下，慢慢的我就开始接触域名的购买，框架的使用，跳转，其中虽然有困难，也好像困惑了很久，但是也都解决了，所以请不要担心你行动的结果——仅仅关注行动本身就好了。行动的结果会自然而然地产生。问题不是用来忧虑的，而是用来解决的，对待问题不应该感到忧虑，而应该感到快乐，快乐的是又有进步的空间，又有一道难题需要攻破。或许当时很忧虑，后来回头看看，回首向来萧瑟处，归去，也无风雨也无晴。每个人都真正会从事一生的事业，那就是：学习和成长！</p><h2 id="意义的来源"><a href="#意义的来源" class="headerlink" title="意义的来源"></a>意义的来源</h2><p>在随笔11中我写道“人生的意义是什么？”回答：“每个人都有不同的答案。”，我的答案是什么？每天进步一点点。<br>认识到死亡给我的意义。明天和意外哪个先来，谁也不知道。死亡不不可以控制的，但是我想心由境转，境由心生。认识到死亡是存在的一段时间，我认为一切是无意义的，死亡到来之时所有的一切都将消散，与我而言没有意义。于浩歌狂热之际中寒，于天上看见深渊。一天无意义，一生无意义。生命呀，你到底是为了什么？活着你到底是为了什么，活着就是为了活着，活着就是为了感受活着，活着就是每一天，每一刻去感受活着，在面对一个个挑战时有勇气去战胜自己，死亡赋予我战胜困难的勇气，在过程中感到意义，感到快乐，活着就是有意义，有意义就是好好活。不以物喜，不以自悲。</p><p>注： 今天重新看了之前的随笔，发现了许多错别字，这里挖个坑（后面慢慢修改，因为看和改完全是两种条件。改的条件是需要电脑和我发现错别字。）</p>]]></content>
    
    
    
    <tags>
      
      <tag>感悟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch基础</title>
    <link href="/2024/04/27/deeplearnbook3-1/"/>
    <url>/2024/04/27/deeplearnbook3-1/</url>
    
    <content type="html"><![CDATA[<p>参考书目：《Python深度学习基于PyTorch》</p><h2 id="Pytorch-基础"><a href="#Pytorch-基础" class="headerlink" title="Pytorch 基础"></a>Pytorch 基础</h2><p>Pytorch采用python语言接口实现编程，非常容易上手。它就像带GPU的Numpy，与Python一样都属于动态框架。PyTorch继承了Torch灵活、动态的编程环境和用户友好的界面，支持以快速灵活的方式构建动态神经网络，还允许在训练过程中快速更改代码而不妨碍其性能，支持动态图形等尖端AI模型的能力，是快速实验的理想选择。</p><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>Pytorch是建立在Torch库上的python包，目的在于加速深度学习的应用。它包含了多维张量的数据结构以及基于其上的多种数学操作。动态计算图<br>PyTorch 主要由4个包组成：<br>torch：类似于Numpy的通用数组库，可将张量类型转换为torch.cuda.Tensor.Float，并在GPU上进行计算。<br>torch.autograd: 用于构建计算图形并自动获取梯度的包<br>torch.nn: 具有共享层和损失函数的神经网络库。<br>torch.ptim： 具有通用优化算法（如SGD，Adam等）的优化包</p><h2 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h2><p>pytorch的GPU版本 的安装配置有一点繁琐，这里阐述一下需要的装备</p><ol><li>电脑（装有显卡，本台电脑是GTX-3080），安装GPU的驱动（如英伟达的NVDIA）以及CUDA，cuDNN计算框架。安装GPU驱动的时候就会安装CUDA，cuDNN的安装要去官网查找对应版本。</li><li>软件miniconda ，python的环境包管理</li><li>VS_code</li></ol><h2 id="Numpy和Tensor"><a href="#Numpy和Tensor" class="headerlink" title="Numpy和Tensor"></a>Numpy和Tensor</h2><p>前面说到深度学习的最主要的东西是矩阵，深度学习就是一个大的函数。Tensor是numpy的Pytorch中的实现(这么说不知道行不行，但我是这么认为的)，pytorch中的Tensor可以是零维（又称为一个标量或一个数）、一维、二维以及多维数组。Tensor可以把产生的Tensor放置在GPU中进行加速计算。<br>对Tensor的操作很多，从接口的角度可以划分为两类，<br>torch.function 如 torch.sum、torch.add<br>tensor.function ，如tensor.view、tensor.add等<br>这些操作对于大部分Tensor都是等价的，比如torch.add(x)与x.add(y)等价（注：前提是x的dtype是tensor）</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs stylus">import torch<br>x = torch<span class="hljs-selector-class">.tensor</span>(<span class="hljs-selector-attr">[1 , 2]</span>)<br>y =torch<span class="hljs-selector-class">.tensor</span>(<span class="hljs-selector-attr">[3,4]</span>)<br>z = x<span class="hljs-selector-class">.add</span>(y)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(z)</span></span><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(x)</span></span><br>x<span class="hljs-selector-class">.add_</span>(y)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(x)</span></span><br></code></pre></td></tr></table></figure><p>Tensor创建的方式</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scss"># <span class="hljs-built_in">Tensor</span>(*size) 直接从参数构建一个张量<br></code></pre></td></tr></table></figure><h2 id="挖坑"><a href="#挖坑" class="headerlink" title="挖坑"></a>挖坑</h2><h3 id="仍然没有搞明白使用梯度下降算法来怎么对矩阵中的参数进行更新的方法？"><a href="#仍然没有搞明白使用梯度下降算法来怎么对矩阵中的参数进行更新的方法？" class="headerlink" title="仍然没有搞明白使用梯度下降算法来怎么对矩阵中的参数进行更新的方法？"></a>仍然没有搞明白使用梯度下降算法来怎么对矩阵中的参数进行更新的方法？</h3><p>目前网络上的梯度下降多使用线性函数来进行距离，没有推导过程，而我又不会推导，死循环了。所以我想知道怎么使用矩阵来实现梯度下降，进而实现SGD，Adam，Rsomp等梯度下降优化函数。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>经典网络结构——ResNet</title>
    <link href="/2024/04/27/deeplearnpaper4/"/>
    <url>/2024/04/27/deeplearnpaper4/</url>
    
    <content type="html"><![CDATA[<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://zhuanlan.zhihu.com/p/101332297">信念网络</a><br><a href="https://zhuanlan.zhihu.com/p/56961832">论文分析</a><br><a href="https://zhuanlan.zhihu.com/p/159162779">论文中文翻译</a><br><a href="https://arxiv.org/pdf/1512.03385">论文原文</a><br><a href="https://www.bilibili.com/video/BV1P3411y7nn/">李沐读论文</a></p><h2 id="论文阅读"><a href="#论文阅读" class="headerlink" title="论文阅读"></a>论文阅读</h2><h2 id="模型代码"><a href="#模型代码" class="headerlink" title="模型代码"></a>模型代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;resnet in pytorch</span><br><span class="hljs-string"></span><br><span class="hljs-string"></span><br><span class="hljs-string"></span><br><span class="hljs-string">[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Deep Residual Learning for Image Recognition</span><br><span class="hljs-string">    https://arxiv.org/abs/1512.03385v1</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BasicBlock</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;Basic Block for resnet 18 and resnet 34</span><br><span class="hljs-string"></span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-comment">#BasicBlock and BottleNeck block</span><br>    <span class="hljs-comment">#have different output size</span><br>    <span class="hljs-comment">#we use class attribute expansion</span><br>    <span class="hljs-comment">#to distinct</span><br>    expansion = <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels, out_channels, stride=<span class="hljs-number">1</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br><br>        <span class="hljs-comment">#residual function</span><br>        self.residual_function = nn.Sequential(<br>            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="hljs-number">3</span>, stride=stride, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(out_channels),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(out_channels * BasicBlock.expansion)<br>        )<br><br>        <span class="hljs-comment">#shortcut</span><br>        self.shortcut = nn.Sequential()<br><br>        <span class="hljs-comment">#the shortcut output dimension is not the same with residual function</span><br>        <span class="hljs-comment">#use 1*1 convolution to match the dimension</span><br>        <span class="hljs-keyword">if</span> stride != <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> in_channels != BasicBlock.expansion * out_channels:<br>            self.shortcut = nn.Sequential(<br>                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=<span class="hljs-number">1</span>, stride=stride, bias=<span class="hljs-literal">False</span>),<br>                nn.BatchNorm2d(out_channels * BasicBlock.expansion)<br>            )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> nn.ReLU(inplace=<span class="hljs-literal">True</span>)(self.residual_function(x) + self.shortcut(x))<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BottleNeck</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot;Residual block for resnet over 50 layers</span><br><span class="hljs-string"></span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    expansion = <span class="hljs-number">4</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels, out_channels, stride=<span class="hljs-number">1</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.residual_function = nn.Sequential(<br>            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(out_channels),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Conv2d(out_channels, out_channels, stride=stride, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(out_channels),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(out_channels * BottleNeck.expansion),<br>        )<br><br>        self.shortcut = nn.Sequential()<br><br>        <span class="hljs-keyword">if</span> stride != <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> in_channels != out_channels * BottleNeck.expansion:<br>            self.shortcut = nn.Sequential(<br>                nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, stride=stride, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>                nn.BatchNorm2d(out_channels * BottleNeck.expansion)<br>            )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> nn.ReLU(inplace=<span class="hljs-literal">True</span>)(self.residual_function(x) + self.shortcut(x))<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ResNet</span>(nn.Module):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, block, num_block, num_classes=<span class="hljs-number">3</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br><br>        self.in_channels = <span class="hljs-number">64</span><br><br>        self.conv1 = nn.Sequential(<br>            nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(<span class="hljs-number">64</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>))<br>        <span class="hljs-comment">#we use a different inputsize than the original paper</span><br>        <span class="hljs-comment">#so conv2_x&#x27;s stride is 1</span><br>        self.conv2_x = self._make_layer(block, <span class="hljs-number">64</span>, num_block[<span class="hljs-number">0</span>], <span class="hljs-number">1</span>)<br>        self.conv3_x = self._make_layer(block, <span class="hljs-number">128</span>, num_block[<span class="hljs-number">1</span>], <span class="hljs-number">2</span>)<br>        self.conv4_x = self._make_layer(block, <span class="hljs-number">256</span>, num_block[<span class="hljs-number">2</span>], <span class="hljs-number">2</span>)<br>        self.conv5_x = self._make_layer(block, <span class="hljs-number">512</span>, num_block[<span class="hljs-number">3</span>], <span class="hljs-number">2</span>)<br>        self.avg_pool = nn.AdaptiveAvgPool2d((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>        self.fc = nn.Linear(<span class="hljs-number">512</span> * block.expansion, num_classes)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_make_layer</span>(<span class="hljs-params">self, block, out_channels, num_blocks, stride</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;make resnet layers(by layer i didnt mean this &#x27;layer&#x27; was the</span><br><span class="hljs-string">        same as a neuron netowork layer, ex. conv layer), one layer may</span><br><span class="hljs-string">        contain more than one residual block</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            block: block type, basic block or bottle neck block</span><br><span class="hljs-string">            out_channels: output depth channel number of this layer</span><br><span class="hljs-string">            num_blocks: how many blocks per layer</span><br><span class="hljs-string">            stride: the stride of the first block of this layer</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Return:</span><br><span class="hljs-string">            return a resnet layer</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br><br>        <span class="hljs-comment"># we have num_block blocks per layer, the first block</span><br>        <span class="hljs-comment"># could be 1 or 2, other blocks would always be 1</span><br>        strides = [stride] + [<span class="hljs-number">1</span>] * (num_blocks - <span class="hljs-number">1</span>)<br>        layers = []<br>        <span class="hljs-keyword">for</span> stride <span class="hljs-keyword">in</span> strides:<br>            layers.append(block(self.in_channels, out_channels, stride))<br>            self.in_channels = out_channels * block.expansion<br><br>        <span class="hljs-keyword">return</span> nn.Sequential(*layers)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        output = self.conv1(x)<br>        output = self.conv2_x(output)<br>        output = self.conv3_x(output)<br>        output = self.conv4_x(output)<br>        output = self.conv5_x(output)<br>        output = self.avg_pool(output)<br>        output = output.view(output.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br>        output = self.fc(output)<br><br>        <span class="hljs-keyword">return</span> output<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">resnet18</span>():<br>    <span class="hljs-string">&quot;&quot;&quot; return a ResNet 18 object</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> ResNet(BasicBlock, [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>])<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">resnet34</span>():<br>    <span class="hljs-string">&quot;&quot;&quot; return a ResNet 34 object</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> ResNet(BasicBlock, [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>, <span class="hljs-number">3</span>])<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">resnet50</span>():<br>    <span class="hljs-string">&quot;&quot;&quot; return a ResNet 50 object</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> ResNet(BottleNeck, [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>, <span class="hljs-number">3</span>])<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">resnet101</span>():<br>    <span class="hljs-string">&quot;&quot;&quot; return a ResNet 101 object</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> ResNet(BottleNeck, [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">23</span>, <span class="hljs-number">3</span>])<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">resnet152</span>():<br>    <span class="hljs-string">&quot;&quot;&quot; return a ResNet 152 object</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> ResNet(BottleNeck, [<span class="hljs-number">3</span>, <span class="hljs-number">8</span>, <span class="hljs-number">36</span>, <span class="hljs-number">3</span>])<br><br><br><br><span class="hljs-comment"># import torch</span><br><span class="hljs-comment"># from torchsummary import summary</span><br><br><span class="hljs-comment"># # Instantiate the ResNet model (choose the variant you want, e.g., resnet18())</span><br><span class="hljs-comment"># model = resnet18()</span><br><br><span class="hljs-comment"># # Move the model to the device (e.g., GPU if available)</span><br><span class="hljs-comment"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="hljs-comment"># model.to(device)</span><br><br><span class="hljs-comment"># # Print the model summary</span><br><span class="hljs-comment"># summary(model, (1, 33, 1025))  # Adjust the input size (channels, height, width) as needed</span><br><br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>经典网络结构——GoogleNet</title>
    <link href="/2024/04/27/deeplearnpaper3/"/>
    <url>/2024/04/27/deeplearnpaper3/</url>
    
    <content type="html"><![CDATA[<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>2014年<br><a href="https://zhuanlan.zhihu.com/p/482776152">GoogleNet解读</a><br><a href="https://blog.csdn.net/Jwenxue/article/details/107788765">论文翻译中文</a><br><a href="https://arxiv.org/pdf/1409.4842v1">论文原文</a><br><a href="https://www.jianshu.com/p/6a9e33e34571">论文中文翻译</a></p><h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="模型代码"><a href="#模型代码" class="headerlink" title="模型代码"></a>模型代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;&quot;&quot;google net in pytorch</span><br><span class="hljs-string"></span><br><span class="hljs-string"></span><br><span class="hljs-string"></span><br><span class="hljs-string">[1] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed,</span><br><span class="hljs-string">    Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Going Deeper with Convolutions</span><br><span class="hljs-string">    https://arxiv.org/abs/1409.4842v1</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Inception</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_channels, n1x1, n3x3_reduce, n3x3, n5x5_reduce, n5x5, pool_proj</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br><br>        <span class="hljs-comment">#1x1conv branch</span><br>        self.b1 = nn.Sequential(<br>            nn.Conv2d(input_channels, n1x1, kernel_size=<span class="hljs-number">1</span>),<br>            nn.BatchNorm2d(n1x1),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br>        )<br><br>        <span class="hljs-comment">#1x1conv -&gt; 3x3conv branch</span><br>        self.b2 = nn.Sequential(<br>            nn.Conv2d(input_channels, n3x3_reduce, kernel_size=<span class="hljs-number">1</span>),<br>            nn.BatchNorm2d(n3x3_reduce),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Conv2d(n3x3_reduce, n3x3, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.BatchNorm2d(n3x3),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br>        )<br><br>        <span class="hljs-comment">#1x1conv -&gt; 5x5conv branch</span><br>        <span class="hljs-comment">#we use 2 3x3 conv filters stacked instead</span><br>        <span class="hljs-comment">#of 1 5x5 filters to obtain the same receptive</span><br>        <span class="hljs-comment">#field with fewer parameters</span><br>        self.b3 = nn.Sequential(<br>            nn.Conv2d(input_channels, n5x5_reduce, kernel_size=<span class="hljs-number">1</span>),<br>            nn.BatchNorm2d(n5x5_reduce),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Conv2d(n5x5_reduce, n5x5, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.BatchNorm2d(n5x5, n5x5),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Conv2d(n5x5, n5x5, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>            nn.BatchNorm2d(n5x5),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br>        )<br><br>        <span class="hljs-comment">#3x3pooling -&gt; 1x1conv</span><br>        <span class="hljs-comment">#same conv</span><br>        self.b4 = nn.Sequential(<br>            nn.MaxPool2d(<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),<br>            nn.Conv2d(input_channels, pool_proj, kernel_size=<span class="hljs-number">1</span>),<br>            nn.BatchNorm2d(pool_proj),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> torch.cat([self.b1(x), self.b2(x), self.b3(x), self.b4(x)], dim=<span class="hljs-number">1</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">GoogleNet</span>(nn.Module):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_class=<span class="hljs-number">3</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.prelayer = nn.Sequential(<br>            nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(<span class="hljs-number">64</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(<span class="hljs-number">64</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">192</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(<span class="hljs-number">192</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>        )<br><br>        <span class="hljs-comment">#although we only use 1 conv layer as prelayer,</span><br>        <span class="hljs-comment">#we still use name a3, b3.......</span><br>        self.a3 = Inception(<span class="hljs-number">192</span>, <span class="hljs-number">64</span>, <span class="hljs-number">96</span>, <span class="hljs-number">128</span>, <span class="hljs-number">16</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>)<br>        self.b3 = Inception(<span class="hljs-number">256</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">192</span>, <span class="hljs-number">32</span>, <span class="hljs-number">96</span>, <span class="hljs-number">64</span>)<br><br>        <span class="hljs-comment">##&quot;&quot;&quot;In general, an Inception network is a network consisting of</span><br>        <span class="hljs-comment">##modules of the above type stacked upon each other, with occasional</span><br>        <span class="hljs-comment">##max-pooling layers with stride 2 to halve the resolution of the</span><br>        <span class="hljs-comment">##grid&quot;&quot;&quot;</span><br>        self.maxpool = nn.MaxPool2d(<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br><br>        self.a4 = Inception(<span class="hljs-number">480</span>, <span class="hljs-number">192</span>, <span class="hljs-number">96</span>, <span class="hljs-number">208</span>, <span class="hljs-number">16</span>, <span class="hljs-number">48</span>, <span class="hljs-number">64</span>)<br>        self.b4 = Inception(<span class="hljs-number">512</span>, <span class="hljs-number">160</span>, <span class="hljs-number">112</span>, <span class="hljs-number">224</span>, <span class="hljs-number">24</span>, <span class="hljs-number">64</span>, <span class="hljs-number">64</span>)<br>        self.c4 = Inception(<span class="hljs-number">512</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">24</span>, <span class="hljs-number">64</span>, <span class="hljs-number">64</span>)<br>        self.d4 = Inception(<span class="hljs-number">512</span>, <span class="hljs-number">112</span>, <span class="hljs-number">144</span>, <span class="hljs-number">288</span>, <span class="hljs-number">32</span>, <span class="hljs-number">64</span>, <span class="hljs-number">64</span>)<br>        self.e4 = Inception(<span class="hljs-number">528</span>, <span class="hljs-number">256</span>, <span class="hljs-number">160</span>, <span class="hljs-number">320</span>, <span class="hljs-number">32</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>)<br><br>        self.a5 = Inception(<span class="hljs-number">832</span>, <span class="hljs-number">256</span>, <span class="hljs-number">160</span>, <span class="hljs-number">320</span>, <span class="hljs-number">32</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>)<br>        self.b5 = Inception(<span class="hljs-number">832</span>, <span class="hljs-number">384</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">48</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>)<br><br>        <span class="hljs-comment">#input feature size: 8*8*1024</span><br>        self.avgpool = nn.AdaptiveAvgPool2d((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>        self.dropout = nn.Dropout2d(p=<span class="hljs-number">0.4</span>)<br>        self.linear = nn.Linear(<span class="hljs-number">1024</span>, num_class)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.prelayer(x)<br>        x = self.maxpool(x)<br>        x = self.a3(x)<br>        x = self.b3(x)<br><br>        x = self.maxpool(x)<br><br>        x = self.a4(x)<br>        x = self.b4(x)<br>        x = self.c4(x)<br>        x = self.d4(x)<br>        x = self.e4(x)<br><br>        x = self.maxpool(x)<br><br>        x = self.a5(x)<br>        x = self.b5(x)<br><br>        <span class="hljs-comment">#&quot;&quot;&quot;It was found that a move from fully connected layers to</span><br>        <span class="hljs-comment">#average pooling improved the top-1 accuracy by about 0.6%,</span><br>        <span class="hljs-comment">#however the use of dropout remained essential even after</span><br>        <span class="hljs-comment">#removing the fully connected layers.&quot;&quot;&quot;</span><br>        x = self.avgpool(x)<br>        x = self.dropout(x)<br>        x = x.view(x.size()[<span class="hljs-number">0</span>], -<span class="hljs-number">1</span>)<br>        x = self.linear(x)<br><br>        <span class="hljs-keyword">return</span> x<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">googlenet</span>():<br>    <span class="hljs-keyword">return</span> GoogleNet()<br><br><br><span class="hljs-comment"># import torch</span><br><span class="hljs-comment"># from torchsummary import summary</span><br><br><span class="hljs-comment"># # Instantiate the GoogleNet model</span><br><span class="hljs-comment"># model = googlenet()</span><br><br><span class="hljs-comment"># # Move the model to the device (e.g., GPU if available)</span><br><span class="hljs-comment"># device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="hljs-comment"># model.to(device)</span><br><br><span class="hljs-comment"># # Print the model summary</span><br><span class="hljs-comment"># summary(model, (1, 33, 1025))  # Adjust the input size (channels, height, width) as needed</span><br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python——flask后端代码开发</title>
    <link href="/2024/04/26/tiankeng5/"/>
    <url>/2024/04/26/tiankeng5/</url>
    
    <content type="html"><![CDATA[<p>看别人的代码是必要的</p><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>最近我们在研究如何将直接的模型部署在网站上面，所以我们打算写一个python工程来放置对模型部署，使用的flask来进行模型和前端的交互。<br>大概思路是这样的，前端传入一个文件，经过flask传输到服务器，触发处理求取，模型处理完成后返回模型处理结果。<br>增加功能是用户可以自己选择模型种类和通道种类。（用户可以自由选取自己想处理的通道对应的模型）</p><h2 id="挖坑"><a href="#挖坑" class="headerlink" title="挖坑"></a>挖坑</h2><p>世界上没有技术驱动的公司，不论是google、facebook，还是阿里腾讯、阿里。技术不是源头，需求才是，因此一切技术问题，都要服从产品交付和市场反馈。所以，任何公司，都不可能以技术去驱动自身。人可以以技术驱动自己进步，但公司不行。以解决问题为导向，我需要解决什么问题，然后了解这个问题，有什么解决问题的思路。<br>资本富集的地方，人都得加班，加班的本质，是人跟着机器跑、人跟着钱跑；更为本质地说，资本富集的地方，人作为劳动力，也是资本的一种。即，人是资本而不是人本身。IT是工科，不是理科，和IT行业相似度最高的行业是盖楼房。真的，相似度相当惊人。<br>一个程序员，应该花80%的时间做代码设计、画UML图、画时序图，20%的时间写code和debug；菜鸟程序员的这个比例恰好是反的。一句话，不论这个需求有多紧急，你都一定要“想好再动手”；“想好”的标志就是设计文档写好了；文档一旦写好，写代码就是纯粹的无脑工作。<br>英语，很重要。能否使用英语查阅资料，是区分技术人员水平的重要指示之一。寄希望于“有人迟早会翻译成中文”的人是愚蠢的、是会被淘汰的。<br>工作要有热情。</p><p>智商决定你的起点情商决定你能走多远爬多高；混职场，靠的是情商。情商高就是：别人愿意和你一起工作、你有问题的时候别人愿意帮你。智商有时候可以稍微弥补一下情商但不起决定性的作用。</p><h2 id="Flask"><a href="#Flask" class="headerlink" title="Flask"></a>Flask</h2><p><a href="https://blog.csdn.net/wly55690/article/details/131683846">参考博客</a></p><ol><li>Flask是一个非常小的PythonWeb框架，被称为微型框架；只提供了一个稳健的核心，其他功能全部是通过扩展实现的；意思就是我们可以根据项目的需要量身定制，也意味着我们需要学习各种扩展库的使用。<br>安装：<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip <span class="hljs-keyword">install</span> flask<br></code></pre></td></tr></table></figure></li><li>Flask 基础入门<br>代码是1.py<br>1）路由route的创建：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-comment"># 通过创建路由并关联函数，实现一个基本的网页：</span><br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask<br><br><span class="hljs-comment"># 用当前脚本名称实例化Flask对象，方便flask从该脚本文件中获取需要的内容,app = Flask(__name__) 创建一个Flask实例</span><br>app = Flask(__name__)<br><br><span class="hljs-comment">#程序实例需要知道每个url请求所对应的运行代码是谁。</span><br><span class="hljs-comment">#所以程序中必须要创建一个url请求地址到python运行函数的一个映射。</span><br><span class="hljs-comment">#处理url和视图函数之间的关系的程序就是&quot;路由&quot;，在Flask中，路由是通过@app.route装饰器(以@开头)来表示的</span><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&quot;/&quot;</span></span>)</span><br><span class="hljs-comment">#url映射的函数，要传参则在上述route（路由）中添加参数申明</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">index</span>():<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;Hello World!&quot;</span><br><br><span class="hljs-comment"># 直属的第一个作为视图函数被绑定，第二个就是普通函数</span><br><span class="hljs-comment"># 路由与视图函数需要一一对应</span><br><span class="hljs-comment"># def not():</span><br><span class="hljs-comment">#     return &quot;Not Hello World!&quot;</span><br><br><span class="hljs-comment"># 启动一个本地开发服务器，激活该网页</span><br>app.run()<br><br><br></code></pre></td></tr></table></figure></li></ol><ul><li>通过路由的methods指定url允许的请求格式：<br>代码是2.py<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 访问方法 http://127.0.0.1:5000/hi</span><br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask<br><br>app = Flask(__name__)<br><br><span class="hljs-comment">#methods参数用于指定允许的请求格式</span><br><span class="hljs-comment">#常规输入url的访问就是get方法</span><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&quot;/hello&quot;</span>,methods=[<span class="hljs-string">&#x27;GET&#x27;</span>,<span class="hljs-string">&#x27;POST&#x27;</span>]</span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">hello</span>():<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;Hello World!&quot;</span><br><span class="hljs-comment">#注意路由路径不要重名，映射的视图函数也不要重名 ,对于方法来讲，methods = []</span><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&quot;/hi&quot;</span>,methods=[<span class="hljs-string">&#x27;POST&#x27;</span>,<span class="hljs-string">&#x27;GET&#x27;</span>]</span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">hi</span>():<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;Hi World!&quot;</span><br><br><span class="hljs-comment"># Ensure the app runs only if executed directly (not when imported as a module)</span><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    app.run(debug=<span class="hljs-literal">True</span>)<br><br><br></code></pre></td></tr></table></figure></li></ul><p>代码是3.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 增加页面，</span><br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask<br><br>app = Flask(__name__)<br><br><span class="hljs-comment"># 可以在路径内以/&lt;参数名&gt;的形式指定参数，默认接收到的参数类型是string</span><br><br><span class="hljs-string">&#x27;&#x27;&#x27;#######################</span><br><span class="hljs-string">以下为框架自带的转换器，可以置于参数前将接收的参数转化为对应类型</span><br><span class="hljs-string">string 接受任何不包含斜杠的文本</span><br><span class="hljs-string">int 接受正整数</span><br><span class="hljs-string">float 接受正浮点数</span><br><span class="hljs-string">path 接受包含斜杠的文本</span><br><span class="hljs-string">########################&#x27;&#x27;&#x27;</span><br><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&quot;/index/&lt;int:id&gt;&quot;</span>,</span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">index</span>(<span class="hljs-params"><span class="hljs-built_in">id</span></span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">id</span> == <span class="hljs-number">1</span>: <span class="hljs-comment"># 访问方法：http://127.0.0.1:5000/index/1</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;first&#x27;</span><br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">id</span> == <span class="hljs-number">2</span>: <span class="hljs-comment"># 访问方法 http://127.0.0.1:5000/index/2</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;second&#x27;</span><br>    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">id</span> == <span class="hljs-number">3</span>: <span class="hljs-comment"># 访问方法 http://127.0.0.1:5000/index/3</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;thrid&#x27;</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;hello world!&#x27;</span><br><br><span class="hljs-keyword">if</span> __name__==<span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    app.run()<br><br><br></code></pre></td></tr></table></figure><ul><li>除了原有的转换器，我们也可以自定义转换器（<code>pip install werkzeug</code>）：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> werkzeug.routing <span class="hljs-keyword">import</span> BaseConverter <span class="hljs-comment">#导入转换器的基类，用于继承方法</span><br><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask<br><br>app = Flask(__name__)<br><br><span class="hljs-comment"># 自定义转换器类</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">RegexConverter</span>(<span class="hljs-title class_ inherited__">BaseConverter</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,url_map,regex</span>):<br>        <span class="hljs-comment"># 重写父类定义方法</span><br>        <span class="hljs-built_in">super</span>(RegexConverter,self).__init__(url_map)<br>        self.regex = regex<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">to_python</span>(<span class="hljs-params">self, value</span>):<br>        <span class="hljs-comment"># 重写父类方法，后续功能已经实现好了</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;to_python方法被调用&#x27;</span>)<br>        <span class="hljs-keyword">return</span> value<br><br><span class="hljs-comment"># 将自定义的转换器类添加到flask应用中</span><br><span class="hljs-comment"># 具体过程是添加到Flask类下url_map属性（一个Map类的实例）包含的转换器字典属性中</span><br>app.url_map.converters[<span class="hljs-string">&#x27;re&#x27;</span>] = RegexConverter<br><span class="hljs-comment"># 此处re后括号内的匹配语句，被自动传给我们定义的转换器中的regex属性</span><br><span class="hljs-comment"># value值会与该语句匹配，匹配成功则传达给url映射的视图函数</span><br><span class="hljs-meta">@app.route(<span class="hljs-params"><span class="hljs-string">&quot;/index/&lt;re(&#x27;1\d&#123;10&#125;&#x27;):value&gt;&quot;</span></span>)</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">index</span>(<span class="hljs-params">value</span>):<br>    <span class="hljs-built_in">print</span>(value)<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;Hello World!&quot;</span><br><br><span class="hljs-keyword">if</span> __name__==<span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    app.run(debug=<span class="hljs-literal">True</span>)<br><br></code></pre></td></tr></table></figure><h3 id="跨域"><a href="#跨域" class="headerlink" title="跨域"></a>跨域</h3><p>http:&#x2F;&#x2F; (协议)<br><a href="http://hostname(主机名)：port（端口号）">http://hostname(主机名)：port（端口号）</a> 这三个东西有一个不同就叫做跨域，跨域的本质是浏览器的安全保护。<br>怎么解决，后端允许跨域。</p>]]></content>
    
    
    
    <tags>
      
      <tag>填坑</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔12</title>
    <link href="/2024/04/26/ganwu12/"/>
    <url>/2024/04/26/ganwu12/</url>
    
    <content type="html"><![CDATA[<h2 id="当我感觉烦躁时我该怎么办？"><a href="#当我感觉烦躁时我该怎么办？" class="headerlink" title="当我感觉烦躁时我该怎么办？"></a>当我感觉烦躁时我该怎么办？</h2><p>感到烦躁是自己告诉自己应该休息了，大脑到达负荷了。出去走走，小睡一会，放松放松。<br>精力越是消极、情绪越低落，表现就越糟糕；相反，精力越积极、情绪越高涨，表现也会越高效。精力主要来自体能、思维、意志、情感</p><ol><li>锻炼，适当的锻炼会对精力有很大的帮助，间歇性训练，每一次哪怕只是维持1分钟左右，都会产生出乎意料的积极影响。俯卧撑微行为计划</li><li>呼吸，恢复精力时有技巧的，三次一组吸气，三次一组吸气、也就是，把一次吸气分为三次，把呼气分成六次，这样通过深度、平静、有节奏地呼吸会激发精力，带来放松、精力不够的时候可以尝试做一下这个动作。</li><li>食物，早餐非常重要，它不仅能提高血糖水平，还能强力推动机体新陈代谢。</li><li>充足的睡眠，充足的睡眠是最重要的精力恢复来源。中午小睡一会，能快速恢复精力。随时准备20分钟的小睡。</li><li>情绪，满足和安全感的活动都能够激发正面情感、能够恢复精力，但是很多人会觉得看电视，拿着Ipad追剧，看综艺也能带来满足感，看电视带来了只是暂时的恢复，时间长了、反而让人消耗精力。要去多做一些能够有社交性的活动，比如骑自行车、参加读书会、听音乐会等等，因为可以和其它人交流，这样满足感会时间会持续的长一些。</li><li>思维精力恢复的关键呢，就是让大脑能有间歇地休息。创造性需要投入和抽离、思考和放松、活跃与休息之间有节奏的交替进行。</li></ol><h2 id="我的精力恢复方式"><a href="#我的精力恢复方式" class="headerlink" title="我的精力恢复方式"></a>我的精力恢复方式</h2><ol><li>抖腿</li><li>小睡</li><li>做一个俯卧撑。</li><li>吃点坚果</li><li>多喝水</li><li>在进步本上记录时间点</li></ol><p>你对自己从事一生的事业了解之匮乏是难以想象的。”每个人都真正会从事一生的事业，那就是：学习和成长！</p>]]></content>
    
    
    
    <tags>
      
      <tag>感悟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>填坑——软编码</title>
    <link href="/2024/04/26/tiankeng4/"/>
    <url>/2024/04/26/tiankeng4/</url>
    
    <content type="html"><![CDATA[<h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>今天想重新复写一下模型结构，让模型能够自适应的去适应在不同的数据集，实现软编码。<br>首先介绍一下硬编码<br><a href="https://blog.csdn.net/weixin_44943389/article/details/134928228">参考博客</a><br>硬编码是指将具体的数值、路径、参数等直接写入程序代码中，而不通过变量或配置文件来表示。这样的做法使得程序中的这些数值和参数变得固定，不容易修改，且缺乏灵活性。硬编码的值通常被称为”魔法数”（Magic Numbers）或”魔法字符串”，因为它们没有直观的含义，只能通过查看代码来了解。<br>例如，以下是一个硬编码的示例，其中数值 10 直接出现在代码中：</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs scss">for <span class="hljs-selector-tag">i</span> in <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Iteration&quot;</span>, i)<br></code></pre></td></tr></table></figure><p>软编码（Softcoding）：</p><p>软编码是指通过变量、配置文件、参数等方式将具体数值或参数抽象出来，而不是直接写入代码。通过软编码，程序变得更加灵活，可以更容易地进行修改和维护，且适应性更强。</p><p>使用软编码的例子：</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs maxima"><span class="hljs-built_in">iterations</span> = <span class="hljs-number">10</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">iterations</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Iteration&quot;</span>, i)<br></code></pre></td></tr></table></figure><p>硬编码：将具体数值、参数等直接写入程序代码中，缺乏灵活性，不易修改和维护。</p><p>软编码：通过变量、配置文件等方式将数值或参数抽象出来，使得程序更具灵活性，易于修改和维护。</p><h2 id="我的解决办法"><a href="#我的解决办法" class="headerlink" title="我的解决办法"></a>我的解决办法</h2><ol><li><p>在foward中进行重新赋值（有问题），问题就是没有前向训练过程中都重新创建了一个linear，这个linear层的参数没有训练，相当于随机（注：只是我猜的，没有验证，挖个坑在这）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">IntegratedNet</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(IntegratedNet, self).__init__()<br>        self.linear = <span class="hljs-literal">None</span> <span class="hljs-comment"># 在初始类中先第一一个self.linear=None ，而后在forward中重新定义</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">if</span> self.linear <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            self.linear = nn.Linear(in_features=x.size(<span class="hljs-number">1</span>), out_features=<span class="hljs-number">1</span>)<br>        <br>        x = self.linear(x)<br>        <span class="hljs-keyword">return</span> x<br><br><span class="hljs-comment"># 创建模型实例</span><br>model = IntegratedNet()<br><br><span class="hljs-comment"># 创建输入数据</span><br>x = torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">512</span>, <span class="hljs-number">64</span>)<br><br><span class="hljs-comment"># 前向传播</span><br>output = model(x)<br><br><span class="hljs-comment"># 打印输出的形状</span><br><span class="hljs-built_in">print</span>(output.size())<br><br></code></pre></td></tr></table></figure></li><li><p>第二种解决方法在__init__中留下一个接口，在调用这个模型时直接重新赋值。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">class</span> IntegratedNet(nn.Module):<br>    <span class="hljs-attribute">def</span> __init__(self, input_size=<span class="hljs-number">3</span>, mlp_dim=<span class="hljs-number">512</span>, mlp_ratio=<span class="hljs-number">4</span>,<br>                 <span class="hljs-attribute">dims</span>=[<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">320</span>, <span class="hljs-number">512</span>],in_feature=<span class="hljs-number">64</span>):<br>        <span class="hljs-attribute">super</span>(IntegratedNet, self).__init__()<br><br><span class="hljs-attribute">model</span> = IntegratedNet(input_size=<span class="hljs-number">2</span>,in_feature=<span class="hljs-number">209</span>)  # 全部重新赋值，实现<br><span class="hljs-attribute">device</span> = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> if torch.cuda.is_available() else <span class="hljs-string">&quot;cpu&quot;</span>)<br><span class="hljs-attribute">model</span> = model.to(device)<br><br><span class="hljs-comment"># 打印模型结构摘要</span><br><span class="hljs-attribute">summary</span>(model, (<span class="hljs-number">2</span>, <span class="hljs-number">33</span>, <span class="hljs-number">3333</span>))<br><br></code></pre></td></tr></table></figure></li><li><p>重新构建网络结构，加入自适应池化层。</p></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>填坑</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《定风波》</title>
    <link href="/2024/04/25/juzhi2/"/>
    <url>/2024/04/25/juzhi2/</url>
    
    <content type="html"><![CDATA[<center> <font size = 6>《定风波》 <font></center>  三月七日，沙湖道中遇雨。雨具先去，同行皆狼狈，余独不觉。已而遂晴，故作此词。  莫听穿林打叶声，何妨吟啸且徐行。竹杖芒鞋轻胜马，谁怕？一蓑烟雨任平生。  料峭春风吹酒醒，微冷，山头斜照却相迎。回首向来萧瑟处，归去，也无风雨也无晴。<p><font size = 3><font>译文：三月七日，在沙湖道上赶上了下雨。雨具先前被带走了，同行的人都觉得很狼狈，只有我不这么觉得。过了一会儿天晴了，就创作了这首词。不用注意那穿林打叶的雨声，不妨一边吟咏长啸着，一边悠然地行走。竹杖和草鞋轻捷得胜过骑马，有什么可怕的？一身蓑衣任凭风吹雨打，照样过我的一生。春风微凉，将我的酒意吹醒，寒意初上，山头初晴的斜阳却应时相迎。回头望一眼走过来遇到风雨的地方，回去吧，对我来说，既无所谓风雨，也无所谓天晴。</p>]]></content>
    
    
    
    <tags>
      
      <tag>句子</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>喜欢的一些句子</title>
    <link href="/2024/04/25/juzhi1/"/>
    <url>/2024/04/25/juzhi1/</url>
    
    <content type="html"><![CDATA[<ol><li><p>于浩歌狂热之际中寒，于天上看见深渊，于一切眼中看见无所有，于无所希望中得救 —— 鲁迅《墓碣文》</p></li><li><p>但是太阳，他每时每刻都是夕阳也都是旭日。 当他熄灭着走下山去收尽苍凉残照之际，正是他在另一面，燃烧着爬上山巅布散烈烈朝辉之时。那一天，我也将沉静着走下山去，扶着我的拐杖。有一天，在某一处山洼里，势必会跑上来一个欢蹦的孩子，抱着他的玩具。——史铁生</p></li><li><p>生命就是这样一个过程，一个不断超越自身局限的过程，这就是命运，任何人都是一样。在这过程中，我们遭遇痛苦、超越局限、从而感受幸福。所以一切人都是平等的，我们毫不特殊。——史铁生 《病隙碎笔》</p></li><li><p>只要你不停的向上走，一级级楼梯就没有尽头，在你向上走的脚下，它们也在向上长。——卡夫卡《律师》</p></li><li><p>找到属于自己的意义，赋予生命目的，每一天都像向日葵朝向太阳一样，充满方向和意义的活，是人类能活出的最好样子，它治愈我们的根本恐惧。</p></li><li><p>成功就是用自己喜欢的方式过一生。这句话分三部分。首先要知道自己喜欢什么，其次要有追逐它的勇气，追到了，还需要一生不渝的毅力。</p></li><li><p>“我来到这个世界，不是为了繁衍后代，而是来看花怎么开，水怎么流，太阳怎么升起，夕阳如何落下。我活在世上，无非是想要明白些道理，遇见有趣的事。生命是一场偶然，我在其中寻找因果。”生命对于每个人，它的意义是不一样的，每个人都是宇宙中一个独特的存在。</p></li><li><p>世界上只有一种英雄主义，那就是认清生活的真相后依旧热爱生活。</p></li><li><p>一切的一切都是个人的选择，自己支付代价，自己承担后果，旁人没什么评价的资格。世界上很多事是你不能细想也不能过分纠结的，太纷杂的想法会如同重重的枷锁，束缚住你的脚步，等你回头看的时候，你发现其实走错路没什么可怕的，反而是踟蹰不决让自己停留在原地，丧失了人生很多重要的体验。</p></li><li><p>愿中国青年都摆脱冷气，只是向上走，不必听自暴自弃者流的话。能做事的做事，能发声的发声。有一分热，发一分光，就令萤火一般，也可以在黑暗里发一点光，不必等候炬火。此后如竟没有炬火：我便是唯一的光。倘若有了炬火，出了太阳，我们自然心悦诚服的消失。不但毫无不平，而且还要随喜赞美这炬火或太阳；因为他照了人类，连我都在内。——鲁迅《热风·随感录四十一》</p></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>句子</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔11</title>
    <link href="/2024/04/25/ganwu11/"/>
    <url>/2024/04/25/ganwu11/</url>
    
    <content type="html"><![CDATA[<p>“人生的意义是什么？”<br>回答：“每个人都有不同的答案。”</p>]]></content>
    
    
    
    <tags>
      
      <tag>感悟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文思路</title>
    <link href="/2024/04/25/paper_idear/"/>
    <url>/2024/04/25/paper_idear/</url>
    
    <content type="html"><![CDATA[<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><ol><li>傅里叶变换 （时间域变换为频域）</li><li>归一化（零归一化，批归一化，层归一化）</li><li>数据增强操作。<br>guding_channl&#x2F;AD -&gt; 训练集大小: 65<br>guding_channl&#x2F;AD -&gt; 测试集大小: 7<br>guding_channl&#x2F;CN -&gt; 训练集大小: 95<br>guding_channl&#x2F;CN -&gt; 测试集大小: 10<br>guding_channl&#x2F;MCI -&gt; 训练集大小: 91<br>guding_channl&#x2F;MCI -&gt; 测试集大小: 10</li></ol><h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><ol><li>startRule</li><li>ReLU</li></ol><h2 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h2><ol><li>编码器——解码器</li><li>残差连接（基于ResNet）</li><li>MLP</li><li>双输入卷积神经网络。</li></ol><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><ol><li>交叉熵损失函数</li></ol><h2 id="优化函数"><a href="#优化函数" class="headerlink" title="优化函数"></a>优化函数</h2><ol><li>SGD</li><li>RMSprop</li></ol><h2 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h2><p>怎么进行评估，<br><img src="/pic/predict.jpg" alt="二分类示意图"><br>True Positives (TP)：正类别样本中被正确预测为正类别的数量。True Negatives (TN)：负类别样本中被正确预测为负类别的数量。False Positives (FP)：负类别样本中被错误预测为正类别的数量。False Negatives (FN)：正类别样本中被错误预测为负类别的数量。</p><ol><li>ACC （准确率） ( TP+TN )  &#x2F; (TP+TN+FP+FN)</li><li>pression (精确率) (TP&#x2F;TP+FP) </li><li>Recall (Sensitivity，灵敏度) (TP &#x2F; TP+FN )</li><li>F1-score (F1 值) （2 x (precision x Recall)&#x2F;(precision + Recall )）</li><li>Specificity (特异性) （TN &#x2F; (TN + FP )）</li><li>混淆矩阵</li></ol><h2 id="数据输入"><a href="#数据输入" class="headerlink" title="数据输入"></a>数据输入</h2><ol><li>双输入卷积神经网络 （傅里叶信号+归一化信号）</li></ol><h2 id="实验补充"><a href="#实验补充" class="headerlink" title="实验补充"></a>实验补充</h2><ol><li>横向实验：按照8：2的数据划分来进行验证。</li><li>做消融实验，三个（原模型，删去） </li><li>验证不同的时间长度的正确性。</li></ol><h2 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h2><ol><li>双数据输入，对数据采用不同的数据预处理，比如FFT(傅里叶变换)，小波变换，零归一化.</li><li>在公开数据集上验证处理不同的数据预处理方法对实验结果的好坏。</li><li>对比私有数据集，验证自己模型的稳健性（鲁棒性）。</li><li>使用图像处理的模型结构。</li><li>公开数据集的二分类结果，对比论文。</li><li>验证选取合适的数据预处理方法是合适的。(注：数据预处理+深度学习模型架构。)</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>论文思路</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python自定义包的层级引用</title>
    <link href="/2024/04/24/tiankeng3/"/>
    <url>/2024/04/24/tiankeng3/</url>
    
    <content type="html"><![CDATA[<h2 id="挖坑"><a href="#挖坑" class="headerlink" title="挖坑"></a>挖坑</h2><p>今天debug的时候自定义了一个函数，使用了start主函数来引用processing函数，processing函数引用了同级文件夹中的python文件中的dataset函数，在运行processing的时候，test是通过的，但是在使用start函数来调用processing函数，processing函数函数调用dataset函数时就出现了报错，提示找不到这个包。（注：这里需要指明的是start函数放置在根文件夹中，processing函数放置在processing文件夹中）问题就在于python文件的文件运行路径的出错。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs stylus">│  start<span class="hljs-selector-class">.py</span><br>│<br>├─static<br>│  │  __init__<span class="hljs-selector-class">.py</span><br>│  │<br>│  ├─model<br>│  │      MLPForMer<span class="hljs-selector-class">.pth</span><br>│  │<br>│  ├─processing<br>│  │  │  dataset<span class="hljs-selector-class">.py</span><br>│  │  │  net<span class="hljs-selector-class">.py</span><br>│  │  │  processing<span class="hljs-selector-class">.py</span><br>│  │  │  __init__<span class="hljs-selector-class">.py</span><br>│  │  │<br>│  │  └─__pycache__<br>│  │          dataset<span class="hljs-selector-class">.cpython-38</span><span class="hljs-selector-class">.pyc</span><br>│  │          net<span class="hljs-selector-class">.cpython-38</span><span class="hljs-selector-class">.pyc</span><br>│  │          processing<span class="hljs-selector-class">.cpython-38</span><span class="hljs-selector-class">.pyc</span><br>│  │          __init__<span class="hljs-selector-class">.cpython-38</span><span class="hljs-selector-class">.pyc</span><br>│  │<br>│  ├─result<br>│  │      average_probabilities<span class="hljs-selector-class">.csv</span><br>│  │      average_probabilities<span class="hljs-selector-class">.png</span><br>│  │<br>│  ├─tmp<br>│  │      <span class="hljs-number">1</span><span class="hljs-selector-class">.edf</span><br>│  │<br>│  └─__pycache__<br>│          __init__<span class="hljs-selector-class">.cpython-38</span><span class="hljs-selector-class">.pyc</span><br>│<br>└─templates<br>        upload.html<br></code></pre></td></tr></table></figure><h2 id="填坑"><a href="#填坑" class="headerlink" title="填坑"></a>填坑</h2><p>对待这种问题目前我知道的有两种方法</p><ol><li>第一种方法在processing文件中明确的所以绝对引用的方法,因为问题是出现在processing中的。</li></ol><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs livescript"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> <span class="hljs-keyword">static</span>.processing.net <span class="hljs-keyword">import</span> * <span class="hljs-comment"># 这里引用是相对于start函数的位置</span><br><br></code></pre></td></tr></table></figure><ol start="2"><li>第二种方法，在__init__文件中给出直接引用<br>1.相对引用package需要采用from 相对位置 import package_name的方式。因为相对位置只能写在from和import中间。<br>2.from . import * 只会检索当前目录下的module，而不会导入package。</li></ol><h3 id="挖坑-1"><a href="#挖坑-1" class="headerlink" title="挖坑"></a>挖坑</h3><h3 id="windown怎么打印树状图？"><a href="#windown怎么打印树状图？" class="headerlink" title="windown怎么打印树状图？"></a>windown怎么打印树状图？</h3><p>使用<code>tree</code>来打印文件夹<br>使用<code>tree /f</code>来打印文件目录，如上面的文件目录结构。</p><h3 id="init-文件的作用是什么？"><a href="#init-文件的作用是什么？" class="headerlink" title="__init__文件的作用是什么？"></a>__init__文件的作用是什么？</h3><p>作为包的标识：</p><ol><li>当一个目录包含__init__.py文件时，Python会将该目录视为一个包，而不仅仅是一个普通的目录。这使得包内的模块可以被正确导入和使用。</li><li><strong>init</strong>.py文件可以是一个空文件，也可以包含初始化包的代码，比如设置包的属性、导入子模块等。</li></ol><p>初始化包：</p><ol><li>在包被导入时，<strong>init</strong>.py文件会在包内的其他模块之前被执行。这使得可以在__init__.py中执行一些初始化操作，比如设置包级别的变量、执行必要的初始化代码等。</li><li>这也可以用于在导入包时自动执行一些操作，比如注册插件、加载配置等。·</li></ol><h2 id="填坑-1"><a href="#填坑-1" class="headerlink" title="填坑"></a>填坑</h2><h3 id="居中显示"><a href="#居中显示" class="headerlink" title="居中显示"></a>居中显示</h3><p>可以使用center标签，或者使用div标签，或者使用p标签，或者h标签都是可以的</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">center</span>&gt;</span> <span class="hljs-tag">&lt;&gt;</span>数据结构和算法是居中展示，使用center标签<span class="hljs-tag">&lt;/<span class="hljs-name">center</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">align</span>=<span class="hljs-string">center</span>&gt;</span>数据结构和算法是居中展示，使用div标签<span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span> <span class="hljs-attr">align</span>=<span class="hljs-string">&quot;center&quot;</span>&gt;</span>数据结构和算法是居中展示，使用p标签<span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">h5</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;text-align:center&quot;</span>&gt;</span>数据结构和算法是居中展示，使用h标签<span class="hljs-tag">&lt;/<span class="hljs-name">h5</span>&gt;</span><br></code></pre></td></tr></table></figure><h3 id="给改文字大小"><a href="#给改文字大小" class="headerlink" title="给改文字大小"></a>给改文字大小</h3><p>使用font标签，字体使用face，颜色使用color，尺寸使用size。<br>颜色可以使用字母比如red，black，blue，yellow等，也可以是十六进制表示比如#0000ff或者#F025AB等等<br>size 是从1到7，数字越小字体越小，浏览器默认是3<br>这几个属性可以都设置，也可以只设置其中的1到2个</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs routeros">&lt;font <span class="hljs-attribute">face</span>=<span class="hljs-string">&quot;黑体&quot;</span>&gt;我是黑体字体&lt;/font&gt;<br>&lt;font <span class="hljs-attribute">face</span>=<span class="hljs-string">&quot;微软雅黑&quot;</span>&gt;我是微软雅黑字体&lt;/font&gt;<br>&lt;font <span class="hljs-attribute">face</span>=<span class="hljs-string">&quot;STCAIYUN&quot;</span>&gt;我是华文彩字体云&lt;/font&gt;<br>&lt;font <span class="hljs-attribute">color</span>=red <span class="hljs-attribute">size</span>=3 <span class="hljs-attribute">face</span>=<span class="hljs-string">&quot;黑体&quot;</span>&gt;我是红色，黑色字体，大小是3&lt;/font&gt;<br>&lt;font <span class="hljs-attribute">color</span>=#F025AB <span class="hljs-attribute">size</span>=5&gt;我的颜色是#F025AB，大小是5&lt;/font&gt;<br><br></code></pre></td></tr></table></figure><h3 id="生成requirements-txt文件"><a href="#生成requirements-txt文件" class="headerlink" title="生成requirements.txt文件"></a>生成requirements.txt文件</h3><ol><li>如果你使用了虚拟环境（virtualenv）来管理项目依赖，可以在激活虚拟环境后运行pip freeze &gt; requirements.txt命令来生成requirements.txt文件。</li><li>使用pipreqs：pipreqs是一个可以根据Python代码中的import语句生成requirements.txt文件的工具。你可以通过以下命令安装pipreqs：<code>pip install pipreqs</code>, 然后在项目的根目录运行以下命令：<code>pipreqs .</code> 这将在当前目录下生成一个requirements.txt文件，其中包含了项目所需的所有包及其版本信息。</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>填坑</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔10</title>
    <link href="/2024/04/24/ganwu10/"/>
    <url>/2024/04/24/ganwu10/</url>
    
    <content type="html"><![CDATA[<h3 id="怎么才能快乐？"><a href="#怎么才能快乐？" class="headerlink" title="怎么才能快乐？"></a>怎么才能快乐？</h3><p>不以物喜，不以己悲。因为外物而带来的快乐是会失去的，喜悦要来源于自己的内心。对我而言，战胜一个又一个困难的过程是有意思的，可能这件事我不是很感兴趣，但是令我开心的是解决问题的过程。我知道自己现在无法解决这个问题，但是慢慢的去做，在做的过程中我发现自己爱上了这个感觉，爱上了解决问题的过程，就像米哈里所说的心流状态，即使是一点点进步我就会产生一点点发自内心的喜悦。</p><p>一呼一吸，一言一行。花开花落，云卷云舒。感受过程，提升自己。一句我从小听到的话，一句很普通的话，隐含着巨大的道理——“每天进步一点点”,这句话在我曾经就读的小学校园的门口就能看到。进步是令人快乐的，这种快乐不是来源于外物，而是来源于自己的内心。胡适先生为“中国科学社”写社歌，最后几句歌词就是:我们唱天行有常，我们唱致知穷理。怕什么真理无穷，进一寸有一寸的欢喜。1934年，他写《“九·一八”的第三周年纪念告全国的青年》。其中说:“努力一分，就有一分的效果。努力百分，就有百分的效果。”</p><p>以勇气来迎接人生的每一个挑战。这个挑战不一定很宏大，可能它就是今天我要8点起床，晚上11点睡觉，可能就是我今天要做一个俯卧撑，跑一圈操场，一个普普通通的挑战。改变总是开始于微小的，即使是写一个project也是从新建文件开始的。积极向上，把每一次挑战看作一次进步的机会，即使失败了又有什么问题，我想这个过程中一定是快乐的。苦难不值得被歌颂，认清苦难的现实和战胜苦难的勇气才值得被歌颂。</p><p>踏上自我成长的道路，每一个过程都是令人快乐的。</p><h3 id="今天冲浪的感受。"><a href="#今天冲浪的感受。" class="headerlink" title="今天冲浪的感受。"></a>今天冲浪的感受。</h3>]]></content>
    
    
    
    <tags>
      
      <tag>感悟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>图像处理-数据预处理</title>
    <link href="/2024/04/23/deeplearnbook3/"/>
    <url>/2024/04/23/deeplearnbook3/</url>
    
    <content type="html"><![CDATA[<h2 id="基本知识"><a href="#基本知识" class="headerlink" title="基本知识"></a>基本知识</h2><p>在深度学习中，图像数据通常以多维数组（在Python中通常使用Numpy数组）的形式表示，这个数组的形状（shape）取决于图像的维度和颜色通道数。<br>灰度图像：对于灰度图像（也就是黑白图像），shape通常是两维的，表示图像的高度和宽度。例如，一个256x256像素的灰度图像的shape将是(256, 256)。灰度图像的像素值通常在0到255之间，其中0表示黑色，255表示白色，中间的值表示不同的灰度级别。这是因为每个像素通常由8位（一个字节）表示，所以可以有256（即$2^8$）个不同的可能值。然而，这并不是唯一的表示方式。有时，为了方便计算，我们可能会将像素值归一化到0到1之间。在这种情况下，0仍然表示黑色，1表示白色，中间的值表示不同的灰度级别。<br>彩色图像：对于彩色图像，通常使用RGB（红，绿，蓝）三个颜色通道，所以shape是三维的。例如，一个256x256像素的RGB彩色图像的shape将是(256, 256, 3)。这里的3代表三个颜色通道。彩色图像通常由三个颜色通道组成：红色（R），绿色（G）和蓝色（B）。每个通道的像素值通常在0到255之间，其中0表示该颜色的完全缺失，255表示该颜色的最大强度。所以，一个RGB颜色图像的像素值范围在理论上是0到255的三维空间，即(0,0,0)到(255,255,255)。同样，有时我们也会将每个颜色通道的像素值归一化到0到1之间。在这种情况下，(0,0,0)表示黑色，(1,1,1)表示白色，其他值表示不同的颜色。需要注意的是，虽然RGB是最常用的颜色空间，但也有其他的颜色空间，如HSV（色相，饱和度，亮度）或者CMYK（青色，品红，黄色，黑色），它们的取值范围可能会有所不同。<br>图像批量：在深度学习中，我们通常会一次处理多个图像，这就是所谓的批量（batch）。在这种情况下，图像数据的shape将是四维的：(批量大小, 高度, 宽度, 颜色通道数)。例如，如果我们有32个256x256像素的RGB图像，那么这个批量的shape将是(32, 256, 256, 3)。</p><h2 id="显示彩色图像"><a href="#显示彩色图像" class="headerlink" title="显示彩色图像"></a>显示彩色图像</h2><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> cv2 # opencv中按BGR排布，蓝绿红<br><span class="hljs-attribute">import</span> numpy as np<br><br><span class="hljs-attribute">img</span> = np.zeros((<span class="hljs-number">5</span>,<span class="hljs-number">5</span>,<span class="hljs-number">3</span>),dtype=np.uint8)<br><br><span class="hljs-attribute">img</span>.itemset((<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>),<span class="hljs-number">255</span>) # 蓝色区块，位于（<span class="hljs-number">0</span> x轴，<span class="hljs-number">0</span> y轴，<span class="hljs-number">0</span>通道位置） 注： 如下图，对于<br><span class="hljs-attribute">img</span>.itemset((<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>),<span class="hljs-number">255</span>) # 绿色区块，位于（<span class="hljs-number">1</span> x轴， <span class="hljs-number">1</span> y轴，<span class="hljs-number">1</span>通道位置 ） <br><span class="hljs-attribute">img</span>.itemset((<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>),<span class="hljs-number">255</span>) # <br><span class="hljs-attribute">img</span>.itemset((<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>),<span class="hljs-number">255</span>) # 中间的白色区块。 <br><span class="hljs-attribute">img</span>.itemset((<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>),<span class="hljs-number">255</span>) # <br><span class="hljs-attribute">img</span>.itemset((<span class="hljs-number">3</span>,<span class="hljs-number">3</span>,<span class="hljs-number">2</span>),<span class="hljs-number">255</span>)<br><span class="hljs-attribute">img</span>.itemset((<span class="hljs-number">4</span>,<span class="hljs-number">4</span>,<span class="hljs-number">1</span>),<span class="hljs-number">255</span>)<br><span class="hljs-attribute">img</span>.itemset((<span class="hljs-number">0</span>,<span class="hljs-number">4</span>,<span class="hljs-number">0</span>),<span class="hljs-number">255</span>)<br><span class="hljs-attribute">img</span>.itemset((<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">2</span>),<span class="hljs-number">255</span>)<br><span class="hljs-attribute">img</span>.itemset((<span class="hljs-number">3</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>),<span class="hljs-number">255</span>)<br><span class="hljs-attribute">img</span>.itemset((<span class="hljs-number">4</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>),<span class="hljs-number">255</span>)<br><br><span class="hljs-attribute">cv2</span>.namedWindow(&#x27;img&#x27;,cv2.WINDOW_NORMAL)<br><span class="hljs-attribute">cv2</span>.resizeWindow(&#x27;img&#x27;,<span class="hljs-number">500</span>,<span class="hljs-number">500</span>)<br><span class="hljs-attribute">cv2</span>.imshow(&#x27;img&#x27;,img)<br><span class="hljs-attribute">cv2</span>.waitKey()<br><span class="hljs-attribute">cv2</span>.destroyAllWindows()<br></code></pre></td></tr></table></figure><p><img src="/pic/sdxxtx1.png" alt="代码结果"></p><h2 id="对图像进行截取操作"><a href="#对图像进行截取操作" class="headerlink" title="对图像进行截取操作"></a>对图像进行截取操作</h2><p>剪裁图片<br><img src="/pic/kongfu_panda.jpg" alt="功夫熊猫"></p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs scss">import cv2<br>import matplotlib<span class="hljs-selector-class">.pyplot</span> as plt<br>def <span class="hljs-built_in">show_plt</span>(path):<br>    # 显示原始图片<br>    image_path = path<br>    image = plt.<span class="hljs-built_in">imread</span>(image_path)<br>    plt.<span class="hljs-built_in">imshow</span>(image)<br>    plt.<span class="hljs-built_in">axis</span>(<span class="hljs-string">&#x27;off&#x27;</span>)<br>    plt.<span class="hljs-built_in">show</span>()<br><br>def <span class="hljs-built_in">mian</span>(path):<br>    img = cv2.<span class="hljs-built_in">imread</span>(path)<br>    if img is not None:<br>        ROI1 = img[<span class="hljs-number">79</span>:<span class="hljs-number">510</span>,<span class="hljs-number">345</span>:<span class="hljs-number">670</span>,:] # 可以看出 先是y轴，而后是x轴，最后是通道<br>        ROI2 = img[<span class="hljs-number">70</span>:<span class="hljs-number">340</span>,<span class="hljs-number">35</span>:<span class="hljs-number">250</span>,:] <br>        ROI3 = img[<span class="hljs-number">227</span>:<span class="hljs-number">499</span>,<span class="hljs-number">213</span>:<span class="hljs-number">356</span>,:]<br>        ROI4 = img[<span class="hljs-number">250</span>:<span class="hljs-number">510</span>,<span class="hljs-number">605</span>:<span class="hljs-number">751</span>,:]<br>        ROI5 = img[<span class="hljs-number">53</span>:<span class="hljs-number">421</span>,<span class="hljs-number">675</span>:<span class="hljs-number">969</span>,:]<br><br>        cv2.<span class="hljs-built_in">imshow</span>(<span class="hljs-string">&#x27;ROI1&#x27;</span>,ROI1)<br>        cv2.<span class="hljs-built_in">imshow</span>(<span class="hljs-string">&#x27;ROI2&#x27;</span>,ROI2)<br>        cv2.<span class="hljs-built_in">imshow</span>(<span class="hljs-string">&#x27;ROI3&#x27;</span>,ROI3)<br>        cv2.<span class="hljs-built_in">imshow</span>(<span class="hljs-string">&#x27;ROI4&#x27;</span>,ROI4)<br>        cv2.<span class="hljs-built_in">imshow</span>(<span class="hljs-string">&#x27;ROI5&#x27;</span>,ROI5)<br>        key = cv2.<span class="hljs-built_in">waitKey</span>(<span class="hljs-number">0</span>) # 等待按键，<br>        if key == <span class="hljs-built_in">ord</span>(<span class="hljs-string">&#x27;q&#x27;</span>):<br>            cv2.<span class="hljs-built_in">destroyAllWindows</span>() # 关闭窗口<br>    else:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;failed to load image&#x27;</span>)<br><br>if __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-built_in">show_plt</span>(<span class="hljs-string">&#x27;1/kongfu_panda.jpg&#x27;</span>)<br>    <span class="hljs-built_in">mian</span>(<span class="hljs-string">&#x27;1/kongfu_panda.jpg&#x27;</span>)<br><br></code></pre></td></tr></table></figure><p>结果图片<br><img src="/pic/tpcl1.png" alt="剪切结果"></p><p><img src="/pic/tpcl2.png" alt="处理图片"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params">path</span>):<br>    img = cv2.imread(path)<br>    <span class="hljs-built_in">print</span>(img.shape)<br>    <span class="hljs-keyword">if</span> img <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        face = np.random.randint(<span class="hljs-number">0</span>,<span class="hljs-number">255</span>,(<span class="hljs-number">600</span>,<span class="hljs-number">445</span>,<span class="hljs-number">3</span>)) <span class="hljs-comment"># 随机产生掩盖矩阵</span><br>        img[<span class="hljs-number">50</span>:<span class="hljs-number">650</span>,<span class="hljs-number">364</span>:<span class="hljs-number">809</span>,:] = face <span class="hljs-comment"># 将图片的重新赋值</span><br>        cv2.namedWindow(<span class="hljs-string">&#x27;Data Masking&#x27;</span>,<span class="hljs-number">0</span>)<br>        cv2.resizeWindow(<span class="hljs-string">&#x27;Data Masking&#x27;</span>,<span class="hljs-number">500</span>,<span class="hljs-number">500</span>) <span class="hljs-comment"># 对现实的图片进行缩放，缩放到（500，500）</span><br>        cv2.imshow(<span class="hljs-string">&#x27;Data Masking&#x27;</span>,img)<br>        cv2.waitKey() <span class="hljs-comment"># 这样写的原因是保持图片的一直显示,否则一闪而逝</span><br>        cv2.destroyAllWindows()<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;falied to load image&#x27;</span>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    main(<span class="hljs-string">&quot;1/police_story.png&quot;</span>)<br></code></pre></td></tr></table></figure><p><img src="/pic/tpcl3.png" alt="处理图片"></p><p>显示RGB通道的图片内容</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><br>lena = cv2.imread(<span class="hljs-string">&#x27;1/lena_color.jpg&#x27;</span>)<br><br><span class="hljs-keyword">if</span> lena <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>    cv2.imshow(<span class="hljs-string">&#x27;lean&#x27;</span>,lena)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;img.shape&#x27;</span>,img.shape)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;img.size&#x27;</span>,img.size)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;omg.dtype&#x27;</span>,img.dtype)<br>    b = lena[:,:,<span class="hljs-number">0</span>]<br>    g = lena[:,:,<span class="hljs-number">1</span>]<br>    r = lena[:,:,<span class="hljs-number">2</span>]<br>    cv2.imshow(<span class="hljs-string">&#x27;r&#x27;</span>,r)<br>    cv2.imshow(<span class="hljs-string">&#x27;g&#x27;</span>,g)<br>    cv2.imshow(<span class="hljs-string">&#x27;b&#x27;</span>,b)<br>    img1 = cv2.resize(img,(<span class="hljs-number">600</span>,<span class="hljs-number">600</span>)) <span class="hljs-comment"># 调整图像本身的大小</span><br>     img1 = cv2.merge([g,r,b]) <span class="hljs-comment"># cv2.merge可以调整BGR图像通道为自定义的[g,r,b]</span><br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;failed to load image&#x27;</span>)<br><br>cv2.waitKey()<br>cv2.destroyAllWindows()<br><span class="hljs-comment"># 可以看到基本的信息都包含，只不过是灰度的图像</span><br></code></pre></td></tr></table></figure><p><img src="/pic/tpcl5.png" alt="通道显示"></p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs stylus">import numpy as np<br>import cv2<br><br>img1=np<span class="hljs-selector-class">.array</span>(<span class="hljs-selector-attr">[[178,83,29]</span>,<span class="hljs-selector-attr">[202,200,158]</span>,<span class="hljs-selector-attr">[27,177,162]</span>],dtype=np.uint8)<br>img2=np<span class="hljs-selector-class">.array</span>(<span class="hljs-selector-attr">[[26,48,57]</span>,<span class="hljs-selector-attr">[52,153,8]</span>,<span class="hljs-selector-attr">[10,232,7]</span>],dtype=np.uint8)<br><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-string">&quot;img1\n&quot;</span>, img1)</span></span><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-string">&quot;img1\n&quot;</span>, img2)</span></span><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-string">&quot;img1+img2\n&quot;</span>,img1+img2)</span></span><br><br><br>cv2<span class="hljs-selector-class">.namedWindow</span>(<span class="hljs-string">&#x27;img&#x27;</span>,cv2.WINDOW_NORMAL)<br>cv2<span class="hljs-selector-class">.imshow</span>(<span class="hljs-string">&quot;img&quot;</span>,img1+img2)<br>cv2<span class="hljs-selector-class">.resizeWindow</span>(<span class="hljs-string">&#x27;img&#x27;</span>,<span class="hljs-number">500</span>,<span class="hljs-number">500</span>)<br>key = cv2<span class="hljs-selector-class">.waitKey</span>()<br><span class="hljs-keyword">if</span> key == <span class="hljs-built_in">ord</span>(<span class="hljs-string">&#x27;q&#x27;</span>):<br>    cv2<span class="hljs-selector-class">.destroyAllWindows</span>()<br></code></pre></td></tr></table></figure><p><img src="/pic/tpcl6.png" alt="3x3矩阵显示"></p><p>对图片进行缩放</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> cv2<br><br><span class="hljs-attribute">img</span> = cv2.imread(&#x27;img/lena_color.jpg&#x27;)<br><br><span class="hljs-attribute">if</span> img is not None:<br>    <span class="hljs-attribute">dst</span> = cv2.resize(img,(<span class="hljs-number">600</span>,<span class="hljs-number">600</span>)) ## 将lena_color.jpg 放大到<span class="hljs-number">600</span>*<span class="hljs-number">600</span><br>    <span class="hljs-attribute">dst1</span> = cv2.resize(img,(<span class="hljs-number">50</span>,<span class="hljs-number">50</span>)) ## 将lena_color.jgp 缩小到<span class="hljs-number">50</span>*<span class="hljs-number">50</span><br>    <span class="hljs-attribute">dst2</span> = cv2.resize(img,None,fx =<span class="hljs-number">2</span>,fy=<span class="hljs-number">1</span>.<span class="hljs-number">5</span>) ##  将lena_color.jgp 在水平方向放大到<span class="hljs-number">2</span>位，垂直方向放大到<span class="hljs-number">1</span>.<span class="hljs-number">5</span>倍<br>    <span class="hljs-attribute">cv2</span>.imshow(&#x27;img&#x27;,img)<br>    <span class="hljs-attribute">cv2</span>.imshow(&#x27;dst&#x27;,dst)<br>    <span class="hljs-attribute">cv2</span>.imshow(&#x27;dst1&#x27;,dst1)<br>    <span class="hljs-attribute">cv2</span>.imshow(&#x27;dst2&#x27;,dst2)<br>    <span class="hljs-attribute">cv2</span>.waitKey()<br>    <span class="hljs-attribute">cv2</span>.destroyAllWindows()<br><br><br></code></pre></td></tr></table></figure><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> cv2<br><span class="hljs-attribute">import</span> numpy as np<br><br><span class="hljs-comment"># 读取图像</span><br><span class="hljs-attribute">img</span> = cv2.imread(&#x27;img/lena_color.jpg&#x27;)<br><br><span class="hljs-comment"># 获取图像中心坐标</span><br><span class="hljs-attribute">center</span> = tuple(np.array(img.shape[<span class="hljs-number">1</span>::-<span class="hljs-number">1</span>]) / <span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># 顺时针旋转60度</span><br><span class="hljs-attribute">rotation_matrix</span> = cv2.getRotationMatrix2D(center, -<span class="hljs-number">60</span>, <span class="hljs-number">1</span>) ##  a、以图像中心为旋转中心，顺时针旋转<span class="hljs-number">60</span>度，<br><span class="hljs-attribute">img_rotated</span> = cv2.warpAffine(img, rotation_matrix, img.shape[<span class="hljs-number">1</span>::-<span class="hljs-number">1</span>], flags=cv2.INTER_LINEAR)<br><br><span class="hljs-comment"># 缩小为原来的0.4倍</span><br><span class="hljs-attribute">img_resized</span> = cv2.resize(img_rotated, None, fx=<span class="hljs-number">0</span>.<span class="hljs-number">4</span>, fy=<span class="hljs-number">0</span>.<span class="hljs-number">4</span>, interpolation=cv2.INTER_LINEAR)<br><br><span class="hljs-comment"># 创建新的画布</span><br><span class="hljs-attribute">canvas</span> = np.zeros_like(img)<br><br><span class="hljs-comment"># 计算平移后的位置</span><br><span class="hljs-attribute">offset</span> = (<span class="hljs-number">50</span>, <span class="hljs-number">25</span>)<br><span class="hljs-attribute">new_position</span> = tuple(np.array(offset) + np.array((<span class="hljs-number">0</span>, <span class="hljs-number">0</span>)))<br><br><span class="hljs-comment"># 在新的画布上粘贴图像</span><br><span class="hljs-attribute">canvas</span>[new_position[<span class="hljs-number">1</span>]:new_position[<span class="hljs-number">1</span>]+img_resized.shape[<span class="hljs-number">0</span>], new_position[<span class="hljs-number">0</span>]:new_position[<span class="hljs-number">0</span>]+img_resized.shape[<span class="hljs-number">1</span>]] = img_resized<br><br><span class="hljs-comment"># 显示图像</span><br><span class="hljs-attribute">cv2</span>.imshow(&#x27;Result&#x27;, canvas)<br><span class="hljs-attribute">cv2</span>.imshow(&#x27;orangin&#x27;,img)<br><span class="hljs-attribute">cv2</span>.waitKey(<span class="hljs-number">0</span>)<br><span class="hljs-attribute">cv2</span>.destroyAllWindows()<br><br></code></pre></td></tr></table></figure><p>对图片进行形态学操作<br>掌握图像形态学的基本原理和常用算法。学会使用形态学操作进行图像处理，如噪声去除、边缘检测、特征提取等。培养分析和解决图像处理问题的能力。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs"><br><br></code></pre></td></tr></table></figure><h2 id="处理方法"><a href="#处理方法" class="headerlink" title="处理方法"></a>处理方法</h2><ol><li>二值化处理：这是最基本的阈值处理方法。对于每个像素，我们选择一个阈值。如果像素值大于阈值，我们将其设置为一个值（通常是白色），如果像素值小于或等于阈值，我们将其设置为另一个值（通常是黑色）。这样我们就得到了一个二值图像。</li><li>反二值化处理：这是二值化处理的反向操作。如果像素值大于阈值，我们将其设置为一个值（通常是黑色），如果像素值小于或等于阈值，我们将其设置为另一个值（通常是白色）。</li><li>截断阈值处理：对于每个像素，如果其值大于阈值，我们将其设置为阈值。如果像素值小于或等于阈值，我们保持其原值不变。</li><li>超阈值零处理：对于每个像素，如果其值大于阈值，我们保持其原值不变。如果像素值小于或等于阈值，我们将其设置为零。</li><li>低阈值零处理：这是超阈值零处理的反向操作。如果像素值大于阈值，我们将其设置为零。如果像素值小于或等于阈值，我们保持其原值不变。</li><li>自适应阈值处理：这是一种更复杂的方法，它不使用固定的阈值。相反，它根据像素周围的小区域计算阈值。因此，对于同一张图片上的不同区域，我们可以有不同的阈值。这对于当图像的光照条件变化很大时，例如，一半是明亮的，一半是暗淡的图像，非常有用。</li></ol><h2 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h2><figure class="highlight smali"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs smali">import cv2<br><br><span class="hljs-comment"># 读取图像</span><br>image = cv2.imread(&#x27;e1.jpg&#x27;, cv2.IMREAD_GRAYSCALE)<br><br><span class="hljs-comment"># 二值化处理</span><br>_, binary_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)<br><br><span class="hljs-comment"># 反二值化处理</span><br>_, binary_inv_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)<br><br><span class="hljs-comment"># 截断阈值处理</span><br>_, trunc_image = cv2.threshold(image, 127, 255, cv2.THRESH_TRUNC)<br><br><span class="hljs-comment"># 超阈值零处理</span><br>_, tozero_inv_image = cv2.threshold(image, 127, 255, cv2.THRESH_TOZERO_INV)<br><br><span class="hljs-comment"># 低阈值零处理</span><br>_, tozero_image = cv2.threshold(image, 127, 255, cv2.THRESH_TOZERO)<br><br><span class="hljs-comment"># 自适应阈值处理</span><br>adaptive_image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)<br><br><span class="hljs-comment"># 保存处理后的图像</span><br>cv2.imwrite(&#x27;binary_image.jpg&#x27;, binary_image)<br>cv2.imwrite(&#x27;binary_inv_image.jpg&#x27;, binary_inv_image)<br>cv2.imwrite(&#x27;trunc_image.jpg&#x27;, trunc_image)<br>cv2.imwrite(&#x27;tozero_inv_image.jpg&#x27;, tozero_inv_image)<br>cv2.imwrite(&#x27;tozero_image.jpg&#x27;, tozero_image)<br>cv2.imwrite(&#x27;adaptive_image.jpg&#x27;, adaptive_image)<br><br></code></pre></td></tr></table></figure><p><img src="/pic/e1.jpg" alt="原图"><br><img src="/pic/binary_image.jpg" alt="二值化处理图像"><br><img src="/pic/binary_inv_image.jpg" alt="反二值化处理图像"><br><img src="/pic/trunc_image.jpg" alt="截断阈值处理图像"><br><img src="/pic/tozero_inv_image.jpg" alt="超阈值处理图像"><br><img src="/pic/tozero_image.jpg" alt="低阈值零处理图像"><br><img src="/pic/adaptive_image.jpg" alt="自适应阈值处理图像"></p><h3 id="挖更大的坑，opencv库。"><a href="#挖更大的坑，opencv库。" class="headerlink" title="挖更大的坑，opencv库。"></a>挖更大的坑，opencv库。</h3><h3 id="彩色图像怎么转换为二维图像的？"><a href="#彩色图像怎么转换为二维图像的？" class="headerlink" title="彩色图像怎么转换为二维图像的？"></a>彩色图像怎么转换为二维图像的？</h3><p>首先灰度图像中的一个像素点的范围为0-255，彩色图像可以理解为3个灰度图重合。</p><h3 id="需要深度解析代码中的含义，比如一个参数有什么用处。"><a href="#需要深度解析代码中的含义，比如一个参数有什么用处。" class="headerlink" title="需要深度解析代码中的含义，比如一个参数有什么用处。"></a>需要深度解析代码中的含义，比如一个参数有什么用处。</h3><p>使用权重标记人脸</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> cv2<br><br><br><br><span class="hljs-comment"># 打开摄像头</span><br><br><span class="hljs-attribute">cap</span> = cv2.VideoCapture(<span class="hljs-number">0</span>)<br><br><br><br><span class="hljs-comment"># 设置图像分辨率为1024x768</span><br><br><span class="hljs-attribute">cap</span>.set(cv2.CAP_PROP_FRAME_WIDTH, <span class="hljs-number">1024</span>)<br><br><span class="hljs-attribute">cap</span>.set(cv2.CAP_PROP_FRAME_HEIGHT, <span class="hljs-number">768</span>)<br><br><br><br><span class="hljs-comment"># 加载人脸检测器</span><br><br><span class="hljs-attribute">face_cascade</span> = cv2.CascadeClassifier(cv2.data.haarcascades + &#x27;haarcascade_frontalface_default.xml&#x27;)<br><br><br><br><span class="hljs-attribute">while</span> True:<br><br>    <span class="hljs-comment"># 从摄像头读取一帧</span><br><br>    <span class="hljs-attribute">ret</span>, frame = cap.read()<br><br><br><br>    <span class="hljs-comment"># 检查帧是否成功读取</span><br><br>    <span class="hljs-attribute">if</span> not ret:<br><br>        <span class="hljs-attribute">print</span>(<span class="hljs-string">&quot;无法从摄像头读取帧&quot;</span>)<br><br>        <span class="hljs-attribute">break</span><br><br><br><br>    <span class="hljs-comment"># 将帧转换为灰度图像</span><br><br>    <span class="hljs-attribute">gray</span> = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)<br><br><br><br>    <span class="hljs-comment"># 检测人脸</span><br><br>    <span class="hljs-attribute">faces</span> = face_cascade.detectMultiScale(gray, scaleFactor=<span class="hljs-number">1</span>.<span class="hljs-number">1</span>, minNeighbors=<span class="hljs-number">5</span>, minSize=(<span class="hljs-number">30</span>, <span class="hljs-number">30</span>))<br><br><br><br>    <span class="hljs-comment"># 在检测到的人脸周围绘制蓝色框</span><br><br>    <span class="hljs-attribute">for</span> (x, y, w, h) in faces:<br><br>        <span class="hljs-attribute">cv2</span>.rectangle(frame, (x, y), (x+w, y+h), (<span class="hljs-number">255</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>), <span class="hljs-number">2</span>)<br><br><br><br>    <span class="hljs-comment"># 显示视频</span><br><br>    <span class="hljs-attribute">cv2</span>.imshow(&#x27;Video&#x27;, frame)<br><br><br><br>    <span class="hljs-comment"># 按下q键退出循环</span><br><br>    <span class="hljs-attribute">if</span> cv2.waitKey(<span class="hljs-number">1</span>) &amp; <span class="hljs-number">0</span>xFF == ord(&#x27;q&#x27;):<br><br>        <span class="hljs-attribute">break</span><br><br><br><br><span class="hljs-comment"># 释放摄像头并关闭窗口</span><br><br><span class="hljs-attribute">cap</span>.release()<br><br><span class="hljs-attribute">cv2</span>.destroyAllWindows()<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>填坑——经典网络结构——AlexNet</title>
    <link href="/2024/04/23/tiankeng2/"/>
    <url>/2024/04/23/tiankeng2/</url>
    
    <content type="html"><![CDATA[<h2 id="问题1，卷积是什么？作用什么？"><a href="#问题1，卷积是什么？作用什么？" class="headerlink" title="问题1，卷积是什么？作用什么？"></a>问题1，卷积是什么？作用什么？</h2><p>卷积（Convolution）是一种数学运算，常用于信号处理和图像处理领域。在信号处理中，卷积用于将输入信号与卷积核（也称为滤波器）进行运算，产生输出信号。<br>卷积的作用有以下几个方面：</p><ol><li>信号滤波：卷积可以用于信号滤波，通过将输入信号与合适的卷积核进行卷积运算，可以实现对信号的滤波操作。滤波可以用于去除信号中的噪声、平滑信号、强调信号中的某些频率成分等。</li><li>特征提取：在图像处理中，卷积可以用于特征提取。通过将图像与不同的卷积核进行卷积运算，可以提取出图像中的不同特征，例如边缘、纹理、角点等。这些特征可以用于图像识别、目标检测和图像处理中的其他任务。</li><li>信号压缩：卷积可以用于信号压缩。通过将输入信号与适当的卷积核进行卷积运算，可以将信号表示转换为另一种表示形式，通常具有更紧凑的表示。这种表示形式可以用于信号压缩和数据压缩。</li><li>卷积神经网络：卷积神经网络（Convolutional Neural Network，CNN）是一种基于卷积运算的深度学习模型，广泛应用于图像识别、计算机视觉和自然语言处理等领域。卷积在 CNN 中用于提取图像或文本的特征，并通过多层卷积和池化操作来实现对输入数据的高级表示和分类。如果输入数据为图片，那么卷积层的作用就是提取图片中的信息，这些信息被称为图像特征，这些特征是由图像中的每个像素通过组合或者独立的方式所体现，比如图片的纹理特征、颜色特征、空间特征。</li></ol><p>卷积的操作过程：<br>请参考<a href="https://blog.csdn.net/weipf8/article/details/103917202">参考博客</a>。image的图片大小为5x5，卷积核为3x3，输出的特征的大小为3x3<br>特征图计算公式：一般情况下,输入的图片矩阵以及后面的卷积核,特征图矩阵都是方阵,这里设输入矩阵大小为w,卷和核大小为k,步幅为s,补零层数为p,则卷积后产生的特征图大小计算公式为:W &#x3D; （w+2p-k）&#x2F;s + 1. 比如说上面5x5的图片与3x3的卷积核进行卷积操作，特征图的大小为： W &#x3D; （5 + 2*0 -3）&#x2F;1 + 1 &#x3D;3<br>特征图相对与下一层的卷积层是图片。<br>卷积核的参数量计算，卷积核尺寸： K， 前一层的通道数：Cin 当前层的卷积核的个数： Cout 。单个卷积核的参数量： params kernel &#x3D; Cin x K x K, 有</p><p>假设有卷积神经网络，输入为大小224<em>224的RGB图，第一层为卷积层，有12个大小为5</em>5的卷积核，填充为2，步长为4。该层参数共有（  912    ）个。计算过程权重参数量：每个卷积核有 75 （5 x 5 x 3）个权重参数，共有12 个卷积核，所以权重参数量为 75×12&#x3D;900.偏置参数量：每个卷积核有一个偏置项，共有 12 个卷积核，所以偏置参数量为 12。<br><a href="https://blog.csdn.net/Together_CZ/article/details/115494176">执行卷积的过程的动态图</a><br>关于卷积其实还有很多问题，比如说输入一张（3x255x255）的图片，输入后经过卷积后输出的特征图大小为： 要考虑卷积核的大小（kernel size ） 步幅（stride），边界填充（padding） 计算公式入上式所示。<br>。1x1卷积为什么可以实现升维和降维。）<br>1x1 卷积可以实现升维和降维的原因在于：（通道数可以自定义数量）<br>升维：当输入特征图的通道数较少时，可以使用 1x1 卷积来增加通道数，从而增加网络的表示能力。这是因为 1x1 卷积可以将输入特征图中的每个通道与卷积核中的权重相乘并求和，从而生成一个新的特征图。<br>降维：当需要减少特征图的通道数时，可以使用 1x1 卷积并调整输出通道数为所需的值。通过调整卷积核中的输出通道数，可以实现特征图通道数的降维。</p><h2 id="问题2，池化是什么？作用是什么？"><a href="#问题2，池化是什么？作用是什么？" class="headerlink" title="问题2，池化是什么？作用是什么？"></a>问题2，池化是什么？作用是什么？</h2><p>池化（Pooling）是一种常用的操作，通常与卷积神经网络（CNN）结合使用。池化操作通过对输入数据的局部区域进行聚合或采样来减小数据的空间尺寸，从而减少参数数量、降低计算量，并提取出输入数据的重要特征。</p><p>池化的作用有以下几个方面</p><ol><li>降采样：池化操作可以减小输入数据的空间尺寸，从而降低后续层的计算复杂度。通过降低数据的维度，池化可以在保留重要特征的同时减少冗余信息，提高计算效率。</li><li>平移不变性：池化操作具有一定的平移不变性。在图像处理中，通过对局部区域进行池化操作，可以使得输入图像在平移、旋转和缩放等变换下具有一定的不变性。这对于图像识别和目标检测等任务是有益的。</li><li>特征提取：池化操作可以提取输入数据的重要特征。通过对局部区域进行池化，池化操作会选择区域中的最大值（最大池化）或平均值（平均池化）作为输出值，从而提取出输入数据的显著特征。这有助于减少数据的维度，并保留重要的特征信息。</li><li>减少过拟合：池化操作可以在一定程度上减少过拟合。通过减小数据的空间尺寸，池化操作可以降低模型的参数数量，从而减少过拟合的风险。此外，池化操作还可以通过丢弃一些冗余信息来提高模型的泛化能力。</li></ol><p>池化的种类</p><ol><li>最大池化（Max Pooling）：最大池化是一种常见的池化操作。在最大池化中，输入数据的局部区域被分割成不重叠的块，然后在每个块中选择最大值作为输出。最大池化可以提取出输入数据的显著特征，同时减小数据的空间尺寸。</li><li>平均池化（Average Pooling）：平均池化是另一种常见的池化操作。在平均池化中，输入数据的局部区域被分割成不重叠的块，然后计算每个块中元素的平均值作为输出。平均池化可以平滑输入数据并减小数据的空间尺寸。</li><li>自适应池化（Adaptive Pooling）：自适应池化是一种具有灵活性的池化操作。与最大池化和平均池化不同，自适应池化不需要指定池化窗口的大小，而是根据输入数据的尺寸自动调整池化窗口的大小。这使得自适应池化可以适应不同尺寸的输入数据。</li><li>全局池化（Global Pooling）：全局池化是一种特殊的池化操作，它将整个输入数据的空间尺寸缩减为一个单一的值或向量。全局池化可以通过对输入数据的所有位置进行池化操作，从而提取出输入数据的全局特征。常见的全局池化有全局平均池化（Global Average Pooling）和全局最大池化（Global Max Pooling）。</li></ol><h2 id="问题3，全连接是什么？作用是什么？"><a href="#问题3，全连接是什么？作用是什么？" class="headerlink" title="问题3，全连接是什么？作用是什么？"></a>问题3，全连接是什么？作用是什么？</h2><p>的是神经网络中的一种连接方式，也称为密集连接（dense connection）。在全连接中，每个神经元都与前一层的所有神经元相连。这意味着前一层的每个神经元的输出都将作为输入传递给下一层的每个神经元。<br>全连接层的作用是将输入数据进行线性变换，并应用激活函数来产生输出。这种连接方式允许神经网络学习输入数据中的复杂关系，从而实现各种任务，例如分类、回归等。<br><img src="/pic/tiankeng1.png" alt="全连接示意图"><br>请问如上DNN神经网络共有几层： 5层<br>请问该DNN神经网络用来解决二分类问题，那么最后一层的激活函数是 Sigmoid<br>请问如上所示的DNN神经网络的第一个隐藏层有多少个参数： 2 x 3 + 3 &#x3D; 9 （前一层输入量 乘以 后一层的神经元数量 + 偏执项。）</p><h2 id="问题4，AlexNet论文使用的loss函数是什么？"><a href="#问题4，AlexNet论文使用的loss函数是什么？" class="headerlink" title="问题4，AlexNet论文使用的loss函数是什么？"></a>问题4，AlexNet论文使用的loss函数是什么？</h2><p>CrossEntropy交叉损失函数： </p><p><a href="https://blog.csdn.net/qq_44629163/article/details/124348366">参考博客</a></p><h2 id="问题5，AlexNet论文中使用的梯度优化方式是什么，梯度怎么实现下降？"><a href="#问题5，AlexNet论文中使用的梯度优化方式是什么，梯度怎么实现下降？" class="headerlink" title="问题5，AlexNet论文中使用的梯度优化方式是什么，梯度怎么实现下降？"></a>问题5，AlexNet论文中使用的梯度优化方式是什么，梯度怎么实现下降？</h2><p>AlexNet论文中使用的梯度优化算法是随机梯度下降（Stochastic Gradient Descent，SGD）。在训练过程中，SGD通过计算损失函数关于网络参数的梯度，并根据该梯度更新参数，以使损失函数最小化。<br><a href="https://blog.csdn.net/qq_58146842/article/details/121280968">SGD参考博客</a></p><h2 id="问题6，AlexNet论文中使用的评价指标是什么？"><a href="#问题6，AlexNet论文中使用的评价指标是什么？" class="headerlink" title="问题6，AlexNet论文中使用的评价指标是什么？"></a>问题6，AlexNet论文中使用的评价指标是什么？</h2><p>错误率 ： ACC 的相反数，计算方法为1-ACC</p><h2 id="问题7，AlexNet中的创新点是什么？"><a href="#问题7，AlexNet中的创新点是什么？" class="headerlink" title="问题7，AlexNet中的创新点是什么？"></a>问题7，AlexNet中的创新点是什么？</h2><ol><li>ReLU激活函数的引入，采样非线性单元（ReLU）的深度卷积神经网络训练时间要比tanh单元要快几倍。而时间开销是进行模型训练过程中的很重要的因数。同时ReLU有效的防止了过拟合的现象。</li><li>层叠池化操作，以往池化的大小PoolingSize与步长stride一般是相等的，例如：图像大小为256*256，PoolingSize&#x3D;2×2，stride&#x3D;2，这样可以使图像或是FeatureMap大小缩小一倍变为128，此时池化过程没有发生层叠。但是AlexNet采用了层叠池化操作，即PoolingSize &gt; stride。这种操作非常像卷积操作，可以使相邻像素间产生信息交互和保留必要的联系。论文中也证明，此操作可以有效防止过拟合的发生。</li><li>Dropout操作， Dropout操作会将概率小于0.5的每个隐层神经元的输出设为0，即去掉了一些神经节点，达到防止过拟合。那些“失活的”神经元不再进行前向传播并且不参与反向传播。这个技术减少了复杂的神经元之间的相互影响。在论文中，也验证了此方法的有效性。</li><li>网络层数更深，与原始的LeNet相比，AlexNet网络结构更深，LeNet为5层，AlexNet为8层。在随后的神经网络发展过程中，AlexNet逐渐让研究人员认识到网络深度对性能的巨大影响。当然，这种思考的重要节点出现在VGG网络（下一篇博文VGG论文中将会讲到）。</li></ol><h2 id="问题8，优化函数的具体实现是什么？"><a href="#问题8，优化函数的具体实现是什么？" class="headerlink" title="问题8，优化函数的具体实现是什么？"></a>问题8，优化函数的具体实现是什么？</h2><p>请参考博客：<br><a href="https://www.bilibili.com/video/BV1Fu4y1N7Qu/?spm_id_from=333.337.search-card.all.click&vd_source=c2d8f28374ac78ec2f99b6321e56032a">以逻辑回归为例讲的梯度下降算法矩阵化</a><br><a href="https://www.bilibili.com/video/BV1eK42147wr/?p=29&vd_source=c2d8f28374ac78ec2f99b6321e56032a">结合看</a><br><a href="https://www.bilibili.com/video/BV1JK411k7ah/?spm_id_from=333.337.search-card.all.click&vd_source=c2d8f28374ac78ec2f99b6321e56032a">代码实现</a></p><h2 id="问题10，什么是过拟合合和欠拟合？"><a href="#问题10，什么是过拟合合和欠拟合？" class="headerlink" title="问题10，什么是过拟合合和欠拟合？"></a>问题10，什么是过拟合合和欠拟合？</h2><p>过拟合：过拟合指的是模型在训练数据上表现良好，但在未见过的测试数据上表现较差的情况。过拟合通常发生在模型过于复杂或训练数据过少的情况下。当模型过度学习了训练数据中的噪声或特定的样本特征时，会导致过拟合问题。在过拟合的情况下，模型可能会过度拟合训练数据，导致泛化能力较差，无法很好地适应新的、未见过的数据。<br>欠拟合：欠拟合指的是模型在训练数据上表现不佳，无法捕捉数据中的足够的信息和结构，导致模型过于简单或不够复杂。欠拟合通常发生在模型复杂度过低或训练数据量不足的情况下。在欠拟合的情况下，模型可能无法捕捉数据中的关键特征或模式，导致训练误差和测试误差都较高。<br><a href="https://zhuanlan.zhihu.com/p/72038532">参考博客</a></p><h2 id="问题9，论文中怎么证明，层叠池化可以有效防止过拟合的发生？"><a href="#问题9，论文中怎么证明，层叠池化可以有效防止过拟合的发生？" class="headerlink" title="问题9，论文中怎么证明，层叠池化可以有效防止过拟合的发生？"></a>问题9，论文中怎么证明，层叠池化可以有效防止过拟合的发生？</h2><p>验对比：作者可能会设计实验，对比使用层叠池化和不使用层叠池化的模型在同一数据集上的性能表现。通过比较两种模型的训练误差和测试误差，可以观察到使用层叠池化的模型是否在测试数据上表现更好，从而证明其能够有效防止过拟合。<br>交叉验证：作者可能会使用交叉验证来评估模型的泛化能力。通过在不同的训练集和测试集上多次进行实验，可以更客观地评估模型的性能，并观察使用层叠池化的模型是否具有更好的泛化能力。<br>可视化分析：作者可能会对模型的训练过程进行可视化分析，比如绘制训练损失曲线和验证损失曲线。通过观察损失曲线的变化趋势，可以了解模型是否存在过拟合问题，并观察是否使用层叠池化的模型更加稳定。</p><h2 id="问题10，-softMax的机制是怎么样的？"><a href="#问题10，-softMax的机制是怎么样的？" class="headerlink" title="问题10， softMax的机制是怎么样的？"></a>问题10， softMax的机制是怎么样的？</h2><p>Softmax函数是一种常用的激活函数，通常用于多分类问题中的输出层。Softmax函数可以将一个具有任意实数值的向量转换成一个概率分布，使得各个元素的值都在 (0, 1) 范围内，并且所有元素的和为1。</p><p><a href="https://zhuanlan.zhihu.com/p/105722023">参考博客</a></p><h2 id="问题15，Dropout的运行机制是什么，论文中怎么证明他们有效-理论证明和实验证明-？"><a href="#问题15，Dropout的运行机制是什么，论文中怎么证明他们有效-理论证明和实验证明-？" class="headerlink" title="问题15，Dropout的运行机制是什么，论文中怎么证明他们有效(理论证明和实验证明)？"></a>问题15，Dropout的运行机制是什么，论文中怎么证明他们有效(理论证明和实验证明)？</h2><p>Dropout是一种常用的正则化技术，用于减少神经网络的过拟合现象。其运行机制如下：</p><p>训练阶段：在每次训练迭代时，以概率 p 将神经网络中的某些神经元（或者称为节点）临时从网络中删除（置为零）。这样，在每次迭代中，都会随机删除一部分神经元，从而导致每次迭代得到的网络结构都不同。<br>预测阶段：在预测阶段，不再使用Dropout，而是使用所有的神经元，但需要对每个神经元的输出值乘以 p，以保持期望的输出值不变。</p><h2 id="问题16，-什么是超参数？"><a href="#问题16，-什么是超参数？" class="headerlink" title="问题16， 什么是超参数？"></a>问题16， 什么是超参数？</h2><p>超参数（Hyperparameters）是机器学习模型训练过程中的配置参数，其值不能通过训练过程自动学习，而是需要人工设置。与模型的参数（例如权重和偏置）不同，超参数通常用于控制模型的结构、学习过程的行为和性能调优。</p><p>一些常见的超参数包括：<br>学习率（Learning Rate）：用于控制每次参数更新的步长。<br>迭代次数（Number of Iterations&#x2F;Epochs）：训练模型时数据集遍历的次数。<br>批量大小（Batch Size）：每次迭代中用于更新参数的样本数量。<br>网络结构参数：例如隐藏层的数量、每个隐藏层的神经元数量、卷积核大小等。<br>正则化参数：用于控制模型的复杂度，例如L1和L2正则化的权重。<br>优化算法参数：例如动量（momentum）、adam的参数等。<br>损失函数参数：例如softmax交叉熵的参数、权重类别平衡等。</p><h2 id="问题17，-什么是监督学习和无监督学习，半监督学习？"><a href="#问题17，-什么是监督学习和无监督学习，半监督学习？" class="headerlink" title="问题17， 什么是监督学习和无监督学习，半监督学习？"></a>问题17， 什么是监督学习和无监督学习，半监督学习？</h2><p>监督学习（Supervised Learning）是一种机器学习任务，其目标是从有标签的数据中学习出一个输入到输出的映射关系，即从输入数据预测出相应的输出标签。在监督学习中，训练数据包括了输入和对应的输出标签，模型通过学习输入和输出之间的关系来进行预测。典型的监督学习任务包括分类和回归。</p><p>无监督学习（Unsupervised Learning）是一种机器学习任务，其目标是从没有标签的数据中学习出数据的内在结构或者特征表示，而无需事先给定标签信息。在无监督学习中，训练数据只包括输入数据，没有对应的输出标签。无监督学习可以用于聚类、降维、异常检测等任务。</p><p>半监督学习（Semi-Supervised Learning）是介于监督学习和无监督学习之间的一种学习方式，其目标是利用少量有标签数据和大量无标签数据来训练模型。在半监督学习中，训练数据同时包括有标签的数据和无标签的数据。半监督学习可以通过结合监督学习和无监督学习的方法，利用无标签数据的信息来提升模型性能，尤其在标注数据有限或者成本较高的情况下具有重要意义。</p>]]></content>
    
    
    
    <tags>
      
      <tag>填坑</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>填坑-PyTorch基础——Numpy</title>
    <link href="/2024/04/23/tiankeng1/"/>
    <url>/2024/04/23/tiankeng1/</url>
    
    <content type="html"><![CDATA[<h3 id="向量和数组之间的关系是什么？向量的定义是什么？"><a href="#向量和数组之间的关系是什么？向量的定义是什么？" class="headerlink" title="向量和数组之间的关系是什么？向量的定义是什么？"></a>向量和数组之间的关系是什么？向量的定义是什么？</h3><p>在数学科物理中，向量被定义为具有大小和方向量。例如速度是一个向量，因为它不仅有大小（数独），还有方向（行进的方向）。<br>数组是编程中的一种基本数据结构，用于存储一组有序的元素。这些元素可以是任何类型，如整形、浮点数、字符串等。<br>标量（scalar）是零维只有大小，没有方向的量，如1，2，3<br>向量（Vector）是一维只有大小和方向的量，如（1，2）。（计算方向的公式为：）<br>矩阵（Matrix）是二维的向量，[[1, 2], [2, 3]]<br>张量（Tensor） 按照任意维排列的一堆数字的推广。矩阵不过是三维张量下的一个二维切面。要在三维张量下找到零维张量需要三个维度的坐标来定位。（注：张量可以是多维的）</p><h3 id="矩阵是什么，作用是什么？如何实现矩阵的加减乘除"><a href="#矩阵是什么，作用是什么？如何实现矩阵的加减乘除" class="headerlink" title="矩阵是什么，作用是什么？如何实现矩阵的加减乘除"></a>矩阵是什么，作用是什么？如何实现矩阵的加减乘除</h3><ol><li>矩阵是一个二维数组，由行和列的元素组成。在数学中，矩阵通常用大写字母表示，如 A，B 等，矩阵中的元素通常用小写字母表示，如aij​，表示矩阵 A 的第 i 行第 j 列的元素。</li><li>矩阵可以用来表示线性变换，解决线性方程组，或者表示图形的变换。在数据科学和机器学习中，矩阵通常用于存储和操作大量的数据。</li></ol><h4 id="实现矩阵的加减乘除。"><a href="#实现矩阵的加减乘除。" class="headerlink" title="实现矩阵的加减乘除。"></a>实现矩阵的加减乘除。</h4><p>加法：两个矩阵相加，只有在它们的行数和列数都相等时才是定义的。结果矩阵的每个元素是相应的元素相加的结果。例如，如果A &#x3D; aij 和B &#x3D; bij 是同样大小的矩阵，那么它们的和C &#x3D; [ cij ]是矩阵 ,其中cij &#x3D; aij + bij。对应相加<br>减法：矩阵的减法与加法类似，只有在两个矩阵的行数和列数都相等时才是定义的。结果矩阵的每个元素是相应的元素相减的结果。<br>乘法：矩阵的乘法比较复杂。如果A 是一个 m×n 的矩阵，B 是一个n×p 的矩阵，那么它们的乘积 AB 是一个 m×p 的矩阵，其元素由A 的行和 B 的列的对应元素的乘积之和给出。<br>除法：在矩阵中，通常不直接定义除法。但是，我们可以通过乘以逆矩阵来实现类似的效果。如果A是一个可逆的（也就是说，存在一个矩阵 （A-1）使得，A（A-1） &#x3D; （A-1）A &#x3D; I其中 𝐼I 是单位矩阵），那么我们可以定义B&#x2F;A为（BA-1），即是B矩阵除以A矩阵等于B乘以A矩阵的转置。但是，请注意，不是所有的矩阵都是可逆的。 </p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs makefile">import numpy as np<br><br><span class="hljs-comment"># 创建两个矩阵</span><br>A = np.array([[1, 2], [3, 4]])<br>B = np.array([[5, 6], [7, 8]])<br><br><span class="hljs-comment"># 矩阵加法</span><br>C = A + B<br><br><span class="hljs-comment"># 矩阵减法</span><br>D = A - B<br><br><span class="hljs-comment"># 矩阵乘法</span><br>E = np.dot(A, B)<br><br><span class="hljs-comment"># 矩阵除法（通过乘以逆矩阵）</span><br>F = np.dot(A, np.linalg.inv(B)) <br><br></code></pre></td></tr></table></figure><h3 id="傅里叶变换是什么？原理是这样的，怎么实现？（这里开一个新坑，数字信号处理）"><a href="#傅里叶变换是什么？原理是这样的，怎么实现？（这里开一个新坑，数字信号处理）" class="headerlink" title="傅里叶变换是什么？原理是这样的，怎么实现？（这里开一个新坑，数字信号处理）"></a>傅里叶变换是什么？原理是这样的，怎么实现？（这里开一个新坑，数字信号处理）</h3><h4 id="基本介绍。"><a href="#基本介绍。" class="headerlink" title="基本介绍。"></a>基本介绍。</h4><p>傅里叶变换是一种在数学、物理和工程中广泛使用的数学变换，它可以将一个函数或信号从其原始的时间或空间表示转换为频率表示。这对于许多应用都非常有用，因为它可以揭示信号的频率成分，这在原始的时间或空间表示中可能不明显。<br>傅里叶变换的基本思想是，任何函数都可以表示为一系列正弦波和余弦波的叠加。换句话说，我们可以将一个复杂的信号分解为一系列更简单的正弦波和余弦波。</p><h4 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍"></a>原理介绍</h4><p>傅里叶变换的基本原理是将一个函数或信号从其原始的时间或空间表示转换为频率表示。这是通过将函数表示为一系列正弦波和余弦波的叠加来实现的。<br><img src="/pic/fly1.jpg" alt="傅里叶变换示意图"></p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> numpy as np<br><span class="hljs-attribute">import</span> matplotlib.pyplot as plt<br><br><span class="hljs-comment"># 创建一个简单的信号</span><br><span class="hljs-attribute">t</span> = np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">500</span>)<br><span class="hljs-attribute">f</span> = np.sin(<span class="hljs-number">2</span> * np.pi * <span class="hljs-number">50</span> * t) + <span class="hljs-number">0</span>.<span class="hljs-number">5</span> * np.sin(<span class="hljs-number">2</span> * np.pi * <span class="hljs-number">120</span> * t)<br><br><span class="hljs-comment"># 绘制原始信号</span><br><span class="hljs-attribute">plt</span>.figure(figsize=(<span class="hljs-number">12</span>, <span class="hljs-number">6</span>))<br><br><span class="hljs-attribute">plt</span>.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br><span class="hljs-attribute">plt</span>.plot(t, f)<br><span class="hljs-attribute">plt</span>.title(&#x27;Original Signal&#x27;)<br><span class="hljs-attribute">plt</span>.xlabel(&#x27;Time&#x27;)<br><span class="hljs-attribute">plt</span>.ylabel(&#x27;Amplitude&#x27;)<br><br><span class="hljs-comment"># 计算傅里叶变换</span><br><span class="hljs-attribute">F</span> = np.fft.fft(f)<br><br><span class="hljs-comment"># 计算频率</span><br><span class="hljs-attribute">freq</span> = np.fft.fftfreq(t.shape[-<span class="hljs-number">1</span>])<br><br><span class="hljs-comment"># 绘制频谱</span><br><span class="hljs-attribute">plt</span>.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br><span class="hljs-attribute">plt</span>.plot(freq, np.abs(F))<br><span class="hljs-attribute">plt</span>.title(&#x27;Frequency Spectrum&#x27;)<br><span class="hljs-attribute">plt</span>.xlabel(&#x27;Frequency&#x27;)<br><span class="hljs-attribute">plt</span>.ylabel(&#x27;Magnitude&#x27;)<br><br><span class="hljs-attribute">plt</span>.tight_layout()<br><span class="hljs-attribute">plt</span>.show()<br><br></code></pre></td></tr></table></figure><h3 id="什么是对象？-封装，继承，多态是什么？"><a href="#什么是对象？-封装，继承，多态是什么？" class="headerlink" title="什么是对象？ 封装，继承，多态是什么？"></a>什么是对象？ 封装，继承，多态是什么？</h3><p>什么是对象？<br>在面向对象编程（Object-Oriented Programming，OOP）中，对象是类的实例。类是一种抽象的概念，用于描述具有相似属性和行为的对象的集合。对象是类的具体实现，它具有类定义的属性和方法。<br>对象可以看作是现实世界中的实体或概念在程序中的表示。每个对象都有自己的状态（属性）和行为（方法），并且可以与其他对象进行交互。</p><p>封装<br>封装是面向对象编程的一种重要概念，它将数据和操作数据的方法捆绑在一起，形成一个称为类的单个实体。封装隐藏了数据的内部实现细节，只暴露对外部可见的接口。这样可以保护数据的完整性，并提供更好的代码组织和维护性。<br>通过封装，对象的内部状态可以被保护起来，只能通过公共接口进行访问和修改。这样可以防止对数据的不合理访问和修改，增加了代码的安全性和可靠性。</p><p>继承<br>继承是面向对象编程中的另一个重要概念，它允许一个类继承另一个类的属性和方法。继承创建了一个类的层次结构，其中一个类（称为子类或派生类）可以从另一个类（称为父类或基类）继承属性和方法。<br>通过继承，子类可以继承父类的特性，并且可以添加自己的特定特性。这样可以实现代码的重用和扩展，减少了重复编写代码的工作量。</p><p>多态<br>多态是面向对象编程中的另一个重要概念，它允许使用统一的接口来处理不同的对象类型。多态性允许同一个方法在不同的对象上产生不同的行为。<br>通过多态，可以编写通用的代码，可以处理多个不同类型的对象，而无需针对每种类型编写特定的代码。这提高了代码的灵活性和可扩展性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 封装示例</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Car</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, brand, model</span>):<br>        self.brand = brand<br>        self.model = model<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">display_info</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Car: <span class="hljs-subst">&#123;self.brand&#125;</span> <span class="hljs-subst">&#123;self.model&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># 创建一个 Car 对象并访问其信息</span><br>my_car = Car(<span class="hljs-string">&quot;Toyota&quot;</span>, <span class="hljs-string">&quot;Corolla&quot;</span>)<br>my_car.display_info()<br><br><span class="hljs-comment"># 继承示例</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ElectricCar</span>(<span class="hljs-title class_ inherited__">Car</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, brand, model, battery_capacity</span>):<br>        <span class="hljs-built_in">super</span>().__init__(brand, model)<br>        self.battery_capacity = battery_capacity<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">display_info</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Electric Car: <span class="hljs-subst">&#123;self.brand&#125;</span> <span class="hljs-subst">&#123;self.model&#125;</span>, Battery Capacity: <span class="hljs-subst">&#123;self.battery_capacity&#125;</span> kWh&quot;</span>)<br><br><span class="hljs-comment"># 创建一个 ElectricCar 对象并访问其信息</span><br>my_electric_car = ElectricCar(<span class="hljs-string">&quot;Tesla&quot;</span>, <span class="hljs-string">&quot;Model S&quot;</span>, <span class="hljs-number">100</span>)<br>my_electric_car.display_info()<br><br><span class="hljs-comment"># 多态示例</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">show_car_info</span>(<span class="hljs-params">car</span>):<br>    car.display_info()<br><br><span class="hljs-comment"># 使用 show_car_info 函数展示不同类型的车辆信息</span><br>show_car_info(my_car)<br>show_car_info(my_electric_car)<br><br></code></pre></td></tr></table></figure><h3 id="python中的不同代码高亮表示什么？"><a href="#python中的不同代码高亮表示什么？" class="headerlink" title="python中的不同代码高亮表示什么？"></a>python中的不同代码高亮表示什么？</h3><p>在Python的IDLE编程环境中，不同颜色的文本表示不同的含义。以下是IDLE中常见的颜色及其含义：<br>黑色：普通的代码文本。<br>蓝色：关键字，例如if、else、for、while等。<br>绿色：字符串文本。<br>红色：语法错误或代码中的错误。<br>紫色：函数和方法的名称。<br>棕色：数字。<br>橙色：内置函数和模块的名称。<br>灰色：注释。</p><h3 id="github上传远端仓库"><a href="#github上传远端仓库" class="headerlink" title="github上传远端仓库"></a>github上传远端仓库</h3>]]></content>
    
    
    
    <tags>
      
      <tag>填坑</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>经典网络结构——VGG</title>
    <link href="/2024/04/22/deeplearnpaper2/"/>
    <url>/2024/04/22/deeplearnpaper2/</url>
    
    <content type="html"><![CDATA[<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>2014年<br><a href="https://blog.csdn.net/C_chuxin/article/details/82833070">中英文对照翻译</a><br><a href="https://zhuanlan.zhihu.com/p/460777014">VGG论文解读</a><br><a href="https://arxiv.org/pdf/1409.1556">原文</a><br><a href="https://zhuanlan.zhihu.com/p/107884876">VGG论文解读</a></p><h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>VGG是牛津大学的Visual Geometry Group的团队在ILSVRC 2014上的相关工作。在这项工作中，主要研究卷积网络深度对大规模图像识别准确率的影响。其主要的贡献是对使用非常小的卷积滤波器（3 X 3）的体系架构来增加网络深度进行彻底的评估。实验结果表明将网络的深度提升至16-19个权重层可以实现对现有技术的显著改进。其在2014年的 imageNet 大规模视觉挑战赛（ILSVRC - 2014）中取得亚军。（冠军是 GoogleNet，预告下一篇是GoogleNet）</p><h2 id="VGG原理"><a href="#VGG原理" class="headerlink" title="VGG原理"></a>VGG原理</h2><p>VGG原理<br>相比于 LeNet 网络，VGG 网络的一个改进点是将 大尺寸的卷积核 用 多个小尺寸的卷积核 代替。</p><p>比如：VGG使用 2个3X3的卷积核 来代替 5X5的卷积核，3个3X3的卷积核 代替7X7的卷积核。</p><p>这样做的好处是：</p><ol><li>在保证相同感受野的情况下，多个小卷积层堆积可以提升网络深度，增加特征提取能力（非线性层增加）。</li><li>参数更少。比如 1个大小为5的感受野 等价于 2个步长为1，3X3大小的卷积核堆叠。（即1个5X5的卷积核等于2个3X3的卷积核）。而1个5X5卷积核的参数量为 5<em>5</em>C^2。而2个3X3卷积核的参数量为 2<em>3</em>3*C^2。很显然，18C^2 &lt; 25C^2。</li><li>3X3卷积核更有利于保持图像性质。</li></ol><p>VGG缺点：</p><p>VGG耗费更多计算资源，并且使用了更多的参数（这里不是3x3卷积的锅），导致更多的内存占用（140M）。其中绝大多数的参数都是来自于第一个全连接层。<br>注：这里参数量的计算，忽略了偏置。并且假设 输入和输出通道数都为C。</p><h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p>VGGNet以下6种不同结构，我们以通常所说的VGG-16(即下图D列)为例，展示其结构示意图<br><img src="/pic/VGG.png" alt="VGG_6种模型结构"><br><img src="/pic/VGG_16.png" alt="VGG_16模型结构图"><br><img src="/pic/VGG_16_chanshu.png" alt="VGG参数图"><br><img src="/pic/VGG_chanshu.png" alt="VGG16参数图"></p><h2 id="摘要-Abstract"><a href="#摘要-Abstract" class="headerlink" title="摘要 Abstract"></a>摘要 Abstract</h2><p>In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Ourmain contribution is a thorough evaluation of networks of increasing depth usingan architecture withvery small (3×3) convolution filters, which shows that a significant improvementon the prior-art configurations can be achieved by pushing the depth to 16–19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisa-tion and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. Wehave made our two best-performing ConvNet models publicly available to facili-tate further research on the use of deep visual representations in computer vision.</p><p>在这项工作中，我们研究了卷积网络深度对其在大规模图像识别设置中的准确性的影响。我们的主要贡献是使用一个非常小的(3×3)卷积filter的架构对增加深度的网络进行了彻底的评估，这表明通过将深度提升到16 - 19个weight层，可以显著改善先前的配置。这些发现是我们提交ImageNet挑战赛2014的基础，我们的团队分别获得了本地化和分类的第一名和第二名。我们还展示了我们的成果可以很好地推广到其他数据集，在这些数据集上他们可以得到最优结果。我们已经公开了两个性能最好的卷积神经网络模型，以促进在计算机视觉中使用深度视觉表示的进一步研究。</p><h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>训练和之前的AlexNet整体类似，使用小批量梯度下降，参数方面：batch设为256，动量设为0.9，除最后一层外的全连接层也都使用了丢弃率0.5的dropout。learning rate最初设为0.01,权重衰减系数为5×10^-4。对于权重层采用了随机初始化，初始化为均值0，方差0.01的正态分布。 训练的图像数据方面，为了增加数据集，和AlexNet一样，这里也采用了随机水平翻转和随机RGB色差进行数据扩增。对经过重新缩放的图片随机排序并进行随机剪裁得到固定尺寸大小为224×224的训练图像。</p><h2 id="训练结果"><a href="#训练结果" class="headerlink" title="训练结果"></a>训练结果</h2><p><img src="/pic/VGG_train_result.webp" alt="对比结果"><br>通过表格间各个网络的对比发现如下结论：</p><p>总体来说卷积网络越深，损失越小，效果越好。<br>C优于B，表明多增加的非线性relu有效<br>D优于C，表明了卷积层filter对于捕捉空间特征有帮助。<br>E深度达到19层后达到了损失的最低点，但是对于其他更大型的数据集来说，可能更深的模型效果更好。<br>B和同类型filter size为5×5的网络进行了对比，发现其top-1错误率比B高7%，表明小尺寸filter效果更好。<br>在训练中，采用浮动尺度效果更好，因为这有助于学习分类目标在不同尺寸下的特征。</p><h2 id="挖坑"><a href="#挖坑" class="headerlink" title="挖坑"></a>挖坑</h2><h3 id="使用VGG来实现垃圾的40分类"><a href="#使用VGG来实现垃圾的40分类" class="headerlink" title="使用VGG来实现垃圾的40分类"></a>使用VGG来实现垃圾的40分类</h3><ol><li>第一步准备训练集，固定数据集（当然也可以不固定数据集，但是在对比实验中一定要固定数据集划分）<br>utils.py文件,这个文件的作业是产生2个csv文件，固定训练集和测试集<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs lua">import <span class="hljs-built_in">os</span><br>import csv<br>import numpy as np<br>train_path = <span class="hljs-string">&quot;train_data.csv&quot;</span><br>val_path = <span class="hljs-string">&quot;val_data.csv&quot;</span><br><br>train_percent = <span class="hljs-number">0.9</span><br><br>def create_data_txt(<span class="hljs-built_in">path</span>):<br>    f_train = <span class="hljs-built_in">open</span>(train_path,<span class="hljs-string">&quot;w&quot;</span>,newline=<span class="hljs-string">&quot;&quot;</span>)<br>    f_val = <span class="hljs-built_in">open</span>(val_path,<span class="hljs-string">&quot;w&quot;</span>,newline=<span class="hljs-string">&quot;&quot;</span>)<br>    train_writer = csv.writer(f_train)<br>    val_writer = csv.writer(f_val)<br><br>    <span class="hljs-keyword">for</span> cls,dirname <span class="hljs-keyword">in</span> enumerate(<span class="hljs-built_in">os</span>.listdir(<span class="hljs-built_in">path</span>)):<br>        flist = <span class="hljs-built_in">os</span>.listdir(<span class="hljs-built_in">os</span>.<span class="hljs-built_in">path</span>.join(<span class="hljs-built_in">path</span>,dirname))<br>        np.<span class="hljs-built_in">random</span>.shuffle(flist)<br>        fnum = <span class="hljs-built_in">len</span>(flist)<br>        <span class="hljs-keyword">for</span> i,filename <span class="hljs-keyword">in</span> enumerate(flist):<br>            <span class="hljs-keyword">if</span> i &lt; fnum*train_percent:<br>                train_writer.writerow([<span class="hljs-built_in">os</span>.<span class="hljs-built_in">path</span>.join(<span class="hljs-built_in">path</span>,dirname,filename),str(cls)])<br>            <span class="hljs-keyword">else</span>:<br>                val_writer.writerow([<span class="hljs-built_in">os</span>.<span class="hljs-built_in">path</span>.join(<span class="hljs-built_in">path</span>, dirname, filename), str(cls)])<br><br>    f_train.<span class="hljs-built_in">close</span>()<br>    f_val.<span class="hljs-built_in">close</span>()<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    create_data_txt(<span class="hljs-string">&quot;data_garbage&quot;</span>)<br><br></code></pre></td></tr></table></figure></li></ol><p>dataset.py 文件根据utisl.py文件来对数据进行数据预处理操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms,utils<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset,DataLoader<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>train_tf = transforms.Compose([<br>    <span class="hljs-comment"># transforms.RandomResizedCrop(size=(224,224), scale=(0.9,1.1)),</span><br>    transforms.Resize(<span class="hljs-number">224</span>),<br>    transforms.CenterCrop((<span class="hljs-number">224</span>,<span class="hljs-number">224</span>)),<br>    transforms.RandomRotation(<span class="hljs-number">10</span>),<br>    transforms.ColorJitter(brightness=(<span class="hljs-number">0.9</span>,<span class="hljs-number">1.1</span>),contrast=(<span class="hljs-number">0.9</span>,<span class="hljs-number">1.1</span>)),<br>    <span class="hljs-comment"># transforms.Resize((50,50)),</span><br>    transforms.ToTensor(),<br>])<br><br>val_tf = transforms.Compose([<br>    transforms.Resize(<span class="hljs-number">224</span>),<br>    transforms.CenterCrop((<span class="hljs-number">224</span>, <span class="hljs-number">224</span>)),<br>    <span class="hljs-comment"># transforms.Grayscale(1),</span><br>    transforms.ToTensor(),<br>])<br><br><span class="hljs-comment">#自定义数据集</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Animals_dataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,istrain=<span class="hljs-literal">True</span></span>):<br>        <span class="hljs-keyword">if</span> istrain:<br>            f = <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;train_data.csv&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>)<br>        <span class="hljs-keyword">else</span>:<br>            f = <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;val_data.csv&quot;</span>, <span class="hljs-string">&quot;r&quot;</span>)<br>        self.dataset = f.readlines()<br>        f.close()<br>        self.istrain = istrain<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.dataset)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>        data = self.dataset[index]<br>        img_path = data.split(<span class="hljs-string">&quot;,&quot;</span>)[<span class="hljs-number">0</span>]<br>        cls = <span class="hljs-built_in">int</span>(data.split(<span class="hljs-string">&quot;,&quot;</span>)[<span class="hljs-number">1</span>])<br><br>        img_data = Image.<span class="hljs-built_in">open</span>(img_path).convert(<span class="hljs-string">&quot;RGB&quot;</span>)<br>        <span class="hljs-keyword">if</span> self.istrain:<br>            dst = train_tf(img_data)<br>        <span class="hljs-keyword">else</span>:<br>            dst =val_tf(img_data)<br><br>        <span class="hljs-keyword">return</span> dst,torch.tensor(cls)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">visulization</span>():<br>    train_dataset = Animals_dataset(<span class="hljs-literal">True</span>)<br>    train_dataloader = DataLoader(train_dataset, batch_size=<span class="hljs-number">16</span>, shuffle=<span class="hljs-literal">True</span>)<br><br>    examples = <span class="hljs-built_in">enumerate</span>(train_dataloader)<br>    batch_index,(data, lable) = <span class="hljs-built_in">next</span>(examples)<br>    <span class="hljs-built_in">print</span>(data.shape)<br><br>    grid = utils.make_grid(data)<br>    plt.imshow(grid.numpy().transpose(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>))<br>    plt.show()<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    visulization()<br></code></pre></td></tr></table></figure><p>train.py 训练模型的代码</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> optim,nn<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> dataset <span class="hljs-keyword">import</span> *<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> models<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt<br><br>m = nn.Softmax(dim=<span class="hljs-number">1</span>)<br>def train(<span class="hljs-keyword">method</span>=&quot;normal&quot;,ckpt_path=&quot;&quot;):<br>    # 数据集和数据加载器<br>    train_dataset = Animals_dataset(<span class="hljs-keyword">True</span>)<br>    train_dataloader = DataLoader(train_dataset, batch_size=<span class="hljs-number">32</span>, shuffle=<span class="hljs-keyword">True</span>)<br>    val_dataset = Animals_dataset(<span class="hljs-keyword">False</span>)<br>    val_dataloader = DataLoader(val_dataset, batch_size=<span class="hljs-number">32</span>, shuffle=<span class="hljs-keyword">False</span>)<br><br>    #模型<br>    device = torch.device(&quot;cuda&quot; <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> &quot;cpu&quot;)#系统自己决定有啥训练<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">method</span>==&quot;normal&quot;:<br>        model = models.vgg16(num_classes=<span class="hljs-number">40</span>,dropout=<span class="hljs-number">0.45</span>).<span class="hljs-keyword">to</span>(device)<br>    elif <span class="hljs-keyword">method</span>==&quot;step1&quot;:<br>        model=models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> model.parameters():<br>            i.requires_grad=<span class="hljs-keyword">False</span><br>        model.classifier=nn.Sequential(<br>            nn.Linear(<span class="hljs-number">512</span>*<span class="hljs-number">7</span>*<span class="hljs-number">7</span>,<span class="hljs-number">2048</span>),<br>            nn.ReLU(<span class="hljs-keyword">True</span>),<br>            nn.Dropout(p=<span class="hljs-number">0.35</span>),<br>            nn.Linear(<span class="hljs-number">2048</span>,<span class="hljs-number">1024</span>),<br>            nn.ReLU(<span class="hljs-keyword">True</span>),<br>            nn.Dropout(p=<span class="hljs-number">0.35</span>),<br>            nn.Linear(<span class="hljs-number">1024</span>,<span class="hljs-number">40</span>)<br>        )<br>        model.<span class="hljs-keyword">to</span>(device)<br>    elif <span class="hljs-keyword">method</span>==&quot;step2&quot;:<br>        model=models.vgg16()<br>        model.classifier=nn.Sequential(<br>            nn.Linear(<span class="hljs-number">512</span> * <span class="hljs-number">7</span> * <span class="hljs-number">7</span>, <span class="hljs-number">2048</span>),<br>            nn.ReLU(<span class="hljs-keyword">True</span>),<br>            nn.Dropout(p=<span class="hljs-number">0.35</span>),<br>            nn.Linear(<span class="hljs-number">2048</span>, <span class="hljs-number">1024</span>),<br>            nn.ReLU(<span class="hljs-keyword">True</span>),<br>            nn.Dropout(p=<span class="hljs-number">0.35</span>),<br>            nn.Linear(<span class="hljs-number">1024</span>, <span class="hljs-number">40</span>)<br>        )<br>        model.load_state_dict(torch.<span class="hljs-keyword">load</span>(&quot;model/vgg16_step1_trush.pth&quot;))<br>        model.<span class="hljs-keyword">to</span>(device)<br>    print(&quot;train on &quot;,device)<br>    #损失函数（二分类交叉熵）<br>    loss_fn = nn.CrossEntropyLoss()<br><br>    #优化器<br>    optimizer = optim.SGD(model.parameters(),lr=<span class="hljs-number">0.01</span>,momentum=<span class="hljs-number">0.9</span>)<br><br>    #断点恢复<br>    start_epoch = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">if</span> ckpt_path != &quot;&quot;:<br>        <span class="hljs-keyword">checkpoint</span> = torch.<span class="hljs-keyword">load</span>(ckpt_path)<br>        model.load_state_dict(<span class="hljs-keyword">checkpoint</span>[&quot;net&quot;])<br>        optimizer.load_state_dict(<span class="hljs-keyword">checkpoint</span>[&quot;optimizer&quot;])<br>        start_epoch = <span class="hljs-keyword">checkpoint</span>[&quot;epoch&quot;] + <span class="hljs-number">1</span><br><br>    #训练<br>    train_loss_arr = []<br>    train_acc_arr = []<br>    val_loss_arr = []<br>    val_acc_arr = []<br><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">10</span>):<br>        train_loss_total = <span class="hljs-number">0</span> #所有batch的loss累加值<br>        train_acc_total = <span class="hljs-number">0</span> #所有batch的acc累加值<br>        val_loss_total = <span class="hljs-number">0</span><br>        val_acc_total = <span class="hljs-number">0</span><br><br>        model.train()#标志此时为训练状态，启用dropout随机失活，否则不启用<br>        <span class="hljs-keyword">for</span> i,(train_x,train_y) <span class="hljs-keyword">in</span> enumerate(train_dataloader):<br>            train_x = train_x.<span class="hljs-keyword">to</span>(device)<br>            train_y = train_y.<span class="hljs-keyword">to</span>(device)<br><br>            #前向传播<br>            train_y_pred = model(train_x)<br>            train_loss = loss_fn(train_y_pred,train_y)<br>            train_acc = (m(train_y_pred).max(dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>]==train_y).sum()/train_y.shape[<span class="hljs-number">0</span>]<br>            train_loss_total += train_loss.data.item()<br>            train_acc_total += train_acc.data.item()<br>            #反向传播<br>            train_loss.backward()<br>             #梯度下降<br>            optimizer.step()<br>            optimizer.zero_grad()<br><br>            print(&quot;epoch:&#123;&#125; train_loss:&#123;&#125; train_acc:&#123;&#125;&quot;.format(epoch, train_loss.data.item(), train_acc.data.item()))<br><br>        train_loss_arr.append(train_loss_total / len(train_dataloader)) #平均值<br>        train_acc_arr.append(train_acc_total / len(train_dataloader))<br><br>        #测试集<br>        <span class="hljs-keyword">for</span> j, (val_x, val_y) <span class="hljs-keyword">in</span> enumerate(val_dataloader):<br>            val_x = val_x.<span class="hljs-keyword">to</span>(device)<br>            val_y = val_y.<span class="hljs-keyword">to</span>(device)<br>            #前向传播<br>            val_y_pred,_,_ = model(val_x)<br>            val_loss = loss_fn(val_y_pred,val_y)<br>            val_acc = (m(val_y_pred).max(dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>]==val_y).sum()/val_y.shape[<span class="hljs-number">0</span>]<br>            val_loss_total += val_loss.data.item()<br>            val_acc_total += val_acc.data.item()<br><br>        val_loss_arr.append(val_loss_total / len(val_dataloader))  # 平均值<br>        val_acc_arr.append(val_acc_total / len(val_dataloader))<br>        print(&quot;epoch:&#123;&#125; val_loss:&#123;&#125; val_acc:&#123;&#125;&quot;.format(epoch, val_loss_arr[<span class="hljs-number">-1</span>], val_acc_arr[<span class="hljs-number">-1</span>]))<br>        #保存模型（断点连续）<br>        <span class="hljs-keyword">checkpoint</span>=&#123;<br>            &quot;net&quot;:model.state_dict(),<br>            &quot;optimizer&quot;:optimizer.state_dict(),<br>            &quot;epoch&quot;:epoch<br>        &#125;<br>        torch.save(<span class="hljs-keyword">checkpoint</span>,&quot;checkpoint/ckpt.pth&quot;)<br><br><br>    plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>) #画布一分为二,<span class="hljs-number">1</span>行<span class="hljs-number">2</span>列，用第一个<br>    plt.title(&quot;loss&quot;)<br>    plt.plot(train_loss_arr,&quot;r&quot;,label = &quot;train&quot;)<br>    plt.plot(val_loss_arr,&quot;b&quot;,label = &quot;val&quot;)<br>    plt.legend()<br><br>    plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)  # 画布一分为二,<span class="hljs-number">1</span>行<span class="hljs-number">2</span>列，用第一个<br>    plt.title(&quot;acc&quot;)<br>    plt.plot(train_acc_arr, &quot;r&quot;, label=&quot;train&quot;)<br>    plt.plot(val_acc_arr, &quot;b&quot;, label=&quot;val&quot;)<br>    plt.legend()<br>    plt.savefig(&quot;loss/loss_acc_vgg.png&quot;)<br><br>    plt.<span class="hljs-keyword">show</span>()<br><br>    #保存模型<br>    #<span class="hljs-number">1.</span>torch.save()<br>    #<span class="hljs-number">2.</span>文件的后缀名：.pt、.pth、.pkl<br>    torch.save(model.state_dict(),&quot;model/vgg_trush.pth&quot;)<br>    print(&quot;保存模型成功!&quot;)<br><br><br><span class="hljs-keyword">if</span> __name__ == &quot;__main__&quot;:<br>    train()<br><br><br></code></pre></td></tr></table></figure><p>test.py测试模型的代码</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><code class="hljs routeros">import torch.cuda<br><br><span class="hljs-keyword">from</span> torchvision import models<br>import os<br><span class="hljs-keyword">from</span> torch import nn<br><span class="hljs-keyword">from</span> dataset import *<br><span class="hljs-keyword">from</span> PIL import Image<br><span class="hljs-keyword">from</span> torch.utils.data import DataLoader<br><span class="hljs-keyword">from</span> dataset import *<br><span class="hljs-keyword">from</span> sklearn.metrics import recall_score, f1_score, precision_score, confusion_matrix<br><span class="hljs-keyword">from</span> matplotlib import rcParams<br>rcParams[<span class="hljs-string">&#x27;font.family&#x27;</span>] = <span class="hljs-string">&#x27;SimHei&#x27;</span><br><br>m = nn.Softmax(<span class="hljs-attribute">dim</span>=1)<br>labels = os.listdir(<span class="hljs-string">&quot;data_garbage&quot;</span>)<br><br>def evaluate():<br>    device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>    model = models.googlenet(<span class="hljs-attribute">num_classes</span>=40).to(device)<br>    model.load_state_dict(torch.load(<span class="hljs-string">&quot;model/vgg_trush.pth&quot;</span>))<br>    model.eval()<br><br>    img = Image.open(<span class="hljs-string">&quot;tests/5.jpg&quot;</span>)<br>    dst = val_tf(img).<span class="hljs-keyword">to</span>(device)<br>    dst = torch.unsqueeze(dst, <span class="hljs-attribute">dim</span>=0)   # (1, 3, 224, 224)<br>    y_hat = model(dst)<br><br>    values = m(y_hat).sort(<span class="hljs-attribute">dim</span>=1, <span class="hljs-attribute">descending</span>=<span class="hljs-literal">True</span>)[0][0]<br>    index = m(y_hat).sort(<span class="hljs-attribute">dim</span>=1, <span class="hljs-attribute">descending</span>=<span class="hljs-literal">True</span>)[1][0]<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(5):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&#123;:&#125; - &#123;:.5f&#125;&quot;</span>.format(labels[index[i]], values[i]))<br><br>    plt.imshow(img)<br>    plt.show()<br><br>def val():<br>    # 数据集和数据加载器<br>    val_dataset = Animals_dataset(<span class="hljs-literal">False</span>)<br>    val_data_loader = DataLoader(val_dataset, <span class="hljs-attribute">batch_size</span>=128, <span class="hljs-attribute">shuffle</span>=<span class="hljs-literal">False</span>, <span class="hljs-attribute">drop_last</span>=<span class="hljs-literal">True</span>)<br><br>    device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>    model = models.googlenet(<span class="hljs-attribute">num_classes</span>=40).to(device)<br>    model.load_state_dict(torch.load(<span class="hljs-string">&quot;model/vgg_trush.pth&quot;</span>))<br>    model.eval()<br><br>    val_y_total = []<br>    val_y_pred_total = []<br>    <span class="hljs-keyword">for</span> val_x, val_y <span class="hljs-keyword">in</span> val_data_loader:<br>        val_x = val_x.<span class="hljs-keyword">to</span>(device)<br>        val_y_pred = model(val_x).cpu()<br><br>        val_y_total.extend(val_y.cpu().numpy())    # 将列表中的数据取出来追加<br>        val_y_pred_total.extend(m(val_y_pred).max(<span class="hljs-attribute">dim</span>=1)[1].cpu().numpy())<br><br>    p = precision_score(val_y_total, val_y_pred_total, <span class="hljs-attribute">average</span>=<span class="hljs-string">&quot;weighted&quot;</span>)<br>    recall = recall_score(val_y_total, val_y_pred_total, <span class="hljs-attribute">average</span>=<span class="hljs-string">&quot;weighted&quot;</span>)<br>    f1 = f1_score(val_y_total, val_y_pred_total, <span class="hljs-attribute">average</span>=<span class="hljs-string">&quot;weighted&quot;</span>)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;precision: &#123;:.5f&#125;, recall=&#123;:.5f&#125;, f1=&#123;:.5f&#125;&quot;</span>.format(p, recall, f1))<br><br>    cm = confusion_matrix(val_y_total, val_y_pred_total)<br><br>    plt.imshow(cm, <span class="hljs-attribute">cmap</span>=plt.cm.Blues)<br>    plt.xticks(range(40), <span class="hljs-attribute">labels</span>=labels)<br>    plt.yticks(range(40), <span class="hljs-attribute">labels</span>=labels)<br><br>    plt.colorbar()<br>    plt.xlabel(<span class="hljs-string">&quot;预测值&quot;</span>)<br>    plt.ylabel(<span class="hljs-string">&quot;真实值&quot;</span>)<br>    thresh = cm.mean()<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(40):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(40):<br>            <span class="hljs-built_in">info</span> = cm[j, i]<br>            plt.text(i, j, info, <span class="hljs-attribute">color</span>=<span class="hljs-string">&quot;white&quot;</span> <span class="hljs-keyword">if</span> info&gt;thresh <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;black&quot;</span>)<br>    plt.savefig(<span class="hljs-string">&quot;confusion_matrix.jpg&quot;</span>)<br>    plt.show()<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    evaluate()<br><br><br></code></pre></td></tr></table></figure><h3 id="什么是感受野？"><a href="#什么是感受野？" class="headerlink" title="什么是感受野？"></a>什么是感受野？</h3>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>填坑博客总目录</title>
    <link href="/2024/04/22/tiankeng/"/>
    <url>/2024/04/22/tiankeng/</url>
    
    <content type="html"><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><h2 id="PyTorch基础——Numpy"><a href="#PyTorch基础——Numpy" class="headerlink" title="PyTorch基础——Numpy"></a>PyTorch基础——Numpy</h2><h2 id="经典网络结构——AlexNet"><a href="#经典网络结构——AlexNet" class="headerlink" title="经典网络结构——AlexNet"></a>经典网络结构——AlexNet</h2>]]></content>
    
    
    
    <tags>
      
      <tag>填坑</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔9</title>
    <link href="/2024/04/22/ganwu9/"/>
    <url>/2024/04/22/ganwu9/</url>
    
    <content type="html"><![CDATA[<h1 id="夜晚思考"><a href="#夜晚思考" class="headerlink" title="夜晚思考"></a>夜晚思考</h1><p>作为一个大学生，住在寝室是很正常的。2024&#x2F;4&#x2F;21的夜晚不是很寻常，床下的键盘声和电脑的光亮让我难以入睡。思绪浮想联翩，世界毁灭了，我要毁灭了。情绪在波动，心脏在疼痛。我该怎么去停止这键盘声和光亮从而让我安静的入眠。<br>人总是以为自己是站在道德的高点，很不幸的告诉我自己，当自以为在道德高点时，我其实已经没有了道德。以自己最大的恶意去揣测他人，已经不道德了。键盘声和光亮真的不能让我入睡吗？还是自己不让自己睡觉，自己的情绪，自己禁锢自己。意识和情绪不是一体的，控制自己的情绪。<br>我总是有两个自己，一个以恶意揣测别人，一个则想怎么去解决这个问题。逃离，争吵，苦恼，毁灭世界。思想斗争吧，预演所有情况吧，一个小时后，问题不能被解决，反而越来越难受。沟通一下吧。起身，正坐。问道：“兄弟，你有什么重要的事情需要去完成吗？” 答曰：“作业没有写完，正在写作业。”听之，甚觉羞愧，焕然冰释。<br>自己禁锢自己，被情绪裹挟，人啊人啊。<br><img src="/pic/ganwu9.jpg"></p>]]></content>
    
    
    
    <tags>
      
      <tag>感悟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔8</title>
    <link href="/2024/04/21/ganwu8/"/>
    <url>/2024/04/21/ganwu8/</url>
    
    <content type="html"><![CDATA[<h1 id="做事中什么最重要？"><a href="#做事中什么最重要？" class="headerlink" title="做事中什么最重要？"></a>做事中什么最重要？</h1><p>明白自己在干什么，明白此时此刻我在干什么。为什么说这是最重要的?拿做数学题来讲吧，要做一道数学题，必须先看题，了解题目的内容，获取前提条件。获取了前提条件之后，有两种可能，会做和不会做，会做的过程中，最好的感觉是，看了一眼题目之后就胸有成竹了，虽然不知道这道题的答案是什么，但是清楚这道题应该怎么去解答，应该在什么部分注意。这是最好的状态，很清晰的明白自己在做什么的状态。对于第二种，不知道该怎么解决的，首先得清楚自己不会做，然后去分析自己哪里不会，而不是自己不会就不会，这样的心态是大忌，不要傲慢，没有人生下来就会所有事情，都是从不会到会的，对待自己会别人不会的题，不要傲慢，不要鄙视他人，因为我也是从不会到会的。了解自己哪里不会了之后，去找到解决方法，补足不会的点，然后就能解决这道数学题了。这是第二个情况的解决方法，在整个流程中，我都清晰自己在干什么，而不是迷迷糊糊的不知道自己在干什么。<br>再举一个例子，拿科研来讲，一篇论文需要注意什么？第一，创新点。第二，实验设计。第三，文章表述。这三点的重要性不分先后。我想的，我做的，我写出来的是三种东西。在这个过程中需要清晰的认识自己在做什么，如果很清晰的知道，胸有成竹的，就可以去做，如果是第二种情况，那就慢慢来补充自己欠缺的知识。需要说明的是，胸有成竹和存在不足的情况可能会周期交互，一段时间的胸有成竹和一段时间的不足。但是在解决不足的过程却是胸有成竹的，清楚的明白自己需要干什么。</p><h2 id="《胸有成竹》-苏轼"><a href="#《胸有成竹》-苏轼" class="headerlink" title="《胸有成竹》-苏轼"></a>《胸有成竹》-苏轼</h2><p>竹之始生，一寸之萌耳，而节叶具焉；自蜩蝮蛇蚹，以至于剑拔十寻者，生而有之也。<br>今画者乃节节而为之，叶叶而累之，岂复有竹乎？故画竹必先得成竹于胸中，执笔熟视，乃见其所欲画者，急起从之，振笔直遂，以追其所见，如兔起鹘落，少纵则逝矣。与可之教予如此。予不能然也，而心识其所以然。夫既心识其所以然，而不能然者，内外不一，心手不相应，不学之过也。故凡有见于中，而操之不熟者，平居自视了然，而临时忽焉丧之，岂独竹乎？子由为《墨竹赋》以遗与可曰：“庖丁，解牛者也，而养生者取之；轮扁，斫轮者也，而读书者与之。今夫夫子之托于斯竹也，而予以为有道者则非耶？”子由未尝画也，故得其意而已。若予者，岂独得其意，并得其法。</p><p>译文：竹子开始生出时，只是一寸高的萌芽而已，但节、叶都具备了。从蝉破壳而出、蛇长出鳞一样的状态，直至像剑拔出鞘一样长到八丈高，都是一生长出来就有的。如今画竹的人都是一节节地画它，一叶叶地堆积它，这样哪里还会有完整的、活生生的竹子呢？所以画竹必定要心里先有完整的竹子形象，拿起笔来仔细看去，就看到了自己所想画的竹子，急速起身跟住它，动手作画，一气呵成，以追上自己所见到的，如兔子跃起奔跑、隼俯冲下搏，稍一放松就消失了。与可告诉我的是如此。我不能做到这样，但心里明白这样做的道理。既然心里明白这样做的道理，但不能做到这样，是由于内外不一，心与手不相适应，没有学习的过错。所以凡是在心中有了构思，但是做起来不熟练的，平常自己认为很清楚，可事到临头忽然又忘记了，这种现象难道仅仅是画竹有吗？ 　子由写了篇《墨竹赋》，把它送给与可，说：“丁厨子，是杀牛的，但讲求养生的人从他的行动中悟出了道理；轮匠扁，是造车轮的，但读书的人赞成他讲的道理。如今您寄托意蕴在这幅竹画上，我认为您是深知道理的人，难道不是吗？”子由没有作过画，所以只得到了他的意蕴。象我这样的人，哪里仅仅是得到与可的意蕴，并且也得到了与可的方法。</p><p>自注： 我觉得苏轼这篇说说很好，但是需要补充的是，这里以做事的态度讨论，其他角度碍于自己的层次有限暂时不讨论，胸有成竹是最好的做事状态。竹子一开始是具备了节和叶，但是只是一寸高的萌芽的，要从一寸长的萌芽成长到高耸，需要很多条件都满足，竹子的成长也是一点点，一节一节来长得。很多时候做事都不是胸有成竹的状态， 一开始都是懵懂不知道的，只有在做的得心应手时才有胸有成竹的状态，在做事之前已作好充分准备，对事情的成功已有了十分的把握；最开始的竹子都是矮小的，高耸的竹子都是一点点成长的。苏轼说的没错的是故画竹必先得成竹于胸中，执笔熟视，乃见其所欲画者，急起从之，振笔直遂，以追其所见，如兔起鹘落，少纵则逝矣。但是他没有说的是这是大佬做事的境界，小白不都是从今画者乃节节而为之，叶叶而累之吗？<br>故凡有见于中，而操之不熟者，平居自视了然，而临时忽焉丧之，岂独竹乎？这句叫人不要傲慢，知行合一。<br>子由为《墨竹赋》以遗与可曰：“庖丁，解牛者也，而养生者取之；轮扁，斫轮者也，而读书者与之。今夫夫子之托于斯竹也，而予以为有道者则非耶？”子由未尝画也，故得其意而已。若予者，岂独得其意，并得其法。这句法则都是相同的，方法是法则的具体体现。</p>]]></content>
    
    
    
    <tags>
      
      <tag>感悟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>经典网络结构——AlexNet</title>
    <link href="/2024/04/21/deeplearnpaper1/"/>
    <url>/2024/04/21/deeplearnpaper1/</url>
    
    <content type="html"><![CDATA[<p>我给自己挖了很多坑没有去填，只能慢慢填了，今天先填第一个坑。<br><a href="https://blog.csdn.net/guzhao9901/article/details/118552085">本人参考博客1-</a><br><a href="https://zhuanlan.zhihu.com/p/618545757">本人参考博客2-</a><br><a href="https://blog.csdn.net/hongbin_xu/article/details/80271291">本人参考博客3-AlexNet的翻译</a><br><a href="https://blog.csdn.net/ARYAD/article/details/107687362">本人参考的博客-模型结构发展简史</a></p><h1 id="AlexNet-介绍"><a href="#AlexNet-介绍" class="headerlink" title="AlexNet 介绍"></a>AlexNet 介绍</h1><p><a href="https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">论文原文链接</a><br>AlexNet是由Alex Krizhevsky、Ilya Sutskever和Geoffrey Hinton在2012年ImageNet图像分类竞赛中提出的一种经典的卷积神经网络。AlexNet在 ImageNet 大规模视觉识别竞赛中取得了优异的成绩，把深度学习模型在比赛中的正确率提升到一个前所未有的高度。因此，它的出现对深度学习发展具有里程碑式的意义。<br><a href="https://github.com/aaron-xichen/pytorch-playground">可以参考的github仓库</a></p><ol><li>AlexNet的输入为RGB三通道大小的图像，图像的shape可以表述为（227x227x3）。AlexNet共包含5个卷积层（包含3个池化）和3个全连接层。其中每个卷积层都包含卷积核、偏置项、ReLU激活函数和局部响应归一化（LRN）模块。第1，2，5个卷积层后面都跟着一个最大池化层，后三个层为全连接层。最终的输出层为softmax（这里有一个很有意思的知识，softmax怎么将网络输出转化为概率值，后面再说。）</li></ol><p><img src="/pic/paper_Alex_1.png" alt="AlexNet模型结构图"><br>这里需要指出的是，在网络设计上并非上图所示，上图包含了GPU通信的部分。这是因为当时的GPU内存的限制引起的，作者使用了两块GPU进行计算<br>废话不多说，直接上代码。代码来源为《动手深度学习》</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-title">from</span> torch <span class="hljs-keyword">import</span> nn, optim<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-meta"># 上面的部分为引入包操作，介绍一下上面引入的包的作用。</span><br><span class="hljs-meta"># time：这是python中的内置的模块，用于处理时间相关的操作。可以用来获取当前的时间，或者在程序中添加延迟。</span><br><span class="hljs-meta"># torch：这是pytorch库的主要部分，一个用于机器学习和深度学习的开源库。提高高效的张量（多维数组）计算（类似于Numpy）的方式，同时支持GPU计算（基于CUDA和CUDNN）</span><br><span class="hljs-meta"># torch.nn 是pytorch中的一个子模块，提供构建神经网络所需要的各种工具和组件。</span><br><span class="hljs-meta"># torch.optim也是pytorch中的一个子模块，提供各种优化算法，比如SGD，Adam和RMSProp等（这里给自己挖个坑）</span><br><span class="hljs-meta"># torch.torchvision，一个与PyTorch关联的库，专门用于处理图像和视频的计算机视觉任务。它提供许多预训练的模型，如ResNet，VGG和AlexNet等，同时还有常见的数据集，如ImageNet，CIFAR10/100，MNIST等。</span><br><br><span class="hljs-title">device</span> = torch.device(&#x27;cuda&#x27; <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> &#x27;cpu&#x27;)<br><span class="hljs-meta"># 这一句的作用是选取GPU训练还是CPU训练。</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-type">AlexNet</span>(<span class="hljs-title">nn</span>.<span class="hljs-type">Module</span>):</span><br><span class="hljs-class">    def __init__(<span class="hljs-title">self</span>):</span><br><span class="hljs-class">        super(<span class="hljs-type">AlexNet</span>, <span class="hljs-title">self</span>).__init__()</span><br><span class="hljs-class">        self.conv = nn.<span class="hljs-type">Sequential</span>(</span><br><span class="hljs-class">            <span class="hljs-title">nn</span>.<span class="hljs-type">Conv2d</span>(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding（输出通道数，输出通道数，卷积核大小，步长，填充，这里又有坑，关于卷积后特征图应该怎么计算？）</span><br><span class="hljs-class">            nn.<span class="hljs-type">ReLU</span>(), # <span class="hljs-type">ReLU</span>激活函数</span><br><span class="hljs-class">            nn.<span class="hljs-type">MaxPool2d</span>(3, 2), # kernel_size, stride 最大池化，3x3的池化层，步长为2.意思是一个3x3的二维矩阵，按照最大值来输出最大特征。</span><br><span class="hljs-class">            # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数</span><br><span class="hljs-class">            nn.<span class="hljs-type">Conv2d</span>(96, 256, 5, 1, 2),</span><br><span class="hljs-class">            nn.<span class="hljs-type">ReLU</span>(),</span><br><span class="hljs-class">            nn.<span class="hljs-type">MaxPool2d</span>(3, 2),</span><br><span class="hljs-class">            # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。</span><br><span class="hljs-class">            # 前两个卷积层后不使用池化层来减小输入的高和宽</span><br><span class="hljs-class">            nn.<span class="hljs-type">Conv2d</span>(256, 384, 3, 1, 1), # 第三个卷积层</span><br><span class="hljs-class">            nn.<span class="hljs-type">ReLU</span>(),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Conv2d</span>(384, 384, 3, 1, 1), # 第四个卷积层</span><br><span class="hljs-class">            nn.<span class="hljs-type">ReLU</span>(),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Conv2d</span>(384, 256, 3, 1, 1), # 第五个卷积层</span><br><span class="hljs-class">            nn.<span class="hljs-type">ReLU</span>(),</span><br><span class="hljs-class">            nn.<span class="hljs-type">MaxPool2d</span>(3, 2)</span><br><span class="hljs-class">        )</span><br><span class="hljs-class">         # 这里全连接层的输出个数比<span class="hljs-type">LeNet</span>中的大数倍。使用丢弃层来缓解过拟合</span><br><span class="hljs-class">        self.fc = nn.<span class="hljs-type">Sequential</span>(</span><br><span class="hljs-class">            <span class="hljs-title">nn</span>.<span class="hljs-type">Linear</span>(256*5*5, 4096), # 线性层，256*5*5为输入大小，4096为输出大小。</span><br><span class="hljs-class">            nn.<span class="hljs-type">ReLU</span>(),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Dropout</span>(0.5), # 随机失活，<span class="hljs-type">AlexNet</span>的主要创新点之一。这里失活率为0.5</span><br><span class="hljs-class">            nn.<span class="hljs-type">Linear</span>(4096, 4096),</span><br><span class="hljs-class">            nn.<span class="hljs-type">ReLU</span>(),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Dropout</span>(0.5),</span><br><span class="hljs-class">            # 输出层。由于这里使用<span class="hljs-type">Fashion</span>-<span class="hljs-type">MNIST</span>，所以用类别数为10，而非论文中的1000</span><br><span class="hljs-class">            nn.<span class="hljs-type">Linear</span>(4096, 10), # 输出类为10.</span><br><span class="hljs-class">        )</span><br><span class="hljs-class"></span><br><span class="hljs-class">    def forward(<span class="hljs-title">self</span>, <span class="hljs-title">img</span>): # 前向传播，forward在代码中需要自定义。在这里可以加入残差等操作。</span><br><span class="hljs-class">        feature = self.conv(<span class="hljs-title">img</span>)</span><br><span class="hljs-class">        output = self.fc(<span class="hljs-title">feature</span>.<span class="hljs-title">view</span>(<span class="hljs-title">img</span>.<span class="hljs-title">shape</span>[0], -1))</span><br><span class="hljs-class">        return output</span><br></code></pre></td></tr></table></figure><ol start="2"><li>背景介绍，在AlexNet网络问世之前，大量的学者在进行图像分类、分割、识别的操作时，主要是通过对图像提取特征或特征+机器学习的方法，手工提取特征是非常难的事情，即特征工程。为了提升准确率或减少人工复杂度等种种原因。因此，学界一直认为，特征是不是可以进行学习？如果可以学习，特征之间的表示方法是什么？例如第一层为线或是点特征，第二层为线与点组成的初步特征，第三层为局部特征）？从这一思想出发，特征可学习且自动组合并给出结果，这是典型的“end-to-end” 。</li></ol><h1 id="论文阅读："><a href="#论文阅读：" class="headerlink" title="论文阅读："></a>论文阅读：</h1><p>先阐述一下论文结构</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">0</span>. 标题（title）<br><span class="hljs-attribute">0</span>.<span class="hljs-number">5</span>. 摘要（Abstract）<br><span class="hljs-attribute">1</span>. 介绍（Introduction）<br><span class="hljs-attribute">2</span>. 数据集（The Dataset）<br><span class="hljs-attribute">3</span>. 网络结构（The Architecture）<br><span class="hljs-attribute">3</span>.<span class="hljs-number">1</span> ReLU非线性单元（ReLU Nonlinearity）<br><span class="hljs-attribute">3</span>.<span class="hljs-number">2</span> 多GPU训练（Training <span class="hljs-literal">on</span> Multiple GPU）<br><span class="hljs-attribute">3</span>.<span class="hljs-number">3</span> 局部响应和归一化（Local Response Normalization）<br><span class="hljs-attribute">3</span>.<span class="hljs-number">4</span> 层叠池化（Overlapping Pooling）<br><span class="hljs-attribute">3</span>.<span class="hljs-number">5</span> 整体结构（Overall Architecture）<br><span class="hljs-attribute">4</span>. 减少过拟合（Reducing Overfitting） <br><span class="hljs-attribute">4</span>.<span class="hljs-number">1</span> 数据增强 （Data Augmentation）<br><span class="hljs-attribute">4</span>.<span class="hljs-number">2</span> 随机失活 （Dropout）<br><span class="hljs-attribute">5</span>. 学习细节 （Details of learning）<br><span class="hljs-attribute">6</span>. 结果 （Results）<br><span class="hljs-attribute">6</span>.<span class="hljs-number">1</span> 定性评估（Qualitative Evacuation）<br><span class="hljs-attribute">6</span>.<span class="hljs-number">2</span> 讨论（Discussion） <br></code></pre></td></tr></table></figure><p>这里需要说明的是由于markdown的限制和本人技术能力的欠缺。在这篇博文中不放公式，如果想看公式，请去看原论文，数学的公式才是最简洁的表达方式，前提是能够看懂，看懂了之后就像打开新世界的大门。感觉就像我有一双滑板鞋，我走到那就穿到哪。<br>0. 标题论文标题为<br>ImageNet Classification with Deep Convolutional Neural Networks<br>摘要： 我们训练了一个庞大的深层卷积神经网络，将ImageNet LSVRC-2010比赛中的120万张高分辨率图像分为1000个不同的类别。（开门见山，直接说干了什么。）在测试数据上，我们取得了37.5％和17.0％的前1和前5的错误率（这里使用的是错误率的评估指标，和我目前使用的Acc，Presion，Recall，召回率评估指标不一样。），这比以前的先进水平要好得多。具有6000万个参数和650,000个神经元的神经网络由五个卷积层组成（这里挖一个坑，参数量和神经元数量的评估指标不一样。），其中一些随后是最大池化层，三个全连接层以及最后的1000个softmax输出。（这里挖个坑softMax的机制是怎么样的？）为了加快训练速度，我们使用非饱和神经元和能高效进行卷积运算的GPU实现。为了减少全连接层中的过拟合，我们采用了最近开发的称为“dropout”的正则化方法（dropout，随机丢弃的机制是什么？），该方法证明是非常有效的。我们还在ILSVRC-2012比赛中使用了这种模式的一个变种，取得了15.3％的前五名测试失误率，而第二名的成绩是26.2％。</p><ol><li><p>介绍：目前，机器学习方法对物体识别非常重要。为了改善他们的表现（前提条件就是之前的表现不是很好），我们可以收集更大的数据集，训练更强大的模型，并使用更好的技术来防止过拟合。（这里指出减少过拟合的方法有增大数据集，更改模型结构，使用更好的优化技术。）直到最近，标记好图像的数据集相对还较小——大约上万的数量级（例如，NORB，Caltech-101&#x2F;256和CIFAR-10&#x2F;100）。使用这种规模的数据集可以很好地解决简单的识别任务，特别是如果他们增加了保留标签转换（label-preserving transformations）。例如，目前MNIST数字识别任务的最低错误率（&lt;0.3％）基本达到了人类的识别水平。但是物体在现实环境中可能表现出相当大的变化性，所以要学会识别它们，就必须使用更大的训练集。事实上，小图像数据集的缺点已是众所周知（例如，Pinto），但直到最近才可以收集到数百万的标记数据集。新的大型数据集包括LabelMe ，其中包含数十万个完全分割的图像，以及ImageNet ，其中包含超过15,000万个超过22,000个类别的高分辨率图像。（目前的研究的对象，研究现状。）<br>要从数百万图像中学习数千个类别，我们需要一个具有强大学习能力的模型。（这里暗示这篇文章的模型大小非常大，但是现在看来入门级把，毕竟是12年前的文章了，开山鼻祖了。）然而，物体识别任务的巨大复杂性意味着即使是像ImageNet这样大的数据集也不能完美地解决这个问题，所以我们的模型也需要使用很多先验知识来弥补我们数据集不足的问题。卷积神经网络（CNN）就构成了一类这样的模型（卷积神经网络可以获取先验的知识，来弥补数据集不足的问题，后面是卷积神经网络为什么能够实现获取先验知识。）。它们的容量可以通过改变它们的深度和宽度来控制，并且它们也对图像的性质（即统计量的定态假设以及像素局部依赖性假设）做出准确而且全面的假设。因此，与具有相同大小的层的标准前馈神经网络相比，CNN具有更少的连接和参数，因此它们更容易训练，而其理论最优性能可能稍微弱一些。<br>尽管CNN具有很好的质量，并且尽管其局部结构的效率相对较高，但将它们大规模应用于高分辨率图像时仍然显得非常昂贵。幸运的是，当前的GPU可以用于高度优化的二维卷积，能够加速许多大型CNN的训练，并且最近的数据集（如ImageNet）包含足够多的标记样本来训练此类模型，而不会出现严重的过度拟合。<br>本文的具体贡献如下：我们在ILSVRC-2010和ILSVRC-2012比赛中使用的ImageNet子集上训练了迄今为止最大的卷积神经网络之一，并在这些数据集上取得了迄今为止最好的结果。我们编写了一个高度优化的2D卷积的GPU实现以及其他训练卷积神经网络的固有操作，并将其公开。（codeing能力还是有的，我的目标就是能够实现自己的想法，Talk is cheap. Show me the code.这句话真的是令人兴奋）我们的网络包含许多新的和不同寻常的功能，这些功能可以提高网络的性能并缩短训练时间，详情请参阅第3章节。我们的网络规模较大，即使有120万个带标签的训练样本，仍然存在过拟合的问题，所以我们采用了几个有效的技巧来阻止过拟合，在第4节中有详细的描述。我们最终的网络包含五个卷积层和三个全连接层，并且这个深度似乎很重要：我们发现去除任何卷积层（每个卷积层只包含不超过整个模型参数的1%的参数）都会使网络的性能变差。（这点可能验证了特征是层级表示的，）最后，网络的规模主要受限于目前GPU上可用的内存量以及我们可接受的训练时间。我们的网络需要在两块GTX 580 3GB GPU上花费五到六天的时间来训练。我们所有的实验都表明，通过等待更快的GPU和更大的数据集出现，我们的结果可以进一步完善。</p></li><li><p>数据集：ImageNet是一个拥有超过1500万个已标记高分辨率图像的数据集，大概有22,000个类别。（对数据集有一个基本介绍，保证权威性，说明没有造假）图像都是从网上收集，并使用Amazon-Mechanical Turk群智工具人工标记（人工智能，人工越多越智能，找不到工作就去打标签，打标签的特点就是不费脑子，一坐坐一天。ImageNet是李飞飞<a href="https://baike.baidu.com/item/%E6%9D%8E%E9%A3%9E%E9%A3%9E/7448630">放个连接</a>。从2010年起，作为Pascal视觉对象挑战赛的一部分，这是每年举办一次的名为ImageNet大型视觉识别挑战赛（ILSVRC）的比赛。 ILSVRC使用的是ImageNet的一个子集，每1000个类别中大约有1000个图像。总共有大约120万张训练图像，50,000张验证图像和150,000张测试图像。<br>ILSVRC-2010是ILSVRC中的唯一可以使用测试集标签的版本，因此这也正是我们进行大部分实验的版本。由于我们也在ILSVRC-2012比赛中引入了我们的模型，因此在第6部分中，我们也会给出此版本数据集的结果，尽管这个版本的测试集标签不可用。在ImageNet上，习惯上使用两种错误率：top-1和top-5，其中top-5错误率是正确标签不在被模型认为最可能的五个标签之中的测试图像的百分率。（原来错误率来源于这个比赛）<br>ImageNet由可变分辨率的图像组成，而我们的系统需要固定的输入尺寸。因此，我们将图像下采样到256×256的固定分辨率。给定一个矩形图像，我们首先重新缩放图像，使得短边长度为256，然后从结果中裁剪出中心的256×256的图片。除了将每个像素中减去训练集的像素均值之外，我们没有以任何其他方式对图像进行预处理。所以我们在像素的（中心）原始RGB值上训练了我们的网络。</p></li><li><p>图（前文放的模型结构图）概括了我们所提出网络的结构。它包含八个学习层——五个卷积层和三个全连接层。下面，我们将描述一些所提出网络框架中新颖或不寻常的地方。 3.1-3.4节按照我们对它们重要性的估计进行排序，其中最重要的是第一个。<br>RelU：对一个神经元模型的输出的常规套路是，给他接上一个激活函数：（tanh（x）的公式，）就梯度下降法的训练时间而言，这些饱和非线性函数比非饱和非线性函数（ReLU的公式f(x)&#x3D;max(0,x)注：因为ReLU的公式比较简单所以这里放一下)如慢得多。根据Nair和Hinton的说法[20]（这篇论文相当于为ReLU背书了，就相当于我的理论依据），我们将这种非线性单元称为——修正非线性单元（Rectified Linear Units (ReLUs)）。使用ReLUs做为激活函数的卷积神经网络比起使用tanh单元作为激活函数的训练起来快了好几倍。这个结果从图1中可以看出来（实验证明来了，填坑，使用了实验证明），该图展示了对于一个特定的四层CNN，CIFAR-10数据集训练中的误差率达到25%所需要的迭代次数。从这张图的结果可以看出，如果我们使用传统的饱和神经元模型来训练CNN，那么我们将无法为这项工作训练如此大型的神经网络。我们并不是第一个考虑在CNN中替换掉传统神经元模型的(继续理论证明，巨大的论文阅读量，)。例如，Jarrett等人[11]声称，非线性函数在他们的对比度归一化问题上，再接上局部均值池化单元，在Caltech-101数据集上表现的非常好。然而，在这个数据集中，主要担心的还是防止过拟合，所以他们观察到的效果与我们在使用ReLU时观察到的训练集的加速能力还是不一样。加快训练速度对大型数据集上训练的大型模型的性能有很大的影响。<br>在多个GPU上训练：单个GTX 580 GPU只有3GB内存（当时GPU的内存确实小，不过也挺厉害了。有时候真觉得自己跟不上时代了，对时间没有一点感觉，12年24年对我有什么区别？），这限制了可以在其上训练的网络的最大尺寸。事实证明，120万个训练样本足以训练那些因规模太大而不适合使用一个GPU训练的网络。因此，我们将网络分布在两个GPU上。目前的GPU很适合于跨GPU并行化操作，因为它们能够直接读写对方的内存，而无需通过主机内存。我们采用的并行化方案基本上将半个内核（或神经元）放在各个GPU上，（有种左右脑的感觉）——另外还有一个技巧：GPU只在某些层间进行通信。这意味着，例如，第3层的内核从第2层的所有内核映射（kernel maps）中获取输入。然而，第4层中的内核又仅从位于同一GPU上的第3层中的那些内核映射获取输入。选择连接模式对于交叉验证是一个不小的问题，但这使得我们能够精确调整通信量，直到它的计算量的达到可接受的程度。由此产生的架构有点类似于Cire¸san等人使用的“柱状”CNN[5]，除了我们的每列不是独立的之外（见图2）。与一个GPU上训练的每个卷积层只有一半的内核数量的网络相比，该方案分别将我们的top-1和top-5错误率分别降低了1.7％和1.2％。双GPU网络的训练时间比单GPU网络更少。<br>局部响应归一化：ReLU具有理想的属性，它们不需要对输入进行归一化来防止它们饱和。如果至少有一些训练实例为ReLU产生了正的输入，那么这个神经元就会学习。然而，我们还是发现下面的这种归一化方法有助于泛化。设aix,y表示第i个内核计算(x,y)位置的ReLU非线性单元的输出，而响应归一化（Local Response Normalization）的输出值定义为bix,y其中，（公式）求和部分公式中的 n表示同一个位置下与该位置相邻的内核映射的数量，而N表示这一层所有的内核数（即通道数）。内核映射的顺序当然是任意的，并且在训练之前就已经定好了。这种响应归一化实现了一种模仿真实神经元的横向抑制，从而在使用不同内核计算的神经元输出之间产生较大的竞争。常数k都是超参数（hyper-parameters），它们的值都由验证集决定。我们取 k&#x3D;2。我们在某些层的应用ReLU后再使用这种归一化方法（参见第3.5节）。这个方案与Jarrett等人[11]的局部对比归一化方案有些相似之处，但我们的被更准确地称为“亮度归一化”，因为我们没有减去均值。响应归一化将我们的top-1和top-5的错误率分别降低了1.4％和1.2％。我们还验证了这种方案在CIFAR-10数据集上的有效性：没有进行归一化的四层CNN实现了13％的测试错误率，而进行了归一化的则为11％。<br>层叠池化：CNN中的池化层汇集了相同内核映射中相邻神经元组的输出。在传统方法中，相邻池化单元之间互不重叠（例如[17,11,4]）。更准确地说，一个池化层可以被认为是由一些间隔为s个像素的池化单元组成的网格，每个都表示了一个以池化单元的位置为中心的大小为z×z的邻域。如果我们令s &#x3D; z，我们就可以得到CNN中常用的传统的局部池化。<br>整体结构：现在我们已经准备好描述CNN的整体架构了。如图2所示，这个网络包含了八层权重;前五个是卷积层，其余三个为全连接层。最后的全连接层的输出被送到1000维的softmax函数，其产生1000个类的预测。我们的网络最大化多项逻辑回归目标，这相当于在预测的分布下最大化训练样本中正确标签对数概率的平均值。第二，第四和第五个卷积层的内核仅与上一层存放在同一GPU上的内核映射相连（见图2）。第三个卷积层的内核连接到第二层中的所有内核映射。全连接层中的神经元连接到前一层中的所有神经元。响应归一化层紧接着第一个和第二个卷积层。 在3.4节中介绍的最大池化层，后面连接响应归一化层以及第五个卷积层。将ReLU应用于每个卷积层和全连接层的输出。第一个卷积层的输入为224×224×3的图像，对其使用96个大小为11×11×3、步长为4（步长表示内核映射中相邻神经元感受野中心之间的距离）的内核来处理输入图像。第二个卷积层将第一个卷积层的输出（响应归一化以及池化）作为输入，并使用256个内核处理图像，每个内核大小为5×5×48。第三个、第四个和第五个卷积层彼此连接而中间没有任何池化或归一化层。第三个卷积层有384个内核，每个的大小为3×3×256，其输入为第二个卷积层的输出。第四个卷积层有384个内核，每个内核大小为3×3×192。第五个卷积层有256个内核，每个内核大小为3×3×192。全连接层各有4096个神经元。</p></li><li><p>减少过拟合。我们的神经网络架构拥有6000万个参数。尽管ILSVRC的1000个类别使得每个训练样本从图像到标签的映射被限制在了10 bit之内，但这不足以保证训练这么多参数而不出现过拟合。下面，我们将介绍对付过度拟合的两个方法。<br>数据增强： 减小过拟合的最简单且最常用的方法就是，使用标签保留转换（label-preserving transformations，例如[25,4,5]），人为地放大数据集。我们采用两种不同形式的数据增强方法，它们都允许通过很少的计算就能从原始图像中生成转换图像，所以转换后的图像不需要存储在硬盘上。在我们实现过程中，转换后的图像是使用CPU上的Python代码生成的，在生成这些转换图像的同时，GPU还在训练上一批图像数据。所以这些数据增强方案实际上是很高效的。<br>数据增强的第一种形式包括平移图像和水平映射。我们通过从256×256图像中随机提取224×224的图像块（及其水平映射）并在这些提取的图像块上训练我们的网络来做到这一点。这使我们的训练集的规模增加了2048倍，尽管由此产生的训练样本当然还是高度相互依赖的。如果没有这个方案，我们的网络就可能会遭受大量的的过拟合，可能会迫使我们不得不使用更小的网络。在测试时，网络通过提取5个224×224的图像块（四个角块和中心块）以及它们的水平映射（因此总共包括10个块）来进行预测，并求网络的softmax层的上的十个预测结果的均值。第二种形式的数据增强包括改变训练图像中RGB通道的灰度。具体而言，我们在整个ImageNet训练集的图像的RGB像素值上使用PCA。对于每个训练图像，我们添加多个通过PCA找到的主成分，大小与相应的特征值成比例，乘以一个随机值，该随机值属于均值为0、标准差为0.1的高斯分布。因此，对于每个图像的RGB像素有：Ixy&#x3D;[IRxy IGxy IBxy]T（自己去看论文中的公式），我们加入如下的值：[p1 p2 p3] [α1λ1 α2λ2 α3λ3]T其中， pi和 λi分别是3x3的RGB协方差矩阵的第 i个特征向量和第i个的特征值，而 αi是前面所说的随机值。对于一张特定图像中的所有像素，每个 αi只会被抽取一次，知道这张图片再次用于训练时，才会重新提取随机变量。这个方案近似地捕捉原始图像的一些重要属性，对象的身份不受光照的强度和颜色变化影响。这个方案将top-1错误率降低了1％以上。<br>Dropout： 结合许多不同模型的预测结果是减少测试错误率的一种非常成功的方法[1,3]，但对于已经花费数天时间训练的大型神经网络来说，它似乎成本太高了。然而，有一种非常有效的模型组合方法，在训练期间，只需要消耗1&#x2F;2的参数。这个新发现的技术叫做“Dropout”[10]，它会以50%的概率将隐含层的神经元输出置为0。以这种方法被置0的神经元不参与网络的前馈和反向传播。因此，每次给网络提供了输入后，神经网络都会采用一个不同的结构，但是这些结构都共享权重。这种技术减少了神经元的复杂适应性，因为神经元无法依赖于其他特定的神经元而存在。因此，它被迫学习更强大更鲁棒的功能，使得这些神经元可以与其他神经元的许多不同的随机子集结合使用。在测试时，我们试着使用了所有的神经元，并将它们的输出乘以0.5。这与采用大量dropout的网络产生的预测结果分布的几何均值近似。我们在图2中的前两个全连接层上使用了dropout。没有dropout，我们的网络会出现严重的过拟合。Dropout大概会使达到收敛的迭代次数翻倍。</p></li><li><p>训练细节。我们使用随机梯度下降法来训练我们的模型，每个batch有128个样本，动量（momentum）为0.9，权重衰减（weight decay）为0.0005。我们发现这种较小的权重衰减对于模型的训练很重要。换句话说，权重衰减在这里不仅仅是一个正则化方法：它减少了模型的训练误差。权重ω的更新法则是：（自己看公式去）<br>我们使用标准差为0.01、均值为0的高斯分布来初始化各层的权重。我们使用常数1来初始化了网络中的第二个、第四个和第五个卷积层以及全连接层中的隐含层中的所有偏置参数。这种初始化权重的方法通过向ReLU提供了正的输入，来加速前期的训练。我们使用常数0来初始化剩余层中的偏置参数。<br>我们对所有层都使用相同的学习率，在训练过程中又手动进行了调整。我们遵循的启发式方法是：以当前的学习速率训练，验证集上的错误率停止降低时，将学习速率除以10.学习率初始时设为0.01，并且在终止前减少3次。我们使用120万张图像的训练集对网络进行了大约90次迭代的训练，这在两块NVIDIA GTX 580 3GB GPU上花费了大约5到6天的时间。（这里说明了优化函数，超参数设置。这里挖个坑，什么是超参数？）</p></li><li><p>结果：我们在ILSVRC-2010上取得的结果如表1所示。我们的网络的top-1和top-5测试集错误率分别为37.5％和17.0％。在ILSVRC-2010比赛期间取得的最佳成绩是47.1％和28.2％，其方法是对六种不同的稀疏编码模型所产生的预测结果求平均[2]。此后公布的最佳结果为45.7％、25.7％，其方法是对两种经过密集采样的特征[24]计算出来的Fisher向量（FV）训练的两个分类器取平均值。我们的网络实现了37.5％和17.0％的前1和前5个测试集错误率5。在ILSVRC-2010比赛期间取得的最佳成绩是47.1％和28.2％，其中一种方法是对六种针对不同特征进行训练的稀疏编码模型所产生的预测进行平均[2]，此后最佳公布结果为45.7％， 25.7％，其中一种方法是：对两个在不同取样密度的Fisher向量上训练的分类器取平均。（纵向对比了，相同数据集，不同模型。）<br>我们还在ILSVRC-2012竞赛中使用了我们的模型，并在表2中给出了我们的结果。由于ILSVRC-2012测试集标签未公开，因此我们无法给出我们测试过的所有模型在测试集上的错误率。在本节的其余部分中，我们将验证集和测试集的错误率互换，因为根据我们的经验，它们之间的差值不超过0.1％（见表2）。本文描述的CNN的top-5错误率达到了18.2％。对五个相似CNN的预测结果计算均值，得到的错误率为16.4％。单独一个CNN，在最后一个池化层之后，额外添加第六个卷积层，对整个ImageNet Fall 2011 release(15M images, 22K categories)进行分类，然后在ILSVRC-2012上“微调”（fine-tuning）网络，得到的错误率为16.6％。对整个ImageNet Fall 2011版本的数据集下预训练的两个CNN，求他们输出的预测值与前面提到的5个不同的CNN输出的预测值的均值，得到的错误率为15.3％。比赛的第二名达到了26.2％的top-5错误率，他们的方法是：对几个在特征取样密度不同的Fisher向量上训练的分类器的预测结果取平均的方法[7]。<br>最后，我们还在ImageNet Fall 2009版本的数据集上提交了错误率，总共有10,184个类别和890万张图像。在这个数据集中，我们遵循文献中的使用一半图像用于训练，一半图像用于测试的惯例。由于没有建立测试集，所以我们的拆分方法有必要与先前作者使用的拆分方法不同，但这并不会对结果产生显著的影响。我们在这个数据集上的top-1和top-5错误率分别是67.4％和40.9％，是通过前面描述的网络获得的，但是在最后的池化层上还有额外的第6个卷积层。该数据集此前公布的最佳结果是78.1％和60.9％[19]。<br>定性评估：图3（自己看论文去）显示了由网络的两个数据连接层学习得到的卷积内核。（网络结构还可以画出来，也是挺有意思的。）该网络已经学习到许多频率和方向提取的内核，以及各种色块。请注意两个GPU所展现的不同特性，这也是3.5节中介绍的限制互连的结果。GPU1上的内核在很大程度上与颜色无关，然而GPU2上的内核在很大程度上都于颜色有关。这种特异性在每次迭代期间都会发生，并且独立于任何特定的随机权重初始化过程（以GPU的重新编号为模）。<br>在图4（自己看论文去，图4展示了一堆实验结果）的左边，我们通过计算8张测试图像的top-5预测来定性评估网络的训练结果。请注意，即使是偏离中心的物体，如左上角的螨虫，也可以被网络识别出来。大多数top-5的标签都显得比较合理。例如，只有其他类型的猫才被认为是豹子的可能标签。在某些情况下（栅栏、樱桃），照片的关注点存在模糊性，不知道到底该关注哪个。另一个研究可视化的网络的方法是，考虑由最后一个4096维隐含层中的图像的特征的激活函数输出值。如果两幅图像产生有的欧氏距离，我们可以认为高层次的神经网络认为它们是相似的。图4显示了测试集中的5个图像和来袭训练集的6个图像，这些图像根据这种度量方法来比较它们中的哪一个与其最相似。请注意，在像素层次上，待检测的训练图像通常不会与第一列中的查询图像有较小的L2距离。例如，检索到的狗和大象有各种不同的姿势。我们在补充材料中提供了更多测试图像的结果。通过使用欧式距离来计算两个4096维实值向量的相似性，效率不高，但是通过训练自编码器可以将这些向量压缩为较短的二进制码，能够使其更高效。与应用自编码器到原始像素[14]相比，这应该是更好的图像检索方法。它不使用图像标签，因此更秦翔宇检索具有相似图案边缘的图像，不管它们的图像语义是否相似。</p></li><li><p>讨论：我们的研究结果表明，一个大的深层卷积神经网络能够在纯粹使用监督学习（这里有个概念，监督学习和无监督学习，半监督学习。挖个坑）的情况下，在极具挑战性的数据集上实现破纪录的结果。值得注意的是，如果移除任何一个卷积层，网络的性能就会下降。例如，删除任何中间层的结果会导致网络性能的top-1错误率下降2%。因此网络的深度对于实现我们的结果真的很重要。（基本上后面的深度学习的思路就是堆网络结构）<br>为了简化我们的实验，我们没有使用任何无监督的预训练方法，尽管这样可能会有所帮助，特别是如果我们获得了足够的计算能力来显著地增加网络的大小而不会相应地增加已标记数据的数量。到目前为止，我们的结果已经获得了足够的进步，因为我们已经使网络更大，并且训练了更长时间。但我们仍然有很大的空间去优化网络，使之能够像人类的视觉系统一样感知。最后，我们希望对视频序列使用非常大的深度卷积神经网路，其中时间结构提供了非常有用的信息，这些信息往往在静态图像中丢失了，或者说不太明显。</p></li></ol><h1 id="个人感觉"><a href="#个人感觉" class="headerlink" title="个人感觉"></a>个人感觉</h1><p>论文很短，内容很多。展现在论文中的，没有展现在论文中的。学习的过程中既有鲜花也有荆棘，这是客观的条件，我承认有人会有论语中的天生的智慧，看待世界的方式就不一样，这是现实，但是那又有什么？不管怎么样先把下面的坑填了。还有就是博客中难免有错别字，记得更改。+</p><hr><h2 id="title-填坑——经典网络结构——AlexNetdate-2024-04-23-10-48-00tags-填坑"><a href="#title-填坑——经典网络结构——AlexNetdate-2024-04-23-10-48-00tags-填坑" class="headerlink" title="title: 填坑——经典网络结构——AlexNetdate: 2024-04-23 10:48:00tags: 填坑"></a>title: 填坑——经典网络结构——AlexNet<br>date: 2024-04-23 10:48:00<br>tags: 填坑</h2><h2 id="问题1，卷积是什么？作用什么？"><a href="#问题1，卷积是什么？作用什么？" class="headerlink" title="问题1，卷积是什么？作用什么？"></a>问题1，卷积是什么？作用什么？</h2><p>卷积（Convolution）是一种数学运算，常用于信号处理和图像处理领域。在信号处理中，卷积用于将输入信号与卷积核（也称为滤波器）进行运算，产生输出信号。<br>卷积的作用有以下几个方面：</p><ol><li>信号滤波：卷积可以用于信号滤波，通过将输入信号与合适的卷积核进行卷积运算，可以实现对信号的滤波操作。滤波可以用于去除信号中的噪声、平滑信号、强调信号中的某些频率成分等。</li><li>特征提取：在图像处理中，卷积可以用于特征提取。通过将图像与不同的卷积核进行卷积运算，可以提取出图像中的不同特征，例如边缘、纹理、角点等。这些特征可以用于图像识别、目标检测和图像处理中的其他任务。</li><li>信号压缩：卷积可以用于信号压缩。通过将输入信号与适当的卷积核进行卷积运算，可以将信号表示转换为另一种表示形式，通常具有更紧凑的表示。这种表示形式可以用于信号压缩和数据压缩。</li><li>卷积神经网络：卷积神经网络（Convolutional Neural Network，CNN）是一种基于卷积运算的深度学习模型，广泛应用于图像识别、计算机视觉和自然语言处理等领域。卷积在 CNN 中用于提取图像或文本的特征，并通过多层卷积和池化操作来实现对输入数据的高级表示和分类。如果输入数据为图片，那么卷积层的作用就是提取图片中的信息，这些信息被称为图像特征，这些特征是由图像中的每个像素通过组合或者独立的方式所体现，比如图片的纹理特征、颜色特征、空间特征。</li></ol><p>卷积的操作过程：<br>请参考<a href="https://blog.csdn.net/weipf8/article/details/103917202">参考博客</a>。image的图片大小为5x5，卷积核为3x3，输出的特征的大小为3x3<br>特征图计算公式：一般情况下,输入的图片矩阵以及后面的卷积核,特征图矩阵都是方阵,这里设输入矩阵大小为w,卷和核大小为k,步幅为s,补零层数为p,则卷积后产生的特征图大小计算公式为:W &#x3D; （w+2p-k）&#x2F;s + 1. 比如说上面5x5的图片与3x3的卷积核进行卷积操作，特征图的大小为： W &#x3D; （5 + 2*0 -3）&#x2F;1 + 1 &#x3D;3<br>特征图相对与下一层的卷积层是图片。<br>卷积核的参数量计算，卷积核尺寸： K， 前一层的通道数：Cin 当前层的卷积核的个数： Cout 。单个卷积核的参数量： params kernel &#x3D; Cin x K x K, 有</p><p>假设有卷积神经网络，输入为大小224<em>224的RGB图，第一层为卷积层，有12个大小为5</em>5的卷积核，填充为2，步长为4。该层参数共有（  912    ）个。计算过程权重参数量：每个卷积核有 75 （5 x 5 x 3）个权重参数，共有12 个卷积核，所以权重参数量为 75×12&#x3D;900.偏置参数量：每个卷积核有一个偏置项，共有 12 个卷积核，所以偏置参数量为 12。<br><a href="https://blog.csdn.net/Together_CZ/article/details/115494176">执行卷积的过程的动态图</a><br>关于卷积其实还有很多问题，比如说输入一张（3x255x255）的图片，输入后经过卷积后输出的特征图大小为： 要考虑卷积核的大小（kernel size ） 步幅（stride），边界填充（padding） 计算公式入上式所示。<br>。1x1卷积为什么可以实现升维和降维。）<br>1x1 卷积可以实现升维和降维的原因在于：（通道数可以自定义数量）<br>升维：当输入特征图的通道数较少时，可以使用 1x1 卷积来增加通道数，从而增加网络的表示能力。这是因为 1x1 卷积可以将输入特征图中的每个通道与卷积核中的权重相乘并求和，从而生成一个新的特征图。<br>降维：当需要减少特征图的通道数时，可以使用 1x1 卷积并调整输出通道数为所需的值。通过调整卷积核中的输出通道数，可以实现特征图通道数的降维。</p><h2 id="问题2，池化是什么？作用是什么？"><a href="#问题2，池化是什么？作用是什么？" class="headerlink" title="问题2，池化是什么？作用是什么？"></a>问题2，池化是什么？作用是什么？</h2><p>池化（Pooling）是一种常用的操作，通常与卷积神经网络（CNN）结合使用。池化操作通过对输入数据的局部区域进行聚合或采样来减小数据的空间尺寸，从而减少参数数量、降低计算量，并提取出输入数据的重要特征。</p><p>池化的作用有以下几个方面</p><ol><li>降采样：池化操作可以减小输入数据的空间尺寸，从而降低后续层的计算复杂度。通过降低数据的维度，池化可以在保留重要特征的同时减少冗余信息，提高计算效率。</li><li>平移不变性：池化操作具有一定的平移不变性。在图像处理中，通过对局部区域进行池化操作，可以使得输入图像在平移、旋转和缩放等变换下具有一定的不变性。这对于图像识别和目标检测等任务是有益的。</li><li>特征提取：池化操作可以提取输入数据的重要特征。通过对局部区域进行池化，池化操作会选择区域中的最大值（最大池化）或平均值（平均池化）作为输出值，从而提取出输入数据的显著特征。这有助于减少数据的维度，并保留重要的特征信息。</li><li>减少过拟合：池化操作可以在一定程度上减少过拟合。通过减小数据的空间尺寸，池化操作可以降低模型的参数数量，从而减少过拟合的风险。此外，池化操作还可以通过丢弃一些冗余信息来提高模型的泛化能力。</li></ol><p>池化的种类</p><ol><li>最大池化（Max Pooling）：最大池化是一种常见的池化操作。在最大池化中，输入数据的局部区域被分割成不重叠的块，然后在每个块中选择最大值作为输出。最大池化可以提取出输入数据的显著特征，同时减小数据的空间尺寸。</li><li>平均池化（Average Pooling）：平均池化是另一种常见的池化操作。在平均池化中，输入数据的局部区域被分割成不重叠的块，然后计算每个块中元素的平均值作为输出。平均池化可以平滑输入数据并减小数据的空间尺寸。</li><li>自适应池化（Adaptive Pooling）：自适应池化是一种具有灵活性的池化操作。与最大池化和平均池化不同，自适应池化不需要指定池化窗口的大小，而是根据输入数据的尺寸自动调整池化窗口的大小。这使得自适应池化可以适应不同尺寸的输入数据。</li><li>全局池化（Global Pooling）：全局池化是一种特殊的池化操作，它将整个输入数据的空间尺寸缩减为一个单一的值或向量。全局池化可以通过对输入数据的所有位置进行池化操作，从而提取出输入数据的全局特征。常见的全局池化有全局平均池化（Global Average Pooling）和全局最大池化（Global Max Pooling）。</li></ol><h2 id="问题3，全连接是什么？作用是什么？"><a href="#问题3，全连接是什么？作用是什么？" class="headerlink" title="问题3，全连接是什么？作用是什么？"></a>问题3，全连接是什么？作用是什么？</h2><p>的是神经网络中的一种连接方式，也称为密集连接（dense connection）。在全连接中，每个神经元都与前一层的所有神经元相连。这意味着前一层的每个神经元的输出都将作为输入传递给下一层的每个神经元。<br>全连接层的作用是将输入数据进行线性变换，并应用激活函数来产生输出。这种连接方式允许神经网络学习输入数据中的复杂关系，从而实现各种任务，例如分类、回归等。<br><img src="/pic/tiankeng1.png" alt="全连接示意图"><br>请问如上DNN神经网络共有几层： 5层<br>请问该DNN神经网络用来解决二分类问题，那么最后一层的激活函数是 Sigmoid<br>请问如上所示的DNN神经网络的第一个隐藏层有多少个参数： 2 x 3 + 3 &#x3D; 9 （前一层输入量 乘以 后一层的神经元数量 + 偏执项。）</p><h2 id="问题4，AlexNet论文使用的loss函数是什么？"><a href="#问题4，AlexNet论文使用的loss函数是什么？" class="headerlink" title="问题4，AlexNet论文使用的loss函数是什么？"></a>问题4，AlexNet论文使用的loss函数是什么？</h2><p>CrossEntropy交叉损失函数： </p><p><a href="https://blog.csdn.net/qq_44629163/article/details/124348366">参考博客</a></p><h2 id="问题5，AlexNet论文中使用的梯度优化方式是什么，梯度怎么实现下降？"><a href="#问题5，AlexNet论文中使用的梯度优化方式是什么，梯度怎么实现下降？" class="headerlink" title="问题5，AlexNet论文中使用的梯度优化方式是什么，梯度怎么实现下降？"></a>问题5，AlexNet论文中使用的梯度优化方式是什么，梯度怎么实现下降？</h2><p>AlexNet论文中使用的梯度优化算法是随机梯度下降（Stochastic Gradient Descent，SGD）。在训练过程中，SGD通过计算损失函数关于网络参数的梯度，并根据该梯度更新参数，以使损失函数最小化。<br><a href="https://blog.csdn.net/qq_58146842/article/details/121280968">SGD参考博客</a></p><h2 id="问题6，AlexNet论文中使用的评价指标是什么？"><a href="#问题6，AlexNet论文中使用的评价指标是什么？" class="headerlink" title="问题6，AlexNet论文中使用的评价指标是什么？"></a>问题6，AlexNet论文中使用的评价指标是什么？</h2><p>错误率 ： ACC 的相反数，计算方法为1-ACC</p><h2 id="问题7，AlexNet中的创新点是什么？"><a href="#问题7，AlexNet中的创新点是什么？" class="headerlink" title="问题7，AlexNet中的创新点是什么？"></a>问题7，AlexNet中的创新点是什么？</h2><ol><li>ReLU激活函数的引入，采样非线性单元（ReLU）的深度卷积神经网络训练时间要比tanh单元要快几倍。而时间开销是进行模型训练过程中的很重要的因数。同时ReLU有效的防止了过拟合的现象。</li><li>层叠池化操作，以往池化的大小PoolingSize与步长stride一般是相等的，例如：图像大小为256*256，PoolingSize&#x3D;2×2，stride&#x3D;2，这样可以使图像或是FeatureMap大小缩小一倍变为128，此时池化过程没有发生层叠。但是AlexNet采用了层叠池化操作，即PoolingSize &gt; stride。这种操作非常像卷积操作，可以使相邻像素间产生信息交互和保留必要的联系。论文中也证明，此操作可以有效防止过拟合的发生。</li><li>Dropout操作， Dropout操作会将概率小于0.5的每个隐层神经元的输出设为0，即去掉了一些神经节点，达到防止过拟合。那些“失活的”神经元不再进行前向传播并且不参与反向传播。这个技术减少了复杂的神经元之间的相互影响。在论文中，也验证了此方法的有效性。</li><li>网络层数更深，与原始的LeNet相比，AlexNet网络结构更深，LeNet为5层，AlexNet为8层。在随后的神经网络发展过程中，AlexNet逐渐让研究人员认识到网络深度对性能的巨大影响。当然，这种思考的重要节点出现在VGG网络（下一篇博文VGG论文中将会讲到）。</li></ol><h2 id="问题8，优化函数的具体实现是什么？"><a href="#问题8，优化函数的具体实现是什么？" class="headerlink" title="问题8，优化函数的具体实现是什么？"></a>问题8，优化函数的具体实现是什么？</h2><p>请参考博客：<br><a href="https://www.bilibili.com/video/BV1Fu4y1N7Qu/?spm_id_from=333.337.search-card.all.click&vd_source=c2d8f28374ac78ec2f99b6321e56032a">以逻辑回归为例讲的梯度下降算法矩阵化</a><br><a href="https://www.bilibili.com/video/BV1eK42147wr/?p=29&vd_source=c2d8f28374ac78ec2f99b6321e56032a">结合看</a><br><a href="https://www.bilibili.com/video/BV1JK411k7ah/?spm_id_from=333.337.search-card.all.click&vd_source=c2d8f28374ac78ec2f99b6321e56032a">代码实现</a></p><h2 id="问题10，什么是过拟合合和欠拟合？"><a href="#问题10，什么是过拟合合和欠拟合？" class="headerlink" title="问题10，什么是过拟合合和欠拟合？"></a>问题10，什么是过拟合合和欠拟合？</h2><p>过拟合：过拟合指的是模型在训练数据上表现良好，但在未见过的测试数据上表现较差的情况。过拟合通常发生在模型过于复杂或训练数据过少的情况下。当模型过度学习了训练数据中的噪声或特定的样本特征时，会导致过拟合问题。在过拟合的情况下，模型可能会过度拟合训练数据，导致泛化能力较差，无法很好地适应新的、未见过的数据。<br>欠拟合：欠拟合指的是模型在训练数据上表现不佳，无法捕捉数据中的足够的信息和结构，导致模型过于简单或不够复杂。欠拟合通常发生在模型复杂度过低或训练数据量不足的情况下。在欠拟合的情况下，模型可能无法捕捉数据中的关键特征或模式，导致训练误差和测试误差都较高。<br><a href="https://zhuanlan.zhihu.com/p/72038532">参考博客</a></p><h2 id="问题9，论文中怎么证明，层叠池化可以有效防止过拟合的发生？"><a href="#问题9，论文中怎么证明，层叠池化可以有效防止过拟合的发生？" class="headerlink" title="问题9，论文中怎么证明，层叠池化可以有效防止过拟合的发生？"></a>问题9，论文中怎么证明，层叠池化可以有效防止过拟合的发生？</h2><p>验对比：作者可能会设计实验，对比使用层叠池化和不使用层叠池化的模型在同一数据集上的性能表现。通过比较两种模型的训练误差和测试误差，可以观察到使用层叠池化的模型是否在测试数据上表现更好，从而证明其能够有效防止过拟合。<br>交叉验证：作者可能会使用交叉验证来评估模型的泛化能力。通过在不同的训练集和测试集上多次进行实验，可以更客观地评估模型的性能，并观察使用层叠池化的模型是否具有更好的泛化能力。<br>可视化分析：作者可能会对模型的训练过程进行可视化分析，比如绘制训练损失曲线和验证损失曲线。通过观察损失曲线的变化趋势，可以了解模型是否存在过拟合问题，并观察是否使用层叠池化的模型更加稳定。</p><h2 id="问题10，-softMax的机制是怎么样的？"><a href="#问题10，-softMax的机制是怎么样的？" class="headerlink" title="问题10， softMax的机制是怎么样的？"></a>问题10， softMax的机制是怎么样的？</h2><p>Softmax函数是一种常用的激活函数，通常用于多分类问题中的输出层。Softmax函数可以将一个具有任意实数值的向量转换成一个概率分布，使得各个元素的值都在 (0, 1) 范围内，并且所有元素的和为1。</p><p><a href="https://zhuanlan.zhihu.com/p/105722023">参考博客</a></p><h2 id="问题15，Dropout的运行机制是什么，论文中怎么证明他们有效-理论证明和实验证明-？"><a href="#问题15，Dropout的运行机制是什么，论文中怎么证明他们有效-理论证明和实验证明-？" class="headerlink" title="问题15，Dropout的运行机制是什么，论文中怎么证明他们有效(理论证明和实验证明)？"></a>问题15，Dropout的运行机制是什么，论文中怎么证明他们有效(理论证明和实验证明)？</h2><p>Dropout是一种常用的正则化技术，用于减少神经网络的过拟合现象。其运行机制如下：</p><p>训练阶段：在每次训练迭代时，以概率 p 将神经网络中的某些神经元（或者称为节点）临时从网络中删除（置为零）。这样，在每次迭代中，都会随机删除一部分神经元，从而导致每次迭代得到的网络结构都不同。<br>预测阶段：在预测阶段，不再使用Dropout，而是使用所有的神经元，但需要对每个神经元的输出值乘以 p，以保持期望的输出值不变。</p><h2 id="问题16，-什么是超参数？"><a href="#问题16，-什么是超参数？" class="headerlink" title="问题16， 什么是超参数？"></a>问题16， 什么是超参数？</h2><p>超参数（Hyperparameters）是机器学习模型训练过程中的配置参数，其值不能通过训练过程自动学习，而是需要人工设置。与模型的参数（例如权重和偏置）不同，超参数通常用于控制模型的结构、学习过程的行为和性能调优。</p><p>一些常见的超参数包括：<br>学习率（Learning Rate）：用于控制每次参数更新的步长。<br>迭代次数（Number of Iterations&#x2F;Epochs）：训练模型时数据集遍历的次数。<br>批量大小（Batch Size）：每次迭代中用于更新参数的样本数量。<br>网络结构参数：例如隐藏层的数量、每个隐藏层的神经元数量、卷积核大小等。<br>正则化参数：用于控制模型的复杂度，例如L1和L2正则化的权重。<br>优化算法参数：例如动量（momentum）、adam的参数等。<br>损失函数参数：例如softmax交叉熵的参数、权重类别平衡等。</p><h2 id="问题17，-什么是监督学习和无监督学习，半监督学习？"><a href="#问题17，-什么是监督学习和无监督学习，半监督学习？" class="headerlink" title="问题17， 什么是监督学习和无监督学习，半监督学习？"></a>问题17， 什么是监督学习和无监督学习，半监督学习？</h2><p>监督学习（Supervised Learning）是一种机器学习任务，其目标是从有标签的数据中学习出一个输入到输出的映射关系，即从输入数据预测出相应的输出标签。在监督学习中，训练数据包括了输入和对应的输出标签，模型通过学习输入和输出之间的关系来进行预测。典型的监督学习任务包括分类和回归。</p><p>无监督学习（Unsupervised Learning）是一种机器学习任务，其目标是从没有标签的数据中学习出数据的内在结构或者特征表示，而无需事先给定标签信息。在无监督学习中，训练数据只包括输入数据，没有对应的输出标签。无监督学习可以用于聚类、降维、异常检测等任务。</p><p>半监督学习（Semi-Supervised Learning）是介于监督学习和无监督学习之间的一种学习方式，其目标是利用少量有标签数据和大量无标签数据来训练模型。在半监督学习中，训练数据同时包括有标签的数据和无标签的数据。半监督学习可以通过结合监督学习和无监督学习的方法，利用无标签数据的信息来提升模型性能，尤其在标注数据有限或者成本较高的情况下具有重要意义。</p><h2 id="挖坑"><a href="#挖坑" class="headerlink" title="挖坑"></a>挖坑</h2><h3 id="关于图像，有很多需要去填坑的部分，这里甚至可以新开一个分类去填关于图像的坑。在这篇文章中先把坑挖起来。免得忘记。（请移步深度学习：图像处理-数据预处理部分）"><a href="#关于图像，有很多需要去填坑的部分，这里甚至可以新开一个分类去填关于图像的坑。在这篇文章中先把坑挖起来。免得忘记。（请移步深度学习：图像处理-数据预处理部分）" class="headerlink" title="关于图像，有很多需要去填坑的部分，这里甚至可以新开一个分类去填关于图像的坑。在这篇文章中先把坑挖起来。免得忘记。（请移步深度学习：图像处理-数据预处理部分）"></a>关于图像，有很多需要去填坑的部分，这里甚至可以新开一个分类去填关于图像的坑。在这篇文章中先把坑挖起来。免得忘记。（请移步深度学习：图像处理-数据预处理部分）</h3>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch基础——Numpy</title>
    <link href="/2024/04/21/deeplearnbook2/"/>
    <url>/2024/04/21/deeplearnbook2/</url>
    
    <content type="html"><![CDATA[<p>第一部分</p><h1 id="Numpy基础"><a href="#Numpy基础" class="headerlink" title="Numpy基础"></a>Numpy基础</h1><h2 id="什么是Numpy？"><a href="#什么是Numpy？" class="headerlink" title="什么是Numpy？"></a>什么是Numpy？</h2><p>NumPy（Numerical Python的简称）是一个开源的Python库，用于进行科学计算。它提供了一个强大的N维数组对象，以及大量的函数用于处理这些数组。NumPy的主要功能包括：</p><ol><li>多维数组对象：NumPy的核心功能是其多维数组对象（ndarray）。这是一个快速、灵活的容器，可以容纳大量同类型数据，使你能够对这些数据进行数学运算。</li><li>广播功能：NumPy提供了广播功能，这是一种强大的机制，允许NumPy在执行算术运算时处理不同形状的数组。</li><li>数学函数：NumPy提供了大量的数学函数，可以对数组中的元素进行各种数学运算，如加、减、乘、除、平方根等。</li><li>线性代数：NumPy包含了线性代数函数库，可以进行矩阵乘法、求逆、解线性方程，傅里叶变换等操作。</li><li>随机数生成：NumPy提供了生成各种随机数的功能，如均匀分布、正态分布等。</li><li>更方便的读取\写入磁盘上的阵列数据和操作存储映像文件的工具。<br>NumPy是许多科学计算库（如Pandas、Matplotlib、SciPy等）的基础库，也是机器学习和数据科学中常用的库。在深度学习中图像、声音、文本等输入数据最终都要转换为数组或矩阵，NumPy的多维数组可以用来表示向量、矩阵和张量，这些都是深度学习算法的基本构成元素。</li></ol><h2 id="为什么要使用Numpy"><a href="#为什么要使用Numpy" class="headerlink" title="为什么要使用Numpy"></a>为什么要使用Numpy</h2><p>实际上python包含多个数据类型，数值类型（int，float，complex）、布尔类型（bool）、字符串（str）、列表（list）、元组（tuple）、字典（dict，{‘name’:’chenli’,’age’: 114514}）、集合（set{}）。<br>python包含这么多的数据类型，其中的列表（list）和数组（array）为什么不能用？原因是对于大数据来说，这些结构有很多不足。比如由于列表的元素可以是任何对象，因此列表中所保存的是对象的指针。例如为了存储[1,2,3],就需要3个指针和3个整数对象，这样对于数值运算来讲，严重浪费了计算机中的内存和CPU或GPU的算力。对于array，它可以直接保存数值，但是它不支持多维，并且对应操作的函数也不多，因此也不适合。</p><h2 id="怎么使用Numpy？"><a href="#怎么使用Numpy？" class="headerlink" title="怎么使用Numpy？"></a>怎么使用Numpy？</h2><p>第一步使用 <code>pip install numpy </code>来下载numpy库。</p><ol><li><p>生成Numpy数组。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs lua">import numpy as np<br>lst1= <span class="hljs-string">[[3.14, 2.17,0,1,2],[1,2,3,4,5]]</span> # 一个二维列表<br>nd1 = np.array(lst1)# 使用np.array()将列表数据类型转换成np数据类型<br><span class="hljs-built_in">print</span>(nd1) # 显示的结果为一个二维列表<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(nd1)) # 显示结果为&lt;class <span class="hljs-string">&#x27;numpy.ndarray&#x27;</span>&gt;    <br></code></pre></td></tr></table></figure></li><li><p>numpy中的random模块生成数组</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> numpy as np<br><br><span class="hljs-attribute">nd1</span> = np.random.random([<span class="hljs-number">3</span>,<span class="hljs-number">3</span>]) # 产生一个[<span class="hljs-number">3</span>,<span class="hljs-number">3</span>]ndarray，范围为<span class="hljs-number">0</span>-<span class="hljs-number">1</span>之间的随机数。<br><span class="hljs-attribute">np</span>.random.seed(<span class="hljs-number">123</span>) # 为了每次生成同一份数据，可以指定一个随机种子，而后生成的随机数据是固定的。<br><span class="hljs-attribute">nd2</span> = np.random.random(<span class="hljs-number">2</span>,<span class="hljs-number">3</span>) # 产生一个[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>]的ndarray<br><span class="hljs-attribute">np</span>.random.shuffle(nd2) # 随机打乱nd2中的数据。<br><span class="hljs-attribute">nd3</span> = np.random.uniform(<span class="hljs-number">2</span>,<span class="hljs-number">3</span>) # 生成均匀分布的随机数<br><span class="hljs-attribute">nd4</span> = np.random.randn(<span class="hljs-number">2</span>,<span class="hljs-number">3</span>) # 生成标准正态分布的随机数 <br><span class="hljs-attribute">nd5</span> = np.random.randint(<span class="hljs-number">2</span>,<span class="hljs-number">3</span>) # 生成随机的整数<br></code></pre></td></tr></table></figure></li><li><p>numpy中创建特定形状的多维数组</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> numpy as np<br><br><span class="hljs-attribute">nd1</span> = np.zeros([<span class="hljs-number">3</span>,<span class="hljs-number">3</span>]) # 生成全是<span class="hljs-number">0</span>的<span class="hljs-number">3</span>x3的矩阵，np.zeros()生成全是<span class="hljs-number">0</span>的ndarray<br><span class="hljs-attribute">nd2</span> = np.zeros_like(nd1) # 以ndrr相同维度创建元素为<span class="hljs-number">0</span>的数组<br><span class="hljs-attribute">nd3</span> = np.ones_like(nd1) # 以nd1维度创建元素全是<span class="hljs-number">1</span>的数组<br><span class="hljs-attribute">nd4</span> = np.empty_like(nd1) # 以nd1维度创建一个空数组<br><span class="hljs-attribute">nd5</span> = np.eye(<span class="hljs-number">5</span>) # 该函数用于创建一个<span class="hljs-number">5</span>x5的矩阵，对角线为<span class="hljs-number">1</span>，其余为<span class="hljs-number">0</span><br><span class="hljs-attribute">nd6</span> = np.full((<span class="hljs-number">3</span>,<span class="hljs-number">5</span>),<span class="hljs-number">666</span>) # 创建<span class="hljs-number">3</span>x5的元素全为<span class="hljs-number">666</span>的数组，<span class="hljs-number">666</span>为指定值<br></code></pre></td></tr></table></figure></li><li><p>保存使用numpy生成的数据</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">import numpy <span class="hljs-keyword">as</span> np<br>nd = np.<span class="hljs-built_in">random</span>.<span class="hljs-built_in">random</span>([<span class="hljs-number">5</span>,<span class="hljs-number">5</span>])<br>np.savetxt(X=nd,fname=<span class="hljs-string">&#x27;test.txt&#x27;</span>) <span class="hljs-comment"># 保存nd，文件名称为test.txt</span><br>nd2 = np.loadtxt(<span class="hljs-string">&#x27;test.txt&#x27;</span>) <span class="hljs-comment"># 从test.txt中加载数据</span><br></code></pre></td></tr></table></figure></li><li><p>利用arange、linspace函数来生成数组<br>arange是numpy模块中的函数，格式为：<code>arange([start],stop[,step],dtype=None)</code><br>其中start与stop用来限定范围，step是步长默认为1，step可以为小数。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> numpy as np<br><span class="hljs-attribute">nd</span> = np.arange(<span class="hljs-number">10</span>) # np中的内容为[<span class="hljs-number">0</span> <span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span> <span class="hljs-number">4</span> <span class="hljs-number">5</span> <span class="hljs-number">6</span> <span class="hljs-number">7</span> <span class="hljs-number">8</span> <span class="hljs-number">9</span>]<br><span class="hljs-attribute">nd1</span> = np.arange(<span class="hljs-number">1</span>，<span class="hljs-number">4</span>，<span class="hljs-number">0</span>.<span class="hljs-number">5</span>) # np中的内容为[<span class="hljs-number">1</span>.<span class="hljs-number">0</span> <span class="hljs-number">1</span>.<span class="hljs-number">5</span> <span class="hljs-number">2</span>.<span class="hljs-number">0</span> <span class="hljs-number">2</span>.<span class="hljs-number">5</span> <span class="hljs-number">3</span>.<span class="hljs-number">0</span> <span class="hljs-number">3</span>.<span class="hljs-number">5</span> <span class="hljs-number">4</span>.<span class="hljs-number">0</span>]<br><span class="hljs-attribute">nd2</span> = np.aramge(<span class="hljs-number">9</span>,-<span class="hljs-number">1</span>,-<span class="hljs-number">1</span>) # nd2中的内容为[<span class="hljs-number">9</span> <span class="hljs-number">8</span> <span class="hljs-number">7</span> <span class="hljs-number">6</span> <span class="hljs-number">5</span> <span class="hljs-number">4</span> <span class="hljs-number">3</span> <span class="hljs-number">2</span> <span class="hljs-number">1</span> <span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure><p>linspace也是numpy中常用的函数，格式为：<code>np.linspace(start,stop,num=50,endpoint=True,retstep=False,dtype=None)</code><br>linspace可以根据输入数据的指定范围以及等份数量，自动生成线性分量。endpoint（包含终点）默认为True。等分量num默认为50，如果将retstep设置为True，则会返回一个带步长的ndarray</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> numpy as np<br><span class="hljs-attribute">print</span>(np.linspace(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">10</span>)) # 产生<span class="hljs-number">10</span>个数，间隔为<span class="hljs-number">0</span>.<span class="hljs-number">111111</span> <br></code></pre></td></tr></table></figure></li><li><p>获取数据。<br>数据生成后，如何读取数据，常用数据的的方法。（类似于python数据切片的方法）</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> numpy as np<br><span class="hljs-attribute">np</span>.random.seed(<span class="hljs-number">2024</span>)<br><span class="hljs-attribute">nd</span> = np.random.random([<span class="hljs-number">10</span>]) # 产生一维的<span class="hljs-number">10</span>个数据点<br><span class="hljs-attribute">nd</span>[<span class="hljs-number">3</span>]  # 获取指定位置的数据，获取第<span class="hljs-number">4</span>个元素<br><span class="hljs-attribute">nd</span>[<span class="hljs-number">3</span>:<span class="hljs-number">6</span>] # 截取一段数据<br><span class="hljs-attribute">nd</span>[<span class="hljs-number">1</span>:<span class="hljs-number">6</span>:<span class="hljs-number">2</span>] # 获取固定间隔的数据<br><span class="hljs-attribute">nd</span>[::-<span class="hljs-number">2</span>] # 倒序取数<br><span class="hljs-attribute">nd2</span> = np.arange(<span class="hljs-number">25</span>).reshape([<span class="hljs-number">5</span>,<span class="hljs-number">5</span>]) # 产生一个<span class="hljs-number">25</span>个数据点的一维数据，而后通过reshape进行形状重整为[<span class="hljs-number">5</span>,<span class="hljs-number">5</span>]<br><span class="hljs-attribute">nd2</span>[:,<span class="hljs-number">1</span>:<span class="hljs-number">3</span>] # 截取多维数组中，指定的列，读取第<span class="hljs-number">2</span>，<span class="hljs-number">3</span>列。<br></code></pre></td></tr></table></figure></li><li><p>Numpy的算术运算<br>在机器学习和深度学习中，涉及大量的数组或矩阵运算，这里介绍两种常用的运算。一种是对应元素相乘，又称逐元乘法（Element-Wisr Product）运算符为np.multiply()或*。一种是点积或内积元素，运算符为np.dot()</p></li></ol><p>逐元乘法</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">a</span> = np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>],[-<span class="hljs-number">1</span>,<span class="hljs-number">4</span>]])<br><span class="hljs-attribute">b</span> = np.array([[<span class="hljs-number">2</span>,<span class="hljs-number">0</span>],[<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]])<br><span class="hljs-attribute">a</span>*b<br><br><span class="hljs-comment"># 结果为array([2,0],[-3,16]) , 运算过程为 1*2 = 2， 2*0 = 0 ， -1*3 = -3， 4*4 =16</span><br><span class="hljs-comment"># 另外一种写法，np.multiply(a,b) 结果和上面一样</span><br><span class="hljs-comment"># Numpy数组不仅可以和数组进行对应元素相乘，还可以和单一数值（或称为标量）来进行运算</span><br></code></pre></td></tr></table></figure><p>点积运算（Dot Product）又可以称为内积，在Numpy用np.dot表示</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs lua">X1 = np.array(<span class="hljs-string">[[1,2],[3,4]]</span>)<br>X2 = np.array(<span class="hljs-string">[[5,6,7],[8,9,10]]</span>)<br>X3 = np.dot(X1,X2)<br><span class="hljs-built_in">print</span>(X3)<br># 结果为<span class="hljs-string">[[21,24,27],[47,54,61]]</span><br># 运算方法，<span class="hljs-number">1</span>*<span class="hljs-number">5</span>+<span class="hljs-number">2</span>*<span class="hljs-number">8</span> = <span class="hljs-number">21</span>, <span class="hljs-number">1</span>*<span class="hljs-number">6</span> + <span class="hljs-number">2</span>*<span class="hljs-number">9</span>=<span class="hljs-number">24</span>, <span class="hljs-number">1</span>*<span class="hljs-number">7</span>+<span class="hljs-number">2</span>*<span class="hljs-number">7</span>=<span class="hljs-number">27</span> <br># <span class="hljs-number">3</span>*<span class="hljs-number">5</span>+<span class="hljs-number">4</span>*<span class="hljs-number">8</span> = <span class="hljs-number">47</span>,<span class="hljs-number">3</span>*<span class="hljs-number">6</span>+<span class="hljs-number">4</span>*<span class="hljs-number">9</span>=<span class="hljs-number">54</span>, <span class="hljs-number">3</span>*<span class="hljs-number">7</span>+<span class="hljs-number">4</span>*<span class="hljs-number">10</span>=<span class="hljs-number">61</span><br></code></pre></td></tr></table></figure><ol start="8"><li>数组变形<br>在机器学习和深度学习任务中，通常需要将处理好的数据以模型能够接收的格式进行输入，然后进行一系列运算，最终返回一个处理结果。然而由于不同模型所接受的输入格式不一样，往往需要先对其进行一系列变形和运算，从而将数据处理成符合模型要求的格式。<br>更改数组的形状。方法有<figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs tap"><span class="hljs-comment"># arr.reshape(),将向量arr维度进行改变，不修改向量本身</span><br><span class="hljs-comment"># arr.resize(), 重新将向量arr维度进行改变，修改向量本身</span><br><span class="hljs-comment"># arr.T ,对向量进行转置</span><br><span class="hljs-comment"># arr.ravel ，对向量arr进行展平，即将多维数组变成1维数组，不会产生原数组的副本</span><br><span class="hljs-comment"># arr.flatten，对向量arr进行展平，即将多维数值变成1维数组，返回原数组的副本</span><br><span class="hljs-comment"># arr.squeeze(), 只能对维度为1的进行降维。对多维数组使用时不会进行任何报错，但是不会产生任何影响</span><br><span class="hljs-comment"># arr.transpose，对高维矩阵进行轴转换</span><br>import numpy as np<br><br>arr = np.arange(10)<br>print(arr.reshape(2,5))<br><span class="hljs-comment"># 指定维度时可以只指定行数和列数，其他用-1代替</span><br>print(arr.reshape([5,-1]))<br>print(arr)<br>print(arr.reshape([-1,5]))<br><br><span class="hljs-comment">#结果[[0 1 2 3 4]</span><br> [5<span class="hljs-number"> 6 </span>7<span class="hljs-number"> 8 </span>9]]<br>[[0 1]<br> [2 3]<br> [4 5]<br> [6 7]<br> [8 9]]<br>arr [0<span class="hljs-number"> 1 </span>2<span class="hljs-number"> 3 </span>4<span class="hljs-number"> 5 </span>6<span class="hljs-number"> 7 </span>8 9] <span class="hljs-comment"># 没有对arr本身进行修改</span><br>[[0<span class="hljs-number"> 1 </span>2<span class="hljs-number"> 3 </span>4]<br> [5<span class="hljs-number"> 6 </span>7<span class="hljs-number"> 8 </span>9]]<br></code></pre></td></tr></table></figure></li></ol><p>使用resize来修改向量维度，</p><figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs coffeescript"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>arr = np.arange(<span class="hljs-number">10</span>)<br><span class="hljs-built_in">print</span>(arr)<br>arr.resize(<span class="hljs-number">2</span>,<span class="hljs-number">5</span>) <span class="hljs-comment"># 直接对向量修改，不像arr.reshape没有对向量进行修改。</span><br><span class="hljs-built_in">print</span>(arr)<br></code></pre></td></tr></table></figure><p>向量转置 ,T</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs stylus">import numpy as np<br><br>arr = np<span class="hljs-selector-class">.arange</span>(<span class="hljs-number">12</span>)<span class="hljs-selector-class">.reshape</span>(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>)#注这里重新进行赋值了，reshape保存了下来<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(arr)</span></span><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(arr.T)</span></span><br></code></pre></td></tr></table></figure><p>向量展平.ravel</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs stylus">import numpy as np<br>arr = np<span class="hljs-selector-class">.arange</span>(<span class="hljs-number">6</span>)<span class="hljs-selector-class">.reshape</span>(<span class="hljs-number">2</span>,-<span class="hljs-number">1</span>)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(arr)</span></span><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-string">&#x27;按照列优先，展平&#x27;</span>)</span></span><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(arr.ravel(<span class="hljs-string">&#x27;F&#x27;</span>)</span></span>)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-string">&#x27;按照行优先，展平&#x27;</span>)</span></span><br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(arr.ravel()</span></span>)<br></code></pre></td></tr></table></figure><p>矩阵转换为向量，这种需求经常出现在卷积神经网络与全连接之间，用于数据的展平,flatten</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs maxima">import numpy as <span class="hljs-built_in">np</span><br>a = <span class="hljs-built_in">np</span>.<span class="hljs-built_in">floor</span>(<span class="hljs-number">10</span>*<span class="hljs-built_in">np</span>.<span class="hljs-built_in">random</span>.<span class="hljs-built_in">random</span>(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>))<br><span class="hljs-built_in">print</span>(a)<br><span class="hljs-built_in">print</span>(a.<span class="hljs-built_in">flatten</span>()) # 需要注意的是一些方法是直接对向量进行修改，一些没有对向量进行修改，这点需要注意。<br></code></pre></td></tr></table></figure><p>降维操作，我也是经常使用的一个方法，squeeze 主要用来降维，把矩阵中含有1的维度去掉，在pytorch中还有一种与之相反的一种操作，torch.unsqueeze()</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> numpy as np<br><span class="hljs-attribute">arr</span> =np.arange(<span class="hljs-number">3</span>).reshape(<span class="hljs-number">3</span>,<span class="hljs-number">1</span>)<br><span class="hljs-attribute">print</span>(arr.shape) # <span class="hljs-number">3</span>,<span class="hljs-number">1</span><br><span class="hljs-attribute">print</span>(arr.squeeze().shape) # (<span class="hljs-number">3</span>,)<br><span class="hljs-attribute">arr1</span> = np.arange(<span class="hljs-number">6</span>).reshpe(<span class="hljs-number">3</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)<br><span class="hljs-attribute">print</span>(arr1.shape) # (<span class="hljs-number">3</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)<br><span class="hljs-attribute">print</span>(arr1.squeeze().shape) #(<span class="hljs-number">3</span>,<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><p>高维转换，transpose，这个在深度学习中经常使用，比如把RGB转换为GBR</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> numpy as np<br><span class="hljs-attribute">arr</span> = np.arange(<span class="hljs-number">24</span>).reshape(<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>)<br><span class="hljs-attribute">print</span>(arr.shape) # (<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>) 注意这里为什么shape不用加括号，因为shape是一个np的属性，而不是方法。在构建一个class时，有属性和方法的区别，这里挖个坑<br><span class="hljs-attribute">print</span>(arr.transpose().shape) # (<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><ol start="9"><li>合并数组<figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs maxima"># <span class="hljs-built_in">np</span>.<span class="hljs-built_in">append</span> ,内存占用大<br># <span class="hljs-built_in">np</span>.concatenate 没有内存占用问题<br># <span class="hljs-built_in">np</span>.stack, 沿着新的轴加入一系列数组<br># <span class="hljs-built_in">np</span>.hstack ，堆栈数组垂直顺序（行）<br># <span class="hljs-built_in">np</span>.vstack ,堆栈数组垂直顺序（列）<br># 对于<span class="hljs-built_in">append</span> 和concatenate ，待合并的数组必须有相同的行数或列数（满足一个即可）<br></code></pre></td></tr></table></figure></li></ol><p>append合并一维数组</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs stylus">import numpy as np<br><span class="hljs-selector-tag">a</span> = np<span class="hljs-selector-class">.array</span>(<span class="hljs-selector-attr">[1,2,3]</span>)<br><span class="hljs-selector-tag">b</span> = np<span class="hljs-selector-class">.array</span>(<span class="hljs-selector-attr">[4,5,6]</span>)<br>c = np<span class="hljs-selector-class">.append</span>(<span class="hljs-selector-tag">a</span>,b)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(c)</span></span><br></code></pre></td></tr></table></figure><p>合并多维数组</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs routeros">import numpy as np<br>a = np.arange(4).reshape(2,2)<br>b = np.arange(4).reshape(2,2)<br>c = np.append(a,b,<span class="hljs-attribute">axis</span>=0)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;按行合并后的结果&#x27;</span>)<br><span class="hljs-built_in">print</span>(c)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;合并后数据维度&#x27;</span>，c.shape) <br><span class="hljs-comment"># 按例合并</span><br>d = np.append(a,b,<span class="hljs-attribute">axis</span>=1)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;按列进行合并&#x27;</span>)<br><span class="hljs-built_in">print</span>(d)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;合并后的数据维度&#x27;</span>,d.shape)<br></code></pre></td></tr></table></figure><p>concatenate沿指定轴连接数组或矩阵</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs stylus">import numpy as np<br><span class="hljs-selector-tag">a</span> = np<span class="hljs-selector-class">.array</span>(<span class="hljs-selector-attr">[[1,2]</span>,<span class="hljs-selector-attr">[3,4]</span>])<br><span class="hljs-selector-tag">b</span> = np<span class="hljs-selector-class">.array</span>(<span class="hljs-selector-attr">[5,6]</span>)<br>c = np<span class="hljs-selector-class">.concatenate</span>((<span class="hljs-selector-tag">a</span>,b),axis=<span class="hljs-number">0</span>)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(c)</span></span><br>d = np<span class="hljs-selector-class">.concatenate</span>((<span class="hljs-selector-tag">a</span>,<span class="hljs-selector-tag">b</span>.T),axis=<span class="hljs-number">1</span>)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(d)</span></span><br></code></pre></td></tr></table></figure><p>stack 沿着固定轴堆积或矩阵</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs lua">import numpy as np<br>a = np.array(<span class="hljs-string">[[1,2],[3,4]]</span>)<br>b = np.array(<span class="hljs-string">[[5,6],[7,8]]</span>)<br><span class="hljs-built_in">print</span>(np.stack((a,b),axis=<span class="hljs-number">0</span>))<br></code></pre></td></tr></table></figure><ol start="11"><li><p>通用函数<br>sqrt ,计算序列化数据的平方根<br>sin,cos 三角函数<br>abs ， 计算序列化数据的绝对值<br>dot， 矩阵运算<br>log,log10,log2， 对数函数<br>exp, 指数函数<br>cumsum,cumproduct , 累计求和，求积<br>sum ,对一个序列化数据进行求和<br>mean ， 计算均值<br>median ，计算中位数<br>std , 计算标准差<br>var ， 计算方差</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs stylus">import <span class="hljs-selector-tag">time</span> <br>import math<br>import numpy as np<br><br>x = <span class="hljs-selector-attr">[i * 0.001 for i in np.arange(1000000)]</span><br>start = <span class="hljs-selector-tag">time</span><span class="hljs-selector-class">.clock</span>()<br><span class="hljs-keyword">for</span> <span class="hljs-selector-tag">i</span> , t <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(x):<br>    x<span class="hljs-selector-attr">[i]</span> = math<span class="hljs-selector-class">.sin</span>(t)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-string">&#x27;math.sin:&#x27;</span>,time.clock()</span></span>-start)<br><br>x = <span class="hljs-selector-attr">[i*0.001 for i in np.arange(100000)]</span><br>x = np<span class="hljs-selector-class">.array</span>(x)<br>start =<span class="hljs-selector-tag">time</span><span class="hljs-selector-class">.clock</span>()<br>np<span class="hljs-selector-class">.sin</span>(x)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-string">&#x27;numpy.sin:&#x27;</span>,time.clock()</span></span>-start)<br></code></pre></td></tr></table></figure></li><li><p>广播机制<br>Numpy 中的Universal functional 中要求输入的数组shape是一致的，当数组的shape不相等时，则会使用广播机制。但是使用广播机制需要满足一定的规则，否则将出错。<br>1） 让所有输入数组都向其中的shape最长的数组看齐，不足的部分则通过在前面加1补齐。<br>2） 输出数组的shape是输出数组shape的各个轴上的最大值</p></li></ol><ol start="3"><li>如果输入数组的某个轴和输出数组的对于长度相同或者某个轴的长度为1时，这个数组能被用来计算，否则出错<br>4） 当输入数组的某个轴的长度为1时，沿着此轴运算时都用（或复制）此轴上的第一组值。</li></ol><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs stylus">import numpy as np<br>A  = np<span class="hljs-selector-class">.arange</span>(<span class="hljs-number">0</span>,<span class="hljs-number">40</span>,<span class="hljs-number">10</span>)<span class="hljs-selector-class">.reshape</span>(<span class="hljs-number">4</span>,<span class="hljs-number">1</span>)<br>B = np<span class="hljs-selector-class">.arange</span>(<span class="hljs-number">0</span>,<span class="hljs-number">3</span>)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-string">&#x27;A矩阵的形状:&#123;&#125;,B矩阵的形状：&#123;&#125;&#x27;</span>.format(A.shape,B.shape)</span></span>)<br>C = A + B<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(<span class="hljs-string">&#x27;C矩阵的形状：&#123;&#125;&#x27;</span>.format(C.shape)</span></span>)<br><span class="hljs-function"><span class="hljs-title">print</span><span class="hljs-params">(C)</span></span><br></code></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Numpy是深度学习的入门库，学习是很重要的。这里只是列举了一些主要内容，如果想要了解更多的内容，可以登录Numpy官网（<a href="http://www.numpy.org/%EF%BC%89%E6%9F%A5%E7%9C%8B%E6%9B%B4%E5%A4%9A%E7%9A%84%E5%86%85%E5%AE%B9%E3%80%82">http://www.Numpy.org/）查看更多的内容。</a></p><h2 id="挖坑"><a href="#挖坑" class="headerlink" title="挖坑"></a>挖坑</h2><h3 id="向量和数组之间的关系是什么？向量的定义是什么？"><a href="#向量和数组之间的关系是什么？向量的定义是什么？" class="headerlink" title="向量和数组之间的关系是什么？向量的定义是什么？"></a>向量和数组之间的关系是什么？向量的定义是什么？</h3><p>在数学科物理中，向量被定义为具有大小和方向量。例如速度是一个向量，因为它不仅有大小（数独），还有方向（行进的方向）。<br>数组是编程中的一种基本数据结构，用于存储一组有序的元素。这些元素可以是任何类型，如整形、浮点数、字符串等。<br>标量（scalar）是零维只有大小，没有方向的量，如1，2，3<br>向量（Vector）是一维只有大小和方向的量，如（1，2）。（计算方向的公式为：）<br>矩阵（Matrix）是二维的向量，[[1, 2], [2, 3]]<br>张量（Tensor） 按照任意维排列的一堆数字的推广。矩阵不过是三维张量下的一个二维切面。要在三维张量下找到零维张量需要三个维度的坐标来定位。（注：张量可以是多维的）</p><h3 id="矩阵是什么，作用是什么？如何实现矩阵的加减乘除"><a href="#矩阵是什么，作用是什么？如何实现矩阵的加减乘除" class="headerlink" title="矩阵是什么，作用是什么？如何实现矩阵的加减乘除"></a>矩阵是什么，作用是什么？如何实现矩阵的加减乘除</h3><ol><li>矩阵是一个二维数组，由行和列的元素组成。在数学中，矩阵通常用大写字母表示，如 A，B 等，矩阵中的元素通常用小写字母表示，如aij​，表示矩阵 A 的第 i 行第 j 列的元素。</li><li>矩阵可以用来表示线性变换，解决线性方程组，或者表示图形的变换。在数据科学和机器学习中，矩阵通常用于存储和操作大量的数据。</li></ol><h4 id="实现矩阵的加减乘除。"><a href="#实现矩阵的加减乘除。" class="headerlink" title="实现矩阵的加减乘除。"></a>实现矩阵的加减乘除。</h4><p>加法：两个矩阵相加，只有在它们的行数和列数都相等时才是定义的。结果矩阵的每个元素是相应的元素相加的结果。例如，如果A &#x3D; aij 和B &#x3D; bij 是同样大小的矩阵，那么它们的和C &#x3D; [ cij ]是矩阵 ,其中cij &#x3D; aij + bij。对应相加<br>减法：矩阵的减法与加法类似，只有在两个矩阵的行数和列数都相等时才是定义的。结果矩阵的每个元素是相应的元素相减的结果。<br>乘法：矩阵的乘法比较复杂。如果A 是一个 m×n 的矩阵，B 是一个n×p 的矩阵，那么它们的乘积 AB 是一个 m×p 的矩阵，其元素由A 的行和 B 的列的对应元素的乘积之和给出。<br>除法：在矩阵中，通常不直接定义除法。但是，我们可以通过乘以逆矩阵来实现类似的效果。如果A是一个可逆的（也就是说，存在一个矩阵 （A-1）使得，A（A-1） &#x3D; （A-1）A &#x3D; I其中 𝐼I 是单位矩阵），那么我们可以定义B&#x2F;A为（BA-1），即是B矩阵除以A矩阵等于B乘以A矩阵的转置。但是，请注意，不是所有的矩阵都是可逆的。 </p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs makefile">import numpy as np<br><br><span class="hljs-comment"># 创建两个矩阵</span><br>A = np.array([[1, 2], [3, 4]])<br>B = np.array([[5, 6], [7, 8]])<br><br><span class="hljs-comment"># 矩阵加法</span><br>C = A + B<br><br><span class="hljs-comment"># 矩阵减法</span><br>D = A - B<br><br><span class="hljs-comment"># 矩阵乘法</span><br>E = np.dot(A, B)<br><br><span class="hljs-comment"># 矩阵除法（通过乘以逆矩阵）</span><br>F = np.dot(A, np.linalg.inv(B)) <br><br></code></pre></td></tr></table></figure><h3 id="傅里叶变换是什么？原理是这样的，怎么实现？（这里开一个新坑，数字信号处理）"><a href="#傅里叶变换是什么？原理是这样的，怎么实现？（这里开一个新坑，数字信号处理）" class="headerlink" title="傅里叶变换是什么？原理是这样的，怎么实现？（这里开一个新坑，数字信号处理）"></a>傅里叶变换是什么？原理是这样的，怎么实现？（这里开一个新坑，数字信号处理）</h3><h4 id="基本介绍。"><a href="#基本介绍。" class="headerlink" title="基本介绍。"></a>基本介绍。</h4><p>傅里叶变换是一种在数学、物理和工程中广泛使用的数学变换，它可以将一个函数或信号从其原始的时间或空间表示转换为频率表示。这对于许多应用都非常有用，因为它可以揭示信号的频率成分，这在原始的时间或空间表示中可能不明显。<br>傅里叶变换的基本思想是，任何函数都可以表示为一系列正弦波和余弦波的叠加。换句话说，我们可以将一个复杂的信号分解为一系列更简单的正弦波和余弦波。</p><h4 id="原理介绍"><a href="#原理介绍" class="headerlink" title="原理介绍"></a>原理介绍</h4><p>傅里叶变换的基本原理是将一个函数或信号从其原始的时间或空间表示转换为频率表示。这是通过将函数表示为一系列正弦波和余弦波的叠加来实现的。<br><img src="/pic/fly1.jpg" alt="傅里叶变换示意图"></p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> numpy as np<br><span class="hljs-attribute">import</span> matplotlib.pyplot as plt<br><br><span class="hljs-comment"># 创建一个简单的信号</span><br><span class="hljs-attribute">t</span> = np.linspace(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">500</span>)<br><span class="hljs-attribute">f</span> = np.sin(<span class="hljs-number">2</span> * np.pi * <span class="hljs-number">50</span> * t) + <span class="hljs-number">0</span>.<span class="hljs-number">5</span> * np.sin(<span class="hljs-number">2</span> * np.pi * <span class="hljs-number">120</span> * t)<br><br><span class="hljs-comment"># 绘制原始信号</span><br><span class="hljs-attribute">plt</span>.figure(figsize=(<span class="hljs-number">12</span>, <span class="hljs-number">6</span>))<br><br><span class="hljs-attribute">plt</span>.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br><span class="hljs-attribute">plt</span>.plot(t, f)<br><span class="hljs-attribute">plt</span>.title(&#x27;Original Signal&#x27;)<br><span class="hljs-attribute">plt</span>.xlabel(&#x27;Time&#x27;)<br><span class="hljs-attribute">plt</span>.ylabel(&#x27;Amplitude&#x27;)<br><br><span class="hljs-comment"># 计算傅里叶变换</span><br><span class="hljs-attribute">F</span> = np.fft.fft(f)<br><br><span class="hljs-comment"># 计算频率</span><br><span class="hljs-attribute">freq</span> = np.fft.fftfreq(t.shape[-<span class="hljs-number">1</span>])<br><br><span class="hljs-comment"># 绘制频谱</span><br><span class="hljs-attribute">plt</span>.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br><span class="hljs-attribute">plt</span>.plot(freq, np.abs(F))<br><span class="hljs-attribute">plt</span>.title(&#x27;Frequency Spectrum&#x27;)<br><span class="hljs-attribute">plt</span>.xlabel(&#x27;Frequency&#x27;)<br><span class="hljs-attribute">plt</span>.ylabel(&#x27;Magnitude&#x27;)<br><br><span class="hljs-attribute">plt</span>.tight_layout()<br><span class="hljs-attribute">plt</span>.show()<br><br></code></pre></td></tr></table></figure><h3 id="什么是对象？-封装，继承，多态是什么？"><a href="#什么是对象？-封装，继承，多态是什么？" class="headerlink" title="什么是对象？ 封装，继承，多态是什么？"></a>什么是对象？ 封装，继承，多态是什么？</h3><p>什么是对象？<br>在面向对象编程（Object-Oriented Programming，OOP）中，对象是类的实例。类是一种抽象的概念，用于描述具有相似属性和行为的对象的集合。对象是类的具体实现，它具有类定义的属性和方法。<br>对象可以看作是现实世界中的实体或概念在程序中的表示。每个对象都有自己的状态（属性）和行为（方法），并且可以与其他对象进行交互。</p><p>封装<br>封装是面向对象编程的一种重要概念，它将数据和操作数据的方法捆绑在一起，形成一个称为类的单个实体。封装隐藏了数据的内部实现细节，只暴露对外部可见的接口。这样可以保护数据的完整性，并提供更好的代码组织和维护性。<br>通过封装，对象的内部状态可以被保护起来，只能通过公共接口进行访问和修改。这样可以防止对数据的不合理访问和修改，增加了代码的安全性和可靠性。</p><p>继承<br>继承是面向对象编程中的另一个重要概念，它允许一个类继承另一个类的属性和方法。继承创建了一个类的层次结构，其中一个类（称为子类或派生类）可以从另一个类（称为父类或基类）继承属性和方法。<br>通过继承，子类可以继承父类的特性，并且可以添加自己的特定特性。这样可以实现代码的重用和扩展，减少了重复编写代码的工作量。</p><p>多态<br>多态是面向对象编程中的另一个重要概念，它允许使用统一的接口来处理不同的对象类型。多态性允许同一个方法在不同的对象上产生不同的行为。<br>通过多态，可以编写通用的代码，可以处理多个不同类型的对象，而无需针对每种类型编写特定的代码。这提高了代码的灵活性和可扩展性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 封装示例</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Car</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, brand, model</span>):<br>        self.brand = brand<br>        self.model = model<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">display_info</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Car: <span class="hljs-subst">&#123;self.brand&#125;</span> <span class="hljs-subst">&#123;self.model&#125;</span>&quot;</span>)<br><br><span class="hljs-comment"># 创建一个 Car 对象并访问其信息</span><br>my_car = Car(<span class="hljs-string">&quot;Toyota&quot;</span>, <span class="hljs-string">&quot;Corolla&quot;</span>)<br>my_car.display_info()<br><br><span class="hljs-comment"># 继承示例</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ElectricCar</span>(<span class="hljs-title class_ inherited__">Car</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, brand, model, battery_capacity</span>):<br>        <span class="hljs-built_in">super</span>().__init__(brand, model)<br>        self.battery_capacity = battery_capacity<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">display_info</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Electric Car: <span class="hljs-subst">&#123;self.brand&#125;</span> <span class="hljs-subst">&#123;self.model&#125;</span>, Battery Capacity: <span class="hljs-subst">&#123;self.battery_capacity&#125;</span> kWh&quot;</span>)<br><br><span class="hljs-comment"># 创建一个 ElectricCar 对象并访问其信息</span><br>my_electric_car = ElectricCar(<span class="hljs-string">&quot;Tesla&quot;</span>, <span class="hljs-string">&quot;Model S&quot;</span>, <span class="hljs-number">100</span>)<br>my_electric_car.display_info()<br><br><span class="hljs-comment"># 多态示例</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">show_car_info</span>(<span class="hljs-params">car</span>):<br>    car.display_info()<br><br><span class="hljs-comment"># 使用 show_car_info 函数展示不同类型的车辆信息</span><br>show_car_info(my_car)<br>show_car_info(my_electric_car)<br><br></code></pre></td></tr></table></figure><h3 id="python中的不同代码高亮表示什么？"><a href="#python中的不同代码高亮表示什么？" class="headerlink" title="python中的不同代码高亮表示什么？"></a>python中的不同代码高亮表示什么？</h3><p>在Python的IDLE编程环境中，不同颜色的文本表示不同的含义。以下是IDLE中常见的颜色及其含义：<br>黑色：普通的代码文本。<br>蓝色：关键字，例如if、else、for、while等。<br>绿色：字符串文本。<br>红色：语法错误或代码中的错误。<br>紫色：函数和方法的名称。<br>棕色：数字。<br>橙色：内置函数和模块的名称。<br>灰色：注释。</p><h3 id="怎么对通道数位置的npy数据进行叠加"><a href="#怎么对通道数位置的npy数据进行叠加" class="headerlink" title="怎么对通道数位置的npy数据进行叠加"></a>怎么对通道数位置的npy数据进行叠加</h3><p>思路分析，<br>x &#x3D; np.array([1 ,  2]) # shape为(1,2)<br>y &#x3D; np.array([3 ,  4]) # shape为(1,2)<br>怎么叠加np为[[1 , 2],[3 ,4]] #shape为(2,2)</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> numpy as np<br><br><span class="hljs-attribute">x</span> = np.array([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>])  # shape为(<span class="hljs-number">2</span>,)<br><span class="hljs-attribute">y</span> = np.array([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>])  # shape为(<span class="hljs-number">2</span>,)<br><br><span class="hljs-attribute">z</span> = np.vstack((x, y))  # 叠加x和y，得到z<br><span class="hljs-attribute">print</span>(z)  # 输出结果为[[<span class="hljs-number">1</span> <span class="hljs-number">2</span>]<br>          <span class="hljs-comment">#           [3 4]]</span><br><span class="hljs-attribute">print</span>(z.shape)  # 输出结果为(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br><br></code></pre></td></tr></table></figure><p>堆栈数组垂直顺序（行）</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">import</span> numpy as np<br><br><span class="hljs-attribute">x</span> = np.array([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>])  # shape为(<span class="hljs-number">2</span>,)<br><span class="hljs-attribute">y</span> = np.array([<span class="hljs-number">3</span>, <span class="hljs-number">4</span>])  # shape为(<span class="hljs-number">2</span>,)<br><br><span class="hljs-attribute">z</span> = np.hstack((x, y))  # 堆叠x和y，得到z<br><span class="hljs-attribute">print</span>(z)  # 输出结果为[<span class="hljs-number">1</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span> <span class="hljs-number">4</span>]<br><span class="hljs-attribute">print</span>(z.shape)  # 输出结果为(<span class="hljs-number">4</span>,)<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch介绍</title>
    <link href="/2024/04/19/deeplearnbook1/"/>
    <url>/2024/04/19/deeplearnbook1/</url>
    
    <content type="html"><![CDATA[<p>在深度学习，要永远抱着学徒的心。<br>本人参考书目为《Python深度学习基于PyTorch》 <a href="http://www.feiguyunai.com/">下载链接</a> <a href="https://github.com/Wumg3000/feiguyunai">使用下载链接——github</a></p><h1 id="目前深度学习的框架有什么？"><a href="#目前深度学习的框架有什么？" class="headerlink" title="目前深度学习的框架有什么？"></a>目前深度学习的框架有什么？</h1><ol><li>TensorFlow ：由Google开发的开源深度学习框架，提供了灵活性和高性能计算能力。TensorFlow 2.x版本引入了更加易用的Keras API作为主要接口。<a href="https://github.com/tensorflow/tensorflow">TensorFlow的github链接</a></li><li>PyTorch ：由Facebook开发的开源深度学习框架，以动态计算图的方式进行建模，易于调试和学习。PyTorch在研究领域广泛应用。<a href="https://github.com/pytorch/pytorch">PyTorch的github链接</a></li><li>Keras：最初作为独立的深度学习框架，现在已经成为TensorFlow的高级API。Keras提供了简单易用的接口，适合快速搭建深度学习模型。 <a href="https://github.com/keras-team/keras">Keras的github链接</a></li><li>MXNet：由Apache软件基金会支持的深度学习框架，具有高度可扩展性和灵活性。MXNet支持动态和静态计算图。[MXNet的github链接]（<a href="https://github.com/apache/mxnet%EF%BC%89">https://github.com/apache/mxnet）</a></li><li>CNTK (Microsoft Cognitive Toolkit)：由微软开发的深度学习框架，提供了高效的性能和多GPU支持。 <a href="https://github.com/microsoft/CNTK">CNTK的github链接</a></li><li>PaddlePaddle（百度飞桨）。这是一个由百度开发的开源深度学习平台，它为深度学习研究人员和开发者提供了丰富的API，支持多种模型结构，可以用来创建各种深度学习模型。[百度飞浆的链接]（<a href="https://www.paddlepaddle.org.cn/%EF%BC%89">https://www.paddlepaddle.org.cn/）</a></li></ol><h1 id="为什么要学习PyTorch？"><a href="#为什么要学习PyTorch？" class="headerlink" title="为什么要学习PyTorch？"></a>为什么要学习PyTorch？</h1><ol><li>pytorch是动态计算图，用法更接近python，并且pytoch与python共同使用了numpy的命令，降低了学习的门槛，比TensorFlow更容易上手</li><li>pytorch需要定义网络层、参数更新等关键步骤，有助于学习深度学习的核心（根据梯度更新参数。）</li><li>pytorch的流行仅次于TensorFlow。在github上的stareed为77.7K （此数据截止到2024&#x2F;4&#x2F;19日）</li><li>pytorch的动态图机制在调试方面非常简单，如果计算图运行出错，马上可以跟踪到问题。pytorch的调试和python一样，可以通过断点检查来解决问题。</li></ol><h1 id="解释一下这本书的结构"><a href="#解释一下这本书的结构" class="headerlink" title="解释一下这本书的结构"></a>解释一下这本书的结构</h1><ol><li>第一部分：介绍深度学习的基石Numpy，介绍PyTorch基础于pytorch构建神经网络的工具箱和数据处理工具。</li><li>第二部分：这本书的核心内容，包括机器学习的流程，常用算法和技巧等内容。实现了基于卷积神经网络的多个视觉处理实例，实现了多个自然语言处理、时间序列方面的实例。介绍了编码器——解码器模型、带注意力的编码器——解码器模型、对抗式生成器以及多种衍生生成器。（注：这里阐述一下关于深度学习、机器学习、人工智能之间的关系。人工智能包含机器学习，机器学习包含深度学习）</li><li>第三部分：实战部分，这部分在介绍相关原理、架构的基础上，使用了pytoch实现了多个深度学习典型实例，比如人脸识别、迁移学习、数据增强、中英文互译、生成式网络实例、模型迁移、强化学习、深度强化学习等实例。</li></ol><h2 id="挖坑"><a href="#挖坑" class="headerlink" title="挖坑"></a>挖坑</h2><h3 id="什么是python的断点检查？"><a href="#什么是python的断点检查？" class="headerlink" title="什么是python的断点检查？"></a>什么是python的断点检查？</h3><h3 id="什么是动态计算图？"><a href="#什么是动态计算图？" class="headerlink" title="什么是动态计算图？"></a>什么是动态计算图？</h3>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔7</title>
    <link href="/2024/04/19/ganwu7/"/>
    <url>/2024/04/19/ganwu7/</url>
    
    <content type="html"><![CDATA[<audio controls>  <source src="https://github.com/changjingzhi/changjingzhi.github.io/blob/master/pic/shueibi7.mp3" type="audio/mp3">  Your browser does not support the audio element.</audio># what is important in life？（生命中什么最重要？）<h3 id="Today-I-can’t-help-but-ask-myself-what-is-most-important-in-life-I-don’t-think-I-can-answer-the-question-because-I-don’t-know-how-to-answer-the-question-But-I-think-I-may-have-a-clue-to-this-problem-thinking-from-my-20-years-of-experience-I-often-worry-about-what-I-don’t-have-but-the-result-of-worrying-is-only-worrying-itself-which-does-nothing-to-change-the-status-quo-or-makes-the-result-worse-I-thought-I-needed-to-get-rid-of-this-worry-so-I-saw-death-I-saw-history-the-flow-of-the-past-the-men-I-have-learned-that-nothing-is-permanent-in-the-face-of-death-and-that-time-diminishes-everything-So-I-saw-the-past-the-future-in-the-past-regret-and-anxiety-about-the-future-saw-the-present-the-past-is-gone-the-future-future-instead-of-falling-into-the-past-regret-and-anxiety-about-the-future-why-not-change-a-mentality-to-spend-the-present-Life-has-no-meaning-instead-of-blindly-looking-for-the-meaning-of-the-castle-in-the-air-it-is-better-to-spend-the-present-with-gratitude-for-the-past-and-hope-for-the-future-Look-to-the-future-based-on-the-present-not-to-worry-about-the-future-the-future-is-not-to-worry-but-to-create-For-the-present-attitude-not-happy-with-things-not-sad-Lief-is-short-kiss-slowly-laugh-insanely-love-truly-and-forgive-quickly"><a href="#Today-I-can’t-help-but-ask-myself-what-is-most-important-in-life-I-don’t-think-I-can-answer-the-question-because-I-don’t-know-how-to-answer-the-question-But-I-think-I-may-have-a-clue-to-this-problem-thinking-from-my-20-years-of-experience-I-often-worry-about-what-I-don’t-have-but-the-result-of-worrying-is-only-worrying-itself-which-does-nothing-to-change-the-status-quo-or-makes-the-result-worse-I-thought-I-needed-to-get-rid-of-this-worry-so-I-saw-death-I-saw-history-the-flow-of-the-past-the-men-I-have-learned-that-nothing-is-permanent-in-the-face-of-death-and-that-time-diminishes-everything-So-I-saw-the-past-the-future-in-the-past-regret-and-anxiety-about-the-future-saw-the-present-the-past-is-gone-the-future-future-instead-of-falling-into-the-past-regret-and-anxiety-about-the-future-why-not-change-a-mentality-to-spend-the-present-Life-has-no-meaning-instead-of-blindly-looking-for-the-meaning-of-the-castle-in-the-air-it-is-better-to-spend-the-present-with-gratitude-for-the-past-and-hope-for-the-future-Look-to-the-future-based-on-the-present-not-to-worry-about-the-future-the-future-is-not-to-worry-but-to-create-For-the-present-attitude-not-happy-with-things-not-sad-Lief-is-short-kiss-slowly-laugh-insanely-love-truly-and-forgive-quickly" class="headerlink" title="Today, I can’t help but ask myself what is most important in life. I don’t think I can answer the question because I don’t know how to answer the question. But I think I may have a clue to this problem, thinking from my 20 years of experience, I often worry about what I don’t have, but the result of worrying is only worrying itself, which does nothing to change the status quo, or makes the result worse. I thought I needed to get rid of this worry, so I saw death, I saw history, the flow of the past, the men. I have learned that nothing is permanent in the face of death, and that time diminishes everything. So I saw the past, the future, in the past regret and anxiety about the future saw the present, the past is gone, the future future, instead of falling into the past regret and anxiety about the future, why not change a mentality to spend the present. Life has no meaning, instead of blindly looking for the meaning of the castle in the air, it is better to spend the present with gratitude for the past and hope for the future. Look to the future based on the present, not to worry about the future, the future is not to worry, but to create. For the present attitude, not happy with things, not sad. Lief is short, kiss slowly, laugh insanely, love truly and forgive quickly."></a>Today, I can’t help but ask myself what is most important in life. I don’t think I can answer the question because I don’t know how to answer the question. But I think I may have a clue to this problem, thinking from my 20 years of experience, I often worry about what I don’t have, but the result of worrying is only worrying itself, which does nothing to change the status quo, or makes the result worse. I thought I needed to get rid of this worry, so I saw death, I saw history, the flow of the past, the men. I have learned that nothing is permanent in the face of death, and that time diminishes everything. So I saw the past, the future, in the past regret and anxiety about the future saw the present, the past is gone, the future future, instead of falling into the past regret and anxiety about the future, why not change a mentality to spend the present. Life has no meaning, instead of blindly looking for the meaning of the castle in the air, it is better to spend the present with gratitude for the past and hope for the future. Look to the future based on the present, not to worry about the future, the future is not to worry, but to create. For the present attitude, not happy with things, not sad. Lief is short, kiss slowly, laugh insanely, love truly and forgive quickly.</h3><h3 id="今天，我情不自禁的问自己生命中什么最重要。我想我不能回答这个问题的答案，因为我不知道怎么去回答这个问题的答案。但是我想我或许有一点关于这个问题线索，从我20年中的经历来思考，我经常为自己所未拥有的事物所忧虑，但是忧虑的结果只能是忧虑本身，对现状没有一点改变，或者导致结果更坏。我想我需要摆脱这种忧虑，于是我看到了死亡，看到了历史，往事流转，风流人物。又有多少存在于世上，我学到了在死亡面前没有什么是永恒的，时间会冲淡一切。于是我看到了过去、未来，在对过去的悔恨和对未来的焦虑中看到了当下，过去已逝，未来未来，与其陷入对过去的悔恨中和对未来的焦虑中，为什么不换一个心态去度过当下。人生本来就没有意义，与其去一味的寻找那空中楼阁的意义，不如怀着对过去的感恩于对未来的期盼去度过当下。基于现状去展望明天，而不是去忧虑未来，未来不是是用来忧虑的，而是用来创造的。对于当下的态度，不以物喜，不以及悲，要发自内心的开心，发自内心的悲伤。既然生命如此短暂，那么慢慢地亲吻，尽情地欢笑，真心去爱，快快的原谅吧！"><a href="#今天，我情不自禁的问自己生命中什么最重要。我想我不能回答这个问题的答案，因为我不知道怎么去回答这个问题的答案。但是我想我或许有一点关于这个问题线索，从我20年中的经历来思考，我经常为自己所未拥有的事物所忧虑，但是忧虑的结果只能是忧虑本身，对现状没有一点改变，或者导致结果更坏。我想我需要摆脱这种忧虑，于是我看到了死亡，看到了历史，往事流转，风流人物。又有多少存在于世上，我学到了在死亡面前没有什么是永恒的，时间会冲淡一切。于是我看到了过去、未来，在对过去的悔恨和对未来的焦虑中看到了当下，过去已逝，未来未来，与其陷入对过去的悔恨中和对未来的焦虑中，为什么不换一个心态去度过当下。人生本来就没有意义，与其去一味的寻找那空中楼阁的意义，不如怀着对过去的感恩于对未来的期盼去度过当下。基于现状去展望明天，而不是去忧虑未来，未来不是是用来忧虑的，而是用来创造的。对于当下的态度，不以物喜，不以及悲，要发自内心的开心，发自内心的悲伤。既然生命如此短暂，那么慢慢地亲吻，尽情地欢笑，真心去爱，快快的原谅吧！" class="headerlink" title="今天，我情不自禁的问自己生命中什么最重要。我想我不能回答这个问题的答案，因为我不知道怎么去回答这个问题的答案。但是我想我或许有一点关于这个问题线索，从我20年中的经历来思考，我经常为自己所未拥有的事物所忧虑，但是忧虑的结果只能是忧虑本身，对现状没有一点改变，或者导致结果更坏。我想我需要摆脱这种忧虑，于是我看到了死亡，看到了历史，往事流转，风流人物。又有多少存在于世上，我学到了在死亡面前没有什么是永恒的，时间会冲淡一切。于是我看到了过去、未来，在对过去的悔恨和对未来的焦虑中看到了当下，过去已逝，未来未来，与其陷入对过去的悔恨中和对未来的焦虑中，为什么不换一个心态去度过当下。人生本来就没有意义，与其去一味的寻找那空中楼阁的意义，不如怀着对过去的感恩于对未来的期盼去度过当下。基于现状去展望明天，而不是去忧虑未来，未来不是是用来忧虑的，而是用来创造的。对于当下的态度，不以物喜，不以及悲，要发自内心的开心，发自内心的悲伤。既然生命如此短暂，那么慢慢地亲吻，尽情地欢笑，真心去爱，快快的原谅吧！"></a>今天，我情不自禁的问自己生命中什么最重要。我想我不能回答这个问题的答案，因为我不知道怎么去回答这个问题的答案。但是我想我或许有一点关于这个问题线索，从我20年中的经历来思考，我经常为自己所未拥有的事物所忧虑，但是忧虑的结果只能是忧虑本身，对现状没有一点改变，或者导致结果更坏。我想我需要摆脱这种忧虑，于是我看到了死亡，看到了历史，往事流转，风流人物。又有多少存在于世上，我学到了在死亡面前没有什么是永恒的，时间会冲淡一切。于是我看到了过去、未来，在对过去的悔恨和对未来的焦虑中看到了当下，过去已逝，未来未来，与其陷入对过去的悔恨中和对未来的焦虑中，为什么不换一个心态去度过当下。人生本来就没有意义，与其去一味的寻找那空中楼阁的意义，不如怀着对过去的感恩于对未来的期盼去度过当下。基于现状去展望明天，而不是去忧虑未来，未来不是是用来忧虑的，而是用来创造的。对于当下的态度，不以物喜，不以及悲，要发自内心的开心，发自内心的悲伤。既然生命如此短暂，那么慢慢地亲吻，尽情地欢笑，真心去爱，快快的原谅吧！</h3>]]></content>
    
    
    
    <tags>
      
      <tag>感悟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《诫子书》</title>
    <link href="/2024/04/18/jzs/"/>
    <url>/2024/04/18/jzs/</url>
    
    <content type="html"><![CDATA[<h1 id="诫子书"><a href="#诫子书" class="headerlink" title="诫子书"></a>诫子书</h1><h2 id="夫君子之行，静以修身，俭以养德。非淡泊无以明志，非宁静无以致远。夫学须静也，才须学也，非学无以广才，非志无以成学。淫慢则不能励精，险躁则不能治性。年与时驰，意与日去，遂成枯落，多不接世，悲守穷庐，将复何及。"><a href="#夫君子之行，静以修身，俭以养德。非淡泊无以明志，非宁静无以致远。夫学须静也，才须学也，非学无以广才，非志无以成学。淫慢则不能励精，险躁则不能治性。年与时驰，意与日去，遂成枯落，多不接世，悲守穷庐，将复何及。" class="headerlink" title="夫君子之行，静以修身，俭以养德。非淡泊无以明志，非宁静无以致远。夫学须静也，才须学也，非学无以广才，非志无以成学。淫慢则不能励精，险躁则不能治性。年与时驰，意与日去，遂成枯落，多不接世，悲守穷庐，将复何及。"></a>夫君子之行，静以修身，俭以养德。非淡泊无以明志，非宁静无以致远。夫学须静也，才须学也，非学无以广才，非志无以成学。淫慢则不能励精，险躁则不能治性。年与时驰，意与日去，遂成枯落，多不接世，悲守穷庐，将复何及。</h2><p>自注：从论语中我们可以得到，圣人的任务是将人不知的世界改造成人不愠的世界。而君子最开始是人不知的，从人不知的群体中诞生的，那么怎么才能从人不知的群体中成长为君子。我想戒子书中给出了一个思路。<br>第一要有志向，但是志向不是说凭空随便想一个就行了，它必须要基于自身条件实现的可能性，不然随便设立的志向即无实现的可能，也把自己的精力给浪费了。那么怎么才能有一个好的志向？在我面前看来，不要期许有什么好的志向，先把眼前要做的做好，基于现在，现实，充分认识到现实存在条件，然后一天天的打算，一天天的实现自己的打算，在实践的过程中不断深化自己做事的观点，想法，我想慢慢的根植于自己内心的想法就能变成志向，而且这个志向会更有实现的可能性。（认知来源于实践，理论指导实践。）<br>第二要对事情的实现减少期望感，为什么要这样说？首先我们讨论事情的实现。怎么才能实现一件事情？构成这件事的基本条件满足时，那么这件事情就已经实现了。比如吃饭，吃饭有人，要有饭，构成吃饭的动作，那么吃饭这件事就可以开始了。那么怎么中断吃饭这件事勒？抽取吃饭的条件就行了，将吃饭的人给抽取，吃饭这件事就不能进行了。所以完成一件事很难，因为要满足各种条件，前提条件满足了，那么这件事就可能完成，为什么是可能完成，因为在事情发展的过程中还会存在各种各样的影响因素，使构成事情的基本条件被抽取，这样事情就不能够发展了。站在这个角度上，不对事情抱有期待感是有道理的。<br>第三要认识到积累的重要性，千里之行，始于足下。可能我看到这个人有很多奖项，很多我没有的条件。但是我想我没有看到的是，人家背后的付出，只看到人家怎么怎么样，没有看到人家付出时的艰辛。经济学上讲，要想收获什么，就必须付出什么。时间，金钱，必须要拿自己拥有的去换取自己想要的。为什么这里要谈积累的重要性？举个例子，拿这个博客来说把，最开始肯定是从第一篇开始的，不可能从第n篇开始吧。而这么多博文的内容，其背后必然是时间，知识的积累才能诞生的。</p><p><img src="/pic/jzs1.jpg" alt="路是靠走出来的，不是靠想出来的"></p>]]></content>
    
    
    
    <tags>
      
      <tag>句子</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深度学习之开篇</title>
    <link href="/2024/04/16/deeplearn1/"/>
    <url>/2024/04/16/deeplearn1/</url>
    
    <content type="html"><![CDATA[<h1 id="为什么要开这个坑"><a href="#为什么要开这个坑" class="headerlink" title="为什么要开这个坑"></a>为什么要开这个坑</h1><ol><li>因为我是人工智能专业的学生</li><li>在学习的过程中起到记录和反思的作用</li><li>单纯想开</li></ol><h1 id="开这个坑，打算怎么填坑"><a href="#开这个坑，打算怎么填坑" class="headerlink" title="开这个坑，打算怎么填坑"></a>开这个坑，打算怎么填坑</h1><p>慢慢填呗，图难于其易，为大于其细。天下难事必作于易，天下大事必作于细。是以圣人终不为大，故能成其大。</p><h1 id="这个坑的流程是什么？"><a href="#这个坑的流程是什么？" class="headerlink" title="这个坑的流程是什么？"></a>这个坑的流程是什么？</h1><ol><li>先讲pytorch</li><li>基于pytorch实现一些经典网络，完成一些案例</li><li>看论文，介绍一些经典的论文，比如AlexNet，VGG，CNN，GoolgeNet，Unet，shuffleNet</li><li>开始跑yolo，更改网络模块。</li></ol><p>注： 这里只是一个流程，在开始后会有更多的坑需要去填的。</p>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>峨眉山</title>
    <link href="/2024/04/14/tupian2/"/>
    <url>/2024/04/14/tupian2/</url>
    
    <content type="html"><![CDATA[<h1 id="清晨的树"><a href="#清晨的树" class="headerlink" title="清晨的树"></a>清晨的树</h1><p><img src="/pic/e1.jpg"><br><img src="/pic/e2.jpg"><br><img src="/pic/e3.jpg"><br><img src="/pic/e4.jpg"></p>]]></content>
    
    
    
    <tags>
      
      <tag>图片</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论语</title>
    <link href="/2024/04/14/luwnyu/"/>
    <url>/2024/04/14/luwnyu/</url>
    
    <content type="html"><![CDATA[<p>注： 本博客参考的论语注解来源于缠中说禅，仅作为学习使用。<br>论语不仅是一本修身的学说，更是一本治世的学说。<br>修身，齐家，平天下。<br>修身（定、静、安、虑、得）</p><h1 id="第一句"><a href="#第一句" class="headerlink" title="第一句"></a>第一句</h1><ol><li>子曰：学而时习之，不亦说乎？有朋自远方来，不亦乐乎？人不知而不愠，不亦君子乎？</li></ol><p>问：什么是学？<br>答：闻“圣人之道”、见“圣人之道”、“对照”“圣人”、在现实社会中不断地“校对”。<br>问：谁学？<br>答：君子。<br>问：学什么？<br>答：成“圣人”之道。<br>问：学了能成什么？<br>答：“圣人”。</p><p>闻，见，学，行<br>闻圣人之道，见圣人之道，学圣人之道，行圣人之道<br>行“圣人之道”的人就是要使得“不知之人”变得“不愠”，使得“不知之世界”变得“不愠”。<br>人不知，人不相，人不愠。</p><p>2024&#x2F;5&#x2F;2注： 人不知：有一种人，不愿意付出努力，希望坐享其成，或者通过捷径来取得成果，即使知道努力是通往外界的必经因素，人的天性是懒惰的，通过自律或者其他外界因素才能让自己足够努力。在这种情况下看到他人付出努力取得成功了，为了让自己不显得那么失败，于是就寻找虚幻的优越感，例如努力的人是因为智商不够才需要努力（或者因为别的不足才需要努力），虚构出别人不如自己的假象，人并不关心真相，只关心如何让自己获得优越感，如何维持自己的傲慢。</p><p>注:人不相，见相非相，即见如来。见性，见智，凡所有相，皆是虚妄，若见诸相非相，既见如来。世界呈现在我们面前的是表象，非相才是本质。一切的现象都是由非相这个条件构成的，非相指一切事物形成的条件，肉眼是看不到的，什么条件产生什么结果，这个叫因果，这个因果本身的来源无从探究。要达到看清事物的本质的境界，首先向内求解，看到自己的本性，清楚自己的条件，这就是觉性，又可称为自我觉醒。之后再通过自己的觉性的智慧看待事物，做符合条件的事物及发展规律的事情，才可能达到与之相应的结果。若执着于事物的表象，不断在这个世界里沉迷见色（色：包括但不限于，酒、色、财、气），一旦执着于这些表现，当然会着像、着礼（人情世俗中的世俗），开始执着于礼的形式，在这种形式下产生各种各样的观点，立场，分别，执着。源于各种各样的概念，这些概念又将事物划分成了各种各样的等级，人的观念自然出现了各种各样鉴别，亲疏，好恶，从而相，而忽视了本质，一直处于人不知，达不到人不相的境界了，。</p><h1 id="第二句"><a href="#第二句" class="headerlink" title="第二句"></a>第二句</h1><ol start="2"><li>子曰：朝闻道夕死，可矣！<br>子曰： 朝闻，夕死。可矣！</li></ol><p>君子慎独，一旦开始走上圣人的道路，就要严格的要求自己。无论什么情况，与大家在一起时与自己一个人在一起时所表现出来的状态是一样的。<br>解释：君子从“闻其道”开始，无论任何地方，无论条件恶劣还是优越，甚至出生入死，都要不断地“固守”，“承担”“圣人之道”之行直到最终成就“不愠的世界”而不退转，只有这样，才可以行“圣人之道”呀。</p><p>自注： 立志走上成为圣人的这条道路上，就要时时刻刻牢记自己内心的要求，以现实为标准。时时刻刻的固守，达到内圣外王的境界。</p><h1 id="第三句"><a href="#第三句" class="headerlink" title="第三句"></a>第三句</h1><ol start="3"><li>子在川上曰：逝者如斯夫，不舍昼夜。</li></ol><p>解释：孔子在河流的源头，抚今追昔、满怀感慨，自告且忠告所有决心开始“见、学、行”“圣人之道”的君子：“立志“见、学、行”“圣人之道”的君子，就要像这江水一样，从“闻其道”的源头开始，后浪推前浪，生生不息、前赴后继，无论任何时候、任何地方，无论条件恶劣还是优越，甚至出生入死，都要不断地“固守”，“承担”“圣人之道”之行直到最终成就“不愠的世界”而不退转。”这里必须明确，这话既是孔子自己的感慨，也是对所有有志于圣人之道的人的忠告和勉励。</p><h1 id="第四句"><a href="#第四句" class="headerlink" title="第四句"></a>第四句</h1><ol start="4"><li>子曰：人能弘道，非道弘人。<br>就是“道”不是目的，只有“人”才是目的，只有现实中的“人”才是目的，一切以打着虚无飘渺的所谓“道”为目的，以现实的“人”为手段的所谓“闻、见、学、行”“圣人之道”，都是《论语》背道而驰的。</li></ol><p>注：孔子说：“人能够把道发扬光大，不是道能把人发扬光大。”</p><h1 id="第五句"><a href="#第五句" class="headerlink" title="第五句"></a>第五句</h1><ol start="5"><li>子曰：攻乎异端，斯害也己。</li></ol><p>对于行“圣人之道”的君子，“异端”只不过是“别为一端行非圣人之道”的“不知”者，如果没有这种人，“圣人之道”之行就成了无源之水。“不知”，如同米；“不愠”，如同饭；<br>在我看来，这句话更像是说要允许矛盾的存在，不能只允许一种情况的存在。毕竟按照矛盾的观点来看，正是矛盾才使事物能够不断地发展。圣人也是从不知者中诞生的，如果不允许不知者的话那么就不可能诞生知者了。<br>那么问题来了，圣人的作用是什么？人不知，人不愠。天下大同。对于“别为一端行非圣人之道”的“不知”者，行“圣人之道”的君子不是要攻打他们、消灭他们，而是要如把“米”煮成“饭”般把他们从“不知”者变成“不愠”者，变成行“圣人之道”的君子，把“不知”的世界变成“不愠”的世界，只有这样，才算是真行“圣人之道”。</p><h1 id="第六句"><a href="#第六句" class="headerlink" title="第六句"></a>第六句</h1><ol start="6"><li>子曰：道，不同、不相为谋。<br>子曰： 道，不同，不相为谋。<br>不相： 不以外在为判断条件，要看其本质。类似于见相非相，即见如来（此中有真意，欲辩以忘言）<br>解释：<br>道，圣人之道，就如同大河，大河是不会去“选择”的、也不会去强迫“一致”，是“不相”、“不同”的。 “圣人之道”之“谋”，就是“不同”、“不相”。最常见的以“相”相之就是所谓的“以貌取人”，延伸下去，根据思想、观点、意识形态、经济水平等等，都是以“相”相之，都不是“不相”，是和“圣人之道”相违的。</li></ol><p>注：“你得允许一部分人先高雅起来，一部分人后高雅起来，一部分人怎么也高雅不起来。”</p><h1 id="第七句"><a href="#第七句" class="headerlink" title="第七句"></a>第七句</h1><ol start="7"><li>子曰：有教无类。<br>自注：学问就一定有好坏之分吗？什么是检验的标准，实践是检验真理的唯一标准。现实是检验真理的唯一标准。</li></ol><h1 id="第八句"><a href="#第八句" class="headerlink" title="第八句"></a>第八句</h1><ol start="8"><li>子曰：士志於道，而耻恶衣恶食者，未足与议也！<br>注：“耻恶衣恶食者”，就是“相”如果一个人，立志要行“圣人之道”，却把人分为“好衣好食”、“恶衣恶食”两类人，也就是以贫富划分人，而选择以“恶衣恶食”也就是穷人为耻，远离他们，那这种人谈论的“圣人之道”只是羊头狗肉的勾当。为什么？因为他不能“不相”。</li></ol><h1 id="第九句"><a href="#第九句" class="headerlink" title="第九句"></a>第九句</h1><ol start="9"><li>子曰：贤哉，回也！一箪食，一瓢饮，在陋巷，人不堪其忧，回也不改其乐。贤哉，回也！<br>自注：真评和加贫。真有本事和假有本事。<br>颜回这个“安贫乐道”的典型，并不是故意去“贫”，并不是故意要“恶衣恶食”，也不是如某些宗教所教唆的故意去苦行，这些都是严重地“相”了，这些都是和君子谋“圣人之道”所必须坚持的“不相”原则背道而驰的。</li></ol><h1 id="第十句"><a href="#第十句" class="headerlink" title="第十句"></a>第十句</h1><ol start="10"><li>子曰：贫而无怨难；富而无骄易。</li></ol><p>这句有多种解释：第一种，从人不知的社会到人不相的社会，过程中，贫穷而不怨恨是困难的，富贵而不骄横是容易的。<br>问题是贫穷真的会使人怨恨吗？富贵真的会使人不骄横吗？在人不知的社会中（最初始的人不知），现实却又是穷人经常乐呵呵，富人却骄横无理。（穷乐呵，为富不仁。）<br>第二种解释，在任何“人不知”的社会中，都体现为“贫而怨难；富而骄易。</p><h1 id="第十一句"><a href="#第十一句" class="headerlink" title="第十一句"></a>第十一句</h1><ol start="11"><li>子贡曰：“贫而无谄，富而无骄，何如？”子曰：“可也；未若贫而乐，富而好礼者也。”</li></ol><p>“贫而谄”不得，最终就会“贫而怨难”，因“怨”有“仇”而“敌对”甚至“造反”，但“造反”成功的马上又成为“富而骄”，又有新的“贫而谄”，结果不断循环，都逃不出这个“贫而谄，富而骄”的“人不知”社会。<br>儒家看穿了这个“贫而谄，富而骄”的恶性循环，知道在这里打圈圈是没用的，而要打破这个恶性循环的办法，只有通过“人不相”而达到“人不愠”，最终摆脱“贫而谄，富而骄”的“人不知”的恶性循环。要实现这个打破，首先就要实现“贫而无谄，富而无骄”的“人不相”，为此，就必须要实现对“贫富”之相的“不相”，达到“人不相”。为什么实现对“贫富”之相的“不相”，就能实现“人不相”？是因为只要存在人与人的地方，就必然会出现各种方面的“贫富”之相，消灭这种“贫富”之相、将之抹平是不可能的，唯一办法就是使之“不相”，使得各种“贫富”之相能平等地存在，实现其“不同”，容纳各种“不同”而成其大，最终成就其“大同”。儒家、《论语》认为，这种“大同社会”的实现是当下的，是可以现世实现的，这种看法是由儒家的入世以及现世精神所决定的。<br>就像天幕红尘中说的，你要允许你得允许一部分人先高雅起来，一部分人后高雅起来，一部分人怎么也高雅不起来。” </p><h1 id="第十二句"><a href="#第十二句" class="headerlink" title="第十二句"></a>第十二句</h1><ol start="12"><li>子曰：齐一变，至於鲁；鲁一变，至於道。<br>在孔子时代是打着以“仁”以“德”治国的典型，号称传承着被孔子当成典范的周公之仁德。以“仁”以“德”治国，强调善的力量，对于一个习惯于以恶为前提的“人不知”世界是不可想象的，相比“齐式”国家模式，“鲁式”国家模式的出现是一种进步，所以才有“齐一变，至於鲁”的说法。</li></ol><h1 id="第十三句"><a href="#第十三句" class="headerlink" title="第十三句"></a>第十三句</h1><ol start="13"><li>子曰：放于利而行，多怨。<br>“放于利而行，多怨。”就是无论放弃还是放纵“利”而行，都会产生“多怨”的结果。 其实，现在的人对于这句话，肯定会更容易理解。计划经济年代，都是放弃“利”而行，结果是“多怨”；而市场经济年代，放纵“利”而行，结果还是“多怨”。这“人不知”社会的总规律，绝对不能放弃或放纵“利”而行，要充分把握其“利”，所谓用其刃而不被其刃所伤。行“圣人之道”的君子，首先要是“知人”，如果自己都还“不知”，又如何去让“人不知”之相“不相”？一事不知，儒者之耻，不尽量用这世界上的知识武装自己，是没资格当儒者的。</li></ol><h1 id="第十四句"><a href="#第十四句" class="headerlink" title="第十四句"></a>第十四句</h1><ol start="14"><li>子曰：好勇疾贫，乱也。人而不仁，疾之已甚，乱也。<br>“人不知”社会中同时存在的两种乱相：“贫者”，好勇斗狠；“富者”，为富不仁，被过分享乐之病急速传染，所谓纸醉金迷、醉生梦死。在“人不知”的社会，单纯的道德说教是没意义的，在“利”面前，所有的道德说教都苍白无力。这种“利”的“贫富”之相的严重对立，使得“富者”因得其“利”而放纵无度，而“贫者”因不得其“利”而不平。就算是一个懦夫，当“利”的“贫富”之相严重对立形成的落差储备到了足够大势能后，懦夫也会成为“勇夫”的。这样，自然就有了“好勇疾贫，乱也。人而不仁，疾之已甚，乱也。”。这种图景在“人不知”的社会随处可见、无处不在，《论语》早在两千多年前就已总结出来了。</li></ol><h1 id="第十五句"><a href="#第十五句" class="headerlink" title="第十五句"></a>第十五句</h1><ol start="15"><li>子曰：善人为邦百年，亦可以胜残去杀矣。诚哉是言也！<br>“胜残”、“去杀”，是两个意思相仿的词并列而成，简单说就是“战胜残暴、制止杀戮”；“善人”，就是“使人善”，“善”就是好的意思。“善人”和“胜残去杀”，其并列是一体的，如两腋之于人，双翼之于鸟，钱币的两面之于钱币。“善人、胜残去杀”，才可能“为邦百年”，让国家长治久安。“胜残去杀”，是针对“人而不仁，疾之已甚”，是针对为富不仁的“富者”，包括贼王暴君、贪官污吏、奸商恶霸等等，所谓杀一暴君而救亿万者乃真大仁矣；“善人”，是针对“好勇疾贫”的“贫者”，改善他们的生存条件、扩展他们的生存空间、提高他们的生存能力等等，都可以归之于“善人”之数。但必须强调的是，站在人和社会的整体角度，没有一个人是在任何方面都是“富”者，也没有一个人在任何方面都是“贫”者，但对于现实中的国家来说，经济、社会地位、权力等角度的“贫富”之相才最具有现实力量，这点也是不能忽视的。</li></ol><h1 id="第十六句"><a href="#第十六句" class="headerlink" title="第十六句"></a>第十六句</h1><ol start="16"><li>子曰：如有王者，必世而后仁。<br>一般来解答这一句为大致意思就成了“如果有称王的，一定要经过一世三十年，才能行其仁政。”国家长治久安的六字箴言“善人、胜残去杀”，而现实中，在“人不知”世界里，这六字箴言又有几人能办到？办不到，就必然是“城头变换大王旗”，中国历史上，这种改朝换代的事情，难道还不司空见惯？这种恶性循环中，有一个规律，就是本章的“如有王者，必世而后仁。”“王”，不一定需要有人当皇帝，如资本主义的确立也是一种王，其后到处贩卖的“民主、自由”就是“必世而后仁”了。</li></ol><h1 id="第十七句"><a href="#第十七句" class="headerlink" title="第十七句"></a>第十七句</h1><ol start="17"><li>子适卫，冉有仆。子曰：“庶矣哉！”冉有曰：“既庶矣，又何加焉？”曰：“富之。”曰：“既富矣，又何加焉？”曰：“教之。”<br>不同的社会，有不同的“庶、富、教”发展程度。而“全面发展的自由人的联合体”，就是“庶、富、教”充分发展所呈现的面貌。只有自由人，才会有多样性，才会有“不相”而“不同”，才有真正的“庶”；只有全面发展，才有真正的“富”；由“庶”而“富”，充分发展而形成“全面发展的自由人的联合体”所构成的社会结构，这才是真正的“教”。“庶、富、教”，就是不同成其大而大同。“庶、富”的发展水平，决定了“教”的发展水平，只有“庶、富”充分发展，才有“教”的充分发展，“庶、富”对应的是“人不相”，而“教”的充分发展最终对应的就是“人不愠”，只有“全面发展的自由人的联合体”构成的“教”，才是构成“人不愠”世界的社会结构基础。而只有“人不愠”，才是真正的“善人”。</li></ol><h1 id="第十八句"><a href="#第十八句" class="headerlink" title="第十八句"></a>第十八句</h1><ol start="18"><li>子曰：善人、教民七年，亦可以即戎矣。<br>通常解释为孔子说：“善人教导训练百姓七年时间，就可以叫他们去作战了”。“善人教民七年，亦可以即戎矣。”的通常断句是错的，应该是“善人、教民七年，亦可以即戎矣。”这一章是在彰显“善人”之道的力量，“教”的力量，文明的力量。“善人”之道，就是“圣人之道”一个具体过程中体现的具体形式，“圣人之道”最终要使得“人不知”的世界变成“人不愠”的世界，当然需要融合、同化那些未开化的、文明程度比较低的人、民族和国家，这是“人不知”世界一个很大的组成部分。如果说上一章更侧重于“善人”之道在国家范围的应用，那这一章就指出，“善人”之道在全世界实现的必然性，而只有在全世界的实现，才算真正的“善人”之道。孔子认为，作为“圣人之道”低级阶段的“善人”之道的实现也只能是一个全球性事件，大同，只能是大同天下，而不可能是某一国的大同，必然要“即戎”而达到天下大同。</li></ol><h1 id="第十九句"><a href="#第十九句" class="headerlink" title="第十九句"></a>第十九句</h1><ol start="19"><li>子曰：以不教民战，是谓弃之。<br>通常解释为“以不教民战”解释成“用不经教练的民众去临战阵”孔子说：“用没有经过军事训练的老百姓去打仗，这是有意让他们去送死。”。滑稽，断句应为，以不教，民战，是谓弃之。不行“善人”之道，那只能用“残、杀”，用所谓的白色恐怖来压制，企图让人民战栗、恐惧而治理国家。用“残、杀”企图使民众战栗、恐惧而治理国家的，就是遗弃、背叛民众，而最终也将被民众所遗弃。</li></ol><h1 id="第二十句"><a href="#第二十句" class="headerlink" title="第二十句"></a>第二十句</h1><ol start="20"><li>哀公问社於宰我。宰我对曰：“夏后氏以松，殷人以柏，周人以栗，曰，使民战栗。”子闻之，曰：“成事不说，遂事不谏，既往不咎。”<br>鲁哀公向孔子的弟子宰我问“土地神的祭祀”，宰我自作聪明道：“夏代用松木，殷代用柏木，而周代用栗木是为了借谐音使民战栗。”孔子听到，就告戒：“正成的事不要妄加评议，即成的事就不要徒劳劝告，已成的事就不要再生灾祸。”<br>“成事”，不是指已成的事，而是指正成的事，也就是在萌芽状态的，这时候，还需要观察，不能妄加评议，胡乱定性；“遂事”，马上就要成的事，已经无可挽回的，就不要徒费口舌去劝告了，这样只能产生怨恨；“既往”，已经过去的已成的事，要“不咎”，“咎”的本义是灾祸，已经成的事，如果错了，就不要错上加错，再生灾祸。这句话针对事物发展的三个不同阶段应该采取的态度。</li></ol><h1 id="第二十一句"><a href="#第二十一句" class="headerlink" title="第二十一句"></a>第二十一句</h1><ol start="21"><li>子曰：夷狄之有君、不如，诸夏之亡也。<br>“夷狄之有君、不如，诸夏之亡也。”的意思是：未开化的、文明程度比较低的人、民族和国家，虽然有他们自己的国体、政体，但由于没有遵从、依照文明程度比较高的人、民族和国家的政体、国体，而被后者所轻视。只要有不同的人、民族、国家同时存在，就必然有“诸夏”、“夷狄”之分，对于民族、国家来说，任何不行“圣人之道”的，无论是“齐式”的“王霸之道”还是“鲁式”的“仁德”之道，都必然会有“先进”对“落后”的轻视、压榨。一个国家、民族，如果不行“善人”之道，用“残、杀”企图让别国、别的民族战栗、恐惧而治理世界，就是遗弃、背叛各国、各民族，而最终也将被各国、各民族所遗弃。一个现成的例子，就是美国</li></ol><h1 id="第二十二句"><a href="#第二十二句" class="headerlink" title="第二十二句"></a>第二十二句</h1><ol start="22"><li>子曰：为政以德譬，如北辰居其所而众星共之。<br>这一章，其实就是上一章所说““圣人之道”、“善人之道”是大道，更是现实之道，无位可本，又何来“本位”？正因为无位可本，才可以无所位而生其本、无所本而生其位。这，才是真正的大道、现实之道。”的进一步展开。何谓“为政以德譬，如北辰居其所而众星共之。”？就是“无所位而生其本、无所本而生其位”。 只有明白了这句话，才可能真正明白马克思意义上的“具体问题具体分析”，也才可能真正明白何谓“为政以德譬，如北辰居其所而众星共之”。当人把北极星的位置确定后，执持这位置相应就可以定出其他星星位置；当人从现实出发分析把握了现实关系的逻辑结构后，“孰敢不正？</li></ol><h1 id="第二十三句"><a href="#第二十三句" class="headerlink" title="第二十三句"></a>第二十三句</h1><ol start="23"><li>季康子问政於孔子，孔子对曰：政者，正也，子帅以正，孰敢不正？<br>季康子，鲁国大夫，向孔子问政。“政者，正也”，为政，就是要立行“圣人之道”而成就之这一逻辑支点；“子帅以正，孰敢不正？”为政的人，遵循现实的逻辑，从现实出发，行“圣人之道”而成就之，其它问题就会以此为基础相应地找到解决的办法。这里必须要明确的是，现实，是最底层的支点，行“圣人之道”而成就之这个逻辑支点必须也必然在现实支点之上，离开现实，无所谓“圣人之道”。“圣人之道”，不是离开现实的乌托邦，那种把“圣人之道”装扮成某种口号、旗帜、目标，以此而驱使人，让人为此而折腾，都和“圣人之道”、《论语》、孔子毫无关系。人不是现实的奴隶，现实必须是人参与其中的，没有了人，也无所谓现实，更无所谓现实逻辑。 现实之于人，按其逻辑，有着各种不同的选择，究竟如何去选择，就构成了各色各样的政治。各种政治结构的逻辑支点，都来自现实，这逻辑支点也如同北极星，一旦确立，其它就以此为基础相应地构建。</li></ol><h1 id="第二十四句"><a href="#第二十四句" class="headerlink" title="第二十四句"></a>第二十四句</h1><ol start="24"><li>子曰：不在其位，不谋其政。<br>“不在其位，不谋其政”，就是“不谋不在其位之政”，不谋划与现实变化的位次不符的政事、政治关系、政治制度、上层建筑、生产关系等等。一切都从也只能从现实出发，现实在什么阶段，什么位次，是必须首要分析的问题。</li></ol><h1 id="第二十五句"><a href="#第二十五句" class="headerlink" title="第二十五句"></a>第二十五句</h1><ol start="25"><li>子曰：“不在其位，不谋其政。”曾子曰：“君子思不出其位。”</li></ol><h1 id="第二十六句"><a href="#第二十六句" class="headerlink" title="第二十六句"></a>第二十六句</h1><ol start="26"><li>子曰：“不患，无位；患，所以立。不患，莫己知求，为可知也。”<br>“无所位而生其本、无所本而生其位”，即所“立”、即所“止”、即所“位”。有所“立”，则“立”其“有”，其“有”必有其“位”<br>儒家，内圣、外王，“不在其位，不谋其政”的外王，是和“不患，无位；患，所以立。不患，莫己知求，为可知也。”的内圣相互相成的。这是参悟儒家之说的大关键。</li></ol><p>缠中说禅白话直译<br>子曰：“不患，无位；患，所以立。不患，莫己知求，为可知也。”<br>孔子说：“不患”，无位次；“患”，以“不患”的“无位次”而“位次”。“不患”，不以自己“所知”来选择，就是“能知”。</p><h1 id="第二十七句"><a href="#第二十七句" class="headerlink" title="第二十七句"></a>第二十七句</h1><ol start="27"><li>子曰：不患人之不己知；患其不能也。<br>通译：不要担心别人不了解自己，应该担心的是自己不了解别人。<br>正因为“不明了”的现实，所以才有了自己不断“明了”自己的可能，所以才有了“明了”的可能，不明白这一点，是不可能明白何谓“内圣”的。</li></ol><p>缠中说禅白话直译<br>子曰：“不患人之不己知；患其不能也。”<br>孔子说：不患别人或自己不明了自己，患别人或自己不能明了自己啊。</p><h1 id="第二十八句"><a href="#第二十八句" class="headerlink" title="第二十八句"></a>第二十八句</h1><ol start="28"><li>子曰：“不患人之不己知；患不知人也。”<br>通译：“不要担心别人不了解自己，应该担心的是自己不了解别人。”<br>缠中说禅白话直译<br>子曰：“不患人之不己知；患不知人也。”<br>孔子说：不患人不明了自己，患“人不知”的世界啊。</li></ol><h1 id="第二十九句"><a href="#第二十九句" class="headerlink" title="第二十九句"></a>第二十九句</h1><ol start="29"><li>子曰：“性相，近也；习相，远也。”</li></ol><p>缠中说禅白话直译<br>子曰：性相，近也；习相，远也。<br>孔子说：以性性相，缠附呀；以习习相，深奥啊。</p><h1 id="第三十句"><a href="#第三十句" class="headerlink" title="第三十句"></a>第三十句</h1><ol start="30"><li>子曰：人无远虑，必有近忧。<br>“远”，深远、深奥，同于“习相，远也”，和“习相”相关，脱离“习相”无所谓深远、深奥，不过幻想而已。“习相”，先要明其“相”，明其“相”必先明其“相”之位次，明其“相”之位次，必对其“相”的当下逻辑关系有一明确把握。<br>“虑”，审察、思虑、谋划。“虑”，不是哈姆雷特式的，而是审察、思虑、谋划的统一，三者缺一不可，而最终必须落在行动上，没有行动的“虑”也不过是幻想而已。<br>人的行为，必须从其苗头下手，不想吃恶果，最简单的方法就是不要种下其种子，忧患、祸患的种子一旦缠附，一有机会就会萌芽，就要结果。别以为可以用任何方法可以消除这种子，种子一旦种下就是无位次的，准确说，相对于现实系统来说，种子是无位次的，任何现实的把戏都消灭不了种子，种子不一定在眼前发芽，但不发芽只是机会不成熟，一旦成熟，逃都逃不掉，眼前看不到、没迹象的忧患、祸患，往往才是致命的。而这，才是真正的“近忧”。</li></ol><p>缠中说禅白话直译<br>子曰：人无远虑，必有近忧。<br>孔子说：人没有深远的审察、思虑、谋划，必然缠附祸患。</p><h1 id="第三十一句"><a href="#第三十一句" class="headerlink" title="第三十一句"></a>第三十一句</h1><ol start="31"><li>子曰：众，恶之，必察焉；众，好之，必察焉。</li></ol><p>缠中说禅白话直译<br>子曰：众，恶之，必察焉；众，好之，必察焉。<br>孔子说：一切现象，当被认为是恶的就会被厌恶，对此必须摈弃一切厌恶当下直观；一切现象，当被认为是好的就会被喜好，对此必须摈弃一切喜好当下直观。（恶并不是恶，好的并不一定是好的。）</p><h1 id="第三十二句"><a href="#第三十二句" class="headerlink" title="第三十二句"></a>第三十二句</h1><ol start="32"><li>子曰：视，其所以；观，其所由；察，其所安。人焉廋哉？人焉廋哉？<br>视”，人与认识对象之间的看，相当于感性以及康德规定性判断力所连接的知性与理性所构成的高级人类认识能力，也就是人类所有的认识能力；“观”，看法，相当于“反思判断力”所连接的自由意志；“察”，当下的直“观”，是自由意志的当下实践。“视，其所以”，认识能力是人所凭借的；</li></ol><p>缠中说禅白话直译<br>子曰：视，其所以；观，其所由；察，其所安。人焉廋哉？人焉廋哉？<br>孔子说：认识能力，人的凭借；自由意志，人的遵从；当下直 “观”，即自由意志的当下实践，人的归依。人，哪里有隈曲啊？人，哪里有隈曲啊？</p><h1 id="第三十三句"><a href="#第三十三句" class="headerlink" title="第三十三句"></a>第三十三句</h1><ol start="33"><li>子曰：不知，命无以为君子也；不知，礼无以立也；不知，言无以知人也。</li></ol><p>缠中说禅白话直译<br>子曰：不知，命无以为君子也。不知，礼无以立也。不知，言无以知人也。<br>孔子说：没有智慧，不可能承担君子的使命；没有智慧，不可能建立社会正常的秩序；没有智慧，不可能产生使人智慧的言论。</p><h1 id="第三十四句"><a href="#第三十四句" class="headerlink" title="第三十四句"></a>第三十四句</h1><ol start="34"><li>子曰：由知、德者，鲜矣！<br>圣人之道”，就是将“人不知”的世界变为“人不愠”世界的道路，这里没有任何固定的模式和先验的走法，路是人走出来的，是人所“由”而来，是人所“蹈行，践履”而来。没有人的“蹈行，践履”，何来路？除了“知、德”，行“圣人之道”的君子无所“蹈行，践履”也无须“蹈行，践履”。</li></ol><p>缠中说禅白话直译<br>子曰：由知、德者，鲜矣！<br>孔子说：蹈行、践履“闻、见、学、行”“圣人之道”智慧、所得的君子，永远处在创新、创造之中啊。</p><h1 id="第三十五句"><a href="#第三十五句" class="headerlink" title="第三十五句"></a>第三十五句</h1><ol start="35"><li>子曰：民可，使由之；不可，使知之。</li></ol><p>缠中说禅白话直译<br>子曰：民可，使由之；不可，使知之。<br>孔子说：民众当下适合的，放任民众去蹈行、践履；民众当下不适合的，放任民众运用智慧去创造、创新。</p><h1 id="第三十六句"><a href="#第三十六句" class="headerlink" title="第三十六句"></a>第三十六句</h1><ol start="36"><li>子曰：由诲女，知之乎！知之为，知之；不知为，不知；是知也！</li></ol><p>缠中说禅白话直译<br>子曰：由诲女，知之乎！知之为，知之；不知为，不知；是知也。<br>孔子说：实践教导你，以此而有智慧啊。依智慧而进一步实践，以此而有新的智慧；不依以实践而有的智慧进一步实践，就不会有新的智慧。这，就是最根本的智慧。</p><p>自注： 认识来源于实践，从无知到有一定的感性认识，再从感性认识到一定的理性认识。认识是一个过程，不可以说是直接没有感性认识就产生了理性认识。在认识的过程中当然时时刻刻伴随着实践，正式有了实践才让认识不断深化。</p><h1 id="第三十七句"><a href="#第三十七句" class="headerlink" title="第三十七句"></a>第三十七句</h1><ol start="37"><li>子曰：我非生而知之者，好古，敏以求之者也。<br>本章，孔子提出了学习前人知识、智慧的三个步骤：好、敏、求。 首先，对前人知识、智慧所凝结成的遗典、典章等必须尊重、善待进而学习、研究，才谈得上“好”。尊重、善待进而学习、研究，真正把握以后，还需要在实践中继续印证，这才是“敏”。“敏”，有两层的含义：其一，前人知识、智慧都来源于其当下的实践，而时代变化了，条件变化了，其应用可能要失效，可能有所改变，这必须在实践中才能印证、发现；其二，对前人知识、智慧的把握，特别对于那些洞穿时间的智慧的把握，必须在实践中慢慢体会、摸索，才能发现前人的真义，决不能像某些人对待孔子、马克思那样，根本没弄明白就扮代表，这样是谈不上“好”，更谈不上“敏”了。有了印证，自然就有了选择的基础，选择不是机械地挑选，不是用对错等简单标准来划分，而是根据当下的实践有机地发展、延伸，这样才不辜负古人，也不辜负自己，这才算得上是“求”。</li></ol><p>缠中说禅白话直译<br>子曰：我非生而知之者，好古，敏以求之者也。<br>孔子说：我不是天生、先验地依赖天生、先验而有智慧的人，只是爱好学习、研究先哲遗典、古代典章，并在实践中对此印证、选择的人。</p><p>自注： 这句话在讲前人的经验可以学习，但是不能直接使用。为什么这么说，因为条件改变了，当时这个方法能解决这个问题，那是因为由实践这个方法的条件，而现在没有满足这个方法的条件，所以这个问题使用这个方法就解决不了。一句话，实事求是。那么有没有普世的方法？答案是没有的，但是有普世的法则，内心有内心的心法，社会有社会的法则。熟悉和了解这些法则的过程中必然要经历大量的实践，才能认识到。但是即使认识到这些法则，能不能熟练的用于也是一件困难的事情，知之为知之，不知为不知。迎接挑战，这样的人生才有意义。征服一个又一个巅峰，达到内圣外王的境界。</p><h1 id="第三十八句"><a href="#第三十八句" class="headerlink" title="第三十八句"></a>第三十八句</h1><ol start="38"><li>孔子曰∶生而知之者，上也；学而知之者，次也；困而学之，又其次也。困而不学，民斯为下矣！<br>缠中说禅白话直译<br>孔子曰∶生而知之者，上也；学而知之者，次也；困而学之，又其次也。困而不学，民斯为下矣！<br>孔子说：所有人，天生地依赖天生而有智慧，是最好的；所有人，都能自由地学习且通过学习而有智慧，是稍差的；所有人，被分为不同类别而得到不同类别的学习，是更差的。所有人，被分为不同类别而某类人得不到学习的机会，这就是民众被当成卑下的原因啊。</li></ol><h1 id="第三十九句"><a href="#第三十九句" class="headerlink" title="第三十九句"></a>第三十九句</h1><ol start="39"><li>子曰：盖有不知而作之者，我无是也。多闻，择其善者而从之；多见而识之；知之次也。</li></ol><p>缠中说禅白话直译<br>子曰∶盖有不知而作之者，我无是也。多闻，择其善者而从之；多见而识之；知之次也。<br>孔子说：大概存在没有智慧却凭没有智慧而有所作为的人，我不是这样的。在一个能让每个人都能自由见闻的社会里，尽可能地扩展自己的见闻，选择超过自己的见解，依据其见解而不是依据有此见解的人或群体，深入探讨、吸收学习；进而让自己的见识逐步深厚，才能更清楚地去辨别、辩正各种知识的真伪、深浅。但这些都是智慧的临时落脚处，不是智慧的真正所在。</p><h1 id="第四十句"><a href="#第四十句" class="headerlink" title="第四十句"></a>第四十句</h1><ol start="40"><li>子张学干禄。子曰：多闻阙疑，慎言其余，则寡尤。多见阙殆，慎行其余，则寡悔。言寡尤，行寡悔，禄在其中矣。</li></ol><p>缠中说禅白话直译<br>子张学干禄。子曰：多闻阙疑，慎言其余，则寡尤。多见阙殆，慎行其余，则寡悔。言寡尤，行寡悔，禄在其中矣。<br>孔子说：子张求问获取福运的方法。孔子说：见闻广泛而去除疑惑，见识深厚而去除危险，遵循如此“闻见”而如此“言行”，那么言行都会少过失。言行少过失，福运在其中啊。</p><h1 id="第四十一句"><a href="#第四十一句" class="headerlink" title="第四十一句"></a>第四十一句</h1><ol start="41"><li>子曰∶君子谋道不谋食。耕也，馁在其中矣；学也，禄在其中矣。君子忧道不忧贫。</li></ol><p>缠中说禅白话直译<br>子曰∶君子谋道不谋食。耕也，馁在其中矣；学也，禄在其中矣。君子忧道不忧贫。<br>孔子说：“闻、见、学、行”“圣人之道”的君子，按“道之谋”谋划而不按“食之谋”谋划。以人的欲望饥饿为基础的生产，新的欲望饥饿就在其中啊；以人与天地关系中对照、校对确定人之所需，福运、真正的幸福就在其中啊。君子只担忧如何“闻、见、学、行”“圣人之道”的“道之谋”，而不担忧“馁、耕、食” “食之谋”的恶性循环必然导致的人在物质与精神上的贫穷。</p><p>自注： 经常的被不知道来源的焦虑所裹挟，思考一下来源有嘈杂的网络环境，以贩卖焦虑为谋利的文章。君子谋道不谋食，这个时代，饿死还是很难的，解决食之谋的方法还是有很多的。减掉一些愿望，不做一些没有实现可能的幻想，仔细想想我有的，然后再想我这么使用我有的来实现我想要的。</p><h1 id="第四十二句"><a href="#第四十二句" class="headerlink" title="第四十二句"></a>第四十二句</h1><ol start="42"><li>子曰：君子不器。</li></ol><p>缠中说禅白话直译<br>子曰∶君子不器。<br>孔子说：君子不相。</p><h1 id="第四十三句"><a href="#第四十三句" class="headerlink" title="第四十三句"></a>第四十三句</h1><ol start="43"><li>子曰：古之学者为己；今之学者为人。</li></ol><p>缠中说禅白话直译<br>子曰：古之学者为己；今之学者为人。<br>孔子说：无论古今，真正的学问与学人，都不离“内圣外王”、“为己为人”的一体之学。</p><p>自注：“是故内圣外王之道，暗而不明，郁而不发，天下之人，各为其所欲焉，以自为方。”<br>在王阳明看来，“内圣”的基础，是人之为人必要有的独立人格，恰如孔子所说的“古之学者为己”。在王阳明看来，唯有找到“天理”的指引，人才有内在驱动力，才能找到人生方向，而获得“天理”途径，便是通过“格物”进而“正心”，通过“知行合一”。通过书本获得知识算不得“理”，只有在生活中对其进行实践、验证进而获得的个人独特的理解，才算是“真知”。博学、审问、慎思、明辨、笃行者，皆所以为惟精而求惟一也。他如博文者，即约礼之功；格物致知者，即诚意之功；道问学即尊德性之功；明善即诚身之功：无二说也。”观诸圣之一学：基督教曰树一、恒一；伊斯兰曰独一无二；印度教曰不二； 佛教曰三昧(一境)；道教曰贞一；黄帝曰守一； 管子曰专一； 老子曰执一； 孔子曰精一； 山人说的就是一个一，故人戏称山人为一先生、不二先生。人要有所作为就必须独善其一，国家民族之强盛势必用一，有统一的思想，有惟一的民族哲学理念。</p><h1 id="第四十四句"><a href="#第四十四句" class="headerlink" title="第四十四句"></a>第四十四句</h1><ol start="44"><li>子曰：三年学不至，於榖不易，得也。</li></ol><p>缠中说禅白话直译<br>子曰：三年学不至，於榖不易，得也。<br>孔子说：多年闻“圣人之道”、见“圣人之道”、“对照”“圣人”、在现实社会中不断地“校对”，虽然不能达到尽善尽美，但能对“圣人之道”的“学”达到一生不退转的位次，这才算是“学”有所得啊。</p><p>自注： 闻，见，学，行圣人之道，就要坚定的走下去。</p><h1 id="第四十五句"><a href="#第四十五句" class="headerlink" title="第四十五句"></a>第四十五句</h1><ol start="45"><li>子曰：学如不及，犹恐失之。</li></ol><p>缠中说禅白话直译<br>子曰：学如不及，犹恐失之。<br>孔子说：闻“圣人之道”、见“圣人之道”、“对照”“圣人”、在现实社会中不断地“校对”而不能达到尽善尽美，是因为踌躇、恐惧、疑虑使它迷失而不能直下承担。</p><h1 id="第四十六句"><a href="#第四十六句" class="headerlink" title="第四十六句"></a>第四十六句</h1><ol start="46"><li>子曰：学而不思则罔，思而不学则殆。<br>学和思本来就是一体的。</li></ol><p>缠中说禅白话直译<br>子曰：学而不思则罔，思而不学则殆。<br>孔子说：将差异性的“学”与同一性的“思”分开，都只能迷惘、疲怠而无所得。</p><h1 id="第四十七句"><a href="#第四十七句" class="headerlink" title="第四十七句"></a>第四十七句</h1><ol start="47"><li>子曰：唯！女子与小人为难、养也。近之则不孙，远之则怨。</li></ol><p>缠中说禅白话直译<br>子曰：唯！女子与小人为难、养也。近之则不孙，远之则怨。<br>孔子说：是的！你的儿女跟随小人而“闻、见、学、行”，就产生灾难、痒疾。依附小人，就失去子嗣；违背小人，就埋下仇恨。</p><h1 id="第四十八句"><a href="#第四十八句" class="headerlink" title="第四十八句"></a>第四十八句</h1><ol start="48"><li>子曰：唯上知与下愚不移。</li></ol><p>缠中说禅白话直译<br>子曰：唯上知与下愚不移。<br>孔子说：愿真正“见、闻、学、行”“圣人之道”的君子，结交、亲附没有智慧、充满贪婪、恐惧的小人而成就“见、闻、学、行”“圣人之道”的不退转。</p><h1 id="第四十九句"><a href="#第四十九句" class="headerlink" title="第四十九句"></a>第四十九句</h1><ol start="49"><li>子曰：温故而知新，可以为师矣。</li></ol><p>缠中说禅白话直译<br>子曰：温故而知新，可以为师矣。<br>孔子说：应当把“积聚、蕴藏故有的、经过时间沉淀、检验的智慧而保持智慧当下鲜活的创造与呈现”作为君子“见、闻、学、行”“圣人之道”所师法的目标啊。</p><p>自注： 温故而知新”有四解。</p><p>1、温故才知新，温习已学的知识，并且由其中获得新的领悟；</p><p>2、温故及知新，一方面要温习典章故事，另一方面又努力撷取新的知识；</p><p>3、温故，知新。随着自己阅历的丰富和理解能力的提高，回头再看以前看过的知识，总能从中体会到更多的东西；</p><p>4、是指通过回味历史，而可以预见，以及解决未来的问题。这才是一个真正的大师应该具有的能力。</p><h1 id="第五十句"><a href="#第五十句" class="headerlink" title="第五十句"></a>第五十句</h1><ol start="50"><li>子曰：吾十有五而志于学，三十而立，四十而不惑，五十而知天命，六十而耳顺，七十而从心所欲不逾矩。</li></ol><p>缠中说禅白话直译<br>子曰：吾十有五而志于学，三十而立，四十而不惑，五十而知天命，六十而耳顺，七十而从心所欲不逾矩。<br>孔子说：我十五岁的境界、所为用“从此闻见学行圣人之道”来标记，三十岁的境界、所为用“穷尽闻见学行圣人之道的现实可能位次”来标记，四十岁的境界、所为用“透彻闻见学行圣人之道现实可能位次的不患”来标记，五十岁的境界、所为用“闻见学行圣人之道让智慧依当下生存鲜活地呈现”来标记，六十岁的境界、所为用“遵循当下生存鲜活呈现的智慧而闻见学行圣人之道以成就内圣”来标记，七十岁的境界、所为用“依从民心期望但不超越闻见学行圣人之道在当下现实中可能实现位次而成就外王”来标记。</p><h1 id="第五十一句"><a href="#第五十一句" class="headerlink" title="第五十一句"></a>第五十一句</h1><ol start="51"><li>子曰：君子，食无求饱，居无求安；敏於事而慎於言；就有，道而正焉；可谓好学也已。</li></ol><p>缠中说禅白话直译<br>子曰：君子，食无求饱，居无求安；敏於事而慎於言；就有，道而正焉；可谓好学也已。<br>孔子说：“闻见学行”“圣人之道”的人，对欲望不贪求从而满足，对生存的环境不贪求从而安身；通过当下的事情去印证，使得理论、言论顺应当下的实际；对现实究底穷源，使现实行“圣人之道”而在现实中成就之，称之为“好学”，是适当的啊。</p><p>自注： 走上圣人之道的人，把对欲望的不贪求看作满足。</p><h1 id="第五十二句"><a href="#第五十二句" class="headerlink" title="第五十二句"></a>第五十二句</h1><ol start="52"><li>子曰：十室之邑，必有忠信如丘者焉，不如丘之好学也。</li></ol><p>缠中说禅白话直译<br>子曰：十室之邑，必有忠信如丘者焉，不如丘之好学也。<br>孔子说：所有国家，倘若有遵从我的“忠信”标准的在其中，不若有遵从我的“好学”标准的在其中。</p><h1 id="第五十三句"><a href="#第五十三句" class="headerlink" title="第五十三句"></a>第五十三句</h1><ol start="53"><li>子曰：三人行，必有我师焉：择其善者而从之，其不善者而改之。</li></ol><p>缠中说禅白话直译<br>子曰：三人行，必有我师焉：择其善者而从之，其不善者而改之。<br>孔子说：与“君、父、师”同行，倘若有让我师法的在此：选取他们完善的并在当下现实更广泛的范围应用、检验，选取他们不完善的并在当下现实中不断修改、完善。</p><h1 id="第五十四句"><a href="#第五十四句" class="headerlink" title="第五十四句"></a>第五十四句</h1><ol start="54"><li>子夏曰：日知其所亡，月无忘其所能，可谓好学也已矣！<br>钱穆：子夏说：“每天能知道所不知道的，每月能不忘了所已能的，可说是好学了。”<br>知识是知识，技术高于知识，心法高于技术，法则高于心法。</li></ol><h1 id="第五十五句"><a href="#第五十五句" class="headerlink" title="第五十五句"></a>第五十五句</h1><ol start="55"><li>子夏曰：仕而优则学；学而优则仕。<br>钱穆：子夏说：“仕者有余力宜从学。学者有余力宜从仕。”</li></ol><h1 id="第五十六句"><a href="#第五十六句" class="headerlink" title="第五十六句"></a>第五十六句</h1><ol start="56"><li>子夏曰：百工居肆以成其事；君子学以致其道。<br>钱穆：子夏说：“百工长日居住肆中以成其器物，君子终身在学之中以求致此道。”<br>直译大致就是：就像各种工匠在手工业作坊里为完成他们的制作，君子在学中为完成他们的事业。</li></ol><h1 id="第五十七句"><a href="#第五十七句" class="headerlink" title="第五十七句"></a>第五十七句</h1><ol start="57"><li>子谓子夏曰：女为君子儒！无为小人儒！<br>钱穆：先生对子夏道：“你该为一君子儒，莫为一小人儒。”</li></ol><p>自注： 这句话更像老人对孩子的劝诫，重点就是看怎么解释这君子儒和小人儒了。</p><h1 id="第五十八句"><a href="#第五十八句" class="headerlink" title="第五十八句"></a>第五十八句</h1><ol start="58"><li>哀公问：“弟子孰为好学？”孔子对曰：“有颜回者好学，不迁怒，不贰过。不幸短命死矣，今也则亡，未闻好学者也。”<br>钱穆：鲁哀公问孔子道：“你的学生们，哪个是好学的呀？”孔子对道：“有颜回是好学的，他有怒能不迁向别处，有过失能不再犯。可惜短寿死了，目下则没有听到好学的了。”</li></ol><h1 id="第五十九句"><a href="#第五十九句" class="headerlink" title="第五十九句"></a>第五十九句</h1><ol start="59"><li>季康子问：“弟子孰为好学？”孔子对曰：“有颜回者好学，不幸短命死矣！今也则亡。”<br>钱穆：季康子问孔子：“你的弟子哪个是好学的呀？”孔子对道：“有颜回是好学的，不幸短命死了，现在是没有了。”</li></ol><h1 id="第六十句"><a href="#第六十句" class="headerlink" title="第六十句"></a>第六十句</h1><ol start="60"><li>子曰：语之而不惰者，其回也与？</li></ol><p>缠中说禅白话直译<br>子曰：语之而不惰者，其回也与？<br>孔子说：任何人与他辩论而他都能语不衰败的所谓能辩之士，难道只有颜回吗？</p><h1 id="第六十一句"><a href="#第六十一句" class="headerlink" title="第六十一句"></a>第六十一句</h1><ol start="61"><li>子贡问君子。子曰：先行其言而后从之。</li></ol><p>缠中说禅白话直译<br>子贡问君子。子曰：先行其言而后从之。<br>子贡问君子，孔子说：“先使自己的言论、思想以及相应的行为一以贯之，然后再使之广泛。”</p><h1 id="第六十二句"><a href="#第六十二句" class="headerlink" title="第六十二句"></a>第六十二句</h1><ol start="62"><li>子贡问曰：“赐也何如？”子曰：“女，器也。”曰：“何器也？”曰：“瑚琏也。”</li></ol><p>缠中说禅白话直译<br>子贡问曰：“赐也何如？”子曰：“女，器也。”曰：“何器也？”曰：“瑚琏也。”<br>子贡问：“我，怎么样？”孔子说：“你，“器”呀。”问：“什么器皿？”答：“宗庙里盛黍稷的瑚琏那样的名贵器皿”</p><h1 id="第六十三句"><a href="#第六十三句" class="headerlink" title="第六十三句"></a>第六十三句</h1><ol start="63"><li>子贡问曰：“有一言而可以终身行之者乎？”子曰：“其恕乎？己所不欲，勿施於人。”</li></ol><p>缠中说禅白话直译<br>子贡问曰：“有一言而可以终身行之者乎？”子曰：“其恕乎？己所不欲，勿施於人。”<br>子贡问：“有可以终身一而贯之的言论吗？”孔子说：“自己不想要的就不施加给别人，难道就是“恕”吗？”</p><h1 id="第六十四句"><a href="#第六十四句" class="headerlink" title="第六十四句"></a>第六十四句</h1><ol start="64"><li>子贡曰：“我不欲人之加诸我也，吾亦欲无加诸人。”子曰：“赐也，非尔所及也。”</li></ol><p>缠中说禅白话直译<br>子贡曰：“我不欲人之加诸我也，吾亦欲无加诸人。”子曰：“赐也，非尔所及也。”<br>子贡问：“我不想别人诬枉我，我也不想诬枉别人。”孔子说：“子贡啊，这不是你所能达到的。”</p><h1 id="第六十五句"><a href="#第六十五句" class="headerlink" title="第六十五句"></a>第六十五句</h1><ol start="65"><li>子曰：“赐也，女以予为多学而识之者与？”对曰：“然，非与？”曰：“非也！予一以贯之。”</li></ol><p>缠中说禅白话直译<br>子曰：“赐也，女以予为多学而识之者与？”对曰：“然，非与？”曰：“非也！予一以贯之。”<br>孔子问：“子贡啊，你把我当成不断学习从而了解现实当下的人吗？”子贡回答：“对，不是这样吗？”孔子说：“不是啊，我只是直下承担当下现实而贯通它。”</p><h1 id="第六十六句"><a href="#第六十六句" class="headerlink" title="第六十六句"></a>第六十六句</h1><ol start="66"><li>子曰：“参乎！吾道一以贯之。”曾子曰：“唯。”子出。门人问曰：“何谓也？”曾子曰：“夫子之道，忠恕而已矣。”</li></ol><p>缠中说禅白话直译<br>子曰：“参乎！吾道一以贯之。”曾子曰：“唯。”子出。门人问曰：“何谓也？”曾子曰：“夫子之道，忠恕而已矣。”<br>孔子说：“曾参啊！我“闻见学行”圣人之道一以贯之。”曾参说：“是。”孔子出去。孔子的其他弟子问：““一以贯之”是什么意思？”曾参回答：“老师的道理，只是“尽已之心以待人，推己之心以及人”罢了。”</p><h1 id="第六十七句"><a href="#第六十七句" class="headerlink" title="第六十七句"></a>第六十七句</h1><ol start="67"><li>有子曰：其为人也孝弟，而好犯上者，鲜矣；不好犯上，而好作乱者，未之有也。君子务本，本立而道生。孝弟也者，其为仁之本与！<br>钱穆：有子说：“若其人是一个孝弟之人，而会存心喜好犯上的，那必很少了。若其人不喜好犯上，而好作乱的，就更不会有了。君子专力在事情的根本处，根本建立起，道就由此而生了。孝弟该是仁道的根本吧？”</li></ol><h1 id="六十八句"><a href="#六十八句" class="headerlink" title="六十八句"></a>六十八句</h1><ol start="68"><li>孟懿子问孝。子曰：“无违”。樊迟御，子告之曰：“孟孙问孝於我，我对曰，”无违。””樊迟曰：“何谓也？”子曰：“生，事之以礼；死，葬之以礼，祭之以礼。”</li></ol><p>缠中说禅白话直译<br>孟懿子问孝。子曰：“无违”。樊迟御，子告之曰：“孟孙问孝於我，我对曰，”无违。””樊迟曰：“何谓也？”子曰：“生，事之以礼；死，葬之以礼，祭之以礼。”<br>孟懿子问孝。孔子说：“不要离开。”樊迟替孔子赶车，孔子对他说：“孟孙向我问孝，我回答说：“不要离开”。”樊迟说：“什么意思？”孔子道：“父母在世，用社会当下约定俗成的规范去侍奉他们；父母去世，用社会当下约定俗成的规范去安葬、祭祀他们。”</p><h1 id="第六十九句"><a href="#第六十九句" class="headerlink" title="第六十九句"></a>第六十九句</h1><ol start="69"><li>子游问孝。子曰：“今之孝者，是谓能养。至於犬马，皆能有养；不敬，何以别乎。”</li></ol><p>缠中说禅白话直译<br>子游问孝。子曰：“今之孝者，是谓能养。至於犬马，皆能有养；不敬，何以别乎。”<br>子游问孝。孔子说：“能养父母就被认为是现在的孝了。甚至狗和马，都会有人养；如果内心不敬，又用什么来区别这两者？”</p><h1 id="第七十句"><a href="#第七十句" class="headerlink" title="第七十句"></a>第七十句</h1><ol start="70"><li>孟武伯问孝。子曰：“父母唯其疾之忧。”</li></ol><p>缠中说禅白话直译<br>孟武伯问孝。子曰：“父母唯其疾之忧。”<br>孟武伯问孝，孔子说：“（孝就是）纵使自己生病也担忧父母的那种当下产生的感情。”</p><h1 id="第七十一句"><a href="#第七十一句" class="headerlink" title="第七十一句"></a>第七十一句</h1><ol start="71"><li>子夏问孝。子曰：色难。有事，弟子服其劳；有酒食，先生馔，曾是以为孝乎？<br>缠中说禅白话直译<br>子夏问孝。子曰：色难。有事，弟子服其劳；有酒食，先生馔，曾是以为孝乎？<br>子夏问孝，孔子说：“有事故，让年轻人负担其中的烦劳；有酒食，让年长者吃喝；但如果这些行为不是发自当下的情感，只是由于一种道德规范的力量，内心不情愿甚至在外显露出脸色为难，那么，难道就能把这种行为当成孝吗？</li></ol><h1 id="第七十二句"><a href="#第七十二句" class="headerlink" title="第七十二句"></a>第七十二句</h1><ol start="72"><li>子曰：父母在，不远游，游必有方。</li></ol><p>缠中说禅白话直译<br>子曰：父母在，不远游，游必有方。<br>孔子说：“当父母健在时，即使是游学也不能到偏远险恶之地，否则一定招致旁人或命运的诅咒。”</p><h1 id="第七十三句"><a href="#第七十三句" class="headerlink" title="第七十三句"></a>第七十三句</h1><ol start="73"><li>子曰：父母之年，不可不知也。一则以喜，一则以惧。</li></ol><p>缠中说禅白话直译<br>子曰：父母之年，不可不知也。一则以喜，一则以惧。<br>孔子说：“父母的年龄、生日等，不能不常常挂念以至能脱口而出。这种当下的情感，一方面带着欢喜，一方面带着忧惧，悲欣交集。</p><h1 id="第七十四句"><a href="#第七十四句" class="headerlink" title="第七十四句"></a>第七十四句</h1><ol start="74"><li>子曰：君子喻於义，小人喻於利。</li></ol><p>缠中说禅白话直译<br>子曰：君子喻於义，小人喻於利。<br>孔子说：“君子被各种现实社会结构以及对应的各种道德、法度等规范的关系之网中蕴藏的力量所开导，小人被利益、利害关系所组成的现实社会结构以及其对应的一套现实运行机制的关系之网中蕴藏的力量所开导。”</p><h1 id="第七十五句"><a href="#第七十五句" class="headerlink" title="第七十五句"></a>第七十五句</h1><ol start="75"><li>子曰：君子周而不比，小人比而不周。</li></ol><p>缠中说禅白话直译<br>子曰：君子周而不比，小人比而不周。<br>孔子说：君子，见闻学行周遍而没有疏漏，却不会让别人和自己步调一致、比肩而行；小人，让别人和自己步调一致、比肩而行，见闻学行却不能周遍而没有疏漏。</p><h1 id="第七十六句"><a href="#第七十六句" class="headerlink" title="第七十六句"></a>第七十六句</h1><ol start="76"><li>子曰：君子和而不同；小人同而不和。</li></ol><p>缠中说禅白话直译<br>子曰：君子和而不同；小人同而不和。<br>孔子说：君子相应而不聚集，小人聚集而不相应。</p><h1 id="第七十七句"><a href="#第七十七句" class="headerlink" title="第七十七句"></a>第七十七句</h1><ol start="77"><li>子曰：君子成，人之美；不成，人之恶。小人反是。</li></ol><p>缠中说禅白话直译<br>子曰：君子成，人之美；不成，人之恶。小人反是。<br>孔子说：人不断滋生美德，君子成就；人不断滋生恶行，君子不成。小人的成就与此相反。</p><h1 id="第七十八句"><a href="#第七十八句" class="headerlink" title="第七十八句"></a>第七十八句</h1><ol start="78"><li>子曰：君子之於天下也，无适也，无莫也，义之於比。</li></ol><p>缠中说禅白话直译<br>子曰：君子之於天下也，无适也，无莫也，义之於比。<br>孔子说：君子对于天下的一切，没有行为的归向，也没有思想的向往，甚至可以让自己的容貌呈现出小人的“比“相。</p>]]></content>
    
    
    
    <tags>
      
      <tag>句子</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔6</title>
    <link href="/2024/04/10/ganwu6/"/>
    <url>/2024/04/10/ganwu6/</url>
    
    <content type="html"><![CDATA[<h1 id="自我成长就是自己塑造自己的过程，要克服自己行为习惯中的不良之处。要把自己应该做的做了，先痛苦后享受，不要先享受后痛苦。"><a href="#自我成长就是自己塑造自己的过程，要克服自己行为习惯中的不良之处。要把自己应该做的做了，先痛苦后享受，不要先享受后痛苦。" class="headerlink" title="自我成长就是自己塑造自己的过程，要克服自己行为习惯中的不良之处。要把自己应该做的做了，先痛苦后享受，不要先享受后痛苦。"></a>自我成长就是自己塑造自己的过程，要克服自己行为习惯中的不良之处。要把自己应该做的做了，先痛苦后享受，不要先享受后痛苦。</h1><h1 id="“道也者，不可须臾离也；可离，非道也。是故君子戒慎乎其所不睹，恐惧乎其所不闻。莫见乎隐，莫显乎微，故君子慎其独也”。"><a href="#“道也者，不可须臾离也；可离，非道也。是故君子戒慎乎其所不睹，恐惧乎其所不闻。莫见乎隐，莫显乎微，故君子慎其独也”。" class="headerlink" title="“道也者，不可须臾离也；可离，非道也。是故君子戒慎乎其所不睹，恐惧乎其所不闻。莫见乎隐，莫显乎微，故君子慎其独也”。"></a>“道也者，不可须臾离也；可离，非道也。是故君子戒慎乎其所不睹，恐惧乎其所不闻。莫见乎隐，莫显乎微，故君子慎其独也”。</h1><p>君子慎独，自己一个人独处时也要保持着德行。控制自己的贪，嗔、痴、慢、疑。活着挺难的，做人是难的。</p><h1 id="情绪的波动让我看不清事情的全貌，要尽力避免情绪的影响。"><a href="#情绪的波动让我看不清事情的全貌，要尽力避免情绪的影响。" class="headerlink" title="情绪的波动让我看不清事情的全貌，要尽力避免情绪的影响。"></a>情绪的波动让我看不清事情的全貌，要尽力避免情绪的影响。</h1>]]></content>
    
    
    
    <tags>
      
      <tag>感悟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔5</title>
    <link href="/2024/04/08/ganwu5/"/>
    <url>/2024/04/08/ganwu5/</url>
    
    <content type="html"><![CDATA[<h1 id="活着需要的能力"><a href="#活着需要的能力" class="headerlink" title="活着需要的能力"></a>活着需要的能力</h1><h2 id="基本生存能力"><a href="#基本生存能力" class="headerlink" title="基本生存能力"></a>基本生存能力</h2><p>1.自我安全保障能力<br>2.基础急救<br>3.基本生存<br>4.方位感</p><h2 id="基础工作能力"><a href="#基础工作能力" class="headerlink" title="基础工作能力"></a>基础工作能力</h2><p>1.制作个人简历<br>2.时间管理能力-如何使用日历和计划清单<br>3.基础写作<br>4.公众讲话<br>5.有效沟通<br>6.基础电脑操作技术<br>7.基础的媒体和文档管理能力<br>8.OFFICE的应用能力<br>9.研究和探索能力</p><h2 id="家务处理能力"><a href="#家务处理能力" class="headerlink" title="家务处理能力"></a>家务处理能力</h2><p>1.如何打扫卫生<br>2.基础烹饪能力<br>3.基础家装修理能力</p><h2 id="财务管理能力"><a href="#财务管理能力" class="headerlink" title="财务管理能力"></a>财务管理能力</h2><p>1.制作家庭预算<br>2.制作家庭账本<br>3.基本投资能力<br>4.基本谈判能力</p><h2 id="自我认知能力"><a href="#自我认知能力" class="headerlink" title="自我认知能力"></a>自我认知能力</h2><p>1.搞清楚自己的使命、方向和人生目标的能力<br>2.平衡生活的能力<br>3.探索并清晰自己的价值观系统<br>4.管理自己情绪的能力</p><h2 id="人际沟通能力"><a href="#人际沟通能力" class="headerlink" title="人际沟通能力"></a>人际沟通能力</h2><p>1.基本礼节常识<br>2.幽默感<br>3.亲密关系的沟通和爱的能力<br>4.表达和赞赏<br>5.接受批评的能力</p><h2 id="思维认知能力"><a href="#思维认知能力" class="headerlink" title="思维认知能力"></a>思维认知能力</h2><p>1.批判性思维（本质思考）<br>2.整合思维能力（迁移思考）<br>3.解决问题能力<br>4.自我控制能力（安排规律的生活作息）<br>5.养生的能力</p>]]></content>
    
    
    
    <tags>
      
      <tag>感悟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔4</title>
    <link href="/2024/04/07/ganwu3/"/>
    <url>/2024/04/07/ganwu3/</url>
    
    <content type="html"><![CDATA[<h1 id="王国维先生曾在《人间词话》中写到对人生三重境界的感悟："><a href="#王国维先生曾在《人间词话》中写到对人生三重境界的感悟：" class="headerlink" title="王国维先生曾在《人间词话》中写到对人生三重境界的感悟："></a>王国维先生曾在《人间词话》中写到对人生三重境界的感悟：</h1><p>“古今成大事业、大学问者，必经过三种境界。‘昨夜西风凋碧树，独上高楼，望尽天涯路’，此第一境界；‘衣带渐宽终不悔，为伊消得人憔悴’，此第二境界；‘众里寻他千百度，蓦然回首，那人却在，灯火阑珊处’，此第三境界。”</p><h2 id="第一境界：“昨夜西风凋碧树。独上高楼，望尽天涯路。”出自北宋晏殊《蝶恋花·槛菊愁烟兰泣露》"><a href="#第一境界：“昨夜西风凋碧树。独上高楼，望尽天涯路。”出自北宋晏殊《蝶恋花·槛菊愁烟兰泣露》" class="headerlink" title="第一境界：“昨夜西风凋碧树。独上高楼，望尽天涯路。”出自北宋晏殊《蝶恋花·槛菊愁烟兰泣露》"></a>第一境界：“昨夜西风凋碧树。独上高楼，望尽天涯路。”出自北宋晏殊《蝶恋花·槛菊愁烟兰泣露》</h2><p>在西风的狂吹下，枝繁叶茂的绿树也开始凋谢了，表示形式非常危急，环境十分恶劣，在这种状态下作者夜不成眠，辗转反侧，为自己前途命运无比担忧，但他并没有丧失信心，因此颓废，而是想要努力克服困难，力求上进，争取找到自己的前进方向。于是，作者愤然起身，独上高楼，高瞻远瞩，想要望尽天涯海角，找到前进的路。在这一境界中，可以看做人涉世不久，对人生的无比迷茫，正如现在刚毕业的大学生。但是在迷茫中有多少人因此而坠入歧途，自暴自弃，人生路漫漫，我们也应该上下而求索。正如鲁迅先生所说的一句话：“世界上本没有路，走的人多了，也便成了路”</p><p>注：走出自己的路，见路不走，实事求是。（2024&#x2F;5&#x2F;3）</p><h2 id="第二境界：“衣带渐宽终不悔，为伊消得人憔悴。”出自北宋柳永《蝶恋花·伫倚危楼风细细》："><a href="#第二境界：“衣带渐宽终不悔，为伊消得人憔悴。”出自北宋柳永《蝶恋花·伫倚危楼风细细》：" class="headerlink" title="第二境界：“衣带渐宽终不悔，为伊消得人憔悴。”出自北宋柳永《蝶恋花·伫倚危楼风细细》："></a>第二境界：“衣带渐宽终不悔，为伊消得人憔悴。”出自北宋柳永《蝶恋花·伫倚危楼风细细》：</h2><p>柳永如此艳丽之词，也被王国维拿来说明学问之事。诗人所忧之事，是“相思”，但相思到如此地步，我只有柳永能做到了，可见柳永真是一个重情之人。联系到人生，做一件事能专一到这种地步，不成功都难。继第一阶段的迷茫之后，在这一阶段中便有了目标了，在追逐目标的过程中，必然会遇到许多的困难，而我们要做的就是像柳永想念女子一样，即使被折磨得瘦骨伶仃，形容憔悴，我始终不放弃自己的目标，一往直前。</p><h2 id="第三境界：“众里寻他千百度。蓦然回首，那人却在灯火阑珊处。”-出自南宋辛弃疾《青玉案·元夕》"><a href="#第三境界：“众里寻他千百度。蓦然回首，那人却在灯火阑珊处。”-出自南宋辛弃疾《青玉案·元夕》" class="headerlink" title="第三境界：“众里寻他千百度。蓦然回首，那人却在灯火阑珊处。” 出自南宋辛弃疾《青玉案·元夕》"></a>第三境界：“众里寻他千百度。蓦然回首，那人却在灯火阑珊处。” 出自南宋辛弃疾《青玉案·元夕》</h2><p>寻觅了千百次，却在无意间看到那人在灯火阑珊处。在苦苦追寻，历经磨难之后，总算看到惊喜了，之前的付出都有了回报。在人生的旅途中，在追求成功的路上，我们时常会陷入迷茫、困惑、苦恼中，甚至怀疑自己有没有选错目标，还该不该坚持下去，这些都很正常的，毕竟成功哪有那么容易呢？在这场旅途中，必定有很多人中途放弃，马云有句话说得好：“今天很残酷，明天更残酷，后天很美好，但大多数人都死在明天晚上，真正的英雄才能见到后天的太阳。”成功总是不经意间到来，这是一个人历尽千帆之后上天赐予的惊喜。这个惊喜有时来的很晚，但只要我们一直坚持，他迟早是要来的。</p>]]></content>
    
    
    
    <tags>
      
      <tag>感悟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔3</title>
    <link href="/2024/04/06/ganwu2/"/>
    <url>/2024/04/06/ganwu2/</url>
    
    <content type="html"><![CDATA[<h1 id="学习最重要的是什么？"><a href="#学习最重要的是什么？" class="headerlink" title="学习最重要的是什么？"></a>学习最重要的是什么？</h1><p>清醒，知道自己在做什么？ 即明白此时此刻到底在做什么。这一刻我在干什么？正在解决什么问题？这一天我学到了什么东西？取得了什么进步？不断回答这些问题的过程就是不断给予大脑正反馈的过程。时时刻刻用收获刺激大脑是学习上瘾和长时间专注学习的秘诀。</p><h1 id="什么在阻挡我进步？"><a href="#什么在阻挡我进步？" class="headerlink" title="什么在阻挡我进步？"></a>什么在阻挡我进步？</h1><p>我自己，我自己的思维在阻挡我的进步。为什么我在刷手机，看视频时不会觉得无聊，在放下手机后，反而觉得我聊了。这样当再次拿起手机时才会解决。我不喜欢这样没有掌控感的感觉，这样的感觉是矛盾的。这样的矛盾怎么来的勒？大脑中的思维和自我的觉知的意识之间的矛盾，怎么化解这种矛盾，我认为的解决方法是清楚自己在干嘛，清楚自己此时此刻在干嘛。建立一个观察者来观察自己。</p><h1 id="我为什么会刷手机？"><a href="#我为什么会刷手机？" class="headerlink" title="我为什么会刷手机？"></a>我为什么会刷手机？</h1><p>我为什么会刷手机，是因为我觉得无聊。我为什么觉得无聊？是因为没有事情可以做，或者是有些事情做了看不到效果，没有刷手机那样即时的奖励感。但是刷手机的过程中的信息是我不喜欢的，这些信息太单一，太主观（酒色财气，好色、贪财、逞气，为人生四戒），很不幸这些都有，当然也有好的，但是需要我去花时间去寻找。这也是一个麻烦事。回到怎么解决刷手机这件事，拿回对做事情的掌控感，明白自己现在在干嘛。就这样简单。</p><h1 id="阐述一下上瘾机制"><a href="#阐述一下上瘾机制" class="headerlink" title="阐述一下上瘾机制"></a>阐述一下上瘾机制</h1><p>上瘾的机理与多巴胺有关，并且随着上瘾行为的次数增多，大脑中的对与多巴胺的神经受体的敏感程度会下降，进而导致要想获取与之前相同的快感，就需要付出更多或更具有刺激性的行为来刺激多巴胺的生成。理论依据，行为和感觉是一体的，感觉会影响行为，行为会影响感觉，但是使用行为去影响感觉是更有理智的。第二点，失乐园理论，按照上述的描述，随着大脑中多巴胺快感产生的受体的敏感性下降，要想获得与之前相同的快感，需要付出的行为会更多，但是这样总会有个上限，导致人在做不出要产生多巴胺的行为时，就会陷入失乐园状态。第三点，痛苦和快感需要平衡，当我感觉痛苦时我需要快乐（多巴胺）来平衡，当我感到快乐时，快乐完成后会产生空虚（痛苦）来平衡快乐。</p>]]></content>
    
    
    
    <tags>
      
      <tag>感悟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔2</title>
    <link href="/2024/04/05/ganwu0/"/>
    <url>/2024/04/05/ganwu0/</url>
    
    <content type="html"><![CDATA[<h1 id="怎么能做好一件事？"><a href="#怎么能做好一件事？" class="headerlink" title="怎么能做好一件事？"></a>怎么能做好一件事？</h1><p>做事，我将其解释为使用自己的方式去实现自己的想法。一个足以支撑去做这件事的动机，加上没有复杂的情绪影响，持之以恒的勤奋，那我觉得这件事的成功概率会大大的加强。一点点自己给自己的意义加上不要脑子的勤奋就可以成事了。为什么说不要脑子，因为带上脑子就会产生情绪，有了情绪就会产生内耗，当然对待情绪要辩证的看待，但是在做事初期一定不要带有情绪，在后面做这件事有一定积累后，就可以带上脑子了。<br>这里需要说明一点的是，成功是一个随机事件，不是必然事件。任何人做任何事情，都不能百分之百的把握成功。但是所有人都可以做一件事情，那就是持之以恒的勤奋，去提升成功的概率。知易行难，从小事做起，不断改变，积少成多。这是一个很重要的思维方法。</p><h1 id="心法、法则、技术之间的关系。"><a href="#心法、法则、技术之间的关系。" class="headerlink" title="心法、法则、技术之间的关系。"></a>心法、法则、技术之间的关系。</h1><p>心法胜于法则，法则胜于技术（方法）。<br>所谓技术，比如说使用进步本的技术来操作管理各个学科的知识，知识会遗忘，技术则能熟能生巧，历久弥新。<br>所谓法则，例如学习过程中唯一不变的目的就是进步，认识到这个法则之后所开发的技术都是为了这个法则服务的。世界上没有普世的方法，却有普世的法则。比如要把一件事做好，就要不断学习，不断学习的目的是不断进步，进而能把事情做的更好。<br>所谓心法，是指人对生命、对世界的基本态度和根本认知。例如，“自胜者强”，给强者下了定义，不胜别人，只胜自己的人是强者，战胜自己内心的情绪，内心的恐惧，控制自己不再内耗的人是强者。以自胜者强的定义去看待别人和自己，自然形成心态，进而形成心法。自胜者强包含了学习进步的法则，但是学习进步的法则取不涵盖自胜者强。</p><h1 id="我该怎么才能做好一件事。"><a href="#我该怎么才能做好一件事。" class="headerlink" title="我该怎么才能做好一件事。"></a>我该怎么才能做好一件事。</h1><p>注意这里的主语是我，我该怎么才能做好一件事？ 那就是不要带着情绪去做一件事，带着脑子去做这件事就行了，凡事想多了，就做不成了。<br>不要急躁，慢慢来才最快。不要傲慢，不要觉得这个太简单就不去做，认识是要不断重复的。<br>要早睡早起，11点之前睡觉，在早上7点起床就是一件很容易的一件事。但是要是在11点之后睡觉，要在早上7点起床就不是那么一件容易的事情了。<br>不要给自己增加烦劳，世上本无事，庸人自扰之。<br>要给自己制定一个计划，在本子上写上自己要做的事情。（这点我确实没有做好，目前来讲，我都是随性而为。）<br>不要在做的过程中去看距离结果还有多远，不要和别人分享自己的喜悦，万一没有成功岂不是很尴尬。生命是一修行。<br>勤奋，不要让事情来裹挟着你，而是让我去驱赶着事情。生命是场旅行，我可以当过过客，也可以成为风景中的一部分。<br>体验是最重要的，体验自己的喜悦，体验自己的悲伤，体验自己的失落，体验自己的愉悦。活在当下，不要考虑过去和未来。<br>不要在乎结果，做好当下的事情，现在的事情做好了，结果不会太差。听天命，尽人事。<br>内心的法则和社会的法则不同，甚至相反，但是我可以使用心法来统领。内圣外王，或许先要内圣，而后外王。<br>决心来自一个明确的、具体的理由。记住是一个理由，唯一的理由，不是许多理由。</p><p>2024&#x2F;5&#x2F;3<br>注：条件，前提，因由，不同条件产生不同的表象，但是背后却有相同的本质。冰、雪、雾、霜、露。</p>]]></content>
    
    
    
    <tags>
      
      <tag>感悟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一点小确幸</title>
    <link href="/2024/04/04/tupian/"/>
    <url>/2024/04/04/tupian/</url>
    
    <content type="html"><![CDATA[<h1 id="这里是图片"><a href="#这里是图片" class="headerlink" title="这里是图片"></a>这里是图片</h1><h2 id="清晨的树"><a href="#清晨的树" class="headerlink" title="清晨的树"></a>清晨的树</h2><p><img src="/pic/79f388cc7d53668d55773baf30bb10c.jpg"></p><h2 id="早晨的红日"><a href="#早晨的红日" class="headerlink" title="早晨的红日"></a>早晨的红日</h2><p><img src="/pic/2.jpg"></p><h2 id="一个不知名的地方"><a href="#一个不知名的地方" class="headerlink" title="一个不知名的地方"></a>一个不知名的地方</h2><p><img src="/pic/l2.jpg"></p><h2 id="图书馆"><a href="#图书馆" class="headerlink" title="图书馆"></a>图书馆</h2><p><img src="/pic/jc1.jpg"></p><h2 id="好看的壁纸"><a href="#好看的壁纸" class="headerlink" title="好看的壁纸"></a>好看的壁纸</h2><p><img src="/pic/3.jpg"><br><img src="/pic/3.png"><br><img src="/pic/v2-3a1fb23e19b2448033a9b7333941f465_r.png"></p>]]></content>
    
    
    
    <tags>
      
      <tag>图片</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔</title>
    <link href="/2024/04/04/ganwu1/"/>
    <url>/2024/04/04/ganwu1/</url>
    
    <content type="html"><![CDATA[<h1 id="随笔"><a href="#随笔" class="headerlink" title="随笔"></a>随笔</h1><h2 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h2><p>为什么要写下这篇随笔，最近经常上网，突然觉得什么都不真实，所以我决定写下一些我觉得真实的想法。并且决定这段时间先不上网看他人的对于这个世界的解释，太嘈杂了。先看看书，集百家之言，成一家之说。先把自己的世界观，人生观，价值观建立完成，才能更好的和人交流，辩论。</p><p>  见相非相，即见如来</p><p>很多时候，我们这个世界的认识是荒谬到极点而不自知的。人是立场的，好恶的，我们总是只相信自己愿意相信的东西。我们习惯于先形成观点，然后再寻找既有立场的正面证据，在不知不觉中偏离真实。改变总是很难的，一点点的进步总是让我感到欢喜的。每个人的生命中都隐含着一颗觉知的种子，一旦唤醒，便势不可挡，在追求真知、真实的路上一去不反。</p><p>世界是真实的，世界就是那样，但是世界的解释权却不再世界本身，而在于我们。解释权归我们所有，对世界的解释的方法造就了不同的人，并且我们对世界的解释的方式会受到各种各样的影响，正确的，错误的，客观的，主观的。不同的解释方式产生不同的行为，不同的行为会造成不同的结果，造成的结果无论好坏都要受着，这是因果，不可能逃脱。</p><p>最近觉得网络的东西太过于无聊，各种各样的信息，不同立场的人，不同角度的人。热爱生活的，厌世嫉俗的。不同境遇的，充满选择的人和没有选择的人。世界就是这么的参差不齐。回到自我本身，我该怎么去解释这个世界。最近读马克思，实事求是是必要的，实践是检验真理的唯一标准是必要的，与其去网络上看别人任何解释这个世界，不如自己拿起笔写下自己对世界的解释。别人的经验是只能参照的，</p><p>要有自我主动权，解放思想，我们要有敢于摸着石头过河的勇气。成功了，增长能力也有了经验；失败了，就有了一次知道错误出在哪儿的认识。不要高估自己的能力，不要傲慢。人都有一个通病：说到别人的时候，就是这也不行，那也不行；而说到自己的时候，就有一种世外高人的感觉。平庸来自傲慢，如果人人生而伟大，如果每个人本来都是生命的奇迹。那么，傲慢毁掉了多少人？<br>成功的经验可以借鉴但是不可以复制，“见路不走”是不唯经验教条。成功的经验我们一般不能复制，因为那个经验发生的条件已成过去式，现在的条件只符合现在时。众生总是看到事物的各种表相而偏离本质，要见，见自本性，向内求解，以自己的觉性来看待事物。大家都是人，别人能做到的我也能做到。事实不是这样的，别人能做到的我不一定能做到，‘都是人’只是其中的一个条件，只有我具备了别人能做到的全部条件，我才可能做到，而事实上我很难悉数复制别人的条件，只有根据我的条件去做我能做到的，才是不脱离实际的。<br>对人必须有理有节，对己则可自由豁达。小到个人，家庭，大到国家，社会，自由都是有前提的；不同的人有不同的自由。</p><p>认识是慢慢的认识的，不可能突然从小学生到大学生的，这需要个过程。如果想要从小学生到大学生，这是不可能的。想可想之想，能可能之能。<br>关于认识我觉得实践论中的阐述是最好的，这里直接粘贴了，实践过程中，开始只是看到过程中各个事物的现象方面，看到各个事物的片面，看到各个事物之间的外部联系。例如有些外面的人们到延安来考察，头一二天，他们看到了延安的地形、街道、屋宇，接触了许多的人，参加了宴会、晚会和群众大会，听到了各种说话，看到了各种文件，这些就是事物的现象，事物的各个片面以及这些事物的外部联系。这叫做认识的感性阶段，就是感觉和印象的阶段。（认识的第一阶段）社会实践的继续，使人们在实践中引起感觉和印象的东西反复了多次，于是在人们的脑子里生起了一个认识过程中的突变（即飞跃），产生了概念。概念这种东西已经不是事物的现象，不是事物的各个片面，不是它们的外部联系，而是抓着了事物的本质，事物的全体，事物的内部联系了。《三国演义》上所谓“眉头一皱计上心来”，我们普通说话所谓“让我想一想”，就是人在脑子中运用概念以作判断和推理的工夫。这是认识的第二个阶段。<br>外来的考察团先生们在他们集合了各种材料，加上他们“想了一想”之后，他们就能够作出“共产党的抗日民族统一战线的政策是彻底的、诚恳的和真实的”这样一个判断了。在他们作出这个判断之后，如果他们对于团结救国也是真实的的话，那末他们就能够进一步作出这样的结论：“抗日民族统一战线是能够成功的。”这个概念、判断和推理的阶段，在人们对于一个事物的整个认识过程中是更重要的阶段，也就是理性认识的阶段。  认识的真正任务在于经过感觉而到达于思维，到达于逐步了解客观事物的内部矛盾，了解它的规律性，了解这一过程和那一过程间的内部联系，即到达于论理的认识。<br>在低级阶段，认识表现为感性的，在高级阶段，认识表现为论理的，但任何阶段，都是统一的认识过程中的阶段。感性和理性二者的性质不同，但又不是互相分离的，它们在实践的基础上统一起来了。</p><p>关于做事（做事也是认识的范畴），也是这样，慢慢来才最快。这里同样copy实践论中的内容。<br>常常听到一些同志在不能勇敢接受工作任务时说出来的一句话：没有把握。为什么没有把握呢？<br>因为他对于这项工作的内容和环境没有规律性的了解，或者他从来就没有接触过这类工作，或者接触得不多，因而无从谈到这类工作的规律性。及至把工作的情况和环境给以详细分析之后，他就觉得比较地有了把握，愿意去做这项工作。如果这个人在这项工作中经过了一个时期，他有了这项工作的经验了，而他又是一个肯虚心体察情况的人，不是一个主观地、片面地、表面地看问题的人，他就能够自己做出应该怎样进行工作的结论，他的工作勇气也就可以大大地提高了。只有那些主观地、片面地和表面地看问题的人，跑到一个地方，不问环境的情况，不看事情的全体（事情的历史和全部现状），也不触到事情的本质（事情的性质及此一事情和其他事情的内部联系），就自以为是地发号施令起来，这样的人是没有不跌交子的。<br>由此看来，认识的过程，第一步，是开始接触外界事情，属于感觉的阶段。第二步，是综合感觉的材料加以整理和改造，属于概念、判断和推理的阶段。只有感觉的材料十分丰富（不是零碎不全）和合于实际（不是错觉），才能根据这样的材料造出正确的概念和论理来。</p><p>实践是认识的来源，认识又可以变革实践。实践和认识的关系如同美和丑的关系，如同硬币的一体两面，是辩证的。通过实践而发现真理，又通过实践而证实真理和发展真理。从感性认识而能动地发展到理性认识，又从理性认识而能动地指导革命实践，改造主观世界和客观世界。实践、认识、再实践、再认识，这种形式，循环往复以至无穷，而实践和认识之每一循环的内容，都比较地进到了高一级的程度。这就是辩证唯物论的全部认识论，这就是辩证唯物论的知行统一观。</p><p>所以我的想法是，自己去实践，去认识，而不是去把他人带有主观的解释当作自己的解释，我不愿意吃别人的口水，关于这个世界我要亲自去尝一尝，去变革一下。</p><h2 id="注文"><a href="#注文" class="headerlink" title="注文"></a>注文</h2><p>注： 2024&#x2F;4&#x2F;30,又一次修改，不上网是真的难（哈哈哈哈）。<br>我看书的最终目的是集成百家之言，成一家之说，以自己的见解和实践去解释这个世界，改造这个世界。</p><p>认识论指出，成功秘诀就是坚持不懈。成功有时不需要精明，更依赖坚持，稳重坚守就是成功。不断的进步，从感性认识到理性认识。<br>2024&#x2F;5&#x2F;2日修改<br>解释一下什么是世界观，价值观，人生观。</p><ol><li>世界观(亦称“宇宙观”)，通常是指人们对整个世界(即对自然界、社会和人的思维)的根本看法。世界观不同，表现为人们在认识和改造世界时的立场、观点和方法的不同。一个人世界观、人生观的改变是一种根本的改变。世界观的基本问题是精神与物质、思维与存在、主观与客观的关系问题。在实践的基础上，实事求是，解放思想，尊重客观规律，注重调查研究，不断总结经验，开动脑筋想问题、办事情。</li><li>人生观，是人们对人生问题的根本看法。主要内容是对人生目的、意义的认识和对人生的态度，具体包括公私观、义利观、苦乐观、荣辱观、幸福观和生死观等。人生观是人们在人生实践和生活环境中逐步形成的。</li><li>价值观，是人们对价值问题的根本看法，是人们在一定历史条件下经过反复实践逐渐形成的一种与人的主观需要相连的判断好坏、是非、利弊、善恶的观念。包括对价值的实质、构成、标准的认识，这些认识的不同，形成了人们不同的价值观。每个人都是在各自的价值观的引导下，形成不同的价值取向，追求着各自认为最有价值的东西。</li></ol><p>阐述一下三者关系<br>世界观是人生观和价值观的基础，世界观决定着人生观和价值观。作为对人生意义和目的的特定理解的人生观，以及作为主体设定其价值目标和行为取向的价值观，都要以一定世界观作为思想基础，并支配其人生思考和选择的表现形式。世界观、人生观、价值观虽然各有自己的特定内容，但三者是统一的，不可分割的。</p>]]></content>
    
    
    
    <tags>
      
      <tag>感悟</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>句子</title>
    <link href="/2024/04/02/juzhi0/"/>
    <url>/2024/04/02/juzhi0/</url>
    
    <content type="html"><![CDATA[<BR><h2 id="1"><a href="#1" class="headerlink" title="1"></a>1</h2><p>图难于其易，为大于其细。天下难事必作于易，天下大事必作于细。是以圣人终不为大，故能成其大。</p><h2 id="2"><a href="#2" class="headerlink" title="2"></a>2</h2><p>天有道，则无常道。事于道，则天有道看与事则无常，无常则明，明则通，则世事洞明。世事洞明则世事可治愈渐达佳境。</p><p>解释： 天如果真的有直指究竟的道，也肯定不是一直不变的道。做事依照着前人经验，则“道”看似有规律可循，其实世事无常没有相同一件事，懂得无常的道理就能把事情看清楚，把事情看清楚了就能做到通达。明白世事无常，才能看清一切事物“无常”的本质，看清本质就能做到通达，通达则洞明世事。世事洞明，才可能治愈一切事。看透世事无常来去皆好的本质，人就能做到通达，通达则洞明世事。世事洞明，自然可以治愈一切事。人能够活成这样的通透，当然就没有任何挂碍，也就步入了人生最妙的佳境!</p><h2 id="3"><a href="#3" class="headerlink" title="3"></a>3</h2><p>夫君子之行，静以修身，俭以养德。非淡泊无以明志，非宁静无以致远。夫学须静也，才须学也，非学无以广才，非志无以成学。淫慢则不能励精，险躁则不能治性。年与时驰，意与日去，遂成枯落，多不接世，悲守穷庐，将复何及。</p><h2 id="4"><a href="#4" class="headerlink" title="4"></a>4</h2><p>为天地立心，为生民立命，为往圣继绝学，为万世开太平</p><p>（注：横渠四句教：第一句，为天地立心，这句话的前提是天地是没有心的，那什么有心，人有心？人有心之后，天地才有了心。人为天地所立的心称为道心，在认识论的层面去为天地所立心。人不知，人不相，人不愠。第二句，为生民立命，说人心，要帮助人构建价值观，要让人心基于正道，构建价值观。只有当一个人构建其了完备自洽的价值观，价值观得出了一个关于人生的终极价值判断，这个价值判断才叫做命，古时候叫“天命”，现在叫“使命”。有了使命我们才能用尽一生去追求，才不会犹豫不决，才不会彷徨不前，才能够“虽千万人吾往矣”。第三局，“为往圣继绝学”，说的是要学习之前的知识，要不断打磨之间的价值观，不断迭代这个时代的价值观。“苟日新，又日新，日日新”。第四句，为万世开太平，怎么才能为万世开太平？哲学家们只是用不用的方式解释世界,问题在于改变世界，实践，理论联系实践，中国的经典从来都是强调实践的，允执厥中”，也就是“中庸”，什么叫“中庸”？“中”的标准就是“仁”，“庸”则是“用”，是时时刻刻、千秋万世的“中用”，不实践怎么能中用呢？所以孔子说“游于艺”，不但要具备付诸实践的才能，还要在领域内追求极致，做到“游”，也就是“游刃有余”。唯有如此，才是“君子不器（而无不器）”，才能做到“无为而无不为”，才能“为万世开太平”。探讨自然与社会的基本规律，为民众摸索出一条共同遵行的大道，继承优良的传统文化，为后世开辟永久太平的基业。概括而言，就是探索精神，担当精神，奉献精神，使命精神。很高大上吗？不，这只是读书人本分而已。）</p><h2 id="5"><a href="#5" class="headerlink" title="5"></a>5</h2><p>真正的理性从来都是当下的，从来都是实践的，而实践，从来都是当下的理性。</p><h2 id="6"><a href="#6" class="headerlink" title="6"></a>6</h2><p>这是一个纷纷扰扰的滚滚红尘，众生沉迷而不求解脱，驱使着尘世中的我们有时也不得不加入其中滚一下；这是一个没有方向的名利场，大家每个人都有自己的执念，且价值观单一，在单一的价值观之下，为了同一个东西，大家便如丛林法则中的生物一样，让名利场成为一个绞肉机。</p><p>注：人总是要死亡的，生命的起点到终点，生命又有生命意义。这个过程就是意义，死亡是告诉我生命的意义就是感受过程，不用太多的去忧愁什么，天下本无事，庸人自扰之。 </p><p>焦虑，欲望，犹豫，焦虑对未来事件的过度担忧和恐慌，对未来的迷茫和没信心。怎么解决这个问题，感受过程，活在当下，专注于眼前的事，不必胡思乱想。静坐，或许是一种回归当下，摆脱头脑中的忧虑的方法。<br>欲望是有好坏之分的，好的欲望能帮我们正向成长，但是不好的欲望却是阻碍成长的绊脚石。要想破除欲望之贼，就要学会舍弃。舍弃不是失去，而是另一种获得。不要害怕舍弃，舍弃一件事物的终点和获得另一件事物的起点重合于一点。<br>犹豫，面对事情犹豫不决是一种很常见的现象。在决心做事时；就立刻去做，不要考虑事情的结果。做事的过程中不断磨砺自己，在事情中做到不以物喜，不以己悲。感受过程中的快乐，这样自然不会害怕因为选择错误而带来的失败。<br>“ 坐中静，破焦虑之贼；舍中得，破欲望之贼；事上练，破犹豫之贼，三贼皆破，则万事可成。”</p><p>长寿秘诀就是生活规律；成功秘诀就是坚持不懈。成功有时不需要精明，更依赖坚持，稳重坚守就是成功。）</p>]]></content>
    
    
    
    <tags>
      
      <tag>句子</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2024/04/02/hello-world/"/>
    <url>/2024/04/02/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span> <br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
